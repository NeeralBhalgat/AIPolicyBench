[
  {
    "id": "Americas-AI-Action-Plan_chunk_0",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nWinning the Race AMERICA’S AI ACTION PLAN JULY 2025 THE WHITE HOUSE AMERICA ’S AI ACTION PLAN i “Today, a new frontier of scientific discovery lies before us, defined by transformative technologies such as artificial intelligence… Breakthroughs in these fields have the potential to reshape the global balance of power, spark entirely new industries, and revolutionize the way we live and work. As our global competitors race to exploit these technologies, it is a national security imperative for the United States to achieve and maintain unquestioned and unchallenged global technological dominance. To secure our future, we must harness the full power of American innovation.” Donald J. Trump 45th and 47th President of the United States AMERICA ’S AI ACTION PLAN ii Table of Contents Introduction ................................ ................................ ................................ .............................. 1 Pillar I: Accelerate AI Innovation ................................ ................................ .............................. 3 Remove Red Tape and Onerous Regulation .................................................................................... 3 Ensure that Frontier AI Protects Free Speech and American Values ......................................... 4 Encourage Open -Source and Open -Weight AI ............................................................................."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_1",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\n45th and 47th President of the United States AMERICA ’S AI ACTION PLAN ii Table of Contents Introduction ................................ ................................ ................................ .............................. 1 Pillar I: Accelerate AI Innovation ................................ ................................ .............................. 3 Remove Red Tape and Onerous Regulation .................................................................................... 3 Ensure that Frontier AI Protects Free Speech and American Values ......................................... 4 Encourage Open -Source and Open -Weight AI ............................................................................. 4 Enable AI Adoption ............................................................................................................................... 5 Empower American Workers in the Age of AI ................................................................................. 6 Support Next -Generation Manufacturing ....................................................................................... 7 Invest in AI -Enabled Science .............................................................................................................. 8 Build World -Class Scientific Datasets .............................................................................................."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_2",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nand Onerous Regulation .................................................................................... 3 Ensure that Frontier AI Protects Free Speech and American Values ......................................... 4 Encourage Open -Source and Open -Weight AI ............................................................................. 4 Enable AI Adoption ............................................................................................................................... 5 Empower American Workers in the Age of AI ................................................................................. 6 Support Next -Generation Manufacturing ....................................................................................... 7 Invest in AI -Enabled Science .............................................................................................................. 8 Build World -Class Scientific Datasets .............................................................................................. 8 Advance the Science of AI ................................................................................................................... 9 Invest in AI Interpretability, Control, and Robustness Breakthroughs ........................................ 9 Build an AI Evaluations Ecosystem .................................................................................................."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_3",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\n............................................................................. 4 Enable AI Adoption ............................................................................................................................... 5 Empower American Workers in the Age of AI ................................................................................. 6 Support Next -Generation Manufacturing ....................................................................................... 7 Invest in AI -Enabled Science .............................................................................................................. 8 Build World -Class Scientific Datasets .............................................................................................. 8 Advance the Science of AI ................................................................................................................... 9 Invest in AI Interpretability, Control, and Robustness Breakthroughs ........................................ 9 Build an AI Evaluations Ecosystem .................................................................................................. 10 Accelerate AI Adoption in Government ......................................................................................... 10 Drive Adoption of AI within the Department of Defense ............................................................."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_4",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nNext -Generation Manufacturing ....................................................................................... 7 Invest in AI -Enabled Science .............................................................................................................. 8 Build World -Class Scientific Datasets .............................................................................................. 8 Advance the Science of AI ................................................................................................................... 9 Invest in AI Interpretability, Control, and Robustness Breakthroughs ........................................ 9 Build an AI Evaluations Ecosystem .................................................................................................. 10 Accelerate AI Adoption in Government ......................................................................................... 10 Drive Adoption of AI within the Department of Defense ............................................................. 11 Protect Commercial and Government AI Innovations ................................................................. 12 Combat Synthetic Media in the Legal System .............................................................................. 12 Pillar II: Build American AI Infrastructure ................................ ................................ .............."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_5",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nin AI Interpretability, Control, and Robustness Breakthroughs ........................................ 9 Build an AI Evaluations Ecosystem .................................................................................................. 10 Accelerate AI Adoption in Government ......................................................................................... 10 Drive Adoption of AI within the Department of Defense ............................................................. 11 Protect Commercial and Government AI Innovations ................................................................. 12 Combat Synthetic Media in the Legal System .............................................................................. 12 Pillar II: Build American AI Infrastructure ................................ ................................ .............. 14 Create Streamlined Permitting for Data Centers, Semiconductor Manufacturing Facilities, and Energy Infrastructure while Guaranteeing Security ..................................... 14 Develop a Grid to Match the Pace of AI Innovation ...................................................................... 15 Restore American Semiconductor Manufacturing ...................................................................... 16 Build High -Security Data Centers for Military and Intelligence Community Usage .............."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_6",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nSystem .............................................................................. 12 Pillar II: Build American AI Infrastructure ................................ ................................ .............. 14 Create Streamlined Permitting for Data Centers, Semiconductor Manufacturing Facilities, and Energy Infrastructure while Guaranteeing Security ..................................... 14 Develop a Grid to Match the Pace of AI Innovation ...................................................................... 15 Restore American Semiconductor Manufacturing ...................................................................... 16 Build High -Security Data Centers for Military and Intelligence Community Usage .............. 16 Train a Skilled Workforce for AI Infrastructure .............................................................................. 17 Bolster Critical Infrastructure Cybersecurity ................................................................................. 18 Promote Secure -By-Design AI Technologies and Applications ............................................... 18 Promote Mature Federal Capacity for AI Incident Response ..................................................... 19 Pillar III: Lead in International AI Diplomacy and Security ................................ ................... 20 Export American AI to Allies and Partners ...................................................................................."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_7",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nand Intelligence Community Usage .............. 16 Train a Skilled Workforce for AI Infrastructure .............................................................................. 17 Bolster Critical Infrastructure Cybersecurity ................................................................................. 18 Promote Secure -By-Design AI Technologies and Applications ............................................... 18 Promote Mature Federal Capacity for AI Incident Response ..................................................... 19 Pillar III: Lead in International AI Diplomacy and Security ................................ ................... 20 Export American AI to Allies and Partners .................................................................................... 20 Counter Chinese Influence in International Governance Bodies .............................................. 20 Strengthen AI Compute Export Control Enforcement ............................................................... 21 Plug Loopholes in Existing Semiconductor Manufacturing Export Controls ......................... 21 Align Protection Measures Globally ................................................................................................ 21 Ensure that the U.S. Government is at the Forefront of Evaluating National Security Risks in Frontier Models ..............................................................................................................."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_8",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nExport American AI to Allies and Partners .................................................................................... 20 Counter Chinese Influence in International Governance Bodies .............................................. 20 Strengthen AI Compute Export Control Enforcement ............................................................... 21 Plug Loopholes in Existing Semiconductor Manufacturing Export Controls ......................... 21 Align Protection Measures Globally ................................................................................................ 21 Ensure that the U.S. Government is at the Forefront of Evaluating National Security Risks in Frontier Models ............................................................................................................... 22 Invest in Biosecurity ............................................................................................................................ 23 AMERICA ’S AI ACTION PLAN 1 Introduction The United States is in a race to achieve global dominance in artificial intelligence (AI). Whoever has the largest AI ecosystem will set global AI standards and reap broad economic and military benefits. Just like we won the space race, it is imperative that the United States and its allies win this race."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_9",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nAMERICA ’S AI ACTION PLAN 1 Introduction The United States is in a race to achieve global dominance in artificial intelligence (AI). Whoever has the largest AI ecosystem will set global AI standards and reap broad economic and military benefits. Just like we won the space race, it is imperative that the United States and its allies win this race. President Trump took decisive steps toward achieving this goal during his first days in office by signing Executive Order 14179, “Removing Barriers to American Leadership in Artificial Intelligence,” calling for America to retain dominance in this glob al race and directing the creation of an AI Action Plan.1 Winning the AI race will usher in a new golden age of human flourishing, economic competitiveness, and national security for the American people. A I will enable Americans to discover new materials, synthesize new chemicals, manufacture new drugs, and develop new methods to harness energy —an industrial revolution. It will enable radically new forms of education, media, and communication —an information revolution. And it will enable altogether new intellectual achievements: unraveling ancient scrolls once tho ught unreadable, making breakthroughs in scientific and mathematical theory, and creating new kinds of digital and physical art —a renaissance . An industrial revolution, an information revolution, and a renaissance —all at once. This is the potential that AI presents ."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_10",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nmedia, and communication —an information revolution. And it will enable altogether new intellectual achievements: unraveling ancient scrolls once tho ught unreadable, making breakthroughs in scientific and mathematical theory, and creating new kinds of digital and physical art —a renaissance . An industrial revolution, an information revolution, and a renaissance —all at once. This is the potential that AI presents . The opportunity that stands before us is both inspiring and humbling. And it is ours to seize, or to lose. America’s AI Action Plan has three pillar s: innovation, infrastructure, and international diplomacy and security . The U nited States needs to innovate faster and more comprehensively than our competitors in the development and distribution of new AI technology across every field, and dismantle unnecessary regulatory barriers that hinder the private sector in doing so. As Vice President Vance remarked at the Paris AI Action Summit in February, restricting AI development with onerous regulation “would not only unfairly benefit incumbents… it would mean paralyzing one of the most promising technologies we have seen in generations.” 2 That is why President Trump rescinded the Biden Administration’s dangerous actions on day one. We need to build and maintain vast AI infrastructure and the energy to power it. To do that, we will continue to reject radical climate dogma and bureaucratic red tape , as the Administration has done since Inauguration Day."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_11",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\ntechnologies we have seen in generations.” 2 That is why President Trump rescinded the Biden Administration’s dangerous actions on day one. We need to build and maintain vast AI infrastructure and the energy to power it. To do that, we will continue to reject radical climate dogma and bureaucratic red tape , as the Administration has done since Inauguration Day. Simply put, we need to “Build, Baby, Build!” We need to establish American AI —from our advanced semiconductors to our models to our applications —as the gold standard for AI worldwide and ensure our allies are building on American technology. Several principles cut across each of these three pillars. First, American workers are central to the Trump Administration’s AI policy. The Administration will ensure that our Nation’s workers and their families gain f rom the opportunities created in this technological revolution. The AI infrastructure buildout will create high -paying jobs for American workers. And the 1 Executive Order 14179 of January 23, 2025, “ Removing Barriers to American Leadership in Artificial Intelligence ,” Federal Register 90 (20) 8741, www.govinfo.gov/content/pkg/FR -2025 -01-31/pdf/2025 -02172.pdf . 2 J.D. Vance, “ Remarks by the Vice President at the Artificial Intelligence Action Summit in Paris, France,” February 11, 2025, www.presidency.ucsb.edu/documents/remarks -the -vice -president -the -artificial -intelligence -action -summit -paris -france."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_12",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\n1 Executive Order 14179 of January 23, 2025, “ Removing Barriers to American Leadership in Artificial Intelligence ,” Federal Register 90 (20) 8741, www.govinfo.gov/content/pkg/FR -2025 -01-31/pdf/2025 -02172.pdf . 2 J.D. Vance, “ Remarks by the Vice President at the Artificial Intelligence Action Summit in Paris, France,” February 11, 2025, www.presidency.ucsb.edu/documents/remarks -the -vice -president -the -artificial -intelligence -action -summit -paris -france. AMERICA ’S AI ACTION PLAN 2 breakthroughs in medicine, manufacturing, and many other fields that AI will make possible will increase the standard of living for all Americans. AI will improve the lives of Americans by complementing their work —not replacing it. Second, o ur AI systems must be free from ideological bias and be designed to pursue objective truth rather than social engineering agendas when users seek factual information or analysis. AI systems are becoming essential tools, profoundly shaping how Americans consume information, but these tools must also be trustw orthy. Finally, we must prevent our advanced technologies from being misused or stolen by malicious actors as well as monitor for emerging and unforeseen risks from AI. Doing so will require constant vigilance. This Action Plan sets forth clear policy goals for near -term execution by the Federal government."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_13",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nhow Americans consume information, but these tools must also be trustw orthy. Finally, we must prevent our advanced technologies from being misused or stolen by malicious actors as well as monitor for emerging and unforeseen risks from AI. Doing so will require constant vigilance. This Action Plan sets forth clear policy goals for near -term execution by the Federal government. The Action Plan’s objective is to articulate policy recommendations that this Administration can deliver for the American people to achieve the President’s vision of global AI dominance . The AI race is America’s to win, and this Action Plan is our roadmap to victory. Michael J. Kratsios Assistant to the President for Science and Technology David O. Sacks Special Advisor for AI and Crypto Marco A. Rubio Assistant to the President for National Security Affairs AMERICA ’S AI ACTION PLAN 3 Pillar I: Accelerate AI Innovation America must have the most powerful AI systems in the world, but we must also lead the world in creative and transformative application of th ese systems. Achieving these goals requires the Federal government to create the conditions where private -sector -led innovation can flourish. Remov e Red Tape and Onerous Regulation To maintain global leadership in AI, America’s private sector must be unencumbered by bureaucratic red tape."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_14",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nin the world, but we must also lead the world in creative and transformative application of th ese systems. Achieving these goals requires the Federal government to create the conditions where private -sector -led innovation can flourish. Remov e Red Tape and Onerous Regulation To maintain global leadership in AI, America’s private sector must be unencumbered by bureaucratic red tape. President Trump has already taken multiple steps toward this goal , including rescinding Biden E xecutive Order 14110 on AI that foreshadowed an onerous regulatory regime .3 AI is far too important to smother in bureaucracy at this early stage , whether at the state or Federal level. The Federal government should not allow AI- related Federal funding to be directed toward s tates with burdensome AI regulations that waste these funds, but should also not interfere with states’ rights to pass prudent laws that are not unduly restrictive to innovation. Recommended Policy Actions • Led by the Office of Science and Technology Policy (OSTP), launch a Request for Information from businesses and the public at large about current Federal regulations that hinder AI innovation and adoption, and work with relevant Federal agencies to take appropriate action."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_15",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nwith states’ rights to pass prudent laws that are not unduly restrictive to innovation. Recommended Policy Actions • Led by the Office of Science and Technology Policy (OSTP), launch a Request for Information from businesses and the public at large about current Federal regulations that hinder AI innovation and adoption, and work with relevant Federal agencies to take appropriate action. • Led by the Office of Management and Budget (OMB) and c onsistent with Executive Order 14192 of January 31, 2025, “ Unleashing Prosperity Through Deregulation, ” work with all F ederal agencies to identify, revise, or repeal regulations, rules, memoranda, administrative orders, guidance documents, policy statements, and interagency agreements that unnecessarily hinder AI development or deployment. 4 • Led by OMB, work with Federal agencies that have AI-related discretionary funding programs to ensure, consistent with applicable law, that they consider a s tate’s AI regulatory climate when making funding decisions and limit funding if the state’s AI regulatory regimes may hinder the effectiveness of that funding or award. • Led by the Federal Communications Commission (FCC), evaluate whether state AI regulations interfere with the agency’s ability to carry out its obligations and authorities under the Communications Act of 1934."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_16",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nconsider a s tate’s AI regulatory climate when making funding decisions and limit funding if the state’s AI regulatory regimes may hinder the effectiveness of that funding or award. • Led by the Federal Communications Commission (FCC), evaluate whether state AI regulations interfere with the agency’s ability to carry out its obligations and authorities under the Communications Act of 1934. 5 • Review all Federal Trade Commission (FTC) investigations commenced under the previous administration to ensure that they do not advance theories of liability that unduly burden AI innovation. Furthermore, review all FTC final orders, consent decrees, 3 Executive Order 14110 of October 30, 2023, “ Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence,” Federal Register 88 (210) 75191, www.govinfo.gov/content/pkg/FR -2023 -11-01/pdf/2023 -24283.pdf . 4 Executive Order 14192 of January 31, 2025, “ Unleashing Prosperity Through Deregulation,” Federal Register 90 (24) 9065, www.govinfo.gov/content/pkg/FR -2025 -02-06/pdf/2025 -02345.pdf . 5 Communications Act of 1934, 47 U.S.C. §§ 151 -646. AMERICA ’S AI ACTION PLAN 4 and injunctions , and, where appropriate, seek to modify or set -aside any that unduly burden AI innovation. Ensure that Frontier AI Protects Free Speech and American Values AI systems will play a profound role in how we educate our children, do our jobs, and consume media."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_17",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nof 1934, 47 U.S.C. §§ 151 -646. AMERICA ’S AI ACTION PLAN 4 and injunctions , and, where appropriate, seek to modify or set -aside any that unduly burden AI innovation. Ensure that Frontier AI Protects Free Speech and American Values AI systems will play a profound role in how we educate our children, do our jobs, and consume media. It is essential that these system s be built from the ground up with freedom of speech and expression in mind, and that U.S. government policy does not interfere with that objective . We must ensure that free speech flourishes in the era of AI and that AI procured by the Federal government objectively reflects truth rather than social engineering agendas. Recommended Policy Actions • Led by the Department of Commerce (DOC) through the National Institute of Standards and Technology (NIST), revise the NIST AI Risk Management Framework to eliminate references to misinformation, Diversity, Equity, and Inclusion, and climate change. 6 • Update Federal procurement guidelines to ensure that the government only contracts with frontier large language model (LLM) developers who ensure that their systems are objective and free from top -down ideological bias. • Led by DOC through NIST’s Center for AI Standards and Innovation (CAISI), conduct research and, as appropriate, publish evaluations of frontier models from the People’s Republic of China for alignment with Chinese Communist Party talking points and censorship."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_18",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nwith frontier large language model (LLM) developers who ensure that their systems are objective and free from top -down ideological bias. • Led by DOC through NIST’s Center for AI Standards and Innovation (CAISI), conduct research and, as appropriate, publish evaluations of frontier models from the People’s Republic of China for alignment with Chinese Communist Party talking points and censorship. Encourage Open- Source and Open -Weight AI Open -source and open -weight AI models are made freely available by developers for anyone in the world to download and modify. Models distributed this way have unique value for innovation because startups can use them flexibly without being dependent on a closed model provider. They also benefit commercial and government adoption of AI because many businesses and governments have sensitive data that they cannot send to closed model vendors. And they are essential for academic research, which often relies on access to the weights and training data of a model to perform scientifically rigorous experiments. We need to ensure America has leading open models founded on American values. Open- source and open -weight models could become global standards in some areas of business and in academic research worldwide. For that reason, they also have geostrategic value."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_19",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nwhich often relies on access to the weights and training data of a model to perform scientifically rigorous experiments. We need to ensure America has leading open models founded on American values. Open- source and open -weight models could become global standards in some areas of business and in academic research worldwide. For that reason, they also have geostrategic value. While the decision of whether and how to release an open or closed model is fundamentally up to the developer, the Federal government should create a supportive environment for open models. Recommended Policy Actions • Ensure access to large -scale computing power for startups and academics by improving the financial market for compute. Currently, a company seeking to use large - scale compute must often sign long -term contracts with hyperscalers —far beyond the 6 National Institute of Standards and Technology, “ Artificial Intelligence Risk Management Framework (AI RMF 1.0),” (Gaithersburg, MD: National Institute of Standards and Technology, 2023), www.doi.org/10.6028/NIST.AI.100 -1. AMERICA ’S AI ACTION PLAN 5 budgetary reach of most academics and many startups. America has solved this problem before with other goods through financial markets, such as spot and forward markets for commodities ."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_20",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nInstitute of Standards and Technology, “ Artificial Intelligence Risk Management Framework (AI RMF 1.0),” (Gaithersburg, MD: National Institute of Standards and Technology, 2023), www.doi.org/10.6028/NIST.AI.100 -1. AMERICA ’S AI ACTION PLAN 5 budgetary reach of most academics and many startups. America has solved this problem before with other goods through financial markets, such as spot and forward markets for commodities . Through collaboration with industry, NIST at DOC, OSTP, and the National Science Foundation’s (NSF) National AI Research Resource (NAIRR) pilot, the Federal government can accelerate the maturation of a healthy financial market for compute. • Partner with leading technology companies to increase the research community’s access to world -class private sector computing, models, data, and software resources as part of the NAIRR pilot. • Build the foundations for a lean and sustainable NAIRR operations capability that can connect an increasing number of researchers and educators across the country to critical AI resources . • Continue to foster the next generation of AI breakthroughs by publishing a new National AI Research and Development (R&D) Strategic Plan, led by OSTP, to guide Federal AI research investments. • Led by DOC through the National Telecommunications and Information Administration (NTIA), convene stakeholders to help drive adoption of open -source and open -weight models by small and medium -sized businesses."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_21",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nto foster the next generation of AI breakthroughs by publishing a new National AI Research and Development (R&D) Strategic Plan, led by OSTP, to guide Federal AI research investments. • Led by DOC through the National Telecommunications and Information Administration (NTIA), convene stakeholders to help drive adoption of open -source and open -weight models by small and medium -sized businesses. Enable AI Adoption Today, the bottleneck to harnessing AI’s full potential is not necessarily the availability of models, tools, or applications. Rather, it is the limited and slow adoption of AI, particularly within large, established organizations. Many of America’s most c ritical sectors, such as healthcare, are especially slow to adopt due to a variety of factors, including distrust or lack of understanding of the technology, a complex regulatory landscape, and a lack of clear governance and risk mitigation standards. A co ordinated Federal effort would be beneficial in establishing a dynamic, “try- first” culture for AI across American industry. Recommended Policy Actions • Establish regulatory sandboxes or AI Centers of Excellence around the country where researchers, startups, and established enterprises can rapidly deploy and test AI tools while committing to open sharing of data and results."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_22",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nrisk mitigation standards. A co ordinated Federal effort would be beneficial in establishing a dynamic, “try- first” culture for AI across American industry. Recommended Policy Actions • Establish regulatory sandboxes or AI Centers of Excellence around the country where researchers, startups, and established enterprises can rapidly deploy and test AI tools while committing to open sharing of data and results. These efforts would be enabled by regulatory agencies such as the Food and Drug Administration (FDA) and the Securities and Exchange Commission (SEC), with support from DOC through its AI evaluation initiatives at NIST. • Launch several domain- specific efforts ( e.g., in healthcare, energy, and agriculture) , led by NIST at DOC, to convene a broad range of public, private, and academic stakeholders to accelerate the development and adoption of national standards for AI systems and to measure how much AI increases productivity at realistic tasks in those domains. • Led by the Department of Defense (DOD) in coordination with the Office of the Director of National Intelligence (ODNI), regularly update joint D OD-I ntelligence Community (IC) assessments of the comparative level of adoption of AI tools by the United States, its competitors, and its adversaries’ national security establishments, and establish an AMERICA ’S AI ACTION PLAN 6 approach for continuous adaptation of the D OD and IC’s respective AI adoption initiatives based on these AI net assessments."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_23",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\n(ODNI), regularly update joint D OD-I ntelligence Community (IC) assessments of the comparative level of adoption of AI tools by the United States, its competitors, and its adversaries’ national security establishments, and establish an AMERICA ’S AI ACTION PLAN 6 approach for continuous adaptation of the D OD and IC’s respective AI adoption initiatives based on these AI net assessments. • Prioritize, collect, and distribute intelligence on foreign frontier AI projects that may have national security implications, via collaboration between the IC, the Department of Energy (DOE), CAISI at DOC, the National Security Council (NSC), and OSTP. Empower American Workers in the Age of AI The Trump Administration supports a worker -first AI agenda. By accelerating productivity and creating entirely new industries, AI can help America build an economy that delivers more pathways to economic opportunity for American workers. But it will also transform how work gets done across all industries and occupations, demanding a serious workforce response to help workers navigate that transition."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_24",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nAI The Trump Administration supports a worker -first AI agenda. By accelerating productivity and creating entirely new industries, AI can help America build an economy that delivers more pathways to economic opportunity for American workers. But it will also transform how work gets done across all industries and occupations, demanding a serious workforce response to help workers navigate that transition. The Trump Administration has already taken significant steps to lead on this front, including the April 2025 Executive Orders 14277 and 14278, “Advancing Artificial Intelligence Education for American Youth ” and “Preparing Americans for High -Paying Skilled Trade Jobs of the Future .” 7, 8 To continue delivering on this vision, the Trump Administration will advance a priority set of actions to expand AI literacy and skills development, continuously evaluate AI’s impact on the labor market, and pilot new innovations to rapidly retrain and help workers thrive in an AI- driven economy. Recommended Policy Actions • Led by the Department of Labor (DOL), the Department of Education (ED), NSF, and DOC, prioritize AI skill development as a core objective of relevant education and workforce funding streams. This should include promoting the integration of AI skill development into relevant programs , including career and technical education (CTE) , workforce training, apprenticeships, and other federal ly supported skills initiatives."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_25",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nby the Department of Labor (DOL), the Department of Education (ED), NSF, and DOC, prioritize AI skill development as a core objective of relevant education and workforce funding streams. This should include promoting the integration of AI skill development into relevant programs , including career and technical education (CTE) , workforce training, apprenticeships, and other federal ly supported skills initiatives. • Led by the Department of the Treasury, issue guidance clarifying that many AI literacy and AI skill development programs may qualify as eligible educational assistance under Section 132 of the Internal Revenue Code , given AI’s widespread impact reshaping the tasks and skills required across industries and occupations . 9 In applicable situations, this will enable employers to offer tax -free reimbursement for AI -related training and help scale private -sector investment in AI skill development, preserving jobs for American workers. • Led by the Bureau of Labor Statistics (BLS) and DOC through the Census Bureau and the Bureau of Economic Analysis (BEA), study AI’s impact on the labor market by using data they already collect on these topics, such as the firm -level AI adoption trends the Census Bureau tracks in its Business Trends and Outlook Survey. These agencies could then provide analysis of AI adoption, job creation, displacement, and wage effects."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_26",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nthe Census Bureau and the Bureau of Economic Analysis (BEA), study AI’s impact on the labor market by using data they already collect on these topics, such as the firm -level AI adoption trends the Census Bureau tracks in its Business Trends and Outlook Survey. These agencies could then provide analysis of AI adoption, job creation, displacement, and wage effects. • Establish the AI Workforce Research Hub under DOL to lead a sustained Federal effort to evaluate the impact of AI on the labor market and the experience of the American 7 Executive Order 14277 of April 23, 2025: “ Advancing Artificial Intelligence Education for American Youth,” Federal Register 90 (80) 17519, www.govinfo.gov/content/pkg/FR -2025 -04-28/pdf/2025 -07368.pdf . 8 Executive Order 14278 of April 23, 2025: “ Preparing Americans for High- Paying Skilled Trade Jobs of the Future,” Federal Register 90 (80) 17525, www.govinfo.gov/content/pkg/FR -2025 -04-28/pdf/2025 -07369.pdf . 9 Revenue Act of 1978, 26 U.S.C. § 132. AMERICA ’S AI ACTION PLAN 7 worker, in collaboration with BLS and DOC through the Census Bureau and BEA. The Hub would produce recurring analys es, conduct scenario planning for a range of potential AI impact levels, and generate actionable insights to inform workforce and education policy. • Led by DOL, leverage available discretionary funding , where appropriate, to fund rapid retraining for individuals impacted by AI -related job displacement."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_27",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nBLS and DOC through the Census Bureau and BEA. The Hub would produce recurring analys es, conduct scenario planning for a range of potential AI impact levels, and generate actionable insights to inform workforce and education policy. • Led by DOL, leverage available discretionary funding , where appropriate, to fund rapid retraining for individuals impacted by AI -related job displacement. Issue clarifying guidance to help states identify eligible dislocated workers in sectors undergoing significant structural change tied to AI adoption , as well as guidance clarifying how state Rapid Response funds can be used to proactively upskill workers at risk of future displacement . • At DOL and DOC, rapidly pilot new approaches to workforce challenges created by AI, which may include areas such as rapid retraining needs driven by worker displacement and shifting skill requirements for entry -level roles. These pilots should be carried out by states and workforce intermediaries using existing authorit ies under the Workforce Innovation and Opportunity Act and the Public Works and Economic Development Act, and should be designed to identify surface scalable, performance -driven strategies that help the workforce system adapt to the speed and complexity of AI -driven labor market change."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_28",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\n-level roles. These pilots should be carried out by states and workforce intermediaries using existing authorit ies under the Workforce Innovation and Opportunity Act and the Public Works and Economic Development Act, and should be designed to identify surface scalable, performance -driven strategies that help the workforce system adapt to the speed and complexity of AI -driven labor market change. 10, 11 Support Next -Generation Manufacturing AI will enable a wide range of new innovations in the physical world: autonomous drones, self - driving cars, robotics, and other inventions for which terminology does not yet exist. It is crucial that America and our trusted allies be world- class manufacturers of these next- generation technologies. AI, robotics, and related technologies create opportunities for novel capabilities in manufacturing and logistics, including ones with applications to defense and national security. The Federal government should prioritize investment in these emerging technologies and usher in a new industrial renaissance."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_29",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nyet exist. It is crucial that America and our trusted allies be world- class manufacturers of these next- generation technologies. AI, robotics, and related technologies create opportunities for novel capabilities in manufacturing and logistics, including ones with applications to defense and national security. The Federal government should prioritize investment in these emerging technologies and usher in a new industrial renaissance. Recommended Policy Actions • Invest in developing and scaling foundational and translational manufacturing technologies via DOD , DOC, DOE , NSF, and other Federal agencies using the Small Business Innovation Research program , the Small Business Technology Transfer program , research grants , CHIPS R&D programs, Stevenson -Wydler Technology Innovation Act authorities, Title III of the Defense Production Act, Other Transaction Authority, and other authorities. 12, 13, 14, 15 • Led by DOC through NTIA, convene industry and government stakeholders to identify supply chain challenges to American robotics and drone manufacturing. 10 Workforce Innovation and Opportunity Act of 2014, 29 U.S.C. §§ 3101- 3361 . 11 Public Works and Economic Development Act of 1965, 42 U.S.C. §§ 3121 -3233. 12 William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, 15 U.S.C. § 4656. 13 Stevenson -Wydler Technology Innovation Act of 1980, Pub. L. No. 96- 480, 94 Stat. 2311 (codified as amended in scattered sections of 15 U.S.C. )."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_30",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\n3101- 3361 . 11 Public Works and Economic Development Act of 1965, 42 U.S.C. §§ 3121 -3233. 12 William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, 15 U.S.C. § 4656. 13 Stevenson -Wydler Technology Innovation Act of 1980, Pub. L. No. 96- 480, 94 Stat. 2311 (codified as amended in scattered sections of 15 U.S.C. ). 14 Defense Production Act of 1950, 50 U.S.C. §§ 4551 -4568. 15 National Defense Authorization Act for Fiscal years 1990 and 1991, 10 U.S.C. §§ 4021 -4022. AMERICA ’S AI ACTION PLAN 8 Invest in AI- Enabled Science Like many other domains, science itself will be transformed by AI. AI systems can already generate models of protein structures, novel materials, and much else. Increasingly powerful general -purpose models show promise in formulating hypotheses and designing experiments. These nascent capabilities promise to accelerate scientific advancement. They will only do so, however, with critical changes in the way science is conducted, including the enabling scientific infrastructure. AI- enabled predictions are of l ittle use if scientists cannot also increase the scale of experimentation. Basic s cience today is often a labor -intensive process; the AI era will require more scientific and engineering research to transform theories into industrial- scale enterprise s. This, in turn, will necessitate new infrastructure and support of new kinds of scientific organizations."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_31",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nAI- enabled predictions are of l ittle use if scientists cannot also increase the scale of experimentation. Basic s cience today is often a labor -intensive process; the AI era will require more scientific and engineering research to transform theories into industrial- scale enterprise s. This, in turn, will necessitate new infrastructure and support of new kinds of scientific organizations. Recommended Policy Actions • Through NSF, DOE , NIST at DOC, and other Federal partners, invest in automated cloud -enabled labs for a range of scientific fields, including engineering, materials science, chemistry, biology, and neuroscience, built by , as appropriate, the private sector , Federal agencies, and research institutions in coordination and collaboration with DOE National Lab oratories. • Use long -term agreements to s upport Focused- Research Organizations or other similar entities using AI and other emerging technologies to make fundamental scientific advancements. • Incentivize researchers to release more high -quality datasets publicly by considering the impact of scientific and engineering datasets from a researchers’ prior funded efforts in the review of proposals for new projects. • Require federally funded researchers to disclose non- proprietary, non -sensitive datasets that are used by AI models during the course of research and experimentation."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_32",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nscientific advancements. • Incentivize researchers to release more high -quality datasets publicly by considering the impact of scientific and engineering datasets from a researchers’ prior funded efforts in the review of proposals for new projects. • Require federally funded researchers to disclose non- proprietary, non -sensitive datasets that are used by AI models during the course of research and experimentation. Build World- Class Scientific Datasets High-quality data has become a national strategic asset as governments pursue AI innovation goals and capitalize on the technology’s economic benefits. Other countries, including our adversaries, ha ve raced ahead of us in amassing vast troves of scientific data. The United States must lead the creation of the world’s largest and highest quality AI -ready scientific datasets, while maintaining respect for individual rights and ensuring civil liberties, privacy, and confidentiality protections . Recommended Policy Actions • Direct the National Science and Technology Council (NSTC) Machine Learning and AI Subcommittee to make recommendations on minimum data quality standards for the use of biological, materials science, chemical, physical, and other scientific data modalities in AI model training."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_33",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nscientific datasets, while maintaining respect for individual rights and ensuring civil liberties, privacy, and confidentiality protections . Recommended Policy Actions • Direct the National Science and Technology Council (NSTC) Machine Learning and AI Subcommittee to make recommendations on minimum data quality standards for the use of biological, materials science, chemical, physical, and other scientific data modalities in AI model training. • Promulgate the OMB regulations required in the Confidential Information Protection and Statistical Efficiency Act of 2018 on presumption of accessibility and expanding secure access , which will lower barriers and break down silos to accessing Federal data , AMERICA ’S AI ACTION PLAN 9 ultimately facilitating the improved use of AI for evidence building by statistical agencies while protecting confidential data from inappropriate access and use.16 • Establish secure compute environments within NSF and DOE to enable secure AI use- cases for controlled access to restricted Federal data. • Create an online portal for NSF’s National Secure Data Service (NSDS) demonstration project to provide the public and Federal agencies with a front door to AI use -cases involving controlled access to restricted Federal data . • Explore the creation of a whole -genome sequencing program for life on Federal lands, led by the NSTC and including members of the U .S."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_34",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nonline portal for NSF’s National Secure Data Service (NSDS) demonstration project to provide the public and Federal agencies with a front door to AI use -cases involving controlled access to restricted Federal data . • Explore the creation of a whole -genome sequencing program for life on Federal lands, led by the NSTC and including members of the U .S. Department of Agriculture, DOE , NIH , NSF, the Department of Interior, and Cooperative Ecosystem Studies Units to collaborate on the development of an initiative to establish a whole genome sequencing program for life on Federal lands (to include all biological domains). This new data would be a valuable resource in training future biological foundation models. Advance the Science of AI Just as LLMs and generative AI systems represented a paradigm shift in the science of AI, future breakthroughs may similarly transform what is possible with AI. It is imperative that the United States remain the leading pioneer of such breakthroughs, and this begins with strategic, targeted investment in the most promising paths at the frontier. Recommended Policy Actions • Prioritize investment in theoretical, computational, and experimental research to preserve America’s leadership in discovering new and transformative paradigms that advance the capabilities of AI, reflecting this priority in the forthcoming National AI R&D Strategic Plan."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_35",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nthe leading pioneer of such breakthroughs, and this begins with strategic, targeted investment in the most promising paths at the frontier. Recommended Policy Actions • Prioritize investment in theoretical, computational, and experimental research to preserve America’s leadership in discovering new and transformative paradigms that advance the capabilities of AI, reflecting this priority in the forthcoming National AI R&D Strategic Plan. Invest in AI Interpretability, Control, and Robustness Breakthroughs Today, the inner workings of frontier AI systems are poorly understood. Technologists know how LLMs work at a high level, but often cannot explain why a model produced a specific output. This can make it hard to predict the behavior of any specific AI system. This lack of predictability, in turn, can make it challenging to use advanced AI in defense, national security, or other applications where lives are at stake. The United States will be better able to use AI systems to their fullest potential in high-s takes national security domains if we make fundamental breakthroughs on these research problems. Recommended Policy Actions • Launch a technology development program led by the Defense Advanced Research Projects Agency in collaboration with CAISI at DOC and NSF, to advance AI interpretability, AI control systems, and adversarial robustness. 16 Confidential Information Protection and Statistical Efficiency Act of 2018, 44 U.S.C. §§ 3561 -3583."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_36",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\ndomains if we make fundamental breakthroughs on these research problems. Recommended Policy Actions • Launch a technology development program led by the Defense Advanced Research Projects Agency in collaboration with CAISI at DOC and NSF, to advance AI interpretability, AI control systems, and adversarial robustness. 16 Confidential Information Protection and Statistical Efficiency Act of 2018, 44 U.S.C. §§ 3561 -3583. AMERICA ’S AI ACTION PLAN 10 • Prioritize fundamental advancements in AI interpretability, control, and robustness as part of the forthcoming National AI R&D Strategic Plan. • The DOD , DOE, CAISI at DOC, the Department of Homeland Security (DHS), NSF, and academic partners should coordinate an AI hackathon initiative to solicit the best and brightest from U .S. academia to test AI systems for transparency, effectiveness, use control, and security vulnerabilities. Build an AI Evaluations Ecosystem Evaluations are how the AI industry assesses the performance and reliability of AI systems. Rigorous evaluations can be a critical tool in defining and measuring AI reliability and performance in regulated industries. Over time, regulators should explore the use of evaluations in their application of existing law to AI systems."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_37",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nuse control, and security vulnerabilities. Build an AI Evaluations Ecosystem Evaluations are how the AI industry assesses the performance and reliability of AI systems. Rigorous evaluations can be a critical tool in defining and measuring AI reliability and performance in regulated industries. Over time, regulators should explore the use of evaluations in their application of existing law to AI systems. Recommended Policy Actions • Publish guidelines and resources through NIST at DOC, including CAISI, for Federal agencies to conduct their own evaluations of AI systems for their distinct missions and operations and for compliance with existing law. • Support the development of the science of measuring and evaluating AI models, led by NIST at DOC, DOE, NSF, and other Federal science agencies. • Convene meetings at least twice per year under the auspices of CAISI at DOC for Federal agencies and the research community to share learnings and best practices on building AI evaluations. • Invest, via DOE and NSF, in the development of AI testbeds for piloting AI systems in secure, real -world settings, allowing researchers to prototype new AI systems and translate them to the market. Such testbeds would encourage participation by broad multistakeholder teams and span a wide variety of economic verticals touched by AI, including agriculture , transportation , and healthcare delivery."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_38",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nvia DOE and NSF, in the development of AI testbeds for piloting AI systems in secure, real -world settings, allowing researchers to prototype new AI systems and translate them to the market. Such testbeds would encourage participation by broad multistakeholder teams and span a wide variety of economic verticals touched by AI, including agriculture , transportation , and healthcare delivery. • Led by DOC, convene the NIST AI Consortium to empower the collaborative establishment of new measurement science that will enable the identification of proven, scalable, and interoperable techniques and metrics to promote the development of AI. Accelerate AI Adoption in Government With AI tools in use , the Federal government can serve the public with far greater efficiency and effectiveness. Use cases include accelerating slow and often manual internal processes , streamlining public interactions , and many others. Taken together, transformative use of AI can help deliver the highly responsive government the American people expect and deserve. AMERICA ’S AI ACTION PLAN 11 OMB has already advanced AI adoption in government by reducing onerous rules imposed by the Biden Administration.17, 18 Now is the time to build on this success. Recommended Policy Actions • Formalize the Chief Artificial Intelligence Officer Council (CAIOC) as the primary venue for interagency coordination and collaboration on AI adoption."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_39",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nexpect and deserve. AMERICA ’S AI ACTION PLAN 11 OMB has already advanced AI adoption in government by reducing onerous rules imposed by the Biden Administration.17, 18 Now is the time to build on this success. Recommended Policy Actions • Formalize the Chief Artificial Intelligence Officer Council (CAIOC) as the primary venue for interagency coordination and collaboration on AI adoption. T hrough the CAIOC , initiate strategic coordination and collaboration with relevant Federal executive councils, to include: the President’s Management Council, Chief Data Officer Council, Chief Information Officer Council, Interagency Council on Statistical Policy, Chief Human Capital Officer Council, and Federal Privacy Council. • Create a talent -exchange program designed to allow rapid details of Federal staff to other agencies in need of specialized AI talent (e.g., data scientists and software engineers) , with input from the Office of Personnel Management. • Create an AI procurement toolbox managed by the General Services Administration (GSA), in coordination with OMB, that facilitates uniformity across the Federal enterprise to the greatest extent practicable. This system would allow any Federal agency to easily choose among multiple models in a manner compliant with relevant privacy, data governance, and transparency laws."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_40",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nfrom the Office of Personnel Management. • Create an AI procurement toolbox managed by the General Services Administration (GSA), in coordination with OMB, that facilitates uniformity across the Federal enterprise to the greatest extent practicable. This system would allow any Federal agency to easily choose among multiple models in a manner compliant with relevant privacy, data governance, and transparency laws. Agencies should also have ample flexibility to customize models to their own ends, as well as to see a catalog of other agency AI uses (based on OMB’s pre -existing AI Use Case Inventory). • Implement an Advanced Technology Transfer and Capability Sharing Program with GSA to quickly transfer advanced AI capabilities and use cases between agencies. • Mandate that all Federal agencies ensure —to the maximum extent practicable —that all employees whose work could benefit from access to frontier language models have access to , and appropriate training for, such tools. • Convene, under the auspices of OMB, a cohort of agencies with High Impact Service Providers to pilot and increase the use of AI to improve the delivery of services to the public. Drive Adoption of AI within the Department of Defense AI has the potential to transform both the warfighting and back -office operations of the DOD."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_41",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nsuch tools. • Convene, under the auspices of OMB, a cohort of agencies with High Impact Service Providers to pilot and increase the use of AI to improve the delivery of services to the public. Drive Adoption of AI within the Department of Defense AI has the potential to transform both the warfighting and back -office operations of the DOD. The United States must aggressively adopt AI within its Armed Forces if it is to maintain its global military preeminence while also ensuring, as outlined throughout this Action Plan, that its use of AI is secure and reliable. Because the DOD has unique operational needs within the Federal government, it merits specific policy actions to drive AI adoption. 17 Office of Management and Budget, “Accelerating Federal Use of AI through Innovation, Governance, and Public Trust (M -25- 21),” (Washington, DC: Executive Office of the President, 2025), www.whitehouse.gov/wp -content/uploads/2025/02/M -25- 21-Accelerating -Federal -Use -of-AI-through -Innovation- Governance -and -Public -Trust.pdf . 18 Office of Management and Budget, “Driving Efficient Acquisition of Artificial Intelligence in Government (M -25 22),” (Washington, DC: Executive Office of the President, 2025), www.whitehouse.gov/wp -content/uploads/2025/02/M -25-22- Driving -Efficient -Acquisition -of-Artificial -Intelligence -in-Government.pdf . AMERICA ’S AI ACTION PLAN 12 Recommended Policy Actions • Identify the talent and skills DOD’s workforce requires to leverage AI at scale."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_42",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\n-Trust.pdf . 18 Office of Management and Budget, “Driving Efficient Acquisition of Artificial Intelligence in Government (M -25 22),” (Washington, DC: Executive Office of the President, 2025), www.whitehouse.gov/wp -content/uploads/2025/02/M -25-22- Driving -Efficient -Acquisition -of-Artificial -Intelligence -in-Government.pdf . AMERICA ’S AI ACTION PLAN 12 Recommended Policy Actions • Identify the talent and skills DOD’s workforce requires to leverage AI at scale. Based on this identification, implement talent development programs to meet AI workforce requirements and drive the effective employment of AI -enabled capabilities. • Establish an AI & Autonomous Systems Virtual Proving Ground at DOD, beginning with scoping the technical, geographic, security, and resourcing requirements necessary for such a facility. • Develop a streamlined process within DOD for classifying, evaluating, and optimizing workflows involved in its major operational and enabling functions, aiming to develop a list of priority workflows for automation with AI. When a workflow is successfully automated, DOD should strive to permanently transition that workflow to the AI -based implementation as quickly as practicable."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_43",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nfor such a facility. • Develop a streamlined process within DOD for classifying, evaluating, and optimizing workflows involved in its major operational and enabling functions, aiming to develop a list of priority workflows for automation with AI. When a workflow is successfully automated, DOD should strive to permanently transition that workflow to the AI -based implementation as quickly as practicable. • Prioritize DOD -led agreements with cloud service providers, operators of computing infrastructure, and other relevant private sector entities to codify priority access to computing resources in the event of a national emergency so that DOD is prepared to fully leverage these technologies during a significant conflict. • Grow our Senior Military Colleges into hubs of AI research, development, and talent building, teaching core AI skills and literacy to future generations. Foster AI -specific curriculum , including in AI use, development, and infrastructure management, in the Senior Military Colleges throughout majors. Protect Commercial and Government AI Innovations Maintaining American leadership in AI necessitates that the U.S. government work closely with industry to appropriately balance the dissemination of cutting -edge AI technologies with national security concerns. It is also essential for the U.S. government to effectively address security risks to American AI companies, talent, intellectual property , and systems."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_44",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nColleges throughout majors. Protect Commercial and Government AI Innovations Maintaining American leadership in AI necessitates that the U.S. government work closely with industry to appropriately balance the dissemination of cutting -edge AI technologies with national security concerns. It is also essential for the U.S. government to effectively address security risks to American AI companies, talent, intellectual property , and systems. Recommended Policy Actions • Led by DOD , DHS , CAISI at DOC, and other appropriate members of the IC, collaborate with leading American AI developers to enable the private sector to actively protect AI innovations from security risks, including malicious cyber actors, insider threats, and others. Combat Synthetic Media in the Legal System One risk of AI that has become apparent to many Americans is malicious deepfakes, whether they be audio recordings, videos, or photos. While President Trump has already signed the TAKE IT DOWN Act, which was championed by First Lady Melania Trump and intended to protect against sexually explicit, non -consensual deepfakes, additional action is needed. 19 In particular, AI -generated media may present novel challenges to the legal system. For example, fake evidence c ould be used to attempt to deny justice to both plaintiffs and 19 TAKE IT DOWN Act, Pub. L. No. 119 -12, 139 Stat. 55 (2025) (codified as 47 U.S.C. § 223(h)). AMERICA ’S AI ACTION PLAN 13 defendants."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_45",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nis needed. 19 In particular, AI -generated media may present novel challenges to the legal system. For example, fake evidence c ould be used to attempt to deny justice to both plaintiffs and 19 TAKE IT DOWN Act, Pub. L. No. 119 -12, 139 Stat. 55 (2025) (codified as 47 U.S.C. § 223(h)). AMERICA ’S AI ACTION PLAN 13 defendants. The Administration must give the courts and law enforcement the tools they need to overcome these new challenges. Recommended Policy Actions • Led by NIST at DOC, consider developing NIST’s Guardians of Forensic Evidence deepfake evaluation program into a formal guideline and a companion voluntary forensic benchmark.20 • Led by the Department of Justice (DOJ), issue guidance to agencies that engage in adjudications to explore adopting a deepfake standard similar to the proposed Federal Rules of Evidence Rule 901(c) under consideration by the Advisory Committee on Evidence Rules. • Led by DOJ’s Office of Legal Policy, file formal comments on any proposed deepfake - related additions to the Federal Rules of Evidence. 20 Haiying Guan, James Horan, and Andrew Zhang, “ Guardians of Forensic Evidence: Evaluating Analytic Systems Against AI - Generated Deepfakes, ” (Gaithersburg, MD: National Institute of Standards and Technology, January 27, 2025), www.nist.gov/publications/guardians -forensic -evidence- evaluating -analytic -systems- against -ai-generated -deepfakes ."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_46",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nPolicy, file formal comments on any proposed deepfake - related additions to the Federal Rules of Evidence. 20 Haiying Guan, James Horan, and Andrew Zhang, “ Guardians of Forensic Evidence: Evaluating Analytic Systems Against AI - Generated Deepfakes, ” (Gaithersburg, MD: National Institute of Standards and Technology, January 27, 2025), www.nist.gov/publications/guardians -forensic -evidence- evaluating -analytic -systems- against -ai-generated -deepfakes . AMERICA ’S AI ACTION PLAN 14 Pillar II: Build American AI Infrastructure AI is the first digital service in modern life that challenges America to build vastly greater energy generation than we have today. American energy capacity has stagnated since the 1970s while China has rapidly built out their grid . America’s path to AI dominance depends on changing this troubling trend. Create Streamlined Permitting for Data Centers, Semiconductor Manufacturing Facilities, and Energy Infrastructure while Guaranteeing Security Like most general -purpose technologies of the past, AI will require new infrastructure — factories to produce chips, data centers to run those chips, and new sources of energy to power it all. America’s environmental permitting system and other regulations make it almost impossible to build this infrastructure in the United States with the speed that is required. Additionally, this infrastructure must also not be built with any adversarial technology that could undermine U.S. AI dominance."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_47",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nproduce chips, data centers to run those chips, and new sources of energy to power it all. America’s environmental permitting system and other regulations make it almost impossible to build this infrastructure in the United States with the speed that is required. Additionally, this infrastructure must also not be built with any adversarial technology that could undermine U.S. AI dominance. Fortunately, the Trump Administration has made unprecedented progress in reforming this system. Since taking office, President Trump has already reformed National Environmental Policy Act (NEPA) regulations across almost every relevant Federal agency , jumpstarted a permitting technology modernization program, created the National Energy Dominance Council (NEDC), and launched the United States Investment Accelerator. 21, 22, 23, 24 Now is the time to build on that momentum . Recommended Policy Actions • Establish new Categorical Exclusions under NEPA to cover data center -related actions that normally do not have a significant effect on the environment. Where possible, adopt Categorical Exclusions already established by other agencies so that each relevant agency can proceed with maximum efficiency. • Expand the use of the FAST -41 process to cover all data center and data center energy projects eligible under the Fixing America’s Surface Transportation Act of 2015."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_48",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nthat normally do not have a significant effect on the environment. Where possible, adopt Categorical Exclusions already established by other agencies so that each relevant agency can proceed with maximum efficiency. • Expand the use of the FAST -41 process to cover all data center and data center energy projects eligible under the Fixing America’s Surface Transportation Act of 2015. 25 • Explore the need for a nationwide Clean Water Act Section 404 permit for data centers, and, if adopted, ensure that this permit does not require a Pre- Construction Notification and covers development sites consistent with the size of a modern AI data center. 26 • Expedite environmental permitting by streamlining or reducing regulations promulgated under the Clean Air Act, the Clean Water Act, the Comprehensive 21 Executive Order 14156 of January 20, 2025, “ Declaring a National Energy Emergency,” Federal Register 90 (18) 8433, www.govinfo.gov/content/pkg/FR -2025 -01-29/pdf/2025 -02003.pdf . 22 Presidential Memorandum of April 15, 2025 , “Updating Permitting Technology for the 21st Century,” www.whitehouse.gov/presidential -actions/2025/04/updating- permitting -technology -for- the -21st -century/ . 23 Executive Order 14213 of February 14, 2025 , “Establishing the National Energy Dominance Council,” Federal Register 90 (33) 9945, www.govinfo.gov/content/pkg/FR -2025 -02-20/pdf/2025 -02928.pdf ."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_49",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nEmergency,” Federal Register 90 (18) 8433, www.govinfo.gov/content/pkg/FR -2025 -01-29/pdf/2025 -02003.pdf . 22 Presidential Memorandum of April 15, 2025 , “Updating Permitting Technology for the 21st Century,” www.whitehouse.gov/presidential -actions/2025/04/updating- permitting -technology -for- the -21st -century/ . 23 Executive Order 14213 of February 14, 2025 , “Establishing the National Energy Dominance Council,” Federal Register 90 (33) 9945, www.govinfo.gov/content/pkg/FR -2025 -02-20/pdf/2025 -02928.pdf . 24 Executive Order 14255 of March 31, 2025 , “Establishing the United States Investment Accelerator,” Federal Register 90 (63) 14701, www.govinfo.gov/content/pkg/FR -2025 -04-03/pdf/2025 -05908.pdf . 25 Fixing America ’s Surface Transportation Act, 42 U.S.C. § § 4370m -4370m -11. 26 Clean Water Act of 1972 , 33 U.S.C. § 1344. AMERICA ’S AI ACTION PLAN 15 Environmental Response, Compensation, and Liability Act, and other relevant related laws.27, 28 • Make Federal lands available for data center construction and the construction of power generation infrastructure for those data centers by directing agencies with significant land portfolios to identify sites suited to large -scale development. • Maintain security guardrails to prohibit adversaries from inserting sensitive inputs to this infrastructure."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_50",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nResponse, Compensation, and Liability Act, and other relevant related laws.27, 28 • Make Federal lands available for data center construction and the construction of power generation infrastructure for those data centers by directing agencies with significant land portfolios to identify sites suited to large -scale development. • Maintain security guardrails to prohibit adversaries from inserting sensitive inputs to this infrastructure. Ensure that the domestic AI computing stack is built on American products and that the infrastructure that supports AI development such as energy a nd telecommunications are free from foreign adversary information and communications technology and services (ICTS) —including software and relevant hardware. • Expand efforts to apply AI to accelerate and improve environmental reviews, such as through expanding the number of agencies participating in DOE’s PermitAI project. 29 Develop a Grid to Match the Pace of AI Innovation The U.S. electric grid is one of the largest and most complex machines on Earth. It, too, will need to be upgraded to support data centers and other energy -intensive industries of the future. The power grid is the lifeblood of the modern economy and a corn erstone of national security, but it is facing a confluence of challenges that demand strategic foresight and decisive action. Escalating demand driven by electrification and the technological advancements of AI are increasing pressures on the grid."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_51",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nsupport data centers and other energy -intensive industries of the future. The power grid is the lifeblood of the modern economy and a corn erstone of national security, but it is facing a confluence of challenges that demand strategic foresight and decisive action. Escalating demand driven by electrification and the technological advancements of AI are increasing pressures on the grid. The United States must develop a comprehensive strategy to enhance and expand the power grid designed not just to weather these challenges, but to ensure the grid’ s continued strength and capacity for future growth. Recommended Policy Actions • Stabilize the grid of today as much as possible. This initial phase acknowledges the need to safeguard existing assets and ensure s an uninterrupted and affordable supply of power. The United States must prevent the premature decommissioning of critical power generation resources and explore innovative ways to harness existing capacity, such as leveraging extant backup power sources to bolster grid reliability during peak demand. A key element of this stabilization is to ensure every corner of the electric g rid is in compliance with nationwide standards for resource adequacy and sufficient power generation capacity is consistently available across the country. • Optimize existing grid resources as much as possible. This involves implementing strategies to enhance the efficiency and performance of the transmission system."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_52",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\ndemand. A key element of this stabilization is to ensure every corner of the electric g rid is in compliance with nationwide standards for resource adequacy and sufficient power generation capacity is consistently available across the country. • Optimize existing grid resources as much as possible. This involves implementing strategies to enhance the efficiency and performance of the transmission system. The United States must explore solutions like advanced grid management technologies and upgrad es to power lines that can increase the amount of electricity transmitted along existing routes. Furthermore, the United States should investigate new and novel ways for large power consumers to manage their power consumption during critical grid periods to enhance reliability and unlock additional power on the system. 27 Clean Air Act of 1963, 42 U.S.C. §§ 7401 -7671 q. 28 Comprehensive Environmental Response, Compensation, and Liability Act of 1980. 42 U.S.C. §§ 9601 -9675. 29 Office of Policy, U.S. Department of Energy, “ Faster, Better Permitting with PermitAI,” (Washington, D.C., July 10, 2025 ), www.energy.gov/policy/articles/faster -better -permitting -permitai . AMERICA ’S AI ACTION PLAN 16 • Prioritize the interconnection of reliable, dispatchable power sources as quickly as possible and embrace new energy generation sources at the technological frontier (e.g., enhanced geothermal, nuclear fission, and nuclear fusion)."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_53",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nof Policy, U.S. Department of Energy, “ Faster, Better Permitting with PermitAI,” (Washington, D.C., July 10, 2025 ), www.energy.gov/policy/articles/faster -better -permitting -permitai . AMERICA ’S AI ACTION PLAN 16 • Prioritize the interconnection of reliable, dispatchable power sources as quickly as possible and embrace new energy generation sources at the technological frontier (e.g., enhanced geothermal, nuclear fission, and nuclear fusion). Reform power markets to align financial incentives with the goal of grid stability, ensuring that investment in power generation reflects the system ’s needs. • Create a strategic blueprint for navigating the complex energy landscape of the 21st century. By stabilizing the grid of today, optimizing existing grid resources, and growing the grid for the future, the United States can rise to the challenge of winning the AI race while also delivering a reliable and affordable power grid for all Americans. Restore American Semiconductor Manufacturing America jump -started modern technology with the invention of the semiconductor. Now America must bring semiconductor manufacturing back to U.S. soil. A revitalized U.S. chip industry will generate thousands of high- paying jobs, reinforce our technological leadership, and protect our supply chains from disruption by foreign rivals. The Trump Administration will lead that revitalization without making bad deals for the American taxpayer or saddling companies with sweeping ideological agendas."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_54",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nthe semiconductor. Now America must bring semiconductor manufacturing back to U.S. soil. A revitalized U.S. chip industry will generate thousands of high- paying jobs, reinforce our technological leadership, and protect our supply chains from disruption by foreign rivals. The Trump Administration will lead that revitalization without making bad deals for the American taxpayer or saddling companies with sweeping ideological agendas. Recommended Policy Actions • Led by DOC’s revamped CHIPS Program Office, continue focusing on delivering a strong return on investment for the American taxpayer and removing all extraneous policy requirements for CHIPS -funded semiconductor manufacturing projects. DOC and other relevant Federal agencies should also collaborate to streamline regulations that slow semiconductor manufacturing efforts. • Led by DOC, review semiconductor grant and research programs to ensure that they accelerate the integration of advanced AI tools into semiconductor manufacturing. Build High- Security Data Centers for Military and Intelligence Community Usage Because AI systems are particularly well -suited to processing raw intelligence data today, and because of the vastly expanded capabilities AI systems could have in the future, it is likely that AI will be used with some of the U .S. government’s most sensitive data. The data centers where these models are deployed must be resistant to attacks by the most determined and capable nation -state actors."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_55",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nto processing raw intelligence data today, and because of the vastly expanded capabilities AI systems could have in the future, it is likely that AI will be used with some of the U .S. government’s most sensitive data. The data centers where these models are deployed must be resistant to attacks by the most determined and capable nation -state actors. Recommended Policy Actions • Create new technical standards for high- security AI data centers, led by DOD, the IC, NSC, and NIST at DOC, including CAISI, in collaboration with industry and, as appropriate, relevant Federally Funded Research and Development Centers. • Advance agency adoption of classified compute environments to support scalable and secure AI workloads. AMERICA ’S AI ACTION PLAN 17 Train a Skilled Workforce for AI Infrastructure To build the infrastructure needed to power America’s AI future, we must also invest in the workforce that will build, operate, and maintain it —including roles such as electricians, advanced HVAC technicians, and a host of other high -paying occupations. To address the shortages in many of these critical jobs , the Trump Administration should identify the priority roles that underpin AI infrastructure, develop modern skill s frameworks, support industry - driven training, and expand early pipelines through gener al education, CTE, and Registered Apprenticeships to fuel American AI leadership."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_56",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nHVAC technicians, and a host of other high -paying occupations. To address the shortages in many of these critical jobs , the Trump Administration should identify the priority roles that underpin AI infrastructure, develop modern skill s frameworks, support industry - driven training, and expand early pipelines through gener al education, CTE, and Registered Apprenticeships to fuel American AI leadership. Recommended Policy Actions • Led by DOL and DOC, create a national initiative to identify high -priority occupations essential to the buildout of AI -related infrastructure. This effort would convene employers, industry groups, and other workforce stakeholders to develop or identify national skill frameworks and competency models for these roles. These frameworks would provide voluntary guidance that may inform curriculum design, credential development, and alignment of workforce investments. • Through DOL, DOE, ED, NSF, and DOC, partner with state and local governments and workforce system stakeholders to support the creation of industry -driven training programs that address workforce needs tied to priority AI infrastructure occupations. These programs should be co- developed by employers and training partners to ensure individuals who complete the program a re job -ready and directly connected to the hiring process. Models could also be explored that incentivize employer upskilling of incumbent wor kers into priority occupations."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_57",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nof industry -driven training programs that address workforce needs tied to priority AI infrastructure occupations. These programs should be co- developed by employers and training partners to ensure individuals who complete the program a re job -ready and directly connected to the hiring process. Models could also be explored that incentivize employer upskilling of incumbent wor kers into priority occupations. DOC should integrate these training models as a core workforce component of its infrastructure investment programs. Funding for this strategy will be prioritized based on a program’s ability to address identified pipeline gaps and deliver talent outcomes aligned to employer demand. • Led by DOL, ED, and NSF, partner with education and workforce system stakeholders to expand early career exposure programs and pre -apprenticeships that engage middle and high school students in priority AI infrastructure occupations. These efforts should focus on creating awareness and excitement about these jobs , aligning with local employer needs, and providing on -ramps into high- quality training and Registered Apprenticeship programs. • Through the ED Office of Career, Technical, and Adult Education, provide guidance to state and local CTE systems about how to update programs of study to align with priority AI infrastructure occupations."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_58",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nfocus on creating awareness and excitement about these jobs , aligning with local employer needs, and providing on -ramps into high- quality training and Registered Apprenticeship programs. • Through the ED Office of Career, Technical, and Adult Education, provide guidance to state and local CTE systems about how to update programs of study to align with priority AI infrastructure occupations. This includes refreshing curriculum, expanding dual enrollment options, and strengthening connections between CTE programs, employers, and training providers serving AI infra structure occupations. • Led by DOL, expand the use of Registered Apprenticeships in occupations critical to AI infrastructure. Efforts should focus on streamlining the launch of new programs in priority industries and occupations and removing barriers to employer adoption, including simplifying registration, supporting intermediaries, and aligning program design with employer needs . • Led by DOE, expand the hands -on research training and development opportunities for undergraduate, graduate , and postgraduate students and educators, leveraging AMERICA ’S AI ACTION PLAN 18 expertise and capabilities in AI across its national laboratories. This should include partnering with community colleges and technical/career colleges to prepare new workers and help transition the existing workforce to fill critical AI roles."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_59",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nDOE, expand the hands -on research training and development opportunities for undergraduate, graduate , and postgraduate students and educators, leveraging AMERICA ’S AI ACTION PLAN 18 expertise and capabilities in AI across its national laboratories. This should include partnering with community colleges and technical/career colleges to prepare new workers and help transition the existing workforce to fill critical AI roles. Bolster Critical Infrastructure Cybersecurity As AI systems advance in coding and software engineering capabilities, their utility as tools of both cyber offense and defense will expand. Maintaining a robust defensive posture will be especially important for owners of critical infrastructure, many of whom operate with limited financial resources. Fortunately, AI systems themselves can be excellent defensive tools. With continued adoption of AI -enabled cyberdefensive tools, providers of critical infrastructure can stay ahead of emerging threats. However , the use of AI in cyber and critical infrastructure exposes those AI systems to adversarial threats. All u se of AI in safety -critical or homeland security applications should entail the use of secure -by-design, robust, and resilient AI systems that are instrumented to detect performance shifts, and alert to potential malicious activities like data poisoning or adversarial example attacks."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_60",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nthe use of AI in cyber and critical infrastructure exposes those AI systems to adversarial threats. All u se of AI in safety -critical or homeland security applications should entail the use of secure -by-design, robust, and resilient AI systems that are instrumented to detect performance shifts, and alert to potential malicious activities like data poisoning or adversarial example attacks. Recommended Policy Actions • Establish an AI Information Sharing and Analysis Center (AI -ISAC), led by DHS, in collaboration with CAISI at DOC and the Office of the National Cyber Director, to promote the sharing of AI -security threat information and intelligence across U .S. critical infrastructure sectors. • Led by DHS, issue and maintain guidance to private sector entities on remediating and responding to AI -specific vulnerabilities and threats. • Ensure collaborative and consolidated sharing of known AI vulnerabilities from within Federal agencies to the private sector as appropriate. This process should take advantage of existing cyber vulnerability sharing mechanisms. Promote Secure -By-Design AI Technologies and Applications AI systems are susceptible to some classes of adversarial inputs ( e.g., data poisoning and privacy attacks), which p uts their performance at risk. The U.S. g overnment has a responsibility to ensure the AI systems it relies on —particularly for national security applications —are protected against spurious or malicious inputs."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_61",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nsharing mechanisms. Promote Secure -By-Design AI Technologies and Applications AI systems are susceptible to some classes of adversarial inputs ( e.g., data poisoning and privacy attacks), which p uts their performance at risk. The U.S. g overnment has a responsibility to ensure the AI systems it relies on —particularly for national security applications —are protected against spurious or malicious inputs. While much work has been done to advance the field of AI Assuranc e, promoting resilient and secure AI development and deployment should be a core activity of the U.S. government. Recommended Policy Actions • Led by DOD in collaboration with NIST at DOC and ODNI , continue to refine DOD’s Responsible AI and Generative AI Frameworks, Roadmaps, and Toolkits. • Led by ODNI i n consultation with DOD and CAISI at DOC, publish an IC Standard on AI Assurance under the auspices of Intelligence Community Directive 505 on Artificial Intelligence. AMERICA ’S AI ACTION PLAN 19 Promote Mature Federal Capacity for AI Incident Response The proliferation of AI technologies means that prudent planning is required to ensure that, if systems fail, the impacts to critical services or infrastructure are minimized and response is imminent . To prepare for such an eventuality, the U .S. government should promote the development and incorporation of AI Incident Response actions into existing incident response doctrine and best-practices for both the public and private sectors."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_62",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nthat prudent planning is required to ensure that, if systems fail, the impacts to critical services or infrastructure are minimized and response is imminent . To prepare for such an eventuality, the U .S. government should promote the development and incorporation of AI Incident Response actions into existing incident response doctrine and best-practices for both the public and private sectors. Recommended Policy Actions • Led by NIST at DOC, including CAISI, partner with the AI and cybersecurity industries to ensure AI is included in the establishment of standards, response frameworks, best - practices, and technical capabilities (e.g., fly- away kits) of incident response teams. • Modify the Cybersecurity and Infrastructure Security Agency’s Cybersecurity Incident & Vulnerability Response Playbooks to incorporate considerations for AI systems and to include requirements for Chief Information Security Officers to consult with Chief A I Officers, Senior Agency Officials for Privacy, CAISI at DOC, and other agency officials as appropriate. Agencies should update their subordinate playbooks accordingly."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_63",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nincident response teams. • Modify the Cybersecurity and Infrastructure Security Agency’s Cybersecurity Incident & Vulnerability Response Playbooks to incorporate considerations for AI systems and to include requirements for Chief Information Security Officers to consult with Chief A I Officers, Senior Agency Officials for Privacy, CAISI at DOC, and other agency officials as appropriate. Agencies should update their subordinate playbooks accordingly. • Led by DOD , DHS , and ODNI , in coordination with OSTP, NSC, OMB , and the Office of the National Cyber Director, encourage the responsible sharing of AI vulnerability information as part of ongoing efforts to implement E xecutive Order 14306, “Sustaining Select Efforts to Strengthen the Nation ’s Cybersecurity and Amending Executive Order 13694 and Executive Order 14144.” 30 30 Executive Order 14306 of June 6, 2025 , “Sustaining Select Efforts To Strengthen the Nation’ s Cybersecurity and Amending Executive Order 13694 and Executive Order 14144,” Federal Register 90 (111) 24723, www.govinfo.gov/content/pkg/FR - 2025 -06-11/pdf/2025 -10804.pdf . AMERICA ’S AI ACTION PLAN 20 Pillar III: Lead in International AI Diplomacy and Security To succeed in the global AI competition, America must do more than promote AI within its own borders . The United States must also drive adoption of American AI systems, computing hardware, and standards throughout the world."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_64",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\n(111) 24723, www.govinfo.gov/content/pkg/FR - 2025 -06-11/pdf/2025 -10804.pdf . AMERICA ’S AI ACTION PLAN 20 Pillar III: Lead in International AI Diplomacy and Security To succeed in the global AI competition, America must do more than promote AI within its own borders . The United States must also drive adoption of American AI systems, computing hardware, and standards throughout the world. America currently is the global leader on data center construction, computing hardware performance, and models. It is imperative that the United States leverage this advantage into an enduring global alliance, while preventing our adversaries from free -riding on our innovation and inves tment. Export American AI to Allies and Partners The U nited States must meet global demand for AI by exporting its full AI technology stack — hardware, models, software, applications, and standards —to all countries willing to join America’s AI alliance. A failure to meet this demand w ould be an unforced error, caus ing these countries to turn to our rivals . The distribution and diffusion of American technology will stop our strategic rivals from making our allies dependent on foreign adversary technology. Recommended Policy Actions • Establish and operationalize a program within DOC aimed at gathering proposals from industry consortia for full- stack AI export packages. Once consortia are selected by DOC, the Economic Diplomacy Action Group, the U .S."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_65",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\n. The distribution and diffusion of American technology will stop our strategic rivals from making our allies dependent on foreign adversary technology. Recommended Policy Actions • Establish and operationalize a program within DOC aimed at gathering proposals from industry consortia for full- stack AI export packages. Once consortia are selected by DOC, the Economic Diplomacy Action Group, the U .S. Trade and Development Agency, the Export- Import Bank, the U.S. International Development Finance Corporation, and the Department of State (DOS) should coordinate with DOC to facilitate deals that meet U.S.- approved security requirements and standards. Counter Chinese Influence in International Governance Bodies A large number of international bodies, including the United Nations, the Organis ation for Economic Co-o peration and Development, G7, G20, International Telecommunication Union, Internet Corporation for Assigned Names and Numbers, and others have proposed AI governance frameworks and AI development strategies. The United States supports like - minded nations working together to encourage the development of AI in line with our shared values. But t oo many of these efforts have advocated for burdensome regulations, vague “codes of conduct” that promote cultural agendas that do not align with American values , or have been influenced by Chinese companies attempting to shape standards for facial recognition and surveillance ."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_66",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nnations working together to encourage the development of AI in line with our shared values. But t oo many of these efforts have advocated for burdensome regulations, vague “codes of conduct” that promote cultural agendas that do not align with American values , or have been influenced by Chinese companies attempting to shape standards for facial recognition and surveillance . Recommended Policy Actions • Led by DOS and DOC, leverage the U.S. position in international diplomatic and standard -setting bodies to vigorously advocate for international AI governance approaches that promote innovation, reflect American values, and counter authoritarian influence. AMERICA ’S AI ACTION PLAN 21 Strengthen AI Compute Export Control Enforcement Advanced AI compute is essential to the AI era, enabling both economic dynamism and novel military capabilities. Denying our foreign adversaries access to this resource, then, is a matter of both geostrategic competition and national security . Therefore, w e should pursue creative approaches to export control enforcement. Recommended Policy Actions • Led by DOC, OSTP , and NSC in collaboration with industry , explore leveraging new and existing location verification features on advanced AI compute to ensure that the chips are not in countries of concern. • Establish a new effort led by DOC to collaborate with IC officials on global chip export control enforcement."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_67",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\ncontrol enforcement. Recommended Policy Actions • Led by DOC, OSTP , and NSC in collaboration with industry , explore leveraging new and existing location verification features on advanced AI compute to ensure that the chips are not in countries of concern. • Establish a new effort led by DOC to collaborate with IC officials on global chip export control enforcement. This would include monitoring emerging technology developments in AI compute to ensure full coverage of possible countries or regions where chips are being diverted . This enhanced monitoring could then be used to expand and increase end -use monitoring in countries where there is a high risk of diversion of advanced, U.S. -origin AI compute, especially where there is not a B ureau of Industry and Secur ity Export Control Officer present in -country . Plug Loopholes in Existing Semiconductor Manufacturing Export Controls Semiconductors are among the most complex inventions ever conceived by man. America and its close allies hold near -monopolies on many critical components and processes in the semiconductor manufacturing pipeline. We must continue to lead the world with pathbreaking research and new inventions in semiconductor manufacturing, but the United States must also prevent our adversaries from using our innovation s to their own ends in ways that undermine our national security. This requires new measures to address g aps in semiconductor manufacturing export controls, coupled with enhanced enforcement."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_68",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nmanufacturing pipeline. We must continue to lead the world with pathbreaking research and new inventions in semiconductor manufacturing, but the United States must also prevent our adversaries from using our innovation s to their own ends in ways that undermine our national security. This requires new measures to address g aps in semiconductor manufacturing export controls, coupled with enhanced enforcement. Recommended Policy Actions • Led by DOC, d evelop new export controls on semiconductor manufacturing sub - systems. Currently, the U nited States and its allies impose export controls on major systems necessary for semiconductor manufacturing, but do not control many of the component sub- systems. Align Protection Measures Globally America must impose strong export controls on sensitive technologies. We should encourage partners and allies to follow U.S. controls, and not backfill. If they do, America should use tools such as the Foreign Direct Product Rule and secondary tariffs to a chieve greater international alignment. Recommended Policy Actions • Led by DOC and DOS and in coordination with NSC, DOE, and NSF, develop, implement, and share information on complementary technology protection measures, including in basic research and higher education, to mitigate risks from strategic adversaries and AMERICA ’S AI ACTION PLAN 22 concerning entities . This work should build on existing efforts underway at DOS and DOC, or, where necessary, involve new diplomatic campaigns."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_69",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nand in coordination with NSC, DOE, and NSF, develop, implement, and share information on complementary technology protection measures, including in basic research and higher education, to mitigate risks from strategic adversaries and AMERICA ’S AI ACTION PLAN 22 concerning entities . This work should build on existing efforts underway at DOS and DOC, or, where necessary, involve new diplomatic campaigns. • Develop a technology diplomacy strategic plan for an AI global alliance to align incentives and policy levers across government to induce key allies to adopt complementary AI protection systems and export controls across the supply chain, led by DOS in coordination with DOC, DOD, and DOE. This plan should aim to ensure that American allies do not supply adversaries with technologies on which the U.S. is seeking to impose export controls. • Expand new initiatives for promoting plurilateral controls for the AI tech stack, avoiding the sole reliance on multilateral treaty bodies to accomplish this objective, while also encompassing existing U.S. controls and all future controls to level the playing field between U.S. and allied controls . • Led by DOC and DOD, coordinate with allies to ensure that they adopt U.S. export controls, work together with the U.S to develop new controls, and prohibit U.S. adversaries from supplying their defense -industrial base or acquiring controlling stakes in def ense suppliers. Ensure that the U .S."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_70",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nto level the playing field between U.S. and allied controls . • Led by DOC and DOD, coordinate with allies to ensure that they adopt U.S. export controls, work together with the U.S to develop new controls, and prohibit U.S. adversaries from supplying their defense -industrial base or acquiring controlling stakes in def ense suppliers. Ensure that the U .S. Government is at the Forefront of Evaluating National Security Risks in Frontier Models The most powerful AI systems may pose novel national security risks in the near future in areas such as cyberattacks and the development of chemical, biological, radiological, nuclear, or explosives (CBRNE) weapons , as well as novel security vulnerabilities . Because America currently leads on AI capabilities, the risks present in American frontier models are likely to be a preview for what foreign adversaries will possess in the near future. Understanding the nature of these risks as they emerge is vital for national defense and homeland security. Recommended Policy Actions • Evaluate frontier AI systems for national security risks in partnership with frontier AI developers, led by CAISI at DOC in collaboration with other agencies with relevant expertise in CBRNE and cyber risks."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_71",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nadversaries will possess in the near future. Understanding the nature of these risks as they emerge is vital for national defense and homeland security. Recommended Policy Actions • Evaluate frontier AI systems for national security risks in partnership with frontier AI developers, led by CAISI at DOC in collaboration with other agencies with relevant expertise in CBRNE and cyber risks. • Led by CAISI at DOC in collaboration with national security agencies, evaluate and assess potential security vulnerabilities and malign foreign influence arising from the use of adversaries’ AI systems in critical infrastructure and elsewhere in the Americ an economy, including the possibility of backdoors and other malicious behavior. These evaluations should include assessments of the capabilities of U.S. and adversary AI systems, the adoption of foreign AI systems, and the state of international AI competition. • Prioritize the recruitment of leading AI researchers at Federal agencies, including NIST and CAISI within DOC , DOE, DOD, and the IC, to ensure that the Federal government can continue to offer cutting -edge evaluations and analysis of AI systems. • Build, maintain, and update as necessary national security -related AI evaluations through collaboration between CAISI at DOC, national security agencies , and relevant research institutions."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_72",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nresearchers at Federal agencies, including NIST and CAISI within DOC , DOE, DOD, and the IC, to ensure that the Federal government can continue to offer cutting -edge evaluations and analysis of AI systems. • Build, maintain, and update as necessary national security -related AI evaluations through collaboration between CAISI at DOC, national security agencies , and relevant research institutions. AMERICA ’S AI ACTION PLAN 23 Invest in Biosecurity AI will unlock nearly limitless potential in biology: cures for new diseases, novel industrial use cases, and m ore . At the same time, it could create new pathways for malicious actors to synthesize harmful pathogens and other biomolecules. The solution to this problem is a multi - tiered approach designed to screen for malicious actors, along with new tools and infrastructure for more effective screening. As these tools, policies, and enforcement mechanisms mature, it will be essential to work with allies and partners to ensure international adoption. Recommended Policy Actions • Require all institutions receiving Federal funding for scientific research to use nucleic acid synthesis tools and synthesis providers that have robust nucleic acid sequence screening and customer verification procedures . Create enforcement mechanisms for this requirement rather than relying on voluntary attestation."
  },
  {
    "id": "Americas-AI-Action-Plan_chunk_73",
    "text": "Source: 1 Americas-AI-Action-Plan.pdf\n\nit will be essential to work with allies and partners to ensure international adoption. Recommended Policy Actions • Require all institutions receiving Federal funding for scientific research to use nucleic acid synthesis tools and synthesis providers that have robust nucleic acid sequence screening and customer verification procedures . Create enforcement mechanisms for this requirement rather than relying on voluntary attestation. • Led by OSTP, convene government and industry actors to develop a mechanism to facilitate data sharing between nucleic acid synthesis providers to screen for potentially fraudulent or malicious customers. • Build, maintain, and update as necessary national security -related AI evaluations through collaboration between CAISI at DOC, national security agencies , and relevant research institutions. AMERICA ’S AI ACTION PLAN 24 This page intentionally left blank. AMERICA ’S AI ACTION PLAN 25"
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_0",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nSecre1t11:1 · U.S. Department of Homeland Security Washington. DC 20528 Homeland Security August 8, 2023 Pol icy Statement 139-06 MEMORANDUM FOR: OHS Agency and Office Leade1 FROM: Alejandro N. Mayorkas Secretary �,� \"11 SUBJECT: Acquisition and Use of Artificial Intelligence and Machine Learning Technologies by OHS Components I.Purpose Artificial intelligence (AI) will drastically alter the threat landscape and greatly augment the arsenal of tools available to succeed against new and existing threats. It has the potential to improve the efficiency of OHS business and operational processes, to strengthen customer service in travel and immigration administration and to facilitate lawful trade, while helping address a range of other challenges to the DI-IS mission. OHS must master this technology, applying it effectively and building a world class workforce that can reap the benefits of Al, while meeting the threats posed by adversaries that wield Al. At the same time, we must also ensure that our use of Al is responsible and trustworthy, that it is rigorously tested to be effective, that it safeguards privacy, civil rights, and civil liberties while avoiding inappropriate biases, and to the extent possible, that it is transparent and explainable to those whom we serve."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_1",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nposed by adversaries that wield Al. At the same time, we must also ensure that our use of Al is responsible and trustworthy, that it is rigorously tested to be effective, that it safeguards privacy, civil rights, and civil liberties while avoiding inappropriate biases, and to the extent possible, that it is transparent and explainable to those whom we serve. This Policy Statement guides Department of Homeland Security (OHS) Operational and Support Components (hereafter referred to as \"Components\") and directs actions that all Components shall undertake to establish policy and practices governing the acquisition and use of Artificial Intelligence (Al) and Machine Learning (ML) technology within the Department. This Policy Statement is the initial step in the Department's implementation of Title LXXII, Subtitle B, Section 7224(b) of the Fiscal Year 2023 National Defense Authorization Act (NOAA) (Pub. L. 117-263). This Policy Statement, and the actions it directs. are in addition to my April 20, 2023, memorandum establishing a OHS Artificial Intelligence Task Force (AITF) that will advance several specific mission applications of AI/ML to effectively address many of the Depa1tment's toughest administrative and operational challenges. www.dhs .gov Acquisition and Use of Artificial Intelligence and Machine Leaming Technologies by DHS Components Page 2 II."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_2",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nthe actions it directs. are in addition to my April 20, 2023, memorandum establishing a OHS Artificial Intelligence Task Force (AITF) that will advance several specific mission applications of AI/ML to effectively address many of the Depa1tment's toughest administrative and operational challenges. www.dhs .gov Acquisition and Use of Artificial Intelligence and Machine Leaming Technologies by DHS Components Page 2 II. Standards Al and its sub-disciplines (such as ML) offer DHS advanced capabilities to inform critical missions to protect and secure our nation. These capabilities, both existing and emerging, can help the Department meet homeland security mission requirements while safeguarding privacy. civil rights, and civil liberties. The use of these capabilities will become more common as technological systems at DHS, and throughout our nation, increasingly rely on advances made in applied Al. The Department must capitalize on the advances in AI technology to further the DHS mission, while adhering to the principles, values, and policies that guide the Department. Principles AI technologies enhance the Department's ability to perform vital missions and to counter threats to the security of the public. As AI technology evolves and improves, the role of AI in mission activities will become more effective and prominent."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_3",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nin AI technology to further the DHS mission, while adhering to the principles, values, and policies that guide the Department. Principles AI technologies enhance the Department's ability to perform vital missions and to counter threats to the security of the public. As AI technology evolves and improves, the role of AI in mission activities will become more effective and prominent. Further, the Department will leverage the benefits of Al to transform how DHS delivers services, improving and enriching the public's experience when individuals engage with the Department, and strengthening customer service and efficiency in many of our mission sets. Along with the benefits, the rapid evolution of applied AI and its adoption by the Department will present new challenges. To achieve the rapid and comprehensive incorporation of AI into the larger DHS enterprise, it is imperative that our internal policies and governance keep pace with this rapid advancement to guarantee effective oversight of the acquisition and use of Al. The policies, updated processes and procedures, and an appropriate oversight framework articulated in this Policy Statement will be driven by the following set of principles."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_4",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\ncomprehensive incorporation of AI into the larger DHS enterprise, it is imperative that our internal policies and governance keep pace with this rapid advancement to guarantee effective oversight of the acquisition and use of Al. The policies, updated processes and procedures, and an appropriate oversight framework articulated in this Policy Statement will be driven by the following set of principles. These principles are tailored to activities enabled by AI, but they are also consistent with core values of the Department and existing governance of all technology-dependent activities within the DHS enterprise: • DHS systems, programs, and activities using AI will conform to the requirements of Executive Order 13960, Promoting the Use of Trustworthy Artificial Intelligence in the Federal Government (December 3, 2020), with particular attention to continued Component participation in the Al Use Case Inventory process, and adherence to the Principles for Use of AI in Government, articulated in Section 3 of that Order. • DHS will only acquire and use AI in a manner that is consistent with the Constitution and all other applicable laws and policies, including those addressing privacy, civil rights, and civil liberties, and only where AI adoption improves mission effectiveness."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_5",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nprocess, and adherence to the Principles for Use of AI in Government, articulated in Section 3 of that Order. • DHS will only acquire and use AI in a manner that is consistent with the Constitution and all other applicable laws and policies, including those addressing privacy, civil rights, and civil liberties, and only where AI adoption improves mission effectiveness. • DHS will not collect, use, or disseminate data used in AI activities, or establish Al - enabled systems that make or support decisions, based on the inappropriate consideration of race, ethnicity, gender, national origin, religion, sexual orientation, gender identity, age, nationality, medical condition, or disability. DHS will continually strive to minimize inappropriate bias utilizing standards required by law and policy. Acquisition and Use of Artificial Intelligence and Machine Leaming Technologies by DHS Components Page 3 • DHS, with external assistance where appropriate, will test and validate AI employed in use cases where discriminatory activity or effects may be possible, to ensure impermissible discrimination is not occurring and to aid in advancing equity and fundamentally fair treatment. DHS will also use civil rights evaluation methods, including disparate impact analysis where appropriate, to detect impermissible discriminatory treatment that may result from the use of AI in DHS processes and activities."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_6",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nin use cases where discriminatory activity or effects may be possible, to ensure impermissible discrimination is not occurring and to aid in advancing equity and fundamentally fair treatment. DHS will also use civil rights evaluation methods, including disparate impact analysis where appropriate, to detect impermissible discriminatory treatment that may result from the use of AI in DHS processes and activities. The threshold civil rights and civil liberties compliance question for AI is whether the algorithm complies with the applicable law and policy governing the domain in which the AI is implemented. 1 • DHS will not use AI to improperly profile, target, or to discriminate against any individual, or entity, based on the individual characteristics identified above, as reprisal or solely because of exercising their Constitutional rights. DHS will not use AI technology to enable improper systemic, indiscriminate, or large-scale monitoring, surveillance, or tracking of individuals. • DHS will develop, adopt, and apply a suitable enterprise risk management framework approach to AI, considering existing Federal and non-governmental risk management frameworks. The DHS AI Risk Management Framework will be applied to evaluate all use cases early in their life cycle to assess risk across a broad range of Departmental and public equities, with DHS stakeholders assessing the risk of each use case."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_7",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nand apply a suitable enterprise risk management framework approach to AI, considering existing Federal and non-governmental risk management frameworks. The DHS AI Risk Management Framework will be applied to evaluate all use cases early in their life cycle to assess risk across a broad range of Departmental and public equities, with DHS stakeholders assessing the risk of each use case. Affected stakeholders will provide advice and oversight support to higher risk use cases, as appropriate, to assist the implementers in the mitigation of the identified risks. • DHS will protect AI technologies from cyber-attacks and malicious degradation of algorithmic functions with adherence to Federal and DHS security standards, starting from the baseline of Government and private sector best practices, and developing new methods of addressing the evolving threat. The DHS Information Technology Security Program will update and develop additional security requirements, as appropriate, to protect AI technologies against novel cybersecurity threats and risks introduced by new applications of these technologies. 1 For example, an AI that provides data management assistance in support of law enforcement activities must comply with the legal and DHS policy standards applicable to law enforcement, including restrictions on the inappropriate consideration of the factors listed in bullet three, above."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_8",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nto protect AI technologies against novel cybersecurity threats and risks introduced by new applications of these technologies. 1 For example, an AI that provides data management assistance in support of law enforcement activities must comply with the legal and DHS policy standards applicable to law enforcement, including restrictions on the inappropriate consideration of the factors listed in bullet three, above. It must also be able to comply with the substantive and procedural requirements of the justice system, such as production of the information relied upon in seeking warrants or justifying investigations and arrests, and production of exculpatory materials (\"Brady material\"), consistent with due process protections. Those Components engaged in AI-enabled activities pursuant to Department of Defense or Intelligence Community authorities should of course comply with their respective requirements, but also seek to harmonize their Component's activities to the extent practicable with general DHS policy. Acquisition and Use of Artificial Intelligence and Machine Learning Technologies by OHS Components Page4 • DHS will continue to develop a workforce that understands the strengths and weaknesses of AI embedded in DHS data systems and operations, and that is aware of the benefits and risks of this technology."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_9",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\ntheir Component's activities to the extent practicable with general DHS policy. Acquisition and Use of Artificial Intelligence and Machine Learning Technologies by OHS Components Page4 • DHS will continue to develop a workforce that understands the strengths and weaknesses of AI embedded in DHS data systems and operations, and that is aware of the benefits and risks of this technology. All OHS users of AI are charged with providing human oversight, safeguards, and, where appropriate, review and redress in AI-enabled processes implemented by DHS, to ensure these principles are applied effectively and efficiently in the design, implementation, and end uses of this technology. Oversight Senior leaders at all levels ofDHS, including my Office and the Office of the Deputy Secretary, as well as Component and Office Leaders, are responsible for ensuring the adoption of effective and trustworthy AI at DHS. The NOAA assigns special responsibility to the Offices named in section 7224(b), but all those engaged in this effort bear this responsibility. Together we will make DHS a leader in this space. Actions and Next Steps The Chief Information Officer (CIO) and the Under Secretary for Science and Technology, in consultation with the Chief Procurement Officer (CPO), the Officer for Civil Rights and Civil Liberties, the Chief Privacy Officer, and the Under Secretary for Strategy, Policy, and Plans, will establish an AI Policy Working Group (AIPWG)."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_10",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nDHS a leader in this space. Actions and Next Steps The Chief Information Officer (CIO) and the Under Secretary for Science and Technology, in consultation with the Chief Procurement Officer (CPO), the Officer for Civil Rights and Civil Liberties, the Chief Privacy Officer, and the Under Secretary for Strategy, Policy, and Plans, will establish an AI Policy Working Group (AIPWG). The AIPWG shall: • Assess the need for Components to update or revise their existing policies, procedures and processes for the responsible, ethical, and authorized acquisition and use of AI/ML technologies across the DHS enterprise; • Compile a record of changes in policies and procedures regarding AI completed during the AIPWG's activities; • Develop a Directive and Instruction for Departmental clearance to drive updates that require formal policy changes to proceed; and • Following completion of the Directive and Instruction, make recommendations to my Office regarding any other changes that should be considered to ensure the development of an enduring governance policy and framework for long term, successful, responsible and trustworthy adoption of AI at DHS. Acquisition and Use of Artificial Intelligence and Machine Learning Technologies by DHS Components Page 5 In conducting these tasks, the AIPWG is directed to engage, support, and coordinate with the Al Task Force (AITF) I established on April 20, 2023, as directed below."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_11",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nenduring governance policy and framework for long term, successful, responsible and trustworthy adoption of AI at DHS. Acquisition and Use of Artificial Intelligence and Machine Learning Technologies by DHS Components Page 5 In conducting these tasks, the AIPWG is directed to engage, support, and coordinate with the Al Task Force (AITF) I established on April 20, 2023, as directed below. As the AIPWG works to effect policy change and apply oversight to all OHS AI activities, the AIPWG will consider the following: • The factors for responsible adoption of AI specifically cited by Congress in Section 7224(a) of the FY23 NDAA, including full implementation ofEO 13960, and due consideration of the recommendations of the National Security Commission on AI; • Best practices, risk management frameworks and other comprehensive enterprise AI governance schema established by Federal and private sector organizations; • In coordination with the Office of the General Counsel, the legal requirements impacting the use of AI for the Department; • Applicable regulatory compliance requirements, including the Federal Policy for the Protection of Human Subjects; • Existing policies requiring revision due to the introduction of this new technology; • Recommendations emerging from the ongoing work of the Homeland Security Advisory Council focused on AI in response to my tasking of March 27, 2023; • Resourcing requirements necessary to implement any recommendations or guidance; • Initial and recurring assessments of existing and future Al-enabled systems, with appropriate provisions for research and development activities, prototyping, and trials; • Existing approval and oversight mechanisms that apply to AI; • Creating a foundation for effective oversight by OHS privacy and civil rights and civil liberties subject matter experts at both the Departmental and Component level; and, • Addressing any other topics deemed necessary by the AIPWG with the concurrence of the CIO and the Under Secretary for Science and Technology."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_12",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nExisting approval and oversight mechanisms that apply to AI; • Creating a foundation for effective oversight by OHS privacy and civil rights and civil liberties subject matter experts at both the Departmental and Component level; and, • Addressing any other topics deemed necessary by the AIPWG with the concurrence of the CIO and the Under Secretary for Science and Technology. Acquisition and Use of Artificial Intelligence and Machine Learning Technologies by DHS Components Page 6 Within two weeks of the issuance of this Policy Statement, DHS Components, in coordination with the AIPWG, shall: • Identify a senior career employee or servicemember with appropriate technical expertise to participate in the AIPWG (this may be the same individual assigned to the AITF), including providing the items that follow: o an updated inventory of current use cases of AI within their respective Component; o an accounting of all planned use-cases of AI within their respective Component; and, o any existing Component-level policies or guidance concerning the use of AI. • Ensure AI implementation follows existing applicable law and policy governing the use, acquisition, and security of AI and similar technology and is aligned with Government­ wide and interagency guidance and processes."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_13",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nrespective Component; o an accounting of all planned use-cases of AI within their respective Component; and, o any existing Component-level policies or guidance concerning the use of AI. • Ensure AI implementation follows existing applicable law and policy governing the use, acquisition, and security of AI and similar technology and is aligned with Government­ wide and interagency guidance and processes. Pending completion of the work assigned to the AIPWG, Components shall: • Consult with the AIPWG when requested for purposes of risk assessment of particular use cases, to receive advice on mitigating identified risks (including but not limited to privacy, civil rights and civil liberties risks) and to support policy development; and • Provide feedback to the AIPWG that assists in developing governance policy and practices that are streamlined, tailored to support Component use cases, and incorporated into and aligned with existing processes to the extent practicable."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_14",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nto receive advice on mitigating identified risks (including but not limited to privacy, civil rights and civil liberties risks) and to support policy development; and • Provide feedback to the AIPWG that assists in developing governance policy and practices that are streamlined, tailored to support Component use cases, and incorporated into and aligned with existing processes to the extent practicable. In order to ensure maximum efficiency and cooperation between the AIPWG and the AITF, the AIPWG shall: • Coordinate with the AITF to ensure governance policy development efforts are aligned with and support the mission-focused Al implementation led by the Task Force; • Provide summaries of all relevant activities to AITF leadership monthly; and, • Open any training, speaker events or workforce development opportunities sponsored by the AIPWG to AITF members and shall seek out the views of AITF members and implementers in developing acquisition, use and security policy. Acquisition and Use of Artificial Intelligence and Machine Learning Technologies by DHS Components Page 7 III. Definitions The term \"artificial intelligence\" as used in this document refers to the definition in Section 7223(3) of the NDAA (which incorporates the definition of AI in the John S. McCain National Defense Authorization Act for Fiscal Year 2019, Pub. L. No. 115-232, 132 Stat. 1636, 1697- 98)."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_15",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nArtificial Intelligence and Machine Learning Technologies by DHS Components Page 7 III. Definitions The term \"artificial intelligence\" as used in this document refers to the definition in Section 7223(3) of the NDAA (which incorporates the definition of AI in the John S. McCain National Defense Authorization Act for Fiscal Year 2019, Pub. L. No. 115-232, 132 Stat. 1636, 1697- 98). The term \"machine learning\" refers to a particular artificial intelligence discipline that is the most common artificial intelligence approach at this moment in time, but \"artificial intelligence\" as used in this document, the NDAA for 2023, and the NDAA for 2019, are inclusive of all types of AI that may be used in DHS programs and activities. IV. Further Implementation Upon completion of the work of the AIPWG and the approval of a formal Directive and Instruction on AI/ML, the Department will implement any new procedures devised under the contemplated formal policy documents and implement relevant training on those procedures. The formal Directive and Instructions on Al/ML will be complete no later than 12 months after the publication of this Policy Statement ( 139-96). Further recommendations of the AIPWG falling outside the scope of a Directive/Instruction process shall be made to my office for consideration and future action. Attachments: FY23 NDAA Section 7224 FY19 NDAA Section 238(g) Attachment FY23 NDAA AI REQUIREMENTS LANGUAGE SEC. 7224."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_16",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\non Al/ML will be complete no later than 12 months after the publication of this Policy Statement ( 139-96). Further recommendations of the AIPWG falling outside the scope of a Directive/Instruction process shall be made to my office for consideration and future action. Attachments: FY23 NDAA Section 7224 FY19 NDAA Section 238(g) Attachment FY23 NDAA AI REQUIREMENTS LANGUAGE SEC. 7224. PRINCIPLES AND POLICIES FOR USE OF ARTIFICIAL INTELLIGENCE IN GOVERNMENT. (a) Guidance.--The Director shall, when developing the guidance required under section 104(a) of the AI in Government Act of 2020 (title I of division U of Public Law 116-260), consider-- (1) the considerations and recommended practices identified by the National Security Commission on Artificial Intelligence in the report entitled ``Key Considerations for the Responsible Development and Fielding of AI'', as updated in April 2021; (2) the principles articulated in Executive Order 13960 (85 Fed. Reg."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_17",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nin Government Act of 2020 (title I of division U of Public Law 116-260), consider-- (1) the considerations and recommended practices identified by the National Security Commission on Artificial Intelligence in the report entitled ``Key Considerations for the Responsible Development and Fielding of AI'', as updated in April 2021; (2) the principles articulated in Executive Order 13960 (85 Fed. Reg. 78939; relating to promoting the use of trustworthy artificial intelligence in Government); and (3) the input of-- (A) the Administrator of General Services; (B) relevant interagency councils, such as the Federal Privacy Council, the Chief Financial Officers Council, the Chief Information Officers Council, and the Chief Data Officers Council; (C) other governmental and nongovernmental privacy, civil rights, and civil liberties experts; (D) academia; (E) industry technology and data science experts; and (F) any other individual or entity the Director determines to be appropriate."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_18",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\n(B) relevant interagency councils, such as the Federal Privacy Council, the Chief Financial Officers Council, the Chief Information Officers Council, and the Chief Data Officers Council; (C) other governmental and nongovernmental privacy, civil rights, and civil liberties experts; (D) academia; (E) industry technology and data science experts; and (F) any other individual or entity the Director determines to be appropriate. (b) Department Policies and Processes for Procurement and Use of Artificial Intelligence-enabled systems.--Not later than 180 days after the date of enactment of this Act-- (1) the Secretary of Homeland Security, with the participation of the Chief Procurement Officer, the Chief Information Officer, the Chief Privacy Officer, and the Officer for Civil Rights and Civil Liberties of the Department and any other person determined to be relevant by the Secretary of Homeland Security, shall issue policies and procedures for the Department related to-- (A) the acquisition and use of artificial intelligence; and (B) considerations for the risks and impacts related to artificial intelligence-enabled systems, including associated data of machine learning systems, to ensure that full consideration is given to-- (i) the privacy, civil rights, and civil liberties impacts of artificial intelligence-enabled systems; and (ii) security against misuse, degradation, or rending inoperable of artificial intelligence-enabled systems; and (2) the Chief Privacy Officer and the Officer for Civil Rights and Civil Liberties of the Department shall report to Congress on any additional staffing or funding resources that may be required to carry out the requirements of this subsection."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_19",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nliberties impacts of artificial intelligence-enabled systems; and (ii) security against misuse, degradation, or rending inoperable of artificial intelligence-enabled systems; and (2) the Chief Privacy Officer and the Officer for Civil Rights and Civil Liberties of the Department shall report to Congress on any additional staffing or funding resources that may be required to carry out the requirements of this subsection. (c) Inspector General.--Not later than 180 days after the date of enactment of this Act, the Inspector General of the Department shall identify any training and investments needed to enable employees of the Office of the Inspector General to continually advance their understanding of-- (1) artificial intelligence systems; (2) best practices for governance, oversight, and audits of the use of artificial intelligence systems; and (3) how the Office of the Inspector General is using artificial intelligence to enhance audit and investigative capabilities, including actions to-- (A) ensure the integrity of audit and investigative results; and (B) guard against bias in the selection and conduct of audits and investigations."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_20",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\n(2) best practices for governance, oversight, and audits of the use of artificial intelligence systems; and (3) how the Office of the Inspector General is using artificial intelligence to enhance audit and investigative capabilities, including actions to-- (A) ensure the integrity of audit and investigative results; and (B) guard against bias in the selection and conduct of audits and investigations. (d) Artificial Intelligence Hygiene and Protection of Government Information, Privacy, Civil Rights, and Civil Liberties.-- (1) Establishment.--Not later than 1 year after the date of enactment of this Act, the Director, in consultation with a working group consisting of members selected by the Director from appropriate interagency councils, shall develop an initial means by which to-- (A) ensure that contracts for the acquisition of an artificial intelligence system or service-- (i) align with the guidance issued to the head of each agency under section 104(a) of the AI in Government Act of 2020 (title I of division U of Public Law 116-260); (ii) address protection of privacy, civil rights, and civil liberties; (iii) address the ownership and security of data and other information created, used, processed, stored, maintained, disseminated, disclosed, or disposed of by a contractor or subcontractor on behalf of the Federal Government; and (iv) include considerations for securing the training data, algorithms, and other components of any artificial intelligence system against misuse, unauthorized alteration, degradation, or rendering inoperable; and (B) address any other issue or concern determined to be relevant by the Director to ensure appropriate use and protection of privacy and Government data and other information."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_21",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nbehalf of the Federal Government; and (iv) include considerations for securing the training data, algorithms, and other components of any artificial intelligence system against misuse, unauthorized alteration, degradation, or rendering inoperable; and (B) address any other issue or concern determined to be relevant by the Director to ensure appropriate use and protection of privacy and Government data and other information. (2) Consultation.--In developing the considerations under paragraph (1)(A)(iv), the Director shall consult with the Secretary of Homeland Security, the Secretary of Energy, the Director of the National Institute of Standards and Technology, and the Director of National Intelligence. (3) Review.--The Director- - (A) should continuously update the means developed under paragraph (1); and (B) not later than 2 years after the date of enactment of this Act and not less frequently than every 2 years thereafter, shall update the means developed under paragraph (1). 2 FY23 NDAA AI REQUIREMENTS LANGUAGE (4) Briefing.--The Director shall brief the appropriate congressional committees-- (A) not later than 90 days after the date of enactment of this Act and thereafter on a quarterly basis until the Director first implements the means developed under paragraph (1); and (B) annually thereafter on the implementation of this subsection. (5) Sunset.--This subsection shall cease to be effective on the date that is 5 years after the date of enactment of this Act. SEC. 7225."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_22",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nafter the date of enactment of this Act and thereafter on a quarterly basis until the Director first implements the means developed under paragraph (1); and (B) annually thereafter on the implementation of this subsection. (5) Sunset.--This subsection shall cease to be effective on the date that is 5 years after the date of enactment of this Act. SEC. 7225. AGENCY INVENTORIES AND ARTIFICIAL INTELLIGENCE USE CASES. (a) Inventory.--Not later than 60 days after the date of enactment of this Act, and continuously thereafter for a period of 5 years, the Director, in consultation with the Chief Information Officers Council, the Chief Data Officers Council, and other interagency bodies as determined to be appropriate by the Director, shall require the head of each agency to-- (1) prepare and maintain an inventory of the artificial intelligence use cases of the agency, including current and planned uses; (2) share agency inventories with other agencies, to the extent practicable and consistent with applicable law and policy, including those concerning protection of privacy and of sensitive law enforcement, national security, and other protected information; and (3) make agency inventories available to the public, in a manner determined by the Director, and to the extent practicable and in accordance with applicable law and policy, including those concerning the protection of privacy and of sensitive law enforcement, national security, and other protected information."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_23",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nof privacy and of sensitive law enforcement, national security, and other protected information; and (3) make agency inventories available to the public, in a manner determined by the Director, and to the extent practicable and in accordance with applicable law and policy, including those concerning the protection of privacy and of sensitive law enforcement, national security, and other protected information. (b) Central Inventory.--The Director is encouraged to designate a host entity and ensure the creation and maintenance of an online public directory to-- (1) make agency artificial intelligence use case information available to the public and those wishing to do business with the Federal Government; and (2) identify common use cases across agencies. (c) Sharing.--The sharing of agency inventories described in subsection (a)(2) may be coordinated through the Chief Information Officers Council, the Chief Data Officers Council, the Chief Financial Officers Council, the Chief Acquisition Officers Council, or other interagency bodies to improve interagency coordination and information sharing for common use cases. (d) Department of Defense.--Nothing in this section shall apply to the Department of Defense. SE C. 7226. RAPID PILOT, DEPLOYMENT AND SCALE OF APPLIED ARTIFICIAL INTELLIGENCE CAPABILITIES TO DEMONSTRATE MODERNIZATION ACTIVITIES RELATED TO USE CASES."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_24",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nthe Chief Financial Officers Council, the Chief Acquisition Officers Council, or other interagency bodies to improve interagency coordination and information sharing for common use cases. (d) Department of Defense.--Nothing in this section shall apply to the Department of Defense. SE C. 7226. RAPID PILOT, DEPLOYMENT AND SCALE OF APPLIED ARTIFICIAL INTELLIGENCE CAPABILITIES TO DEMONSTRATE MODERNIZATION ACTIVITIES RELATED TO USE CASES. ( a) Identification of Use Cases.--Not later than 270 days after the date of enactment of this Act, the Director, in consultation with the Chief Information Officers Council, the Chief Data Officers Council, the Chief Financial Officers Council, and other interagency bodies as determined to be appropriate by the Director, shall identify 4 new use cases for the application of artificial intelligence-enabled systems to 3 FY23 NDAA AI REQUIREMENTS LANGUAGE support interagency or intra-agency modernization initiatives that require linking multiple siloed internal and external data sources, consistent with applicable laws and policies, including those relating to the protection of privacy and of sensitive law enforcement, national security, and other protected information."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_25",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nidentify 4 new use cases for the application of artificial intelligence-enabled systems to 3 FY23 NDAA AI REQUIREMENTS LANGUAGE support interagency or intra-agency modernization initiatives that require linking multiple siloed internal and external data sources, consistent with applicable laws and policies, including those relating to the protection of privacy and of sensitive law enforcement, national security, and other protected information. (b) Pilot Program.-- (1) Purposes.--The purposes of the pilot program under this subsection include- - (A) to enable agencies to operate across organizational boundaries, coordinating between existing established programs and silos to improve delivery of the agency mission; (B) to demonstrate the circumstances under which artificial intelligence can be used to modernize or assist in modernizing legacy agency systems; and (C) to leverage commercially available artificial intelligence technologies that-- (i) operate in secure cloud environments that can deploy rapidly without the need to replace existing systems; and (ii) do not require extensive staff or training to build."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_26",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nmission; (B) to demonstrate the circumstances under which artificial intelligence can be used to modernize or assist in modernizing legacy agency systems; and (C) to leverage commercially available artificial intelligence technologies that-- (i) operate in secure cloud environments that can deploy rapidly without the need to replace existing systems; and (ii) do not require extensive staff or training to build. (2) Deployment and pilot.--Not later than 1 year after the date of enactment of this Act, the Director, in coordination with the heads of relevant agencies and Federal entities, including the Administrator of General Services, the Bureau of Fiscal Service of the Department of the Treasury, the Council of the Inspectors General on Integrity and Efficiency, and the Pandemic Response Accountability Committee, and other officials as the Director determines to be appropriate, shall ensure the initiation of the piloting of the 4 new artificial intelligence use case applications identified under subsection (a), leveraging commercially available technologies and systems to demonstrate scalable artificial intelligence-enabled capabilities to support the use cases identified under subsection (a)."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_27",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nIntegrity and Efficiency, and the Pandemic Response Accountability Committee, and other officials as the Director determines to be appropriate, shall ensure the initiation of the piloting of the 4 new artificial intelligence use case applications identified under subsection (a), leveraging commercially available technologies and systems to demonstrate scalable artificial intelligence-enabled capabilities to support the use cases identified under subsection (a). (3) Risk evaluation and mitigation plan.--In carrying out paragraph (2), the Director shall require the heads of agencies to-- (A) evaluate risks in utilizing artificial intelligence systems; and (B) develop a risk mitigation plan to address those risks, including consideration of-- (i) the artificial intelligence system not performing as expected or as designed; (ii) the quality and relevancy of the data resources used in the training of the algorithms used in an artificial intelligence system; (iii) the processes for training and testing, evaluating, validating, and modifying an artificial intelligence system; and (iv) the vulnerability of a utilized artificial intelligence system to unauthorized manipulation or misuse, including the use of data resources that substantially differ from the training data."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_28",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nof the data resources used in the training of the algorithms used in an artificial intelligence system; (iii) the processes for training and testing, evaluating, validating, and modifying an artificial intelligence system; and (iv) the vulnerability of a utilized artificial intelligence system to unauthorized manipulation or misuse, including the use of data resources that substantially differ from the training data. (4) Prioritization.--In carrying out paragraph (2), the Director shall prioritize modernization projects that-- 4 FY23 NDAA AI REQUIREMENTS LANGUAGE (A) would benefit from commercially available privacy-preserving techniques, such as use of differential privacy, federated learning, and secure multiparty computing; and (B) otherwise take into account considerations of civil rights and civil liberties. (5) Privacy protections.--In carrying out paragraph (2), the Director shall require the heads of agencies to use privacy-preserving techniques when feasible, such as differential privacy, federated learning, and secure multiparty computing, to mitigate any risks to individual privacy or national security created by a project or data linkage."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_29",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\n(B) otherwise take into account considerations of civil rights and civil liberties. (5) Privacy protections.--In carrying out paragraph (2), the Director shall require the heads of agencies to use privacy-preserving techniques when feasible, such as differential privacy, federated learning, and secure multiparty computing, to mitigate any risks to individual privacy or national security created by a project or data linkage. (6) Use case modernization application areas.--Use case modernization application areas described in paragraph (2) shall include not less than 1 from each of the following categories: (A) Applied artificial intelligence to drive agency productivity efficiencies in predictive supply chain and logistics, such as-- (i) predictive food demand and optimized supply; (ii) predictive medical supplies and equipment demand and optimized supply; or (iii) predictive logistics to accelerate disaster preparedness, response, and recovery."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_30",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nin paragraph (2) shall include not less than 1 from each of the following categories: (A) Applied artificial intelligence to drive agency productivity efficiencies in predictive supply chain and logistics, such as-- (i) predictive food demand and optimized supply; (ii) predictive medical supplies and equipment demand and optimized supply; or (iii) predictive logistics to accelerate disaster preparedness, response, and recovery. (B) Applied artificial intelligence to accelerate agency investment return and address mission- oriented challenges, such as-- (i) applied artificial intelligence portfolio management for agencies; (ii) workforce development and upskilling; (iii) redundant and laborious analyses; (iv) determining compliance with Government requirements, such as with Federal financial management and grants management, including implementation of chapter 64 of subtitle V of title 31, United States Code; (v) addressing fraud, waste, and abuse in agency programs and mitigating improper payments; or (vi) outcomes measurement to measure economic and social benefits."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_31",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\ndevelopment and upskilling; (iii) redundant and laborious analyses; (iv) determining compliance with Government requirements, such as with Federal financial management and grants management, including implementation of chapter 64 of subtitle V of title 31, United States Code; (v) addressing fraud, waste, and abuse in agency programs and mitigating improper payments; or (vi) outcomes measurement to measure economic and social benefits. (7) Requirements.--Not later than 3 years after the date of enactment of this Act, the Director, in coordination with the heads of relevant agencies and other officials as the Director determines to be appropriate, shall establish an artificial intelligence capability within each of the 4 use case pilots under this subsection that-- (A) solves data access and usability issues with automated technology and eliminates or minimizes the need for manual data cleansing and harmonization efforts; (B) continuously and automatically ingests data and updates domain models in near real-time to help identify new patterns and predict trends, to the extent possible, to help agency personnel to make better decisions and take faster actions; (C) organizes data for meaningful data visualization and analysis so the Government has predictive transparency for situational awareness to improve use case outcomes; 5 FY23 NDAA AI REQUIREMENTS LANGUAGE (D) is rapidly configurable to support multiple applications and automatically adapts to dynamic conditions and evolving use case requirements, to the extent possible; (E) enables knowledge transfer and collaboration across agencies; and (F) preserves intellectual property rights to the data and output for benefit of the Federal Government and agencies and protects sensitive personally identifiable information."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_32",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nNDAA AI REQUIREMENTS LANGUAGE (D) is rapidly configurable to support multiple applications and automatically adapts to dynamic conditions and evolving use case requirements, to the extent possible; (E) enables knowledge transfer and collaboration across agencies; and (F) preserves intellectual property rights to the data and output for benefit of the Federal Government and agencies and protects sensitive personally identifiable information. (c) Briefing.--Not earlier than 270 days but not later than 1 year after the date of enactment of this Act, and annually thereafter for 4 years, the Director shall brief the appropriate congressional committees on the activities carried out under this section and results of those activities. (d) Sunset.--The section shall cease to be effective on the date that is 5 years after the date of enactment of this Act. 6 FY23 NDAA AI REQUIREMENTS LANGUAGE Attachme nt -FY19 NDAA Section 238 (g) JOHN S. MCCAIN NATIONAL DEFENSE AUTHORIZATION ACT FOR FISCAL YEAR 2019 SEC 238 -JOINT ARTIFICIAL INTELLIGENCE RESEARCH, DEVELOPMENT, AND TRANSITION ACTIVITIES. (g)Artificial Intelligence Defined.--In this section, the term ``artificial intelligence'' i ncludes the following: (1)Any artificial system that performs tasks under varying and unpredictable circumstances without significant human oversight, or that can learn from experience and improve performance when exposed to data sets."
  },
  {
    "id": "23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components_chunk_33",
    "text": "Source: 10 23_0913_mgmt_139-06-acquistion-use-ai-technologies-dhs-components.pdf\n\nNATIONAL DEFENSE AUTHORIZATION ACT FOR FISCAL YEAR 2019 SEC 238 -JOINT ARTIFICIAL INTELLIGENCE RESEARCH, DEVELOPMENT, AND TRANSITION ACTIVITIES. (g)Artificial Intelligence Defined.--In this section, the term ``artificial intelligence'' i ncludes the following: (1)Any artificial system that performs tasks under varying and unpredictable circumstances without significant human oversight, or that can learn from experience and improve performance when exposed to data sets. (2)An artificial system developed in computer software, physical hardware, or other context that solves tasks requiring human-like perception, cognition, planning, learning, communication, or physical action. (3)An artificial system designed to think or act like a human, including cognitive architectures and neural networks. (4)A set of techniques, including machine learning, that is designed to approximate a cognitive task. (5)An artificial system designed to act rationally, including an intelligent software agent or embodied robot that achieves goals using perception, planning, reasoning, learning, communicating, decision making, and acting."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_0",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nSeptember 24, 2024 MEMORANDUM FOR THE OFFICE OF MANAGEMENT AND BUDGET (OMB) ISSUED BY: Polly Trottenberg Deputy Secretary of Transportation PREPARED BY: Mike Horton, DBA Acting Chief Artificial Intelligence Officer SUBJECT: US Department of Transportation (DOT) Compliance Plan for OMB Memorand um M-24-10 (September 2024) This Compliance Plan conveys DOT’s approach to achieving consistency with OMB Memorand um M -24-10 Advancing Governance, Innovation, and Risk Management for Agency Use of Artificial Intelligence . The plan aligns with M -24-10’s three main pillars of Strengthening AI Governance, Advancing Responsible AI Innovation, and Managing Risks from AI. The Department will execute this Compliance Plan commensurate with available resources and update the Plan as our understanding, experience, and Federal guidance mature. This Compliance Plan is applicable to all DOT Operating Administrations and Secretarial Offices only to the extent that it is co nsistent with the expressed language contained in 49 U.S.C. 106 and 40110 as applicable to the Federal Aviation Administration and Office of Inspector General. 1. STRENGTHENING AI GOVERNANCE a. General."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_1",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nPlan as our understanding, experience, and Federal guidance mature. This Compliance Plan is applicable to all DOT Operating Administrations and Secretarial Offices only to the extent that it is co nsistent with the expressed language contained in 49 U.S.C. 106 and 40110 as applicable to the Federal Aviation Administration and Office of Inspector General. 1. STRENGTHENING AI GOVERNANCE a. General. Internal AI stakeholders in the Office of the Secretary and the Operating Administrations will create and upda te Departmental AI-related principles, guidelines, and policies to align with this Compliance Plan to include the: •AI Strategic Plan, •AI Minimum Risk Management for Safety -Impacting and Rights -Impacting Use Cases, •AI Governance Structure, •IT Privacy, Records Management, Cybersecurity, and Data policy and guidance, •ITIM 2023 -005 AI Use Case Inventory Policy, and •Generative AI Use Guidance. b. AI Governance Body. DOT’s Non -Traditional and Emerging Transportation Technology (NETT) Council serves as the Department’s AI Governance Board. The Council comprises the Secretary (ex officio), Deputy Secretary (chair), Und er Secretary of Transportation for Policy (vice chair), and other senior Departmental leaders. 2 The NETT Council was established in December 2018 as an internal DOT vetting body for new and emerging transportation technologies that are not yet established enough to fit into obvious modal categories or require new policy approaches."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_2",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\ncomprises the Secretary (ex officio), Deputy Secretary (chair), Und er Secretary of Transportation for Policy (vice chair), and other senior Departmental leaders. 2 The NETT Council was established in December 2018 as an internal DOT vetting body for new and emerging transportation technologies that are not yet established enough to fit into obvious modal categories or require new policy approaches. In April 2024, DOT initiated updates to the Council’s membership and charter to reflect its additiona l role of serving as the Department’s AI Governance Board to govern the use of AI, remove barriers to the use of AI, and manage its inherent risks. The NETT Council first met in its capacity as DOT’s AI Governance Board in April 2024 and will continue mee ting in this capacity at least twice annually with those meeting chaired by the Deputy Secretary and vice - chaired by the Chief Artificial Intelligence Officer (CAIO). DOT will also continue convening the NETT Council outside of the AI Governance Board capacity to satisfy other needs and requirements , as appropriate . The NETT Council will fulfill its role as DOT’s AI Governance Board through the following functions: •Review and approv e all AI governance structures, processes, policies, and guidance. •Approv e criteria for the CAIO’s exclusion of AI use cases from dissemination in the Public Use Case Inventory, including mission -sensitive, safety -sensitive, and exploratory, experimental, and unvalidated research scenarios."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_3",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\n. The NETT Council will fulfill its role as DOT’s AI Governance Board through the following functions: •Review and approv e all AI governance structures, processes, policies, and guidance. •Approv e criteria for the CAIO’s exclusion of AI use cases from dissemination in the Public Use Case Inventory, including mission -sensitive, safety -sensitive, and exploratory, experimental, and unvalidated research scenarios. •Approv e criteria for designation of operational AI use cases as safety -impacting or rights - impacting. •Incorporat e external expert viewpoints to broaden the Council’s perspective on technical, ethics, civil rights, workforce, and transportation -sector specific AI challenges, implications, and best practices in accordance with applicable law. These external collaboration efforts currently include the Department’s Advanced Research Projects Agency – Infrastructure (ARPA -I) Request for Information (RFI) for Opportunities and Challenges of Artificial Intelligence (AI) in Transportation, released on May 3, 2024. •Govern the establishment and providing oversight for the NETT Council AI Coordination and Activities Working Group and the Safety, Rights, and Security Review Advisory Committee."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_4",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nThese external collaboration efforts currently include the Department’s Advanced Research Projects Agency – Infrastructure (ARPA -I) Request for Information (RFI) for Opportunities and Challenges of Artificial Intelligence (AI) in Transportation, released on May 3, 2024. •Govern the establishment and providing oversight for the NETT Council AI Coordination and Activities Working Group and the Safety, Rights, and Security Review Advisory Committee. NETT Council AI Coordination and Activities Working Group (AICA Working Group) The NETT Council established the AI Coordination and Activities Working Group to support the CAIO in meeting M -24-10 coordination and AI activity tracking requirements and contribute to collaboration on AI compliance, governance, and guidance documents. This working group is chaired by the CAIO and vice -chaired by representatives from the Office of the Assistant Secretary for Transportation Policy (OST -P) and the Office of the Assistant Secretary for Research and Technology (OST - R)."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_5",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nin meeting M -24-10 coordination and AI activity tracking requirements and contribute to collaboration on AI compliance, governance, and guidance documents. This working group is chaired by the CAIO and vice -chaired by representatives from the Office of the Assistant Secretary for Transportation Policy (OST -P) and the Office of the Assistant Secretary for Research and Technology (OST - R). Members include representation from the Office of the Chief Information Officer (OCIO) responsible for cybersecurity, IT infrastructure, privacy, and records management; other areas within the Office of the Secretary of Transportation responsible for civil rights, human resources, budget, and training; the Office of General Counsel; O perating Administration (OA) representatives responsible for accelerating and helping guide AI development and safe adoption; and representatives from other research and statistical initiatives. 3 AI Safety, Rights, and Security Review Advisory Committee (SR 2 Committee) The NETT Council also e stablished the SR2 Committee to assist the CAIO in reviewing and approving the operational deployment of all safety -impacting and rights -impacting AI use cases . The SR2 Committee is also responsible for performing the Security Review required by Executive Order 14110 Section 4.7(a) before AI data, custom code, and models are shared with the public. This Committee is chaired by the CAIO."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_6",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nCommittee to assist the CAIO in reviewing and approving the operational deployment of all safety -impacting and rights -impacting AI use cases . The SR2 Committee is also responsible for performing the Security Review required by Executive Order 14110 Section 4.7(a) before AI data, custom code, and models are shared with the public. This Committee is chaired by the CAIO. Committee members include representatives from the Office of the Secretary (OST) responsible for safety, security, civil rights, privacy, and data, and relevant re presentatives from the sponsoring AI use case OA. c. AI Acceleration Infrastructure. The CAIO, in collaboration with the OCIO and AICA Working Group, will accelerate safe, secure, and equitable AI development through leading -edge and best - practic e compliance tools, technology, procedures, and education that will harness AI developer creativity, reduce barriers, and ensure continual risk management and co mpliance, especially for safety -impacting and rights -impacting use cases. The AI Accelerator Roadmap provides OA developers with expedited access to a secure laboratory environment for experimentation with potential solutions to critical operational challenges and to robust development, testing, and depl oyment environments. The AI Accelerator Roadmap also provides researchers and their external research partners with their own secure access to approved state -of-the-art AI functionality."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_7",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nrights -impacting use cases. The AI Accelerator Roadmap provides OA developers with expedited access to a secure laboratory environment for experimentation with potential solutions to critical operational challenges and to robust development, testing, and depl oyment environments. The AI Accelerator Roadmap also provides researchers and their external research partners with their own secure access to approved state -of-the-art AI functionality. The AI Support and Collaboration Center provides technical and non -technical employees with tools to educate themselves about AI capab ilities and risks, get inspired through best -in-class Government and private sector use cases, collaborate with AI workgroups and communities of practice, partner with Department subject matter experts, and follow the AI Accelerator Roadmap to turn their A I concept into operational reality. AI Accelerator Roadmap i.Transportation Use Case Knowledge Repository (TrUCKR). TrUCKR is the CAIO platform for tracking the Department’s AI use case development, maturity, assessments, 4 clearances, risk eval uations and mitigations, and authorities to operate from conception through retirement. Operational use case development, maturity, and risk compliance are driven and sponsored by each OA and Secretarial Office in coordination with the CAIO . Research use case development, maturity, and risk compliance are driven and sponsored b y OST -R."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_8",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nuse case development, maturity, assessments, 4 clearances, risk eval uations and mitigations, and authorities to operate from conception through retirement. Operational use case development, maturity, and risk compliance are driven and sponsored by each OA and Secretarial Office in coordination with the CAIO . Research use case development, maturity, and risk compliance are driven and sponsored b y OST -R. Operational use case AI Developers begin their AI Accelerator Roadmap journey by working with their OA to mature the use case for CAIO review, potential inclusion in the Public Use Case Inventory, and approval for initial concept development in the AI Operations Laboratory (OPSLAB). Developers for use cases designated by the CAIO as “research” based on the requirements of OMB M -24-10 and other Federal Use Case Inventory gu idance are directed to OST -R for further development in the Advanced Research and Testing Network as further discussed in the next clause. These research -based use cases are maintained in TrUCKR within the Restricted Use Case Inventory to fulfill OMB reporting requirements under M -24-10 for those use cases. ii.Advanced Research and Testing (ART) Network. The ART Network is the OST-R- controlled and funded IT environments for AI research and development activities. It allows for rapid AI innovati on, exploration, and sharing with external research partners while adhering to OCIO system requirements and CAIO compliance and risk mitigation mandates."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_9",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nOMB reporting requirements under M -24-10 for those use cases. ii.Advanced Research and Testing (ART) Network. The ART Network is the OST-R- controlled and funded IT environments for AI research and development activities. It allows for rapid AI innovati on, exploration, and sharing with external research partners while adhering to OCIO system requirements and CAIO compliance and risk mitigation mandates. A CAIO -led accelerated Authority to Operate (ATO) and system implementation process for emerging technology will provide researchers with essential leading -edge AI capabilities required by M-24-10 Section 4(b). iii.AI Operations Laboratory (OPSLAB). OPSLAB is the CAIO -managed IT environments operated by the OCIO that is segmented from the r est of the Department’s IT infrastructure . OPSLAB provides AI Developers with access to all OCIO -cleared AI functionality for use case experimentation, development and initial data and model risk management identification and mitigation. OPSLAB’s primary pu rpose is to accelerate the determination of the required AI architecture, gain initial CAIO and SR2 Committee use case Authorization to Operate (ATO), and prepare for OCIO IT Spend Plan clearance and funding. All OPSLAB activity is managed and funded by t he sponsoring OA. iv.Transportation AI -enabled Network (TrAIN)."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_10",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nand model risk management identification and mitigation. OPSLAB’s primary pu rpose is to accelerate the determination of the required AI architecture, gain initial CAIO and SR2 Committee use case Authorization to Operate (ATO), and prepare for OCIO IT Spend Plan clearance and funding. All OPSLAB activity is managed and funded by t he sponsoring OA. iv.Transportation AI -enabled Network (TrAIN). The TrAIN supports the rapid deployment of AI solutions by aggregating all DOT AI -enabled development, testing, and production operational environm ents under the CAIO compliance and risk management monitoring umbrella where continuous AI model, AI data, and risk management monitoring will occur. OA and Secretarial Offices can either opt to rapidly develop and deploy their AI solutions within a dedicated OCIO -managed environment or to create new, separate OA operational environments with the required CAIO compliance and risk management functionality by using established OCIO Authority to Operate processes. v.OPEN Data and AI Model Sharing. The CAIO will ensure that operational use case AI data and models that receive SR2 Committee clearance will be shared with the public through established OPEN Data and Code.gov workflows. 5 vi.Use Case Compliance Monitoring. The CAIO, in collaboration with OAs and OST -R, will monitor all AI -enabled environments in the ART Network, OPSLAB, and TrAIN , as well as software that continually reports AI model purpose, impacts, and data usage."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_11",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nthat receive SR2 Committee clearance will be shared with the public through established OPEN Data and Code.gov workflows. 5 vi.Use Case Compliance Monitoring. The CAIO, in collaboration with OAs and OST -R, will monitor all AI -enabled environments in the ART Network, OPSLAB, and TrAIN , as well as software that continually reports AI model purpose, impacts, and data usage. OAs are responsible for using these reports to enforce use case compliance and documented inclusion in TrUCKR . The CAIO will work to ensure t hat the OAs properly resolve use case application, component, and data usage discrepancies. AI Support and Collaboration Center (AISCC) The AISCC is the joint initiative of the CAIO, the Office of Innovation and Engagement (OIE), OST-R, and OCIO . Its mission is to accelerate safe, secure, transformative, and innovative AI solutions and research in DOT through employee education, collaboration, and governance through the following resources: vii.Get Educated. Learn. Provides educatio n videos, links, documents, information, and training on AI concepts and methodologies, as well as risk management considerations and mitigation approaches. viii.Get Inspired. Dream. Provides access to the Department’s Public Use Case Inventory, highlights use case lessons learned and best practices, and links to other Federal and private sector success stories. ix.Join a Community. Collaborate."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_12",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nvii.Get Educated. Learn. Provides educatio n videos, links, documents, information, and training on AI concepts and methodologies, as well as risk management considerations and mitigation approaches. viii.Get Inspired. Dream. Provides access to the Department’s Public Use Case Inventory, highlights use case lessons learned and best practices, and links to other Federal and private sector success stories. ix.Join a Community. Collaborate. Provides listings and contact inform ation for Department, Federal, and private sector AI workgroups and communities and their meeting artifacts where available. x.Find a Subject Matter Expert. Partner. Provides the Department’s subject matter expert listing, contact information, and areas of AI expertise. xi.Follow the AI Accelerator Roadmap Implementation Process. Make it Happen. Provides detailed instructions, expectations, and examples for following the AI Accelerator Roadmap. xii.ASK AISCC. Get Answers. Provides a tool for reques ting support in conceptualizing and operationalizing use cases. d. Public AI Use Case Inventories. The CAIO, in collaboration with OAs and OST -R, will ensure that all AI use cases will be tracked within TrUCKR through the AI Accelerator Roadmap from conception to retirement ."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_13",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nfor following the AI Accelerator Roadmap. xii.ASK AISCC. Get Answers. Provides a tool for reques ting support in conceptualizing and operationalizing use cases. d. Public AI Use Case Inventories. The CAIO, in collaboration with OAs and OST -R, will ensure that all AI use cases will be tracked within TrUCKR through the AI Accelerator Roadmap from conception to retirement . TrUCKR will include comprehensive and com plete use case status and compliance information, including the use case lifecycle stage, designation of rights - impacting or safety -impacting, documentation for risk management activities, and continuous authority to operate evaluations. Through the AI Accelerator Roadmap , the CAIO ensures accountability for all AI use cases by utilizing TrUCKR as the entry point for access to all Departmental AI environments and continuous monitoring within the ART Network and TrAIN to identify AI models and associated data that are not aut horized to operate. The CAIO wil l also ensure that all AI use cases that meet the reporting requirements of Executive Order 13960 Promoting the Use of Trustworthy Artificial Intelligence in Federal 6 Government are identified within TrUCKR and reported in compliance with that order. T he CAIO will also update the Department’s ITIM 2023 -005: US Department of Transportation (DOT) Artificial Intelligence Use Cases Governance to implement this process and align with the recent final OMB guidance on reporting requirements. e."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_14",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\n13960 Promoting the Use of Trustworthy Artificial Intelligence in Federal 6 Government are identified within TrUCKR and reported in compliance with that order. T he CAIO will also update the Department’s ITIM 2023 -005: US Department of Transportation (DOT) Artificial Intelligence Use Cases Governance to implement this process and align with the recent final OMB guidance on reporting requirements. e. Reporting on AI Use Cases Not Subject to Public Inventory. The Department’s AI Governance Board (NETT Council) sets the criteria for complying with Executive Order 13960 Promoting the Use of Trustworthy Artificial Intelligence in the Federal Government . Based on those criteria, the CAIO effectuates determinations for exclusion from the Public Use Case Inventory in TrUCKR. i.Exclusion Process."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_15",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nrequirements. e. Reporting on AI Use Cases Not Subject to Public Inventory. The Department’s AI Governance Board (NETT Council) sets the criteria for complying with Executive Order 13960 Promoting the Use of Trustworthy Artificial Intelligence in the Federal Government . Based on those criteria, the CAIO effectuates determinations for exclusion from the Public Use Case Inventory in TrUCKR. i.Exclusion Process. The CAIO applies the following exclusion criteria compliant with Executive Order 13960 to determine whether to include a use case in the Public Use Case Invent ory before granting operational use case access to TrAIN : A.classified or sensitive, B.used in defense or national security systems as defined in 44 USC 2552(b)(6) (generally not applicable to DOT), C.embedded within standard commercial products, or D.research and development activities that meet the definition of basic research or applied research in M -24-10, where “basic research” is experimental or theoreti cal work undertaken primarily to acquire new knowledge of the underlying foundations of phenomena and observable facts without a specific application towards processes or products in mind, and “applied research” is an original investigation undertaken to acquire new knowledge to determine how a specific practical aim or objective may be met."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_16",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nM -24-10, where “basic research” is experimental or theoreti cal work undertaken primarily to acquire new knowledge of the underlying foundations of phenomena and observable facts without a specific application towards processes or products in mind, and “applied research” is an original investigation undertaken to acquire new knowledge to determine how a specific practical aim or objective may be met. The CAIO, through collaboration with the SR2 Committee, will also exclude from the Public Use Case Inventory AI use cases designated as mission -sensitive, safety -sensit ive, confidential, or otherwise potential targets for malicious interference. ii.Exclusion Reevaluation Process. The CAIO, in collaboration with OAs and the SR2 Committee, will update and revalidate all AI use cases within TrUCKR when that use case is modified but no less frequently than annually. During that update and re validation process, the OA, CAIO, and SR2 Committee will evaluate if the use case exemption to reporting in the Public Use Case Inventory continues to meet the exclusion criteria. 2. ADV ANCING RESPONSIBLE AI INNOV ATION a. Removing Barriers to the Responsib le Use of AI. The Department’s AI Accelerator Roadmap and AISCC provide the foundational tools, systems, best practices, playbooks, resources and procedures to responsibly, safely, and securely enable AI innovation and development. i.Barrier Identi fication and Mitigation."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_17",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nPublic Use Case Inventory continues to meet the exclusion criteria. 2. ADV ANCING RESPONSIBLE AI INNOV ATION a. Removing Barriers to the Responsib le Use of AI. The Department’s AI Accelerator Roadmap and AISCC provide the foundational tools, systems, best practices, playbooks, resources and procedures to responsibly, safely, and securely enable AI innovation and development. i.Barrier Identi fication and Mitigation. Accelerating responsible AI adoption requires vigilance in identifying structural, procedural, educational, and training barriers and reducing compliance and administrative friction during development, all while 7 controlling risks to safety, privacy, accessibility, civil rights , and other rights, and adherence to applicable laws, regulations, and policies. IT Infrastructure The AI Accelerator Roadmap depicts the Department’s IT infrastructure to ensure AI developer access t o software tools, open -source libraries, secure cloud storage, and deployment and monitoring capabilities necessary to rapidly develop, test, and maintain AI applications. A.Advanced Research and Testing (ART) Network. M-24-10 Section 4(a)(v) mandates that the Department provide sufficient AI tools and capacity to support research and development work. The ART Network accelerates AI Developer access to those tools by creating a platform of established, stand -alone, IT - compliant, AI -enabled environments."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_18",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nmonitoring capabilities necessary to rapidly develop, test, and maintain AI applications. A.Advanced Research and Testing (ART) Network. M-24-10 Section 4(a)(v) mandates that the Department provide sufficient AI tools and capacity to support research and development work. The ART Network accelerates AI Developer access to those tools by creating a platform of established, stand -alone, IT - compliant, AI -enabled environments. Th rough a collaboration between OST-R, OCIO, and the CAIO , the ART Network receives a prioritized review of critical and emerging technology platforms in Authorizations to Operate and other release or oversight processes to conform with guidelines discussed in M -24-10 Section 4(b)(iii). B.AI Operations Laboratory (OPSLAB). The OPSLAB mirrors the stand -alone ART Network but focuses instead on operational AI developers for use case experimentation and maturation. Unlike the ART Network, OPSLAB also supports accelerated model compliance, security, and risk management evaluati ons, initial data quality, representativeness, and bias assessments, and the buildout of required system architecture and costing parameters necessary for IT Spend Plan approval, operational environment deployment, and Authorization to Operate. C.Transportat ion AI -enabled Network (TrAIN). The TrAIN aggregates all Department AI -enabled development, test, and production (DTP) operational environments under one umbrella."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_19",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\ncompliance, security, and risk management evaluati ons, initial data quality, representativeness, and bias assessments, and the buildout of required system architecture and costing parameters necessary for IT Spend Plan approval, operational environment deployment, and Authorization to Operate. C.Transportat ion AI -enabled Network (TrAIN). The TrAIN aggregates all Department AI -enabled development, test, and production (DTP) operational environments under one umbrella. The primary environments in TrAIN, typically one for each cloud provider of AI services, a re part of the DTP service. These environments accelerate operational use case deployment, simplify safety, security, and risk monitoring, and reduce administrative friction, costs, and delays created by the need to establish new environments for each use case along with the required AI model and data compliance and risk management surveillance tools. Data The AI Accelerator Roadmap provides the Department with adequate infrastructure to share, curate, and govern data used in training, testing, an d operating AI. This infrastructure includes resources that enable sound data governance and management best practices, including assessing all AI -related datasets for quality, accuracy, functionality, representativeness, and bias."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_20",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nmodel and data compliance and risk management surveillance tools. Data The AI Accelerator Roadmap provides the Department with adequate infrastructure to share, curate, and govern data used in training, testing, an d operating AI. This infrastructure includes resources that enable sound data governance and management best practices, including assessing all AI -related datasets for quality, accuracy, functionality, representativeness, and bias. 8 All AI training dataset s in the research -based ART Network, operations -based OPSLAB, and TrAIN will use commercially available tools and best practices to build trustworthiness and to continually monitor those data for unacceptable bias to help ensure fair, equitable, and inclus ive results that appropriately balance model fairness, performance, and real -world impact. Cybersecurity The AI Accelerator Roadmap also provides researchers and OAs access to AI -enabled environments with established continuously monitored AI mode l Authorizations to Operate. Cybersecurity in these platforms is further enhanced by segregating ART Network and OPSLAB environments from the Department’s operational IT infrastructure. The Department is also developing the ability to prioritize Authoriza tions to Operate and other release authorizations for generative AI and other critical and emerging technologies to accelerate AI research, operational development, and adoption. ii.Generative AI Internal Guidance."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_21",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nto Operate. Cybersecurity in these platforms is further enhanced by segregating ART Network and OPSLAB environments from the Department’s operational IT infrastructure. The Department is also developing the ability to prioritize Authoriza tions to Operate and other release authorizations for generative AI and other critical and emerging technologies to accelerate AI research, operational development, and adoption. ii.Generative AI Internal Guidance. The CAIO, in collaboration with OST-P, OST -R, OCIO, and OAs, is establishing policy, safeguards, and oversight mechanisms that will embrace the benefits of GenAI while mitigating its risks. b. AI Talent. The precursor to accelerated, safe, and secure AI ado ption is the acquisition and maintenance of a well -educated and trained workforce empowered with the skills, resources, guidance, inspiration, creative freedom, and implementation roadmap to stay abreast of evolving AI capabilities and risks and contribute AI-enabled solutions that assist DOT in delivering the world’s leading transportation system. i.AI Talent Acquisition. DOT is looking to increase AI talent throughout the OAs, which includes using all applicable hiring authorities and flexibilities. DO T’s Chief Artificial Intelligence Officer position is established and w ill serve as a central source of information to support other AI recruitment activities throughout the Department."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_22",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nthat assist DOT in delivering the world’s leading transportation system. i.AI Talent Acquisition. DOT is looking to increase AI talent throughout the OAs, which includes using all applicable hiring authorities and flexibilities. DO T’s Chief Artificial Intelligence Officer position is established and w ill serve as a central source of information to support other AI recruitment activities throughout the Department. In addition, DOT is providing support to the Office of Personnel Mana gement in its efforts to better define AI for the Federal workforce including appropriate occupational series and duties to be used for AI positions and position titles. To promote greater understanding of AI and how it impacts workforce planning and hirin g initiatives, a learning session was held for the DOT Human Resources community. This session provided an overview of AI, including AI concepts and terminology, and promoted the use of tagging vacancies on USA Jobs that are AI related to allow potential a pplicants to find the AI related vacancy announcements more easily. ii.Internal AI Training. The AISCC is the centralized, self -service hub for promoting the development of AI talent internally, providing pathways to AI occupations, and assistin g employees affected by the application of AI to their work. An executive learning session was held to level set executives understanding of AI and terminology based on EO 14110."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_23",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nvacancy announcements more easily. ii.Internal AI Training. The AISCC is the centralized, self -service hub for promoting the development of AI talent internally, providing pathways to AI occupations, and assistin g employees affected by the application of AI to their work. An executive learning session was held to level set executives understanding of AI and terminology based on EO 14110. In addition, AI Day showcased AI efforts wi thin DOT and use cases throughout the OAs. The event was open to all DOT employees . 9 c.AI Sharing and Collaboration. DOT is committed to the open sharing of AI custom code, models, and data that promote the reuse and collabo ration with the Federal Government and public to enhance innovation and transparency while maintaining the public’s rights, safety, and security. i.Custom -Developed AI Code. As the world leader in the transportation sector, the CAIO will prioritize the sharin g of custom -developed code, including commonly used packages and functions, models, and model weights, which have potential for reuse by other agencies and the public to the maximum extent possible in compliance with M -24-10 Section 4(d)(i). ii.Public Sha ring. The CAIO will ensure TrAIN -related data, custom code, and models that clear the SR2 Com mittee’s security review as required under Executive Order 14110 Section 4.7(a) are shared with the public. The CAIO will maintain use case security review justification, documen tation, and sharing methodologies in TrUCKR."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_24",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nextent possible in compliance with M -24-10 Section 4(d)(i). ii.Public Sha ring. The CAIO will ensure TrAIN -related data, custom code, and models that clear the SR2 Com mittee’s security review as required under Executive Order 14110 Section 4.7(a) are shared with the public. The CAIO will maintain use case security review justification, documen tation, and sharing methodologies in TrUCKR. The CAIO, in collaboration with the use case owners, will ensure cleared data are shared through established OPEN Data workflows. Custom code will be released through Code.gov using the guidance and best practices found in OMB Memorandum M -16-21, Feder al Source Code Policy: Achieving Efficiency, Transparency, and Innovation through Reusable and Open Source Software (August 8, 2016) , collaboration methods found in Executive Order 14110, the General Services Administration’s AI Community of Practice, and other Federal requirements to include the OST -R-led Public Access Plan for research data. d. Harmonization of Artificial Intelligence Requirements."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_25",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nOMB Memorandum M -16-21, Feder al Source Code Policy: Achieving Efficiency, Transparency, and Innovation through Reusable and Open Source Software (August 8, 2016) , collaboration methods found in Executive Order 14110, the General Services Administration’s AI Community of Practice, and other Federal requirements to include the OST -R-led Public Access Plan for research data. d. Harmonization of Artificial Intelligence Requirements. The CAIO along with other members of the DOT AI community are active collaborators with the Office of Science and Technology Policy (OSTP), the National Institu te of Standards and Technology (NIST), the Chief Artificial Intelligence Officer Council (CAIOC), and other Federal entities that seek to interpret and implement AI management requirements consistently across Federal agencies and create efficiencies and op portunities for sharing resources and best practices. 3. MANAGING RISKS FROM THE USE OF ARTIFICIAL INTELLIGENCE A clear risk management process and documentation system are essential for effectively governing AI risks and ensuring that all use cases are properly monitored. The AI Accelerator Roadmap ensures that all use cases are correctly assessed as earl y as possible in the AI lifecycle. The CAIO makes initial safety -impacting or rights -impacting risk use case determinations during the Use Case Clearance stage before authorization to access the AI Operations Laboratory."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_26",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\ngoverning AI risks and ensuring that all use cases are properly monitored. The AI Accelerator Roadmap ensures that all use cases are correctly assessed as earl y as possible in the AI lifecycle. The CAIO makes initial safety -impacting or rights -impacting risk use case determinations during the Use Case Clearance stage before authorization to access the AI Operations Laboratory. The CAIO re -evaluates that determ ination in the Risk Management Clearance stage before permission is granted for access to TrAIN for development and testing. CAIO and SR2 Committee clearance is required prior to use case advancement into production. Reassessment determinations are condu cted at least annually or when significant use case changes are made. The TrUCKR platform maintains CAIO context -specific and system -specific risk evaluation, reevaluation, determination, reassessment, certification, and reporting documentatio n for each use case. All initial decisions and any changes in determination prompted by significant 10 modifications to the conditions or context in which the AI is used, including the scope, justification, and supporting evidence, will be reported by the CAIO to OMB wi thin 30 days of the decision. In conjunction with M -24-10 Section 5(a)(ii), the CAIO will ensure a summary of each use case determination and waiver, including its justification, will be publicly released as required by Executive Order 13960 Use Case Inventory guidance. a."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_27",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nincluding the scope, justification, and supporting evidence, will be reported by the CAIO to OMB wi thin 30 days of the decision. In conjunction with M -24-10 Section 5(a)(ii), the CAIO will ensure a summary of each use case determination and waiver, including its justification, will be publicly released as required by Executive Order 13960 Use Case Inventory guidance. a. De termining Which Artificial Intelligence Is Presumed to Be Safety -Impacting or Rights - Impacting. When an underlying AI use case status may be safety -impacting or rights -impacting, the CAIO will assess whether the AI application or component output would se rve as a principal basis for a decision or action that will be used in real -world conditions, or significantly influence the outcomes of Department activities or decisions that impact safety or rights. The CAIO will base these assessments on the advi ce of the SR2 Committee using criteria approved by DOT’s AI Governance Board. i.Safety -Impacting and Rights -Impacting Determinations. OAs are responsible for adequately identifying, evaluating, and continually monitoring each AI use case for its potential and realized impact on safety and rights and sufficiently documenting those assessments and reassessments in TrUCKR for CAIO initial determination. The NETT Council’s SR2 Committee advises the CAIO on the final determination for each use case prior to deploy ment. OAs can appeal that the determination to the NETT Council."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_28",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nand continually monitoring each AI use case for its potential and realized impact on safety and rights and sufficiently documenting those assessments and reassessments in TrUCKR for CAIO initial determination. The NETT Council’s SR2 Committee advises the CAIO on the final determination for each use case prior to deploy ment. OAs can appeal that the determination to the NETT Council. The CAIO uses M-24-10 Appendix I: Purposes for Which AI is Presumed to be Safety - Impacting and Rights -Impacting as the general criteria for making these determinations. Through the CAIO’s a nnual review of the evolution of deployment context, risks, benefits, and needs, the CAIO will recommend additional criteria and requirements for approval by the NETT Council. ii.Agency -Developed Minimum Risk Management Practice Waiver Criteria. The Depa rtment does not anticipate any agency -developed minimum risk criteria that would waive use case compliance with minimum risk management practices defined in M -24- 10. iii.Waiver Processes. OAs can request a waiver to minimum risk management requirements a nd provide supporting justification within TrUCKR for consideration by the CAIO and SR2 Committee. All CAIO final waiver decisions will be reviewed by the NETT Council and documented in TrUCKR. b. Implementation of Risk Management Practices and Terminatio n of Non -Compliant AI."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_29",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nin M -24- 10. iii.Waiver Processes. OAs can request a waiver to minimum risk management requirements a nd provide supporting justification within TrUCKR for consideration by the CAIO and SR2 Committee. All CAIO final waiver decisions will be reviewed by the NETT Council and documented in TrUCKR. b. Implementation of Risk Management Practices and Terminatio n of Non -Compliant AI. OAs are responsible for following the AI Accelerator Roadmap, ensuring continuous use case compliance with any minimum risk management requirements for their safety -impacting and rights -impacting use cases throughout the AI lifecycl e, and reporting in TrUCKR any changes in AI application or component impacts on safety or rights for CAIO reassessment. i.Non-Compliant Controls. All research and operational development of AI applications and components will be implemented through the Department’s AI Accelerator Roadmap and included in TrUCKR. All environments within that Roadmap, including the ART Network, OPSLAB , and TrAIN , will deploy AI model and data usage monitoring software to continuously evaluate use case and data usage compli ance as well as 11 minimum risk management compliance for safety -impacting and rights -impacting use cases. OAs are responsible for using these reports to enforce compliance. The CAIO is responsible for ensuring that the OA use case and risk monitoring and re porting responsibilities are met."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_30",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\ndata usage monitoring software to continuously evaluate use case and data usage compli ance as well as 11 minimum risk management compliance for safety -impacting and rights -impacting use cases. OAs are responsible for using these reports to enforce compliance. The CAIO is responsible for ensuring that the OA use case and risk monitoring and re porting responsibilities are met. No safety -impacting or rights -impacting use case will be authorized for deployment if it does not meet and maintain minimum risk management compliance. ii.Non-Compliant Termination. All safety -impacting and rights -impac ting AI applications and components in production will be under a continuous Authority to Operate (ATO) initially issued by the CAIO as part of the CAIO Risk Management Clearance action in the AI Accelerator Roadmap. To receive and maintain continuous AI - model ATO, safety -impacting and rights -impacting use cases will be required to maintain an alternative process that does not depend on the AI -enabled capability. Use cases out of compliance with minimum risk standards, as determined by the CAIO through advisement with the SR2 Committee, will suspend operations and revert to the non -AI process until compliance is reinstituted and the use case is cleared to resume operations by the CAIO or terminated if minimum risk standards cannot be met. c."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_31",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nthe AI -enabled capability. Use cases out of compliance with minimum risk standards, as determined by the CAIO through advisement with the SR2 Committee, will suspend operations and revert to the non -AI process until compliance is reinstituted and the use case is cleared to resume operations by the CAIO or terminated if minimum risk standards cannot be met. c. Minimum Risk P ractices Through the AI Accelerator Roadmap and its associated processes and AI -enabled environments, DOT has the foundation for meeting, documenting, and governing the M -24-10 Section 5(c) minimum risk management practices as follows: •TrUCKR will document use case adherence to minimum risk management tracking requirements throughout the AI use case lifecycle. •OAs will document potential use case exposure to safety -impacting and rights -impacting risks within the initial use case entry into TrUCKR. •During use case maturity in OPSLAB , use cases determined by the CAIO through consultation with the SR2 Committee as safety -impacting or rights -impacting will require the OAs to update TrUCKR with a detailed Minimum Risk Management Mitigation Plan to receive use case CAIO ATOs and begin AI use case development in TrAIN . •Before AI application deployment, the OA must document the completion of the initial Minimum Risk Management Mitigation Plan in TrUCKR to receive CAIO and SR2 Committee use case ATO in TrAIN production."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_32",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nthe OAs to update TrUCKR with a detailed Minimum Risk Management Mitigation Plan to receive use case CAIO ATOs and begin AI use case development in TrAIN . •Before AI application deployment, the OA must document the completion of the initial Minimum Risk Management Mitigation Plan in TrUCKR to receive CAIO and SR2 Committee use case ATO in TrAIN production. •OAs will also need to certify and document continued use case adherence to the Minimum Risk Management Mitigation Plan annually or when significant changes to the conditions or c ontext in which the AI is used to maintain AI use case ATO in TrAIN. 4. DEFINITIONS This document incorporates the following relevant definitions as provided in OMB Memoranda M-24-10 Advancing Governance, Innovation, and Risk Management for Agency Use of Artificial Intelligence : 12 Artificial Intelligence (AI). The term “artificial intellig ence” has the meaning provided in Section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019, which states that “the term ‘artificial intelligence’ includes the following”: 1. Any artificial system that performs tasks under v arying and unpredictable circumstances without significant human oversight, or that can learn from experience and improve performance when exposed to data sets. 2."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_33",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nmeaning provided in Section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019, which states that “the term ‘artificial intelligence’ includes the following”: 1. Any artificial system that performs tasks under v arying and unpredictable circumstances without significant human oversight, or that can learn from experience and improve performance when exposed to data sets. 2. An artificial system developed in computer software, physical hardware, or other context that s olves tasks requiring human -like perception, cognition, planning, learning, communication, or physical action. 3. An artificial system designed to think or act like a human, including cognitive architectures and neural networks. 4. A set of techniques, including machine learning, that is designed to approximate a cognitive task. 5. An artificial system designed to act rationally, including an intelligent software agent or embodied robot that achieves goals using perception, planning, reasoning, learning, communicati ng, decision making, and acting. For the purposes of this memorandum, the following technical context should guide interpretation of the definition above: 1. This definition of AI encompasses, but is not limited to, the AI technical subfields of machine learn ing (including deep learning as well as supervised, unsupervised, and semi -supervised approaches), reinforcement learning, transfer learning, and generative AI. 2."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_34",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\ndecision making, and acting. For the purposes of this memorandum, the following technical context should guide interpretation of the definition above: 1. This definition of AI encompasses, but is not limited to, the AI technical subfields of machine learn ing (including deep learning as well as supervised, unsupervised, and semi -supervised approaches), reinforcement learning, transfer learning, and generative AI. 2. This definition of AI does not include robotic process automation or other systems whose behavi or is defined only by human -defined rules or that learn solely by repeating an observed practice exactly as it was conducted. 3. For this definition, no system should be considered too simple to qualify as covered AI due to a lack of technical complexity (e.g ., the smaller number of parameters in a model, the type of model, or the amount of data used for training purposes). 4. This definition includes systems that are fully autonomous, partially autonomous, and not autonomous, and it includes systems that operate both with and without human oversight. AI Maturity. The term “AI maturity” refers to a Federal Government organization’s capacity to successfully and responsibly adopt AI into their operations and decision -making across the organization, manage its risks , and comply with relevant Federal law, regulation, and policy on AI. AI Model."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_35",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nand not autonomous, and it includes systems that operate both with and without human oversight. AI Maturity. The term “AI maturity” refers to a Federal Government organization’s capacity to successfully and responsibly adopt AI into their operations and decision -making across the organization, manage its risks , and comply with relevant Federal law, regulation, and policy on AI. AI Model. The term “AI model” has the meaning provided in Section 3(c) of Executive Order 14110 that states “a component of an informational system that implements AI technology and uses computational, statistical, or machine -learning techniques to produce outputs from a given set of inputs”. Applied Research. The term “applied research” refers to original investigation undertaken in order to acquire new knowledge to determine the means by which a specific practical aim or objective may be met. 13 Automation Bias. The term “automation bias” refers to the propensity for humans to inordinately favor suggestions from automated decision -making systems and to ignore or fail to seek out contradi ctory information made without automation. Basic Research. The term “basic research” refers to experimental or theoretical work undertaken primarily to acquire new knowledge of the underlying foundations of phenomena and observable facts without a specifi c application towards processes or products in mind. Custom -Developed Code."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_36",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nfrom automated decision -making systems and to ignore or fail to seek out contradi ctory information made without automation. Basic Research. The term “basic research” refers to experimental or theoretical work undertaken primarily to acquire new knowledge of the underlying foundations of phenomena and observable facts without a specifi c application towards processes or products in mind. Custom -Developed Code. The term “custom -developed code” has the meaning provided in Appendix A of OMB Memorandum M -16-21 which states “custom -developed code is code that is first produced in the perform ance of a Federal contract or is otherwise fully funded by the Federal Government. It includes code, or segregable portions of code, for which the Government could obtain unlimited rights under Federal Acquisition Regulations (FAR) Pt. 27 and relevant age ncy FAR Supplements. Custom -developed code also includes code developed by agency employees as part of their official duties. For the purposes of this policy, custom - developed code may include, but is not limited to, code written for software projects, m odules, plugins, scripts, middleware, and APIs; it does not, however, include code that is truly exploratory or disposable in nature, such as that written by a developer experimenting with a new language or library. Data Asset."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_37",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nduties. For the purposes of this policy, custom - developed code may include, but is not limited to, code written for software projects, m odules, plugins, scripts, middleware, and APIs; it does not, however, include code that is truly exploratory or disposable in nature, such as that written by a developer experimenting with a new language or library. Data Asset. The term “data asset” has t he meaning provided in 44 USC § 3502 which states “the term ‘data asset’ means a collection of data elements or data sets that m ay be grouped together.” Equity. The term “equity” has the meaning provided in Section 10(a) of Executive Order 14091 that stat es “the term ‘equity’ means the consistent and systematic treatment of all individuals in a fair, just, and impartial manner, including individuals who belong to communities that often have been denied such treatment, such as Black, Latino, Indigenous and Native American, Asian American, Native Hawaiian, and Pacific Islander persons and other persons of color; members of religious minorities; women and girls; LGBTQI+ persons; persons with disabilities; persons who live in rural areas; persons who live in Un ited States Territories; persons otherwise adversely affected by persistent poverty or inequality; and individuals who belong to multiple such communities.” Generative AI."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_38",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nNative American, Asian American, Native Hawaiian, and Pacific Islander persons and other persons of color; members of religious minorities; women and girls; LGBTQI+ persons; persons with disabilities; persons who live in rural areas; persons who live in Un ited States Territories; persons otherwise adversely affected by persistent poverty or inequality; and individuals who belong to multiple such communities.” Generative AI. The term “generative AI” has the meaning provided in Section 3(p) of Executive Orde r 14110 which states “the term ‘generative AI’ means the class of AI models that emulate the structure and characteristics of input data in order to generate derived synthetic content. This can include images, videos, audio, text, and other digital conten t.” Model Weight. The term “model weight” has the meaning provided in Section 3(u) of Executive Order 14110 that states “the term ‘model weight’ means a numerical parameter within an AI model that helps determine the model’s outputs in response to inputs. ” Open Government Data Asset."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_39",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nsynthetic content. This can include images, videos, audio, text, and other digital conten t.” Model Weight. The term “model weight” has the meaning provided in Section 3(u) of Executive Order 14110 that states “the term ‘model weight’ means a numerical parameter within an AI model that helps determine the model’s outputs in response to inputs. ” Open Government Data Asset. The term “open government data asset” has the meaning provided in 44 USC § 3502 that states “the term ‘open Government data asset’ means a public data asset that is machine -readable; available (or could be made available) in an open format; not encumbered by restrictions, other than intellectual property rights, including under titles 17 and 35, that would impede the use or reuse of such asset; and based on an underlying open standard that is maintained by a standards organization.” Open Source Software. The term “open source software” has the meaning provided in Appendix A of OMB Memorandum M -16-21 that states “Open Source Software (OSS) is software that can be accessed, used, modified, and shared by anyone. OSS is often distributed under licenses that 14 comply with the definition of “Open Source” provided by the Open Source Initiative (https://opensource.org/osd) and/or that meet the definition of “Free Software” provided by the Free Software Foundation (https://www.gnu.org/philosophy/free -sw.html). Rights -Impacting AI."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_40",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\n-16-21 that states “Open Source Software (OSS) is software that can be accessed, used, modified, and shared by anyone. OSS is often distributed under licenses that 14 comply with the definition of “Open Source” provided by the Open Source Initiative (https://opensource.org/osd) and/or that meet the definition of “Free Software” provided by the Free Software Foundation (https://www.gnu.org/philosophy/free -sw.html). Rights -Impacting AI. The term “rights -impacting AI” refers to AI whose output serves as a principal basis for a decision or action concerning a specific individual or entity that has a legal, material, binding, or similarly significant effect on that individual ’s or entity’s: 1. Civil rights, civil liberties, or privacy, including but not limited to freedom of speech, voting, human autonomy, and protections from discrimination, excessive punishment, and unlawful surveillance; 2. Equal opportunities, including equitabl e access to education, housing, insurance, credit, employment, and other programs where civil rights and equal opportunity protections apply; or 3. Access to or the ability to apply for critical government resources or services, including healthcare, financia l services, public housing, social services, transportation, and essential goods and services. Risks from the Use of AI."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_41",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\n2. Equal opportunities, including equitabl e access to education, housing, insurance, credit, employment, and other programs where civil rights and equal opportunity protections apply; or 3. Access to or the ability to apply for critical government resources or services, including healthcare, financia l services, public housing, social services, transportation, and essential goods and services. Risks from the Use of AI. The term “risks from the use of AI” refers to risks related to efficacy, safety, equity, fairness, transparency, accountability, appro priateness, or lawfulness of a decision or action resulting from the use of AI to inform, influence, decide, or execute that decision or action. This includes such risks regardless of whether: 1. The AI merely informs the decision or action, partially automates it, or fully automates it; 2. There is or is not human oversight for the decision or action; 3. It is or is not easily apparent that a decision or action took place, such as when an AI application performs a background task or silently declin es to take an action; or 4. The humans involved in making the decision or action or that are affected by it are or are not aware of how or to what extent the AI influenced or automated the decision or action. While the particular forms of these risks continue to evolve, at least the following factors can create, contribute to, or exacerbate these risks: 1. AI outputs that are inaccurate or misleading; 2."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_42",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nor action or that are affected by it are or are not aware of how or to what extent the AI influenced or automated the decision or action. While the particular forms of these risks continue to evolve, at least the following factors can create, contribute to, or exacerbate these risks: 1. AI outputs that are inaccurate or misleading; 2. AI outputs that are unreliable, ineffective, or not robust; 3. AI outputs that are discriminatory or have a discrimi natory effect; 4. AI outputs that contribute to actions or decisions resulting in harmful or unsafe outcomes, including AI outputs that lower the barrier for people to take intentional and harmful actions; 5. AI being used for tasks to which it is poorly suited or being inappropriately repurposed in a context for which it was not intended; 6. AI being used in a context in which affected people have a reasonable expectation that a human is or should be primarily responsible for a decision or action; and 7. the adversari al evasion or manipulation of AI, such as an entity purposefully inducing AI to misclassify an input. This definition applies to risks specifically arising from using AI and that affect the outcomes of decisions or actions. It does not include all risks a ssociated with AI, such as risks related to the privacy, security, and confidentiality of the data used to train AI or used as inputs to AI models. 15 Safety -Impacting AI."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_43",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nmisclassify an input. This definition applies to risks specifically arising from using AI and that affect the outcomes of decisions or actions. It does not include all risks a ssociated with AI, such as risks related to the privacy, security, and confidentiality of the data used to train AI or used as inputs to AI models. 15 Safety -Impacting AI. The term “safety -impacting AI” refers to AI whose output produces an action or serves as a principal basis for a decision that has the potential to significantly impact the safety of: 1. Human life or well -being, including loss of life, serious injury, bodily harm, biological or chemical harms, occupational hazards, harassment or abuse, or men tal health, including both individual and community aspects of these harms; 2. Climate or environment, including irreversible or significant environmental damage; 3. Critical infrastructure, including the critical infrastructure sectors defined in Presidential Policy Directive 21 or any successor directive and the infrastructure for voting and protecting the integrity of elections; or, 4. Strategic assets or resources, including high -value property and information marked as sensitive or classified by t he Federal Government. Significant Modification."
  },
  {
    "id": "USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_September_2024_chunk_44",
    "text": "Source: 11 USDOT_Compliance_Plan-for-OMB_Memorandum_M-24-10_(September_2024).pdf\n\nenvironment, including irreversible or significant environmental damage; 3. Critical infrastructure, including the critical infrastructure sectors defined in Presidential Policy Directive 21 or any successor directive and the infrastructure for voting and protecting the integrity of elections; or, 4. Strategic assets or resources, including high -value property and information marked as sensitive or classified by t he Federal Government. Significant Modification. The term “significant modification” refers to an update to an AI application or to the conditions or context in which it is used that meaningfully alters the AI’s impact on rights or safety, such as through changing its functionality, underlying structure, or performance such that prior evaluations, training, or documentation become misleading to users, overseers, or individuals affected by the system. This includes significantly changing the context, scope , or intended purpose in which the AI is used."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_0",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nRESEARCH, APPLIED ANALYTICS AND STATISTICS DEPARTMENT OF THE TREASURY INTERNAL REVENUE SERVICE WASHINGTON , DC 20224 March 11, 2025 Control Number: RAAS-10-0325-0001 Expiration Date: March 10, 2027 Affected IRM: Proposed New IRM 10.24.1 (IGM RAAS-10-0524-0001) MEMORANDUM FOR ALL SENIOR EXECUTIVES Reza Rashidi Digitally signed by Reza Rashidi Date: 2025.03.11 12:39:53 -04'00' FROM: Reza Rashidi Acting Chief Data and Analytics Officer (CDAO) and Responsible AI Official (RAIO) SUBJEC T: Interi m Polic y for AI Governance This interi m guidance memorandu m (IGM ) is issued to communicate t hat IG M RAAS-10-0524-0001 for New I RM 10.24.1 , Artifici al Intelligence (AI ) Governance and Principle s is suspended unti l further notice. I t is superseded b y the “I nterim Polic y for AI Governance” prov ided by thi s IGM. The Responsibl e AI Offici al (RAI O) issue s this IGM due t o impact s of executive orders fro m President Donald Trum p on government-wi de directives , processes , and prioritie s for AI governance. T he content of RAAS-10-0524-0001 wil l be rev iewed and updated a s necess ary to ensure alignmen t with new executive order s and directives , and updat ed guidance wil l be iss ued a s soon as practicable. Please distribut e this IGM and attachmen t to al l IRS employees , contractors , and vendor s responsible for developing , procuri ng, usi ng, and monitori ng AI."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_1",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\ns necess ary to ensure alignmen t with new executive order s and directives , and updat ed guidance wil l be iss ued a s soon as practicable. Please distribut e this IGM and attachmen t to al l IRS employees , contractors , and vendor s responsible for developing , procuri ng, usi ng, and monitori ng AI. Purpo se: The R AIO issue s this IGM to ens ure IR S alignmen t with executive orders t hat remain in effec t regardi ng AI governanc e whil e awaiting updated guidanc e as a resul t of E O 14179 on Removing Barrie rs to A meric an Leadershi p in A rtificial Intelligenc e (January 23, 2025). T he Offic e of Management and Budge t (OMB ) will issu e revision s to Memoranda M -24-10 on Advancing Governance , Innovation, and Ris k Managem ent for Agenc y Use of Artifici al Intelligenc e (Marc h 28, 2 024) and M- 24-18 on Advanci ng the Responsible Acquisiti on of Artifici al Intelligenc e in Governme nt (Septem ber 24, 2024). Effect on Othe r Documents : This IGM supersede s RAAS- 10-0524-0001, Interi m Guidanc e for New IRM 10.24.1, Artificial Intelligence (AI) Governance and Principles."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_2",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\ny Use of Artifici al Intelligenc e (Marc h 28, 2 024) and M- 24-18 on Advanci ng the Responsible Acquisiti on of Artifici al Intelligenc e in Governme nt (Septem ber 24, 2024). Effect on Othe r Documents : This IGM supersede s RAAS- 10-0524-0001, Interi m Guidanc e for New IRM 10.24.1, Artificial Intelligence (AI) Governance and Principles. Effective Date: March 11, 2025 Contact : Please send question s or inquiri es related to thi s guidance t o # # Attachment: Interim Po licy for AI Governance cc: FOI A Librar y on IRS.gov Attachment: Interim Policy for AI Governance Manual Transmittal Month DD, YYYY Purpose (1) This transmits proposed new Internal Revenue Manual (IRM) 10.24.1, Interim Policy for Artificial Intelligence (AI) Governance. Material Changes (1) This update to proposed IRM 10.24.1 suspends certain requirements for Internal Revenue Service (IRS) development, implementation, and use of AI, in light of recent executive orders from President Donald Trump. It replaces suspended requirements with an interim policy for AI governance while the IRS awaits additional guidance from the Office of Management and Budget (OMB) and the Department of the Treasury. (2) The table below provides a summary of changes from the prior version of this proposed IRM issued as interim guidance on May 20, 2024 (control number RAAS-10-0524-0001)."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_3",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nTrump. It replaces suspended requirements with an interim policy for AI governance while the IRS awaits additional guidance from the Office of Management and Budget (OMB) and the Department of the Treasury. (2) The table below provides a summary of changes from the prior version of this proposed IRM issued as interim guidance on May 20, 2024 (control number RAAS-10-0524-0001). IRM Subsection Summary of Changes 10.24.1.1, (1) Replaced content of 10.24.1.1.1, Background, with a Program Scope description of recent executive orders affecting AI governance and Objectives and explaining the need for this policy change. (2) Updated 10.24.1.1.2, Authority, to reflect executive orders that remain in effect which direct activities related to AI governance. Removed authorities that have been rescinded or are currently under revision, along with superfluous authorities not specifically directing AI governance activities. (3) Updated 10.24.1.1.3, Roles and Responsibilities, to explain the designation of the Chief Data and Analytics Officer (CDAO) as the IRS Responsible AI Official (RAIO). That explanation was previously included in Exhibit 10.24.1-1, Terms and Acronyms. Additionally, removed description of the Data and Analytics Strategic Integration Board (DASIB), as their role in AI governance is being suspended, and removed description of the AI Governance Project Management Office (PMO), which is referred to more generally in this revised policy as the CDAO team."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_4",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nAI Official (RAIO). That explanation was previously included in Exhibit 10.24.1-1, Terms and Acronyms. Additionally, removed description of the Data and Analytics Strategic Integration Board (DASIB), as their role in AI governance is being suspended, and removed description of the AI Governance Project Management Office (PMO), which is referred to more generally in this revised policy as the CDAO team. 10.24.1.2, Principles for Use of AI (1) Renamed subsection and clarified in paragraph 1 that the IRS follows the “Principles for Use of AI in Government” outlined in EO 13960. 10.24.1.3, AI Use (1) Renumbered subsection (previously 10.24.1.4). Consolidated Case Inventory and reordered content for clarity. (2) Updated paragraph 2 to provide additional details regarding project team responsibilities for entering and maintaining AI use case entries in the inventory. 10.24.1.4, AI (1) Renumbered subsection (previously 10.24.1.5). Governance (2) Added paragraphs 2-5 to define operational use of AI and to explain the new interim policy governing approval for operational use of AI. (3) Renumbered subsection 10.24.1.4.1 (previously 10.24.1.5.2). In that subsection, paragraph 1 adds the authority requiring model card and datasheet artifacts, and sub-points (a) and (b) Any text marked with a # is designated Official Use Only Page 1 of 11 Attachment: Interim Policy for AI Governance clarify the number of Model Card and Datasheet artifacts required per use case."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_5",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nAI. (3) Renumbered subsection 10.24.1.4.1 (previously 10.24.1.5.2). In that subsection, paragraph 1 adds the authority requiring model card and datasheet artifacts, and sub-points (a) and (b) Any text marked with a # is designated Official Use Only Page 1 of 11 Attachment: Interim Policy for AI Governance clarify the number of Model Card and Datasheet artifacts required per use case. Paragraphs 2-5 explain project team and CDAO responsibilities for submission, revision, and review of Model Card and Datasheet artifacts. (4) Removed description of artifacts outlined in previous subsection 10.24.1.5.2 that are not required at this time. 10.24.1.5, Protection of Taxpayer Rights (1) Renamed and renumbered subsection (previously 10.24.1.9, Ethical Standards and Protection of Taxpayer Rights). (2) Updated to remove citation of rescinded EO 14110. 10.24.1.6, Privacy and Security Requirements (1) Renumbered subsection (previously 10.24.1.10). (2) Added reference to IRM 10.5.1.6, Practical Privacy Policy. Exhibit 10.24.1-1, Terms and Acronyms (1) Removed terms and definitions from rescinded EO 14110 and from OMB M-24-10, which is currently under revision. (2) Removed terms and acronyms not used in this revised policy. Exhibit 10.24.1-2, Related Resources (1) Removed references that have been rescinded or are currently under revision, along with superfluous authorities not specifically directing AI governance activities."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_6",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nExhibit 10.24.1-1, Terms and Acronyms (1) Removed terms and definitions from rescinded EO 14110 and from OMB M-24-10, which is currently under revision. (2) Removed terms and acronyms not used in this revised policy. Exhibit 10.24.1-2, Related Resources (1) Removed references that have been rescinded or are currently under revision, along with superfluous authorities not specifically directing AI governance activities. (3) The supplementary table below identifies content from the prior version of this proposed IRM that was removed in this update. IRM Subsection (Prior Version) Reason for Removal 10.24.1.3, Content relied on rescinded EO 14110 and on OMB Responsible Artificial Memorandum M-24-10, which is currently under revision. Intelligence Official Role of RAIO was incorporated in 10.24.1.1.2, Roles and (RAIO) Responsibilities. 10.24.1.5.1, AI AI governance roles and responsibilities for the DASIB and Governance Key the AI Assurance Team (AIAT) are suspended pending Stakeholders and additional guidance from OMB and the Department of the Responsibilities Treasury regarding AI governance activities. Remaining roles and responsibilities are incorporated under 10.24.1.1.3, Roles and Responsibilities. 10.24.1.5.3, AI Governance Process for AI Use Cases Superseded by this revised policy. See subsection 10.24.1.4, AI Governance. 10.24.1.6, AI Sharing and Collaboration Content relied on rescinded EO 14110 and on OMB Memorandum M-24-10, which is currently under revision."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_7",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nthe Department of the Responsibilities Treasury regarding AI governance activities. Remaining roles and responsibilities are incorporated under 10.24.1.1.3, Roles and Responsibilities. 10.24.1.5.3, AI Governance Process for AI Use Cases Superseded by this revised policy. See subsection 10.24.1.4, AI Governance. 10.24.1.6, AI Sharing and Collaboration Content relied on rescinded EO 14110 and on OMB Memorandum M-24-10, which is currently under revision. 10.24.1.7, Determining Whether AI is Safety-Impacting or Rights-Impacting Content relied on rescinded EO 14110 and on OMB Memorandum M-24-10, which is currently under revision. 10.24.1.8, Minimum Practices Before and During Use of Safety-Impacting or Rights- Impacting AI Content relied on rescinded EO 14110 and on OMB Memorandum M-24-10, which is currently under revision. Any text marked with a # is designated Official Use Only Page 2 of 11 Attachment: Interim Policy for AI Governance Effect on Other Documents (1) This update to proposed new IRM 10.24.1 supersedes a prior version of this proposed IRM issued as interim guidance on May 20, 2024 (RAAS-10-0524-0001). Audience (1) IRM 10.24.1, Interim Policy for AI Governance, will be distributed to all personnel responsible for developing, procuring, using, and monitoring AI. This policy applies to all IRS employees, contractors, and vendors."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_8",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nOther Documents (1) This update to proposed new IRM 10.24.1 supersedes a prior version of this proposed IRM issued as interim guidance on May 20, 2024 (RAAS-10-0524-0001). Audience (1) IRM 10.24.1, Interim Policy for AI Governance, will be distributed to all personnel responsible for developing, procuring, using, and monitoring AI. This policy applies to all IRS employees, contractors, and vendors. Effective Date (MM-DD-YYYY) Signature Reza Rashidi Acting Chief Data and Analytics Officer IRM Part 10 Security, Privacy, Assurance and Artificial Intelligence Chapter 24 Artificial Intelligence Section 1 Interim Policy for AI Governance Any text marked with a # is designated Official Use Only Page 3 of 11 Table of Contents Section 1 Interim Policy for AI Governance 00 10.24.1.1 Program Scope and Objectives 00 10.24.1.1.1 Background 00 10.24.1.1.2 Authority 00 10.24.1.1.3 Roles and Responsibilities 00 10.24.1.1.4 Program Management and Review 00 10.24.1.1.5 Program Controls 00 10.24.1.1.6 Terms and Acronyms 00 10.24.1.1.7 Related Resources 00 10.24.1.2 Principles for Use of AI 00 10.24.1.3 AI Use Case Inventory 00 10.24.1.4 AI Governance 00 10.24.1.4.1 AI Use Case Artifacts 00 10.24.1.5 Protection of Taxpayer Rights 00 10.24.1.6 Privacy and Security Requirements 00 List of Exhibits Exhibit 10.24.1-1 Terms and Acronyms 00 Exhibit 10.24.1-2 Related Resources 00 Attachment: Interim Policy for AI Governance 10.24.1.1 (MM-DD-YYYY) Program Scope and Objectives (1) Overview: This Internal Revenue Manual (IRM) lays the foundation to implement and manage the use of artificial intelligence (AI) within the Internal Revenue Service (IRS)."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_9",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nRights 00 10.24.1.6 Privacy and Security Requirements 00 List of Exhibits Exhibit 10.24.1-1 Terms and Acronyms 00 Exhibit 10.24.1-2 Related Resources 00 Attachment: Interim Policy for AI Governance 10.24.1.1 (MM-DD-YYYY) Program Scope and Objectives (1) Overview: This Internal Revenue Manual (IRM) lays the foundation to implement and manage the use of artificial intelligence (AI) within the Internal Revenue Service (IRS). (2) Purpose of the Program: The purpose of this program is to develop and publish governance policies to create trust in the use of AI through responsible AI practices, and to ensure compliance with federal mandates. (3) Audience: The provisions within this manual apply to: a) All offices, businesses, operating units, and functional units within the IRS. b) Individuals and organizations having contractual arrangements with the IRS, including employees, contractors, vendors, and outsourcing providers, which use or operate information systems that store, process, or transmit IRS information or connect to an IRS network or system. (4) Policy Owner: Chief Data and Analytics Officer (CDAO), who also serves as the IRS Responsible AI Official (RAIO). (5) Program Owner: CDAO, who also serves as the IRS RAIO. (6) Program Goals: To support the responsible use of AI at the IRS."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_10",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\ninformation systems that store, process, or transmit IRS information or connect to an IRS network or system. (4) Policy Owner: Chief Data and Analytics Officer (CDAO), who also serves as the IRS Responsible AI Official (RAIO). (5) Program Owner: CDAO, who also serves as the IRS RAIO. (6) Program Goals: To support the responsible use of AI at the IRS. 10.24.1.1.1 (MM-DD-YYYY) Background (1) IRS use of AI is governed by executive orders (EOs) and other government-wide guidance and directives, and by direction received from the Department of the Treasury. For example, EO 13859 of February 11, 2019, on Maintaining American Leadership in Artificial Intelligence, called for American leadership in AI research and development and outlined a policy to foster public trust and confidence in AI technologies. EO 13960 of December 8, 2020, on Promoting the Use of Trustworthy Artificial Intelligence in the Federal Government, directed agencies to abide by nine guiding principles for government use of AI and to collect and report an annual AI use case inventory."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_11",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nin AI research and development and outlined a policy to foster public trust and confidence in AI technologies. EO 13960 of December 8, 2020, on Promoting the Use of Trustworthy Artificial Intelligence in the Federal Government, directed agencies to abide by nine guiding principles for government use of AI and to collect and report an annual AI use case inventory. (2) Two January 2025 executive orders from President Trump affect prior AI governance policy outlined in RAAS-10-0524-0001 of May 20, 2024, on Interim Guidance for New IRM 10.24.1, Artificial Intelligence ( AI) Governance and Principles: a) EO 14148 of January 20, 2025, on Initial Rescissions of Harmful Executive Orders and Actions, revoked E O 14110 of October 30, 2023, on Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence. EO 14110 had previously been a primary authority for federal AI governance policy."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_12",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nGuidance for New IRM 10.24.1, Artificial Intelligence ( AI) Governance and Principles: a) EO 14148 of January 20, 2025, on Initial Rescissions of Harmful Executive Orders and Actions, revoked E O 14110 of October 30, 2023, on Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence. EO 14110 had previously been a primary authority for federal AI governance policy. b) EO 14179 of January 23, 2025, on Removing Barriers to American Leadership in Any text marked with a # is designated Official Use Only Page 4 of 11 Attachment: Interim Policy for AI Governance Artificial Intelligence , directed a group of presidential advisors to “review […] all policies, directives, regulations, orders, and other actions taken pursuant to the revoked Executive Order 14110” and to “identify any actions taken pursuant to Executive Order 14110 that are or may be inconsistent with, or present obstacles to, the policy [to sustain and enhance America’s global AI dominance in order to promote human flourishing, economic competitiveness, and national security].” It further directs agency heads to “suspend, revise, or rescind [any agency actions identified by the designated reviewers as inconsistent with new policy]” or to “propose suspending, revising, or rescinding such actions [as appropriate and consistent with applicable law].” If such actions cannot be finalized immediately, agencies are instructed to provide all available exemptions until such action can be finalized."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_13",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nIt further directs agency heads to “suspend, revise, or rescind [any agency actions identified by the designated reviewers as inconsistent with new policy]” or to “propose suspending, revising, or rescinding such actions [as appropriate and consistent with applicable law].” If such actions cannot be finalized immediately, agencies are instructed to provide all available exemptions until such action can be finalized. c )E O 14179 also tasks the Office of Management and Budget (OMB) Director, in c oordination with the Assistant to the President for Science and Technology, to revis e t wo OMB Memoranda within 60 days to make them consistent with the January 2 3 E O: OMB M-24-10 of March 28, 2024 on Advancing Governance, Innovation, an d R isk Management for Agency Use of Artificial Intelligence , and OMB M-24- 18 of S eptember 24, 2024 on Advancing the Responsible Acquisition of Artificial Intelligenc e in G overnment . Both memos were originally issued under the authority of rescind ed E O 141 10. (3)R AAS-10-0524-0001 of May 20, 2024, on Interim Guidance for New IRM 10.24.1 , A rtificial Intelligence (AI) Governance and Principles , is based on EO 13960 and OM B M emorandum M-24-10. While EO 13960 remains in effect, OMB M-24-10 is currently unde r r evision per EO 14179. RAAS-10-0524-0001 is being updated accordingly . 10.24.1.1.2 (MM-DD-YYYY) Authority (1) EO 13859 , Maintaining A merican Leadership in Artificial Intelligence."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_14",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nNew IRM 10.24.1 , A rtificial Intelligence (AI) Governance and Principles , is based on EO 13960 and OM B M emorandum M-24-10. While EO 13960 remains in effect, OMB M-24-10 is currently unde r r evision per EO 14179. RAAS-10-0524-0001 is being updated accordingly . 10.24.1.1.2 (MM-DD-YYYY) Authority (1) EO 13859 , Maintaining A merican Leadership in Artificial Intelligence. (2) EO 13960 , Promoting the Use of Tr ustworthy A rtificial Intelligence in the Federal Government. (3) EO 14179, Removing Barriers to American Leadership in Artific ial Intelligence. 10.24.1.1.3 (MM-DD-YYYY) Roles and Responsibilities (1)T he CDAO acts as the RAIO to oversee IRS implementation of federal A I r equirements, in alignment with direction from the Department of the Treasury. The CDA O is also responsible for coordination of AI governance and assurance activities within the IRS . a)T his designation follows EO 13960 Section 8(c), which directs agencies to appoi nt \" responsible [AI] official(s) at that agency,\" and 2022 OMB guidance titled “Suggeste d P ractices for Assessing Agency AI Use Case Inventory, per EO 13960. ” (2) Senior executives in each business unit are respons ible for conduc ting and managing AI use within their bus iness units in compliance with this IRM and other applicable policies. (3) Executives in each business unit are responsible for following the policies in IRM Any text marked with a # is designated Official Use Only Page 5 of 11 # use."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_15",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nexecutives in each business unit are respons ible for conduc ting and managing AI use within their bus iness units in compliance with this IRM and other applicable policies. (3) Executives in each business unit are responsible for following the policies in IRM Any text marked with a # is designated Official Use Only Page 5 of 11 # use. Business units and program offices may also seek support or guidance from the Attachment: Interim Policy for AI Governance 10.5.2.2, Privacy and Civil Liberties Impact Assessment (PCLIA), to ensure their business units complete a PCLIA when required, such as for systems or projects that involve personally identifiable information (PII). (4) Employees are responsible for complying with this IRM and related IRS AI requirements, guidance, and processes, as well as other relevant information disclos ure laws, regulations, and policies, including Internal Revenue Code (IRC) 6103 and the Priv acy Act. See IRM 11.3, Disclosure of Offic ial Infor mation, and IRM 10.5.6, Privacy Act. (5) Any IRS business unit or program office may contact the CDAO team at # f or information about opportunities and requirements for AI CDAO team for training, communication, and other actions related to the use of AI. 10.24.1.1.4 (MM-DD-YYYY) Program Management and Review (1)U se of AI at the IRS will be managed and reported in accordance with the provisions of t his IRM, subject to applicable laws, policies, and security and privacy protections."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_16",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nf or information about opportunities and requirements for AI CDAO team for training, communication, and other actions related to the use of AI. 10.24.1.1.4 (MM-DD-YYYY) Program Management and Review (1)U se of AI at the IRS will be managed and reported in accordance with the provisions of t his IRM, subject to applicable laws, policies, and security and privacy protections. T he C DAO, as RAIO, will oversee all internal and external reporti ng. 10.24.1.1.5 (MM-DD-YYYY) Program Controls (1)T he Office of the CDAO will monitor authoritative sources of federal guidance fo r r evisions that may affect policies and programs for AI governance at the IRS and will updat e t his IRM and related policies as needed . (2)T he contents of this IRM provide program controls for IRS use of AI . 10.24.1.1.6 (MM-DD-YYYY) Terms and Acronyms (1)R efer to Exhibit 10.24.1-1, Terms and Acronyms, for a list of terms, acronyms, a nd def initions . 10.24.1.1.7 (MM-DD-YYYY) Related Resources (1)R efer to Exhibit 10.24.1-2, Related Resources, for a list of related resources a nd r eferences . 10.24.1.2 (MM-DD-YYYY) Principles for Use of AI (1)T he IRS adheres to the “Principles for Use of AI in Government” outlined in EO 139 60, on P romoting the Use of Trustworthy Artificial Intelligence in the Federal Government (Sec . 3 )."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_17",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\n(1)R efer to Exhibit 10.24.1-2, Related Resources, for a list of related resources a nd r eferences . 10.24.1.2 (MM-DD-YYYY) Principles for Use of AI (1)T he IRS adheres to the “Principles for Use of AI in Government” outlined in EO 139 60, on P romoting the Use of Trustworthy Artificial Intelligence in the Federal Government (Sec . 3 ). Accordingly, IRS design, development, acquisition, and use of AI must be : a)La wful and respectful of the nation’s values , and consistent with the Constitutio n Any text marked with a # is designated Official Use Only Page 6 of 11 Attachment: Interim Policy for AI Governance and all other applicable laws and policies, including those addressing privacy, civil rights, and civil liberties. b)Pur poseful and performance-driven , where the benefits of designing, developin g, ac quiring, and using AI significantly outweigh the risks, and the risks can be assess ed an d manage d. c)A ccurate, reliable, and effective , where the application of AI is consistent with th e us e cases for which the AI is traine d. d)S afe, secure, and resilient , including resilience when confronted with systemati c v ulnerabilities, adversarial manipulation, and other malicious exploitation . e)U nderstandable , where operations and outcomes of AI must be sufficient ly un derstandable by subject matter experts, users, and others, as appropriat e."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_18",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nwith th e us e cases for which the AI is traine d. d)S afe, secure, and resilient , including resilience when confronted with systemati c v ulnerabilities, adversarial manipulation, and other malicious exploitation . e)U nderstandable , where operations and outcomes of AI must be sufficient ly un derstandable by subject matter experts, users, and others, as appropriat e. f)R esponsible and traceable , such that human roles are clearly defined, AI is use d in a manner consistent with its intended purpose, and documentation clearly explains th e des ign, development, acquisition, use, and relevant inputs and outputs of the AI . g)R egularly monitored and tested against these principles. Mechanisms s hould be maint ained to supersede, disengage, or deactivate existing applications of AI t hat demo nstrate performance or outcomes that are inconsistent with their intended us e or f ederal requirements . h)T ransparent in disclosing relevant information regarding the use of AI to appropriat e s takeholders, including Congress and the public . i)A ccountable , where appropriate safeguards for the proper use and functioning of A I mus t be implemented and enforced, and AI must be appropriately monitored a nd au dited to document compliance with those safeguards ."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_19",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nh)T ransparent in disclosing relevant information regarding the use of AI to appropriat e s takeholders, including Congress and the public . i)A ccountable , where appropriate safeguards for the proper use and functioning of A I mus t be implemented and enforced, and AI must be appropriately monitored a nd au dited to document compliance with those safeguards . 10.24.1.3 (MM-DD-YYYY) AI Use Case Inventory (1)I n accordance with EO 13960, Section 5, Agency Inventory of AI Use Cases, the IR S m ust maintain an inventory of all its AI use cases and comply with government-w ide r eporting requirements. External reporting will be coordinated through the Department o f t he Treasury. Certain use cases may be excluded from external reporting, in accordanc e w ith Treasury and OMB guidance; however, in general no unclassified use cas e is ex cluded from entry in the IRS internal AI use case inventory . (2)A ll IRS business units and program offices are responsible for documenting their us es of AI in the AI use case inventory and following all applicable guidance in this IRM . a)A I project teams must create entries for new AI use cases once the use case has be en ini tiated—that is, once the need for the use case has been expressed and its intende d pur pose and high-level requirements are documented. Initiation generally requir es ap proval from a manager or executive, and includes a commitment of IRS resources t o t he use case (e.g., by allocating IRS funds or employee time)."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_20",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\ncase has be en ini tiated—that is, once the need for the use case has been expressed and its intende d pur pose and high-level requirements are documented. Initiation generally requir es ap proval from a manager or executive, and includes a commitment of IRS resources t o t he use case (e.g., by allocating IRS funds or employee time). Any use case n ot ent ered in the inventory after it has been initiated is out of compliance with this IRM’ s r equirements and should be submitted as soon as possible . b)P roject teams must answer all required inventory questions and provide respons es w ith the clarity and detail necessary to understand the use case . c)P roject teams must also maintain the accuracy and currency of their use case ’s inf ormation in the inventory over time. Project teams must update the inventory recor d w hen a change occurs to the use case that meaningfully affects the accuracy of t he Any text marked with a # is designated Official Use Only Page 7 of 11 Attachment: Interim Policy for AI Governance current record. Additionally, project teams must review and validate or update the inventory record at least annually or when directed by the CDAO team. Examples of changes requiring an inventory record update include changes to the use case’s name, purpose, lifecycle status, risks, or benefits. Note: # # (3)T he CDAO will oversee the collection and review of the AI use case inventory."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_21",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nproject teams must review and validate or update the inventory record at least annually or when directed by the CDAO team. Examples of changes requiring an inventory record update include changes to the use case’s name, purpose, lifecycle status, risks, or benefits. Note: # # (3)T he CDAO will oversee the collection and review of the AI use case inventory. Th e C DAO team will review inventory entries and support project teams in providing necessar y c larity and detai l. ( 4)T he IRS follows guidance from Treasury and OMB regarding what specific informatio n t o include in the AI use case inventory and in what format to report and publish th e inv entory. Guidance from OMB and Treasury may be updated periodically . Note : IRM 10.8.1.4.13.5, PM-05 System Inventory, contains guidance regarding the IRS AI use case inventory that will be superseded by the guidance in this IRM if the two are in conflict (paragraph 12). 10.24.1.4 (MM-DD-YYYY) AI Governance (1)T he IRS governs AI use cases, which are specific business uses of an AI techniq ue. E ffective governance, including risk assessment and mitigation, must consider the busines s c ontext in which AI is being use d. (2)T his IRM provides an interim policy for AI governance while the IRS awaits revis ed gui dance from OMB and Treasury per EO 1417 9."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_22",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nuse cases, which are specific business uses of an AI techniq ue. E ffective governance, including risk assessment and mitigation, must consider the busines s c ontext in which AI is being use d. (2)T his IRM provides an interim policy for AI governance while the IRS awaits revis ed gui dance from OMB and Treasury per EO 1417 9. (3)I RS business units and program offices may begin operational use of AI use cas es dur ing this interim period upon receiving approval from an appropriate governing body or aut horizing official for their business unit or program office. Enterprise-level approval f or op erational use is not currently required . (4)“ Operational use” means the AI or its output is being employed or put into service in a w ay that affects IRS business operations. It does not include preliminary development or us e in exploratory or research-only contexts that do not affect IRS business operations . (5)A I use cases that begin operational use in this interim period will be subject to any a dditional requirements in future policy updates. For example, use cases with elevated ri sk pr ofiles may undergo a post-hoc review and approval for continued use. Any revisions t o I RS AI governance policy will align with guidance issued by the President, OMB, a nd Tre asury ."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_23",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nuse in this interim period will be subject to any a dditional requirements in future policy updates. For example, use cases with elevated ri sk pr ofiles may undergo a post-hoc review and approval for continued use. Any revisions t o I RS AI governance policy will align with guidance issued by the President, OMB, a nd Tre asury . 10.24.1.4.1 (MM-DD-YYYY) AI Use Case Artifacts (1)I n accordance with Executive Order 13859, on Maintaining American Leadershi p in A rtificial Intelligence , Section 5(a), the IRS requires Model Card and Datasheet artifact s Any text marked with a # is designated Official Use Only Page 8 of 11 Attachment: Interim Policy for Al Governance from Al use cases in addition to their entry in the Al use case inventory. a) Model Card: Provides detailed documentation explaining the Al model(s) of a particu lar Al use case , such as expected inputs and outputs, performance metrics, risks of use, limitations, intended user audience, and points of contact. Project teams should submit one model card per model included in the use case. b) Datasheet: Provides detailed documentation explaining the data used by a particular Al use case, such as its source , size, provenance, sensitivity, intended use, transformation pipelines, and known quality issues. Project teams should submit one datasheet per dataset included in the use case."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_24",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nof contact. Project teams should submit one model card per model included in the use case. b) Datasheet: Provides detailed documentation explaining the data used by a particular Al use case, such as its source , size, provenance, sensitivity, intended use, transformation pipelines, and known quality issues. Project teams should submit one datasheet per dataset included in the use case. Note: (2) In their Model Card and Datasheet artifacts , Al project teams must provide the clarity and detail necessary to understand the use case, the sponsoring business development office and product owner, the intended purpose and benef its, and the identified risks and risk control measures. (3) The CDAO will oversee the collection and review of these artifacts. The CDAO team will review the artifacts and support project teams in providing the necessary clarity and detail. (4) Project teams must complete and submit these artifacts prior to beginning operational use of an Al use case. (5) For use cases in operational use, project teams must update Model Card and Datasheet artifacts when the use case changes in a way that meaningfully affects the accuracy of the current artifacts. Project teams must also review and validate or update these artifacts at least annually or when directed by the CDAO team. Examples of changes that require Model Card and Datasheet updates may include: a) Changing the context, scope, or intended purpose of the use case."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_25",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nuse case changes in a way that meaningfully affects the accuracy of the current artifacts. Project teams must also review and validate or update these artifacts at least annually or when directed by the CDAO team. Examples of changes that require Model Card and Datasheet updates may include: a) Changing the context, scope, or intended purpose of the use case. b) Changing the use case's output or impact on IRS operat ions. c) Updating or retraining the underlying Al model(s). d) Incorporating new data elements or data sources. 10.24.1.5 (MM-OO-YYYY) Protection of Taxpayer Rights (1) The Internal Revenue Code (IRC) lists specific taxpayer rights which are further explained in The Taxpayer Bill of Rights. See IRC § 7803(a)(3); Publication 1, Your Rights as a Taxpayer ; and www .irs.gov /taxpayer -bill-of-rights . (2) IRS employees are responsible for being familiar with and acting in accordance with these rights. IRS use of Al must not violate these rights. 10.24.1.6 (MM-OO-YYYY) Privacy and Security Requirements Any text marked with a# is designated Offic ial Use Only Page 9 of11 Attachment: Interim Policy for AI Governance (1) AI use cases must follow all relevant IRS privacy and security policies, s uch as t hose set forth in IRM 10.5, Privacy and Information Protection, and IRM 10.8 , Information Technology (IT) S ecurity."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_26",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nPrivacy and Security Requirements Any text marked with a# is designated Offic ial Use Only Page 9 of11 Attachment: Interim Policy for AI Governance (1) AI use cases must follow all relevant IRS privacy and security policies, s uch as t hose set forth in IRM 10.5, Privacy and Information Protection, and IRM 10.8 , Information Technology (IT) S ecurity. (2) In particular , those developing, procuring, or using AI must follow requirements in these IRM subsections where applicable: a)IRM 10.5.1.6, Practical Privacy Policy b)IRM 10.5.2.2, Privacy and Civil Liberties Impact Assessment ( PCLIA). NOTE : For an explanation of civil liberties, see IRM 10.5.2.2.2.1, Civil Li berties. c)IRM 10.5.6.3, Privacy Act System of R ecords Notices (SORNs). d)IRM 10.5.6.5, Privacy Act Recordkeeping Restrictions (Civ il Liberties Protections). Exhibit 10.24.1-1 (MM-DD-YYYY) Terms and Acronyms Term Definition Artificial Intelligence (AI) In accordance with Executive Order 13960 Section 9(a), the term ‘‘artificial intelligence’’ or ‘‘AI’’ has the meaning provided in Section 238(g) of the National Defense Authorization Ac t for Fiscal Year 2019 (NDAA). The NDAA definition states that the term “artificial intelligence” includes the following: 1. Any artificial system that performs tasks under varying a nd un predictable circumstances without significant huma n ov ersight, or that can learn from experience and improv e per formance when exposed to data sets . 2."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_27",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nNational Defense Authorization Ac t for Fiscal Year 2019 (NDAA). The NDAA definition states that the term “artificial intelligence” includes the following: 1. Any artificial system that performs tasks under varying a nd un predictable circumstances without significant huma n ov ersight, or that can learn from experience and improv e per formance when exposed to data sets . 2. An artificial system developed in computer software, physic al har dware, or other context that solves tasks requiring human- like perception, cognition, planning, learning, communicati on, or physical action . 3. An artificial system designed to think or act like a huma n, inc luding cognitive architectures and neural networks . 4. A set of techniques, including machine learning, that is des igned to approximate a cognitive task . 5. An artificial system designed to act rationally, including an int elligent software agent or embodied robot that achiev es go als using perception, planning, reasoning, learni ng, c ommunicating, decision making, and actin g. T he IRS will align with future guidance provided by OMB and Treasury in interpreting or updating this definition of AI. AI Use Case An AI use case is a specific business use of an AI technique, e.g., to solve a problem or increase operational efficiency. It includes outcomes or impact of the business use. It may use one or more AI models and one or more datasets to achieve its objective(s)."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_28",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nTreasury in interpreting or updating this definition of AI. AI Use Case An AI use case is a specific business use of an AI technique, e.g., to solve a problem or increase operational efficiency. It includes outcomes or impact of the business use. It may use one or more AI models and one or more datasets to achieve its objective(s). AI Model An AI model is the specific set of AI methods used to carry out the objective of the use case, e.g., a large language model or a machine learning model. Any text marked with a # is designated Official Use Only Page 10 of 11 Attachment: Interim Policy for AI Governance CDAO Chief Data and Analytics Officer. Refer to IRM 1.1.18.1, Research, Applied Analytics and Statistics Division, for a detailed description of responsibilities. EO Executive Order. IRC Internal Revenue Code. IT I nformation Technology . N DAA N ational Defense Authorization Act. O MB Office of Management and Budget. Operational Use “Operational use” means AI or its output is being employed or put into service in a way that affects IRS business operations. It does not include preliminary development or use in exploratory or research-only contexts that do not affect IRS business operations. PCLIA Privacy and Civil Liberties Impact Assessment. RAAS Research, Applied Analytics and Statistics. RA IO R esponsible Artificial Intelligence Official ."
  },
  {
    "id": "raas-10-0325-0001-public_chunk_29",
    "text": "Source: 12 raas-10-0325-0001-public.pdf\n\nAI or its output is being employed or put into service in a way that affects IRS business operations. It does not include preliminary development or use in exploratory or research-only contexts that do not affect IRS business operations. PCLIA Privacy and Civil Liberties Impact Assessment. RAAS Research, Applied Analytics and Statistics. RA IO R esponsible Artificial Intelligence Official . Exhibit 10.24.1-2 (MM-DD-YYYY) Related Resources Executive Orders •Executive Order 13859 , Maintaining American Leadership in Artificial I ntelligence •Executive Order 13960 , Promoting the Use of Trustworthy Artificial Intelligence in the F ederal Governmen t •Executive Order 14179 , Removing Barriers to American Leadership in Artificial I ntelligence IR S Publications •IRM 10.5.1, Privacy Po licy •IRM 10.5.2, Privacy Compliance and Assurance (PCA) P rogram •IRM 10.5.6, Privacy Ac t •IRM 10.8.1, Security Policy •IRM 10.8.2, IT Security Roles and Responsibilities •Publication 1 , Your Rights as a Taxpayer Any text marked with a # is designated Official Use Only Page 11 of 11"
  },
  {
    "id": "nasa-omb-compliance-plan-20240923_chunk_0",
    "text": "Source: 13 nasa-omb-compliance-plan-20240923.pdf\n\nNASA Compliance Plan for OMB Memorand um M-24-10 September 23, 2024 2 Table of Contents Strengthening Artificial Intelligence (AI) Governance ................................ ................................ ... 3 General ................................ ................................ ................................ ................................ ........ 3 AI Governance Bodies ................................ ................................ ................................ ................ 3 AI Use Case Inventories ................................ ................................ ................................ .............. 4 Reporting on AI Use Cases Not Subject to Inventory ................................ ................................ . 5 Advancing Responsible AI Innovation ................................ ................................ ........................... 5 AI Strategy ................................ ................................ ................................ ................................ .. 5 Removing Barriers to the Responsible Use of AI ................................ ................................ ....... 5 AI Talent ................................ ................................ ................................ ................................ ...... 6 AI Sharing and Collaboration ................................ ................................ ................................ ....."
  },
  {
    "id": "nasa-omb-compliance-plan-20240923_chunk_1",
    "text": "Source: 13 nasa-omb-compliance-plan-20240923.pdf\n\n................................ .............. 4 Reporting on AI Use Cases Not Subject to Inventory ................................ ................................ . 5 Advancing Responsible AI Innovation ................................ ................................ ........................... 5 AI Strategy ................................ ................................ ................................ ................................ .. 5 Removing Barriers to the Responsible Use of AI ................................ ................................ ....... 5 AI Talent ................................ ................................ ................................ ................................ ...... 6 AI Sharing and Collaboration ................................ ................................ ................................ ..... 6 Harmonization of Artificial Intelligence Requirements ................................ .............................. 6 Managi ng Risks from the Use of Artificial Intelligence ................................ ................................ . 7 Determining Which Artificial Intelligence Is Presumed to Be Safety -Impacting or Rights - Impacting ................................ ................................ ................................ ................................ ..... 7 Implementation of Risk Management Practices and Termination of Non -Compliant AI ..........."
  },
  {
    "id": "nasa-omb-compliance-plan-20240923_chunk_2",
    "text": "Source: 13 nasa-omb-compliance-plan-20240923.pdf\n\nand Collaboration ................................ ................................ ................................ ..... 6 Harmonization of Artificial Intelligence Requirements ................................ .............................. 6 Managi ng Risks from the Use of Artificial Intelligence ................................ ................................ . 7 Determining Which Artificial Intelligence Is Presumed to Be Safety -Impacting or Rights - Impacting ................................ ................................ ................................ ................................ ..... 7 Implementation of Risk Management Practices and Termination of Non -Compliant AI ........... 8 Minimum Risk Management Practices ................................ ................................ ....................... 8 Appendix ................................ ................................ ................................ ................................ ......... 9 A. 1 AISB membership ................................ ................................ ................................ ............... 9 3 Strengthening Artificial Intelligence ( AI) Governance General NASA is committed to advancing leadership in artificial intelligence and intends to maximize AI value to the Agency while managing AI risk. NASA is taking steps to expand the use of artificial intelligence and machine learning to amplify productivity and increase capabilities."
  },
  {
    "id": "nasa-omb-compliance-plan-20240923_chunk_3",
    "text": "Source: 13 nasa-omb-compliance-plan-20240923.pdf\n\n9 A. 1 AISB membership ................................ ................................ ................................ ............... 9 3 Strengthening Artificial Intelligence ( AI) Governance General NASA is committed to advancing leadership in artificial intelligence and intends to maximize AI value to the Agency while managing AI risk. NASA is taking steps to expand the use of artificial intelligence and machine learning to amplify productivity and increase capabilities. Agency leaders and AI practitioners are actively contributing to plans for AI adoption and governance which is providing NASA with an excellent foundation for safe, secure, responsible, and rights - respecti ng AI use across the agency . NASA will publish or update policy directive s and requirements to includ e the roles and responsibilities of the Chief AI Officer . The policy updates will ensure consistency with OMB M -24-10. NASA intends to meet Federal deadlines from EO 14110, OMB M -24-10, and AI Inventory instructions. AI Governance Bodies NASA has established a governing board within the agency to serve as a forum for senior leaders to drive AI adoption and governance for NASA. The Artificial Intelligence Strategy Board (AISB) is responsible for defining the vision and strategy for AI, promoting AI adoption an d innovation, establishing AI policy and procedural guardrails, identifying AI risk mitigation practices across the Agency , as well as monitoring NASA compliance with Federal guidelines ."
  },
  {
    "id": "nasa-omb-compliance-plan-20240923_chunk_4",
    "text": "Source: 13 nasa-omb-compliance-plan-20240923.pdf\n\na forum for senior leaders to drive AI adoption and governance for NASA. The Artificial Intelligence Strategy Board (AISB) is responsible for defining the vision and strategy for AI, promoting AI adoption an d innovation, establishing AI policy and procedural guardrails, identifying AI risk mitigation practices across the Agency , as well as monitoring NASA compliance with Federal guidelines . The AISB membership is shown in Appendix A.1 and may be evolve as changes occur or NASA AI governance matures. AISB’s specific functions are to: a. Review and approve a NASA AI Strategy to harness the mission value of AI while assuring responsible and e thical use. b. Monitor NASA progress and accomplishment of objectives with NASA’s AI Strategy. c. Facilitate Agency -wide consensus on NASA AI policies to allow adaptation to a rapidly changing AI landscape while remaining aligned with mission priorities. d. Review the NASA AI use case registration process and approve Agency submissions to the annual AI reporting requirements and compliance actions required by OMB. e. Review safety and rights impacting AI -use case assessments and waiver procedures and monitor overall AI risk mitigation procedures. f. Issue actions for NASA’s continued AI success and remov e barriers to responsible use of AI and to advance AI innovation. g. Make recommendations to the M ission Support Council (M SC) on NASA -wide impacts."
  },
  {
    "id": "nasa-omb-compliance-plan-20240923_chunk_5",
    "text": "Source: 13 nasa-omb-compliance-plan-20240923.pdf\n\nrequired by OMB. e. Review safety and rights impacting AI -use case assessments and waiver procedures and monitor overall AI risk mitigation procedures. f. Issue actions for NASA’s continued AI success and remov e barriers to responsible use of AI and to advance AI innovation. g. Make recommendations to the M ission Support Council (M SC) on NASA -wide impacts. The AI Strateg y Board will provide senior leadership level emphasis for AI, actively guiding NASA AI adoption, investment, and responsible use. The Agency has also created the Artificial Intelligence Strategic Working Group (AISWG) to advise and serve the AISB. The AI SWG consists of NASA personnel selected to provide key insights into the use of AI and appropriate governance for the Agency. 4 The AISWG is responsible for: a. Forming topics of discussion for the AISB regard ing implications of AI within the Agency . b. Supporting AI Governance creation within the Agency . c. Providing recommendations to the CAIO in relevant matters . d. Coordinating with practitioners to understand AI work at NASA . e. Advocating for AI plans and strategies . f. Reviewing and providi ng feedback for NASA AI Strategy to harness the mission value of AI and assur e responsible and ethical use . g. Defining and advancing strategic objectives . h. Drafting, establishing, and maintaining AI policies that addresses the implications of the rapidly chan ging AI landscape . i."
  },
  {
    "id": "nasa-omb-compliance-plan-20240923_chunk_6",
    "text": "Source: 13 nasa-omb-compliance-plan-20240923.pdf\n\ne. Advocating for AI plans and strategies . f. Reviewing and providi ng feedback for NASA AI Strategy to harness the mission value of AI and assur e responsible and ethical use . g. Defining and advancing strategic objectives . h. Drafting, establishing, and maintaining AI policies that addresses the implications of the rapidly chan ging AI landscape . i. Developing an inventory of AI use at NASA includ ing the annual process for registering AI use cases as they are developed, tested, operationalized, and retired . j. Creating a process for reviewing and approving safety and rights impacting a ssessment and wa iver procedures and manag ing overall risk . k. Identifying and removing barriers to the responsible use of AI and advanc ing responsible AI innovation . NASA will also consult with external organizations in a variety of mechanisms. NASA participates in cross -Federal forums for AI, such as the Chief AI Officers’ Council. NASA also participates in industry and academic symposia where emergent AI techniques, best practices and risks are discussed . NASA Mission Directorates engage with their respective public communities . For example, the Science Mission Directorate works across the broad , open science community which includes industry, academia, other nations, and the publi c. NASA will also continue to leverage external consulting firms for advice on technical advancements and procedural approaches to responsibly adopt and use AI throughout NASA."
  },
  {
    "id": "nasa-omb-compliance-plan-20240923_chunk_7",
    "text": "Source: 13 nasa-omb-compliance-plan-20240923.pdf\n\n. NASA Mission Directorates engage with their respective public communities . For example, the Science Mission Directorate works across the broad , open science community which includes industry, academia, other nations, and the publi c. NASA will also continue to leverage external consulting firms for advice on technical advancements and procedural approaches to responsibly adopt and use AI throughout NASA. AI Use Case Inventories NASA will update its AI inventory to meet FY24 instructions and to facilitate internal awareness and management of AI use within NASA . The AISB will oversee collection of AI inventory data for FY24 and subsequent years . NASA is updating prior inventory data structures, collection mechani sms, and query / visualization capabilities to form an AI registry which will provide the data required for the federal AI inventory . The AI registry will inform AI governance, planning, and connect NASA AI practitioners with one another to promote awarene ss and re -use. All prior use cases will be loaded into the new AI registry and use case points of contact will be required to update their entries. If use cases have expired, they will be archived instead of deleted. If points of contact have changed, the inventory will allow for an update . 5 Reporting on AI Use Cases Not Subject to Inventory NASA’s AI registry will encourage NASA -internal collection, visibility, and tracking of AI use cases not reportable to the Federal level."
  },
  {
    "id": "nasa-omb-compliance-plan-20240923_chunk_8",
    "text": "Source: 13 nasa-omb-compliance-plan-20240923.pdf\n\nupdate their entries. If use cases have expired, they will be archived instead of deleted. If points of contact have changed, the inventory will allow for an update . 5 Reporting on AI Use Cases Not Subject to Inventory NASA’s AI registry will encourage NASA -internal collection, visibility, and tracking of AI use cases not reportable to the Federal level. The NASA AI Registry and supporting governance procedures provide a continuous and enduring process to capture AI us e and track it through its lifecycle. Along with updates at any time, NASA will emphasize use case updates or validation aligned with yearly Federal inventory deadlines. The planned update cycle will support re -assessing previously non -reportable use cases to evaluate if reporting criteria have changed, such as maturity of the AI, addition of safety - or rights -impacting elements, etc. It will also allow NASA to address an y changes to annual reporting requirements. Advancing Responsible AI Innovation AI Strategy NASA will publish a n AI strategy that addresses the areas in M -24-10, section 4.a by March 2025. Removing Barriers to the Responsible Use of AI NASA has identified several barriers to AI adoption and has begun taking action to resolve them. Barriers include access to AI tools and platforms, the need to make data AI -ready, and quality control issues with generative AI outputs . 1."
  },
  {
    "id": "nasa-omb-compliance-plan-20240923_chunk_9",
    "text": "Source: 13 nasa-omb-compliance-plan-20240923.pdf\n\naddresses the areas in M -24-10, section 4.a by March 2025. Removing Barriers to the Responsible Use of AI NASA has identified several barriers to AI adoption and has begun taking action to resolve them. Barriers include access to AI tools and platforms, the need to make data AI -ready, and quality control issues with generative AI outputs . 1. For AI tools and platforms, NASA intends, within budget limitations, to make multiple cloud -hosted AI capabilities available in FY25 . NASA is also working to authorize AI upgrades to common , off-the-shelf software, such as office automation tools, to inclu de streamlining technology onboarding processes. 2. For making data AI -ready, NASA Digital Transformation is conducting a series of facilitated AI workshops with NASA organizations. These workshops seek to envision the latest transformation goals, highlight A I ambitions, and identify data enhancements required to fuel transformation with data and AI . In preparation for broa der use of AI, better understanding the characteristics of AI-ready data has continued to be an area of focus for the Enterprise Data Worki ng Group (EDWG). 3. For quality control of AI outputs, NASA will augment standard engineering , system engineering processes , and software engineering with additional AI considerations. Human verification and validation , as well as science evaluation and benchmarks, are being strongly emphasized, especially with generative AI. 4."
  },
  {
    "id": "nasa-omb-compliance-plan-20240923_chunk_10",
    "text": "Source: 13 nasa-omb-compliance-plan-20240923.pdf\n\ncontinued to be an area of focus for the Enterprise Data Worki ng Group (EDWG). 3. For quality control of AI outputs, NASA will augment standard engineering , system engineering processes , and software engineering with additional AI considerations. Human verification and validation , as well as science evaluation and benchmarks, are being strongly emphasized, especially with generative AI. 4. The NASA Chief Information Officer issued initial guidance for use of generative AI in May 2023, which was distributed via an email to all NASA employees, pos ted on the CIO’s internal web space, and is activel y referenced by AI leaders in advising generative AI adopters. The CAIO is overseeing an update of th e generative AI guidance in Fall 2024 based on additional developments in AI capabilities and Federal gu idance . As specific topics related to responsible AI use emerge, the CAIO is postured to issue interim policy memorandums to address concerns and mitigate risk . 6 AI Talent NASA ’s existing workforce is highly technical, and includes personnel with deep exper tise in traditional AI, machine learning, software development, statistics, data science, modeling, simulation, high performance computing, robotics, autonomy , and more. NASA encourages up- skilling , which helps the previously mentioned personnel continue to grow and allows additional workers to learn new AI skills."
  },
  {
    "id": "nasa-omb-compliance-plan-20240923_chunk_11",
    "text": "Source: 13 nasa-omb-compliance-plan-20240923.pdf\n\n6 AI Talent NASA ’s existing workforce is highly technical, and includes personnel with deep exper tise in traditional AI, machine learning, software development, statistics, data science, modeling, simulation, high performance computing, robotics, autonomy , and more. NASA encourages up- skilling , which helps the previously mentioned personnel continue to grow and allows additional workers to learn new AI skills. NASA steadily increased AI -specific training from 2020 to 2023 and launched the “Summer of AI” learning campaign in 2024 reaching nearly 4,000 unique learners over a 90 -day period . Encouraged by the Office of Personnel Management (OPM), NASA has begun using the OPM 1560 Data Scientist Series position s and leverages many creative mechanisms to acquire cutting -edge talent, such as direct hires, federally funded research and development contractors, university grants, industry partnerships, internships, fellowships, and military transition opportunities. NASA will continue to evaluate the learning needs of its workforce and provide training across multiple disciplines at all levels to address the rapidly evolving AI landscape and to assure responsible adoption and compliance with executive orders and OMB memorandums."
  },
  {
    "id": "nasa-omb-compliance-plan-20240923_chunk_12",
    "text": "Source: 13 nasa-omb-compliance-plan-20240923.pdf\n\nsuch as direct hires, federally funded research and development contractors, university grants, industry partnerships, internships, fellowships, and military transition opportunities. NASA will continue to evaluate the learning needs of its workforce and provide training across multiple disciplines at all levels to address the rapidly evolving AI landscape and to assure responsible adoption and compliance with executive orders and OMB memorandums. AI Sharing and Collaboration NASA plans to share custom -developed AI code , models, model weights, and other artifacts , as- appropriate, while balancing its open science policies with the need to protect certain products for safety, rights, security, or protection of industry -proprietary intellectual property. NASA’s AI inventory will report links to relevant shared repositories. NASA will advocate for and encourage open sharing via multiple methods, such as posting public recognition or sponsoring open sharing events. Organizations across NASA already conduct widespread e xternal engagement , to include sharing relevant code and data, as well as eliciting external partner contributions via grants, crowdsource campaign s, and more. NASA plans to continue these engagements, expanding to include AI topics , where relevant. Harmonization of Artificial Intelligence Requirements NASA has multiple mechanisms to help document and share best practices for AI governance, innovation, and risk management ."
  },
  {
    "id": "nasa-omb-compliance-plan-20240923_chunk_13",
    "text": "Source: 13 nasa-omb-compliance-plan-20240923.pdf\n\n, to include sharing relevant code and data, as well as eliciting external partner contributions via grants, crowdsource campaign s, and more. NASA plans to continue these engagements, expanding to include AI topics , where relevant. Harmonization of Artificial Intelligence Requirements NASA has multiple mechanisms to help document and share best practices for AI governance, innovation, and risk management . These include existing engineering, safety , and risk bodies with decades of practical AI experience to newly formed AI governance structures : 1. The CAIO is establishing AI governance in two tiers: senior leaders of NASA will guide NASA’s approach to AI and subordinate leaders will maximize NASA’s value from AI while managing risks. These two AI leadership bodies are the core of NASA’s new structures to ad vance AI . These bodies span NASA by design and will encourage widespread collaboration . New AI governance bodies are integrate d with existing program management and technical authority structure s in place at NASA. 2. NASA’s Autonomous Systems System Capability Leadership Team (AS -SLCT) includes many deep AI experts who have been using AI for decades to fuel autonomy in Mission - embedded work, such as rovers on Mars. T his team actively shares lessons and best 7 practices among the members and beyond."
  },
  {
    "id": "nasa-omb-compliance-plan-20240923_chunk_14",
    "text": "Source: 13 nasa-omb-compliance-plan-20240923.pdf\n\nmanagement and technical authority structure s in place at NASA. 2. NASA’s Autonomous Systems System Capability Leadership Team (AS -SLCT) includes many deep AI experts who have been using AI for decades to fuel autonomy in Mission - embedded work, such as rovers on Mars. T his team actively shares lessons and best 7 practices among the members and beyond. NASA continues to leverage existing standards, policies, and procedures like the Autonomous Systems Classification Framework to help guide AI and inform AI quality control measurers as well as verification and validation testing . 3. NASA’s Digital Transformation initiative includes an AI and Machine Learning (ML) facet, which has built a robust community of AI and ML adopters who actively share techniques, lessons, and training. The community also includes an AI /ML consultation team with a portal si te that matches expertise seekers with AI experts. 4. NASA also participates in the Chief AI Officers’ Council, and three sub-teams, to learn from other Federal agencies, and to contribute insights ."
  },
  {
    "id": "nasa-omb-compliance-plan-20240923_chunk_15",
    "text": "Source: 13 nasa-omb-compliance-plan-20240923.pdf\n\na robust community of AI and ML adopters who actively share techniques, lessons, and training. The community also includes an AI /ML consultation team with a portal si te that matches expertise seekers with AI experts. 4. NASA also participates in the Chief AI Officers’ Council, and three sub-teams, to learn from other Federal agencies, and to contribute insights . Managing Risks from the Use of Artificial Intelligence Determining Which Artificial Intelligence Is Presumed to Be Safety -Impacting or Rights -Impacting NASA plans to use the AI definitions from NASA Policy Directive (NPD) do cuments, NASA Procedure Requirement (NPR) documents, NASA standards, EO14110, OMB M -24-10, and the draft AI Inventory Instructions to 1) assess if a use case meets the definition for AI, and 2) meets the definitions for either safety - or rights - impact s. The C AIO team and AI SWG will promulgate these definitions, along with examples from Fed eral directives and NASA. In concert with existing NPRs, NASA will utilize existing internal policies and empower organizational leaders and their AI -using Subject Matter Experts ( SMEs ) to serve as the first tier of assessment whether a use case meets safe ty- or rights - impacting definitions . The CAIO team and governance bodies will track and check organizational / SME assessments and will help make judgements i f categorization is unclear for some use cases."
  },
  {
    "id": "nasa-omb-compliance-plan-20240923_chunk_16",
    "text": "Source: 13 nasa-omb-compliance-plan-20240923.pdf\n\nleaders and their AI -using Subject Matter Experts ( SMEs ) to serve as the first tier of assessment whether a use case meets safe ty- or rights - impacting definitions . The CAIO team and governance bodies will track and check organizational / SME assessments and will help make judgements i f categorization is unclear for some use cases. NASA will continue to conduct workshops among AI use case owners, AI leader s in various NASA organizations, Chief AI Officer team members , organizations such as the Office of Safety and Mission Assurance ( OSMA ), and other stakeholders to work through safety - and rights - impacting use case actions and reporting. If a use case requires a waiver, that team will work together to author a waiver, a different sub -team will provide an independent review, the CAIO will provide a review, and the CAIO will team with other approval authorit ies (e.g., Safety & Mission Assurance, Chief Engineer) to take the appropriate action on the waiver . The CAIO team will maintain a list of waivers and will track them in similar fashion to NASA’s processes for tracking actions, audits, etc. 8 Implementation of Risk Management Practices and Termination of Non - Compliant AI NASA takes risk management across all mission and support functions very seriously. A s such, NASA has extremely robust risk manag ement measures that have evolved and have been refined for decades."
  },
  {
    "id": "nasa-omb-compliance-plan-20240923_chunk_17",
    "text": "Source: 13 nasa-omb-compliance-plan-20240923.pdf\n\nand will track them in similar fashion to NASA’s processes for tracking actions, audits, etc. 8 Implementation of Risk Management Practices and Termination of Non - Compliant AI NASA takes risk management across all mission and support functions very seriously. A s such, NASA has extremely robust risk manag ement measures that have evolved and have been refined for decades. These measures are well documented in policies and overseen by risk management boards and NASA Technical Authorities. For AI use cases that may be publicly deployed , NASA will leverage existing quality control and risk management processes to assure all AI use is compliant with OMB M -24-10 and other guidelines. NASA plans to approach safety - and rights - impacting compliance from a perspective of assisting NASA AI users in accomplishing their mission go als while aligning with relevant best practices. NASA’s intent is to either help safety - and rights - impacting AI use cases achieve compliance with a plan of action and milestones approach , evaluate the mission impact of retirement , or consider granting a waiver if necessary. Directing AI practitioners to cease use of non-compliant AI is seen as a last resort , but if that last resort becomes necessary, it can be escalated through the AI governance process to the Deputy Administrator ."
  },
  {
    "id": "nasa-omb-compliance-plan-20240923_chunk_18",
    "text": "Source: 13 nasa-omb-compliance-plan-20240923.pdf\n\nwith a plan of action and milestones approach , evaluate the mission impact of retirement , or consider granting a waiver if necessary. Directing AI practitioners to cease use of non-compliant AI is seen as a last resort , but if that last resort becomes necessary, it can be escalated through the AI governance process to the Deputy Administrator . Minimum Risk Management Practices NASA plans to document and validate implementation of additional AI risk management process in accordance with the Federal instruction in combination with existing NASA quality control processes and policies for engineeri ng, system engineering, software development , and information technology authority to operate determinations . Existing policies and processes provide the foundation and will undergo continuous assessment so they may be evolved to address emerging risks. The AI Registry enables a perpetual update process of AI use-case information that is reportable to t he AISB and AI SWG. As such the AI Governance, Risk Management Boards and Technical Authorities will have the necessary awareness of emergent risks along with the authority to take action to address and mitigate those risks. 9 Appendix A. 1 AISB membershi p a. Chair: Deputy Administrator (DA) b. Alternate Chair: Chief AI Officer (CAIO) c. Officers in Charge (OICs) or deputy OICs from each Mission Directorate or senior designee d. Mission Support 1. Office of the Chief Information Officer 2. Office of the Chief Financial Officer 3."
  },
  {
    "id": "nasa-omb-compliance-plan-20240923_chunk_19",
    "text": "Source: 13 nasa-omb-compliance-plan-20240923.pdf\n\ntake action to address and mitigate those risks. 9 Appendix A. 1 AISB membershi p a. Chair: Deputy Administrator (DA) b. Alternate Chair: Chief AI Officer (CAIO) c. Officers in Charge (OICs) or deputy OICs from each Mission Directorate or senior designee d. Mission Support 1. Office of the Chief Information Officer 2. Office of the Chief Financial Officer 3. Office of Diversity and Equal Opportunity 4. Office of General Counsel 5. Office of Chief Human Capital Officer 6. Office of Procurement e. Headquarters Technical Authorities 1. Office of Safety and Mission Assurance 2. Office of the Chief Engineer 3. Office of the Chief Scientist 4. Office of Technology, Policy and Strategy 5. Office of the Chief Health and Medical Office"
  },
  {
    "id": "ML23132A305_chunk_0",
    "text": "Source: 14 ML23132A305.pdf\n\nARTIFICIAL INTELLIGENCE STRATEGIC PLAN Fiscal Years 2023-2027U.S. NUCLEAR REGULATORY COMMISSIONNUREG-2261 AVAILABILITY OF REFERENCE MATERIALS IN NRC PUBLICATIONS NRC Reference Material As of November 1999, you may electronically access NUREG-series publications and other NRC records at the NRC’s Library at www.nrc.gov/reading-rm.html. Publicly released records include, to name a few, NUREG-series publications; Federal Register notices; applicant, licensee, and vendor documents and correspondence; NRC correspondence and internal memoranda; bulletins and information notices; inspection and investigative reports; licensee event reports; and Commission papers and their attachments. NRC publications in the NUREG series, NRC regulations, and Title 10, “Energy,” in the Code of Federal Regulations may also be purchased from one of these two sources : 1. The Superintendent of Documents U.S. Government Publishing Office Washington, DC 20402-0001 Internet: https://bookstore.gpo.gov/ Telephone: (202) 512-1800 Fax: (202) 512-2104 2. The National Technical Information Service 5301 Shawnee R oad Alexandria, VA 22312-0002 Internet: https://www.ntis.gov/ 1-800-553-6847 or, locally, (703) 605-6000 A single copy of each NRC draft report for comment is available free, to the extent of supply, upon writtenrequest as follows: Address: U.S."
  },
  {
    "id": "ML23132A305_chunk_1",
    "text": "Source: 14 ML23132A305.pdf\n\nDocuments U.S. Government Publishing Office Washington, DC 20402-0001 Internet: https://bookstore.gpo.gov/ Telephone: (202) 512-1800 Fax: (202) 512-2104 2. The National Technical Information Service 5301 Shawnee R oad Alexandria, VA 22312-0002 Internet: https://www.ntis.gov/ 1-800-553-6847 or, locally, (703) 605-6000 A single copy of each NRC draft report for comment is available free, to the extent of supply, upon writtenrequest as follows: Address: U.S. Nuclear Regulatory Commission Office of Administration Digital Communications and Administrative Services Branch Washington, DC 20555-0001 E-mail: Reproduction.R esource@nrc.gov Facsimile: (301) 415-2289 Some publications in the NUREG series that are posted at the NRC’s Web site address www.nrc.gov/reading-rm/ doc-collections/nuregs are updated periodically and may differ from the last printed version. Although references to material found on a Web site bear the date the material was accessed, the material available on the date cited may subsequently be removed from the site.Non-NRC Reference Material Documents available from public and special technical libraries include all open literature items, such as books, journal articles, transactions, Federal Register notices, Federal and State legislation, and congressional reports. Such documents as theses, dissertations, foreign reports and translations, and non-NRC conference proceedings may be purchased from their sponsoring organization."
  },
  {
    "id": "ML23132A305_chunk_2",
    "text": "Source: 14 ML23132A305.pdf\n\ndate cited may subsequently be removed from the site.Non-NRC Reference Material Documents available from public and special technical libraries include all open literature items, such as books, journal articles, transactions, Federal Register notices, Federal and State legislation, and congressional reports. Such documents as theses, dissertations, foreign reports and translations, and non-NRC conference proceedings may be purchased from their sponsoring organization. Copies of industry codes and standards used in a substantive manner in the NRC regulatory process are maintained at— The NRC Technical Library Two White Flint North 11545 Rockville Pike Rockville, MD 20852-2738 These standards are available in the library for reference use by the public. Codes and standards are usually copyrighted and may be purchased from the originating organization or, if they are American National Standards, from— American National Standards Institute 11 West 42nd Street New York, NY 10036-8002 Internet: www.ansi.org (212) 642-4900 Legally binding regulatory requirements are stated only in laws; NRC regulations; licenses, including technical specifications; or orders, not in NUREG-series publications. The views expressed in contractor prepared publications in this series are not necessarily those of the NRC."
  },
  {
    "id": "ML23132A305_chunk_3",
    "text": "Source: 14 ML23132A305.pdf\n\nthey are American National Standards, from— American National Standards Institute 11 West 42nd Street New York, NY 10036-8002 Internet: www.ansi.org (212) 642-4900 Legally binding regulatory requirements are stated only in laws; NRC regulations; licenses, including technical specifications; or orders, not in NUREG-series publications. The views expressed in contractor prepared publications in this series are not necessarily those of the NRC. The NUREG series comprises (1) technical and administrative reports and books prepared by the staff (NUREG–XXXX) or agency contractors (NUREG/CR–XXXX), (2) proceedings of conferences (NUREG/CP–XXXX), (3) reports resulting from international agreements (NUREG/IA–XXXX),(4) brochures (NUREG/BR–XXXX), and (5)compilations of legal decisions and orders of the Commission and the Atomic and Safety Licensing Boards and of Directors’ decisions under Section 2.206 of the NRC’s regulations (NUREG -0750 ), (6) Knowledge Management prepared by NRC staff or agency contractors (NUREG/KM- XXXX). DISCLAIMER: This report was prepared as an account of work sponsored by an agency of the U.S. Government. Neither the U.S."
  },
  {
    "id": "ML23132A305_chunk_4",
    "text": "Source: 14 ML23132A305.pdf\n\ndecisions and orders of the Commission and the Atomic and Safety Licensing Boards and of Directors’ decisions under Section 2.206 of the NRC’s regulations (NUREG -0750 ), (6) Knowledge Management prepared by NRC staff or agency contractors (NUREG/KM- XXXX). DISCLAIMER: This report was prepared as an account of work sponsored by an agency of the U.S. Government. Neither the U.S. Government nor any agency thereof, nor any employee, makes any warranty, expressed or implied, or assumes any legal liability or responsibility for any third party’s use, or the results of such use, of any information, apparatus, product, or process disclosed in this publication, or represents that its use by such third party would not infringe privately owned rights. The U.S. Nuclear Regulatory Commission (NRC) recognizes that interest in artificial intelligence (AI) is growing rapidly in both the public and private sectors and anticipates increased use of AI in NRC-regulated activities. For the purposes of this document, AI refers to a machine-based system that can go beyond defined results and scenarios and has the ability to emulate human-like perception, cognition, planning, learning, communication, or physical action. For a given set of human-defined objectives, AI can make predictions, recommendations, or decisions influencing real or virtual environments."
  },
  {
    "id": "ML23132A305_chunk_5",
    "text": "Source: 14 ML23132A305.pdf\n\nuse of AI in NRC-regulated activities. For the purposes of this document, AI refers to a machine-based system that can go beyond defined results and scenarios and has the ability to emulate human-like perception, cognition, planning, learning, communication, or physical action. For a given set of human-defined objectives, AI can make predictions, recommendations, or decisions influencing real or virtual environments. This strategic plan focuses on a broad spectrum of AI sub-specialties (e.g., natural language processing, machine learning, deep learning, etc.) which could encompass various algorithms and application examples which the NRC has not previously reviewed and evaluated. Anticipating the industry’s potential application of AI to NRC-regulated activities, the NRC has developed this strategic plan to ensure the agency’s readiness to review such uses. The strategic plan includes five goals: (1) ensure NRC readiness for regulatory decision-making, (2) establish an organizational framework to review AI applications, (3) strengthen and expand AI partnerships, (4) cultivate an AI-proficient workforce, and (5) pursue use cases to build an AI foundation across the NRC. The overall goal of this strategic plan is to ensure continued staff readiness to review and evaluate AI applications effectively and efficiently. ABSTRACTNRC headquarters in Rockville, Maryland iii TABLE OF CONTENTS ABSTRACT........................................................................................"
  },
  {
    "id": "ML23132A305_chunk_6",
    "text": "Source: 14 ML23132A305.pdf\n\nto review AI applications, (3) strengthen and expand AI partnerships, (4) cultivate an AI-proficient workforce, and (5) pursue use cases to build an AI foundation across the NRC. The overall goal of this strategic plan is to ensure continued staff readiness to review and evaluate AI applications effectively and efficiently. ABSTRACTNRC headquarters in Rockville, Maryland iii TABLE OF CONTENTS ABSTRACT........................................................................................ .........iii LIS T OF FIGURES.....................................................................................vii LIST OF TABLES.......................................................................................vii EXECUTIVE SUMMARY....................................................................... .......ix FOREWORD.........................................................................................."
  },
  {
    "id": "ML23132A305_chunk_7",
    "text": "Source: 14 ML23132A305.pdf\n\nan AI-proficient workforce, and (5) pursue use cases to build an AI foundation across the NRC. The overall goal of this strategic plan is to ensure continued staff readiness to review and evaluate AI applications effectively and efficiently. ABSTRACTNRC headquarters in Rockville, Maryland iii TABLE OF CONTENTS ABSTRACT........................................................................................ .........iii LIS T OF FIGURES.....................................................................................vii LIST OF TABLES.......................................................................................vii EXECUTIVE SUMMARY....................................................................... .......ix FOREWORD.......................................................................................... .....xi ABBREVIATIONS AND ACRONYMS.........................................................xiii INTRODUC TION......................................................................................1-1 VISION.....................................................................................................2-1 PURPOSE AND DRIVERS........................................................................3-1STRATEGIC GOALS..................................................................................4-1 4.1 Strategic Goal 1: Ensure NRC Readiness for Regulatory Decision-Making..............................................................................4-24.2 Strategic Goal 2: Establish an Organizational Framework to Review AI Applications.................................................................4-44.3 Strategic Goal 3: Strengthen and Expand AI Partnerships..............4-44.4 Strategic Goal 4: Cultivate an AI-Proficient Workforce....................4-54.5 Strategic Goal 5: Pursue Use Cases to Build an AI Foundation Across the NRC................................................................................4-6CONCLUSION...........................................................................................5-1REFERENCES...........................................................................................6-1APPENDIX A GLOSSARY................................................................................................A-1APPENDIX B USING ARTIFICIAL INTELLIGENCE TOOLS TO ENHANCE NRC ACTIVITIES .....................................................................................B-1 v NRC staff observe advanced reactor vendor X-energy’s simulator for their proposed high-temperature gas-cooled reactor facility LIST OF FIGURES Figure 1 Artificial Intelligenc e Hierarchy and Relationship with the NRC AI Strat egic Plan (adapted from [5] and [6])................................................1-3 Figure 2 Overvie w of Strategic Goals..........................................................................4-1 LIST OF TABLES Table 1 Notional AI and Autonomy Levels in Commercial Nuclear Activities..........1-4 Table 2 Pot ential AI Technical Considerations for Regulatory Decision-Making ...........................................................................................4-3 vii Limerick Generating Station, Units 1 and 2 EXECUTIVE SUMMARY For the purposes of this document, artificial intelligence (AI) refers to a machine- based system that can go beyond defined results and scenarios and has the ability to emulate human-like perception, cognition, planning, learning, communication, or physical action."
  },
  {
    "id": "ML23132A305_chunk_8",
    "text": "Source: 14 ML23132A305.pdf\n\nActivities..........1-4 Table 2 Pot ential AI Technical Considerations for Regulatory Decision-Making ...........................................................................................4-3 vii Limerick Generating Station, Units 1 and 2 EXECUTIVE SUMMARY For the purposes of this document, artificial intelligence (AI) refers to a machine- based system that can go beyond defined results and scenarios and has the ability to emulate human-like perception, cognition, planning, learning, communication, or physical action. For a given set of human-defined objectives, AI can make predictions, recommendations, or decisions influencing real or virtual environments. AI is one of the fastest-growing technologies globally and has the potential to enhance decision-making processes for the nuclear industry by providing insights into vast amounts of data generated during the design and operation of nuclear facilities. As a result, the nuclear industry has expressed a growing interest in researching and using AI technologies to improve operational performance and mitigate operational risk. The AI Strategic Plan focuses on a broad spectrum of AI sub-specialties (e.g., natural language processing, machine learning, deep learning, etc.) which could encompass various algorithms and application examples which the U.S. Nuclear Regulatory Commission (NRC) has not previously reviewed and evaluated."
  },
  {
    "id": "ML23132A305_chunk_9",
    "text": "Source: 14 ML23132A305.pdf\n\nexpressed a growing interest in researching and using AI technologies to improve operational performance and mitigate operational risk. The AI Strategic Plan focuses on a broad spectrum of AI sub-specialties (e.g., natural language processing, machine learning, deep learning, etc.) which could encompass various algorithms and application examples which the U.S. Nuclear Regulatory Commission (NRC) has not previously reviewed and evaluated. The NRC is committed to continue to keep pace with technological innovations to ensure the safe and secure use of AI in NRC-regulated activities. The NRC has developed the AI Strategic Plan to plan and prepare for new technologies involving AI. The NRC’s AI Strategic Plan, covering fiscal years (FY) 2023–2027, establishes the vision and goals for the NRC to continue to improve its skills and capabilities to review and evaluate the application of AI to NRC-regulated activities, maintain awareness of technological innovations, and ensure the safe and secure use of AI in NRC-regulated activities. The AI Strategic Plan includes five goals: (1) ensure NRC readiness for regulatory decision-making, (2) establish an organizational framework to review AI applications, (3) strengthen and expand AI partnerships, (4) cultivate an AI-proficient workforce, and (5) pursue use cases to build an AI foundation across the NRC."
  },
  {
    "id": "ML23132A305_chunk_10",
    "text": "Source: 14 ML23132A305.pdf\n\ninnovations, and ensure the safe and secure use of AI in NRC-regulated activities. The AI Strategic Plan includes five goals: (1) ensure NRC readiness for regulatory decision-making, (2) establish an organizational framework to review AI applications, (3) strengthen and expand AI partnerships, (4) cultivate an AI-proficient workforce, and (5) pursue use cases to build an AI foundation across the NRC. The AI Strategic Plan supports the NRC’s mission, broadly aligns with the agency’s Principles of Good Regulation, and is tied to multiple NRC FY 2022–2026 Strategic Plan safety, security, and openness strategies [1] . The o verall goal of the AI Strategic Plan is to ensure the staff’s readiness to effectively and efficiently review and evaluate the use of AI in NRC-regulated activities. Any future guidance or rulemaking, if needed, will follow the agency’s typical processes. In part, the AI Strategic Plan’s success will depend on early and frequent industry stakeholder engagement on envisioned AI applications and partnering with domestic and international counterparts to gain valuable information to benchmark the agency’s AI activities. ix Comanche Peak Nuclear Power Plant, Units 1 and 2 FOREWORD MESSAGE FROM THE DIRECTOR OF THE OFFICE OF NUCLEAR REGULATORY RESEARCH RAYMOND FURSTENAU I am pleased to present the U.S. Nuclear Regulatory Commission’s (NRC’s) Artificial Intelligence (AI) Strategic Plan for Fiscal Years 2023-2027."
  },
  {
    "id": "ML23132A305_chunk_11",
    "text": "Source: 14 ML23132A305.pdf\n\npartnering with domestic and international counterparts to gain valuable information to benchmark the agency’s AI activities. ix Comanche Peak Nuclear Power Plant, Units 1 and 2 FOREWORD MESSAGE FROM THE DIRECTOR OF THE OFFICE OF NUCLEAR REGULATORY RESEARCH RAYMOND FURSTENAU I am pleased to present the U.S. Nuclear Regulatory Commission’s (NRC’s) Artificial Intelligence (AI) Strategic Plan for Fiscal Years 2023-2027. The objective of the NRC’s AI Strategic Plan is to ensure continued staff readiness to review and evaluate future AI applications effectively and efficiently. We recognize that interest in AI is growing rapidly in both, the public and private sectors. As such, I think is important to lay the groundwork needed to ensure the safe and secure use of AI in NRC-regulated activities. The AI Strategic Plan illuminates our path forward for the NRC to continue to improve its skills and capabilities to review and evaluate the application of AI to NRC-regulated activities, maintain awareness of technological innovations, and ensure the safe and secure use of AI in NRC-regulated activities. This strategy is a critical step in our journey to continue to keep pace with technological innovations such as AI and furthers the agency’s commitment to being a transparent, modern, risk-informed regulator. Lastly, I believe in the power of collaboration, especially when trying to develop a strategy to resolve complex technical challenges."
  },
  {
    "id": "ML23132A305_chunk_12",
    "text": "Source: 14 ML23132A305.pdf\n\nand secure use of AI in NRC-regulated activities. This strategy is a critical step in our journey to continue to keep pace with technological innovations such as AI and furthers the agency’s commitment to being a transparent, modern, risk-informed regulator. Lastly, I believe in the power of collaboration, especially when trying to develop a strategy to resolve complex technical challenges. Moving forward, we are committed to continuing to engage the public and external stakeholders and strengthening and expanding partnerships with domestic and international counterparts. I have great confidence, that working together, we will accomplish the goals of this strategic plan. xi Palo Verde Generating Station spray pond ABBREVIATIONS AND ACRONYMS AI Artificial Intelligenc e AICoP Artificial Intelligenc e Community of Practice AISC Artificial Intelligenc e Steering Committee FR Federal Register FY Fiscal Year NRC U.S. Nuclear R egulatory Commission xiiiNRC Chairman Hanson receives a demonstration of a robot used for limited-access area inspections. INTRODUCTION For the purposes of this document, artificial intelligence (AI) refers to a machine- based system that can go beyond defined results and scenarios and has the ability to emulate human-like perception, cognition, planning, learning, communication, or physical action. For a given set of human-defined objectives, AI can make predictions, recommendations, or decisions influencing real or virtual environments."
  },
  {
    "id": "ML23132A305_chunk_13",
    "text": "Source: 14 ML23132A305.pdf\n\narea inspections. INTRODUCTION For the purposes of this document, artificial intelligence (AI) refers to a machine- based system that can go beyond defined results and scenarios and has the ability to emulate human-like perception, cognition, planning, learning, communication, or physical action. For a given set of human-defined objectives, AI can make predictions, recommendations, or decisions influencing real or virtual environments. These systems use machine- and human-based inputs to perceive real and virtual environments, abstract such perceptions into models through analysis in an automated manner, and use model inference to formulate options for information or action [2] . The AI Strategic Plan focuses on a broad spectrum of AI sub-specialties (e.g., natural language processing, machine learning, deep learning, etc.) which could encompass various algorithms and application examples which the U.S. Nuclear Regulatory Commission (NRC) has not previously reviewed and evaluated. The NRC has developed the AI Strategic Plan to plan and prepare for new technologies involving AI. Any future guidance or rulemaking, if needed, will follow the agency’s routine processes. An AI algorithm is a computer program that has been trained on a set of data to recognize certain types of patterns. AI uses various types of algorithms to reason over and learn from this data, with the overarching goal of providing solutions that mimic human-based decisions and predictions for problems."
  },
  {
    "id": "ML23132A305_chunk_14",
    "text": "Source: 14 ML23132A305.pdf\n\nrulemaking, if needed, will follow the agency’s routine processes. An AI algorithm is a computer program that has been trained on a set of data to recognize certain types of patterns. AI uses various types of algorithms to reason over and learn from this data, with the overarching goal of providing solutions that mimic human-based decisions and predictions for problems. Unlike developing and coding a traditional software program with specific instructions to complete a task, AI seeks to learn to recognize patterns and make predictions. This AI Strategic Plan considers an evolving landscape where computers use data and unseen behavior to construct the underlying algorithmic model, draw inferences, and define the rules to achieve a task. Advances in computing technologies have led to the expanded use of AI across multiple disciplines in the public and private sectors, both domestically and internationally. AI provides new opportunities for organizations to enhance safety and security, improve processes, leverage historical and current data, identify research needs, and even explore autonomous control and operation. As a result, the nuclear industry has expressed interest in deploying these technologies. The NRC remains committed to enabling the safe and secure use of new technologies, especially those that can enhance the safety and security of nuclear facilities."
  },
  {
    "id": "ML23132A305_chunk_15",
    "text": "Source: 14 ML23132A305.pdf\n\nenhance safety and security, improve processes, leverage historical and current data, identify research needs, and even explore autonomous control and operation. As a result, the nuclear industry has expressed interest in deploying these technologies. The NRC remains committed to enabling the safe and secure use of new technologies, especially those that can enhance the safety and security of nuclear facilities. The NRC is committed to keeping pace with technological innovations to effectively and efficiently carry out its safety and security mission. 1-1 The AI Strategic Plan was developed considering a variety of ongoing and future regulatory actions, and this strategy and its implementation will support those other activities. Thus, this strategy supports the NRC’s mission, 1 broadly aligns with the agency’s Principles of Good Regulation,2 and is tied to the following: • NUREG-1614, Volume 8, “U.S. Nuclear Regulatory Commission Strategic Plan: Fiscal Years 2022-2026,” issued April 2022 [1] • NRC, “International Strategy: 2021-2025,” issued August 2021 [3] • NUREG-1908, Volume 4, “Information Technology Information Management Strategic Plan: Fiscal Years 2020-2024,” issued November 2019 [4] AI encompasses numerous technical disciplines involving data and foundational concepts (e.g., data analysis, statistics, computer programming, engineering), many of which the NRC already has experience with to conduct its regulatory mission."
  },
  {
    "id": "ML23132A305_chunk_16",
    "text": "Source: 14 ML23132A305.pdf\n\nApril 2022 [1] • NRC, “International Strategy: 2021-2025,” issued August 2021 [3] • NUREG-1908, Volume 4, “Information Technology Information Management Strategic Plan: Fiscal Years 2020-2024,” issued November 2019 [4] AI encompasses numerous technical disciplines involving data and foundational concepts (e.g., data analysis, statistics, computer programming, engineering), many of which the NRC already has experience with to conduct its regulatory mission. However, given major advancements in AI, it is critical to establish how AI builds upon and relates to other data fields to understand the potential uses of AI in NRC-regulated activities. Figure 1 illustrates these relationships in two different ways. On the left is a pyramid representing the increasing levels of complexity and maturity needed to implement AI within an organization. The foundation of this pyramid is data collection, which establishes the databases from which the AI is developed. Next is data infrastructure, which includes tools to organize and transform the collected data, make it available, and govern its use. From this point, the data may be used in data analytics, which provides plots and descriptive statistics that can be used in decision-making. Once the organization is capable of data analytics, it can pursue data science, which entails predictive modeling using data. Lastly, AI is at the apex of the pyramid with the supporting foundational fields underneath."
  },
  {
    "id": "ML23132A305_chunk_17",
    "text": "Source: 14 ML23132A305.pdf\n\ngovern its use. From this point, the data may be used in data analytics, which provides plots and descriptive statistics that can be used in decision-making. Once the organization is capable of data analytics, it can pursue data science, which entails predictive modeling using data. Lastly, AI is at the apex of the pyramid with the supporting foundational fields underneath. As shown Figure 1, this AI Strategic Plan primarily covers AI and data science applications. 1-21 The NRC’s mis sion can be found at https://www.nrc.gov/about-nrc/values.html. 2 The NRC’s Principl es of Good Regulation and other values can be found at https://www.nrc.gov/ about-nrc/values.html#principles. Figure 1 Artificial Intelligenc e Hierarchy and Relationship with the NRC AI Strat egic Plan (adapted from [5] and [6]) The right side of Figure 1 illustrates an overview of major fields within the scope of the AI Strategic Plan. As shown in the figure, this AI Strategic Plan considers machine learning, deep learning, and natural language processing to be subsets of AI with data science being a foundational discipline. AI technologies provide the underlying capability for autonomous systems. While AI enables autonomy, not all uses of AI are autonomous. For example, many AI capabilities may be used to augment human decision-making rather than replace it. Table 1 provides notional AI and autonomy levels in potential commercial nuclear activities."
  },
  {
    "id": "ML23132A305_chunk_18",
    "text": "Source: 14 ML23132A305.pdf\n\nbe subsets of AI with data science being a foundational discipline. AI technologies provide the underlying capability for autonomous systems. While AI enables autonomy, not all uses of AI are autonomous. For example, many AI capabilities may be used to augment human decision-making rather than replace it. Table 1 provides notional AI and autonomy levels in potential commercial nuclear activities. Higher autonomy levels indicate less reliance on human intervention or oversight and, therefore, may require greater regulatory scrutiny of the AI system. AI Strategic Goal 1, discussed further in Section 4.1, will assess the current regulatory framework and establish the appropriate regulatory requirements for varying degrees of AI and autonomy. Lastly, the NRC recognizes that there are differences between automation 3 and autonomy in potential uses of AI in NRC-regulated applications. As such, the NRC will treat these differences with the appropriate level of regulatory scrutiny and consider the multiple criteria necessary to determine the appropriate regulatory involvement for each level. 1-3 3 Automation is considered to be a system that automatically takes action on a specific task according to pre-defined, prescriptive rules. For example, reactor protection systems are automatically actuated when process parameters exceed certain defined limits."
  },
  {
    "id": "ML23132A305_chunk_19",
    "text": "Source: 14 ML23132A305.pdf\n\ndifferences with the appropriate level of regulatory scrutiny and consider the multiple criteria necessary to determine the appropriate regulatory involvement for each level. 1-3 3 Automation is considered to be a system that automatically takes action on a specific task according to pre-defined, prescriptive rules. For example, reactor protection systems are automatically actuated when process parameters exceed certain defined limits. In an autonomous system, both the point at which action is taken and the action that is taken are the result of training an algorithm on data collected about the system."
  },
  {
    "id": "ML23132A305_chunk_20",
    "text": "Source: 14 ML23132A305.pdf\n\nsystem that automatically takes action on a specific task according to pre-defined, prescriptive rules. For example, reactor protection systems are automatically actuated when process parameters exceed certain defined limits. In an autonomous system, both the point at which action is taken and the action that is taken are the result of training an algorithm on data collected about the system. Table 1 Notional AI and Aut onomy Levels in Commercial Nuclear Activities Notional AI and Autonomy LevelsPotential Uses of AI and Autonomy in Commercial Nuclear Activities Level 0: AI Not Used No AI or autonomy integration in systems or processes Level 1: Insight (Human decision-making assisted by a machine)AI integration in systems is used for optimization, operational guidance, or business process automation that would not affect plant safety/security and control Level 2: Collaboration (Human decision-making augmented by a machine)AI integration in systems where algorithms make recommendations that could affect plant safety/security and control are vetted and carried out by a human decisionmaker Level 3: Operation (Machine decision-making supervised by a human)AI and autonomy integration in systems where algorithms make decisions and conduct operations with human oversight that could affect plant safety/ security and control Level 4: Fully Autonomous (Machine decision-making with no human intervention)Fully autonomous AI in systems where the algorithm is responsible for operation, control, and intelligent adaptation without reliance on human intervention or oversight that could affect plant safety/security and control The NRC recognizes the output of this AI Strategic Plan may also support agency use of AI tools to enhance internal NRC activities."
  },
  {
    "id": "ML23132A305_chunk_21",
    "text": "Source: 14 ML23132A305.pdf\n\nFully Autonomous (Machine decision-making with no human intervention)Fully autonomous AI in systems where the algorithm is responsible for operation, control, and intelligent adaptation without reliance on human intervention or oversight that could affect plant safety/security and control The NRC recognizes the output of this AI Strategic Plan may also support agency use of AI tools to enhance internal NRC activities. For example, the NRC will gain additional knowledge and expertise in AI and data literacy to potentially support expanding use for decision-making across the agency. Further discussion related to considerations on internal agency use of AI can be found in Appendix B. 1-4 VISION The NRC’s vision is to continue to keep pace with technological innovations to allow for the safe and secure use of AI in NRC-regulated activities, when appropriate. 2-1 Palo Verde Nuclear Generating Station control room PURPOSE AND DRIVERS The purpose of the AI Strategic Plan is to ensure the staff’s readiness to review the use of AI in NRC-regulated activities as the nuclear industry has expressed interest in deploying AI applications. Based on feedback from the NRC’s Data Science and AI Regulatory Applications Public Workshops, 4 the nuclear industry could start deploying AI technologies in the near future and has already begun investigating, developing, and assessing how such technologies can be used."
  },
  {
    "id": "ML23132A305_chunk_22",
    "text": "Source: 14 ML23132A305.pdf\n\nreview the use of AI in NRC-regulated activities as the nuclear industry has expressed interest in deploying AI applications. Based on feedback from the NRC’s Data Science and AI Regulatory Applications Public Workshops, 4 the nuclear industry could start deploying AI technologies in the near future and has already begun investigating, developing, and assessing how such technologies can be used. Licensing applications that include the use of AI technologies may be submitted to the NRC for review and approval in the next few years. In fiscal year (FY) 2021, the NRC began actively coordinating within the agency and across the nuclear industry to better understand activities and plans for AI by (1) conducting an internal scan to ascertain the scope of existing NRC projects that may fall within the technical area of AI, (2) issuing a Federal Register (FR) notice 5 to solicit feedback on the nuclear industry’s AI readiness and applications, and (3) hosting a series of Data Science and AI Regulatory Applications Public Workshops to provide a forum for the NRC, nuclear industry, and relevant stakeholders to discuss the state of knowledge and research activities related to data science and AI and their application in the nuclear industry."
  },
  {
    "id": "ML23132A305_chunk_23",
    "text": "Source: 14 ML23132A305.pdf\n\n5 to solicit feedback on the nuclear industry’s AI readiness and applications, and (3) hosting a series of Data Science and AI Regulatory Applications Public Workshops to provide a forum for the NRC, nuclear industry, and relevant stakeholders to discuss the state of knowledge and research activities related to data science and AI and their application in the nuclear industry. In February 2022, the NRC issued NUREG/CR-7294, “Exploring Advanced Computational Tools and Techniques with Artificial Intelligence and Machine Learning in Operating Nuclear Plants” [7] , documenting the current state of practice of AI tools in the nuclear industry. In July 2022, the NRC issued an FR notice 6 to solicit feedback on the draft AI Strategic Plan. The staff used these insights in the development of this AI Strategic Plan. The NRC has also learned from nuclear industry, U.S. Government agencies, nonprofit organizations, academia, international counterparts with mature or developing AI programs, and the public to gain valuable insights to inform the development of this AI Strategic Plan. 4 The NRC hosted a series o f Data Science and AI Regulatory Applications Public Workshops in June, August, and November 2021 to provide a forum for the NRC, nuclear industry, and stakeholders to discuss the state of knowledge and research activities related to data science and AI and their application in the nuclear industry."
  },
  {
    "id": "ML23132A305_chunk_24",
    "text": "Source: 14 ML23132A305.pdf\n\nof this AI Strategic Plan. 4 The NRC hosted a series o f Data Science and AI Regulatory Applications Public Workshops in June, August, and November 2021 to provide a forum for the NRC, nuclear industry, and stakeholders to discuss the state of knowledge and research activities related to data science and AI and their application in the nuclear industry. At these workshops, the NRC worked with internal and external stakeholders to identify the benefits and risks associated with the use of AI in regulatory activities and discussed ongoing and planned projects in the nuclear industry. For more details, see the NRC public Web site at https://www.nrc.gov/public-involve/conference-symposia/data-science-ai-reg-workshops.html. 5 See 86 FR 20744, “Role of Artificial Intelligence Tools in U.S. Commercial Nuclear Power Operations,” at https://www.federalregister .gov/documents/2021/04/21/2021-08177/role-of-artificial-intelligence-tools-in-us-commercial-nuclear-power-operations. 6 See 87 FR 39874, “NRC’s Fiscal Years 2023-2027 Artificial Intelligence Strategic Plan,” at https:// www.federalregister .gov/documents/2022/07/05/2022-14239/nrcs-fiscal-years-2023-2027-artificial-intelligence-strategic-plan. 3-1 Spent fuel pool of Unit 2 at Brunswick Nuclear Power Plant STRATEGIC GOALS The AI Strategic Plan sets out the five strategic goals shown in Figure 2 to ensure readiness for reviewing the use of AI in NRC-regulated activities."
  },
  {
    "id": "ML23132A305_chunk_25",
    "text": "Source: 14 ML23132A305.pdf\n\nat https://www.federalregister .gov/documents/2021/04/21/2021-08177/role-of-artificial-intelligence-tools-in-us-commercial-nuclear-power-operations. 6 See 87 FR 39874, “NRC’s Fiscal Years 2023-2027 Artificial Intelligence Strategic Plan,” at https:// www.federalregister .gov/documents/2022/07/05/2022-14239/nrcs-fiscal-years-2023-2027-artificial-intelligence-strategic-plan. 3-1 Spent fuel pool of Unit 2 at Brunswick Nuclear Power Plant STRATEGIC GOALS The AI Strategic Plan sets out the five strategic goals shown in Figure 2 to ensure readiness for reviewing the use of AI in NRC-regulated activities. 4-1 Figure 2 Ov erview of Strategic Goals As shown above, the first strategic goal is the ultimate outcome of the implementation of this strategic plan, which is to continue to keep pace with technological innovations to allow for the safe and secure use of AI in NRC-regulated activities, when appropriate, through existing or new regulatory guidance, rules, inspection procedures, or oversight activities (AI Strategic Goal 1). AI Strategic Goals 2 through 5 directly support preparatory activities that culminate in successfully supporting technical readiness for regulatory decision-making activities desired in AI Strategic Goal 1. The establishment of the organizational framework (AI Strategic Goal 2) ensures all aspects of the NRC are represented in the preparations for reviewing AI in NRC-regulated activities."
  },
  {
    "id": "ML23132A305_chunk_26",
    "text": "Source: 14 ML23132A305.pdf\n\noversight activities (AI Strategic Goal 1). AI Strategic Goals 2 through 5 directly support preparatory activities that culminate in successfully supporting technical readiness for regulatory decision-making activities desired in AI Strategic Goal 1. The establishment of the organizational framework (AI Strategic Goal 2) ensures all aspects of the NRC are represented in the preparations for reviewing AI in NRC-regulated activities. Strong partnerships are essential to ensuring the safe and secure use of AI in the nuclear industry. As such, the NRC is committed to engaging the industry and relevant stakeholders to maintain awareness of industry efforts (AI Strategic Goal 3) and prepare for regulatory reviews. The NRC will also engage in workforce development and acquisition to ensure that the NRC staff and contractors have the critical skills required (AI Strategic Goal 4) to evaluate the use of AI in NRC-regulated activities. The NRC recognizes the establishment of a foundation in data science as a fundamental requirement for evaluating AI applications. Therefore, the NRC will build the necessary AI foundation to pursue use cases across the NRC (AI Strategic Goal 5), which will foster organizational experience that supports future regulatory reviews and oversight activities. The AI Strategic Goals are listed in order of priority and are expected to be initiated during different timeframes."
  },
  {
    "id": "ML23132A305_chunk_27",
    "text": "Source: 14 ML23132A305.pdf\n\nas a fundamental requirement for evaluating AI applications. Therefore, the NRC will build the necessary AI foundation to pursue use cases across the NRC (AI Strategic Goal 5), which will foster organizational experience that supports future regulatory reviews and oversight activities. The AI Strategic Goals are listed in order of priority and are expected to be initiated during different timeframes. Several organizations within the NRC play a significant role in achieving the strategic goals, and the successful implementation of activities necessary to achieve the goals outlined in this AI Strategic Plan will involve NRC staff members with varied expertise. The NRC will also continue to monitor external factors that may influence the ability to achieve these strategic goals. The NRC developed an agency evidence-building plan [8] , as r equired by the Foundations for Evidence-Based Policymaking Act of 2018 [9] , f or identifying and addressing priority questions relevant to the agency’s programs, policies, and regulations. The NRC will leverage the resulting evidence gathered through the execution of the agency evidence-building plan to support the AI strategic goals. Furthermore, the AI strategic goals may inform the use of AI tools within the agency and enhance select activities, as discussed in Appendix B of this AI Strategic Plan."
  },
  {
    "id": "ML23132A305_chunk_28",
    "text": "Source: 14 ML23132A305.pdf\n\nquestions relevant to the agency’s programs, policies, and regulations. The NRC will leverage the resulting evidence gathered through the execution of the agency evidence-building plan to support the AI strategic goals. Furthermore, the AI strategic goals may inform the use of AI tools within the agency and enhance select activities, as discussed in Appendix B of this AI Strategic Plan. 4.1 Str ategic Goal 1: Ensure NRC Readiness for Regulatory Decision-Making The deployment of AI technologies by the nuclear industry is on the horizon. The NRC anticipates that within the next few years an existing licensee, new, or advanced nuclear technology applicant may employ AI in such a manner that it requires NRC regulatory approval or oversight. Guided by the agency’s Principles of Good Regulation, 7 the NRC will continue to be effective and efficient as it conducts its safety and security mission. This goal focuses on developing the regulatory guidance and tools to prepare the staff to assess AI as part of NRC regulatory activities. The NRC recognizes that the nuclear industry is likely to use AI in applications (e.g., notional AI and autonomy adoption levels in Table 1) for the design and operation of nuclear facilities that may require regulatory approval or oversight."
  },
  {
    "id": "ML23132A305_chunk_29",
    "text": "Source: 14 ML23132A305.pdf\n\nfocuses on developing the regulatory guidance and tools to prepare the staff to assess AI as part of NRC regulatory activities. The NRC recognizes that the nuclear industry is likely to use AI in applications (e.g., notional AI and autonomy adoption levels in Table 1) for the design and operation of nuclear facilities that may require regulatory approval or oversight. Therefore, the NRC will assess whether any regulatory guidance (e.g., regulatory guides or standard review plan sections) or inspection procedures need to be updated or created to clarify the process and procedure for the licensing and oversight of AI in NRC-regulated activities. The need for revision will be based on the information gathered through the execution of this AI Strategic Plan, engagement with external stakeholders (AI Strategic Goal 3), and experience obtained through pursuing internal use cases and their impact on the agency’s regulatory framework (AI Strategic Goal 5). For example, the NRC will leverage its experience reviewing relevant historical 7 The NRC’ s Principles of Good Regulation and other values can be found at https://www.nrc.gov/ about-nrc/values.html#principles. 4-2 models as it determines the requirements for new, more detailed models. Additionally, the NRC will leverage lessons learned from previous new technology applications in NRC-regulated activities to inform the development of the AI framework."
  },
  {
    "id": "ML23132A305_chunk_30",
    "text": "Source: 14 ML23132A305.pdf\n\nNRC will leverage its experience reviewing relevant historical 7 The NRC’ s Principles of Good Regulation and other values can be found at https://www.nrc.gov/ about-nrc/values.html#principles. 4-2 models as it determines the requirements for new, more detailed models. Additionally, the NRC will leverage lessons learned from previous new technology applications in NRC-regulated activities to inform the development of the AI framework. Lastly, additional options for long-range changes for AI regulatory reviews and oversight that might require rulemaking will also be considered. The NRC will undertake research to develop an AI framework to determine the approach to assess technical areas such as, but not limited to, topics shown in Table 2. The NRC will also work with agency stakeholders and the international regulatory community to determine the currently available AI standards and identify the technical areas where gaps may exist. In addition, the NRC will participate with standards development organizations and work with Federal agencies and the international regulatory community (AI Strategic Goal 3) to offer critical expertise and perspectives to inform the drafting and revision of AI standards and guidance documents."
  },
  {
    "id": "ML23132A305_chunk_31",
    "text": "Source: 14 ML23132A305.pdf\n\nregulatory community to determine the currently available AI standards and identify the technical areas where gaps may exist. In addition, the NRC will participate with standards development organizations and work with Federal agencies and the international regulatory community (AI Strategic Goal 3) to offer critical expertise and perspectives to inform the drafting and revision of AI standards and guidance documents. Table 2 Potential AI Technical Considerations for Regulatory Decision-Making The development of the AI framework will be communicated with agency stakeholders and the public to maintain transparency and clearly communicate regulatory guidance to the nuclear industry as early as possible in the process (AI Strategic Goal 3). For this goal, a successful outcome is providing, as needed, the regulatory guidance and tools to ensure readiness for reviewing the use of AI in NRC-regulated activities. 4-3Explainability Trustworthiness Bias Robustness Ethics Security Risk AnalysisTest, Evaluation, Verification and ValidationAssurance Processes Model Maintenance Domain Adaptation Data Drift Fielded Performance DegradationLife Cycle ManagementData Quality, Quantity, Applicability, and Uncertainty 4.2 Str ategic Goal 2: Establish an Organizational Framework to Review AI Applications The successful implementation of the AI Strategic Plan requires effective coordination and collaboration across the NRC, at both the management and staff levels."
  },
  {
    "id": "ML23132A305_chunk_32",
    "text": "Source: 14 ML23132A305.pdf\n\nSecurity Risk AnalysisTest, Evaluation, Verification and ValidationAssurance Processes Model Maintenance Domain Adaptation Data Drift Fielded Performance DegradationLife Cycle ManagementData Quality, Quantity, Applicability, and Uncertainty 4.2 Str ategic Goal 2: Establish an Organizational Framework to Review AI Applications The successful implementation of the AI Strategic Plan requires effective coordination and collaboration across the NRC, at both the management and staff levels. The NRC will establish an internal Artificial Intelligence Steering Committee (AISC) to provide cross- office coordination and direction to ensure readiness for regulatory decision-making and develop AI governance. The AISC will include senior management with responsibility for AI technology across the agency. The AISC may engage external subject-matter experts with AI expertise to assist with specific issues, as needed. The AISC will also leverage existing information technology, data, and security communities and expertise. They will coordinate with the Information Technology and Information Management Portfolio Executive Council to ensure direct prioritization of the activities that will enable the achievement of the strategic goals outlined in this document."
  },
  {
    "id": "ML23132A305_chunk_33",
    "text": "Source: 14 ML23132A305.pdf\n\nexternal subject-matter experts with AI expertise to assist with specific issues, as needed. The AISC will also leverage existing information technology, data, and security communities and expertise. They will coordinate with the Information Technology and Information Management Portfolio Executive Council to ensure direct prioritization of the activities that will enable the achievement of the strategic goals outlined in this document. To support staff engagement and collaboration, the NRC will need to establish an internal AI Community of Practice (AICoP) to provide a forum for the NRC staff to (1) discuss best practices and lessons learned for reviewing requests that include the use of AI technologies, (2) provide agencywide awareness on active and potential use cases, and (3) facilitate the sharing of best practices and lessons learned. The AICoP will be compromised of NRC staff members from across the agency who are active in or interested in AI policy, technology, standards, and programs. In addition, AI working groups will support the AISC’s efforts as needed to execute the AI Strategic Plan, such as prioritization of AI research, technical workshops, and specific subject-matter tasks as assigned. Membership for the AI working groups to support relevant subject matter expertise can be drawn from the AICoP."
  },
  {
    "id": "ML23132A305_chunk_34",
    "text": "Source: 14 ML23132A305.pdf\n\nin or interested in AI policy, technology, standards, and programs. In addition, AI working groups will support the AISC’s efforts as needed to execute the AI Strategic Plan, such as prioritization of AI research, technical workshops, and specific subject-matter tasks as assigned. Membership for the AI working groups to support relevant subject matter expertise can be drawn from the AICoP. A successful outcome of this goal is an organization that facilitates effective coordination and collaboration across the NRC to ensure readiness for reviewing the use of AI in NRC-regulated activities. 4.3 Str ategic Goal 3: Strengthen and Expand AI Partnerships Strong partnerships across the Federal Government, with the nuclear industry, and with international counterparts are essential in order to gain valuable information to benchmark the agency’s AI activities and serve as force multipliers to optimize resources and effort. Scientific and technological exchange ensures the NRC remains current in the rapidly evolving AI field. 4-4 The NRC will continue to strengthen and expand strong AI working partnerships with domestic and international counterparts within the nuclear industry to stay abreast of industry interests, activities, and plans to deploy AI. For domestic AI activities, the NRC will continue to engage with stakeholders, including the public, nongovernmental organizations, and regulated entities through existing and new memoranda of understanding, public meetings, and workshops."
  },
  {
    "id": "ML23132A305_chunk_35",
    "text": "Source: 14 ML23132A305.pdf\n\nto strengthen and expand strong AI working partnerships with domestic and international counterparts within the nuclear industry to stay abreast of industry interests, activities, and plans to deploy AI. For domestic AI activities, the NRC will continue to engage with stakeholders, including the public, nongovernmental organizations, and regulated entities through existing and new memoranda of understanding, public meetings, and workshops. For international AI activities, the NRC will continue to engage with international counterparts and multilateral organizations to collaborate in sharing information on the use of AI in NRC-regulated activities, conduct cooperative research, and influence the development of international standards and guidance. The NRC is aware that other Federal agencies and industry sectors are faced with the potential challenges of safely and securely deploying, overseeing, and evaluating AI technologies. In some cases, other Government agencies have more experience with assessment and implementation of AI. Their experience and lessons learned provide the NRC with a unique opportunity to engage in intergovernmental information sharing, collaboration, and potential technology transfer from those agencies. The NRC will continue to build partnerships with other Government agencies to facilitate the exchange of ideas, practices, and procedures."
  },
  {
    "id": "ML23132A305_chunk_36",
    "text": "Source: 14 ML23132A305.pdf\n\nsome cases, other Government agencies have more experience with assessment and implementation of AI. Their experience and lessons learned provide the NRC with a unique opportunity to engage in intergovernmental information sharing, collaboration, and potential technology transfer from those agencies. The NRC will continue to build partnerships with other Government agencies to facilitate the exchange of ideas, practices, and procedures. Incorporating the information and knowledge gathered from external organizations, including regulatory research, industry, Federal partners, standards, and international bodies, into the NRC staff knowledge base will allow for timely and informed regulatory decision-making. The NRC will coordinate external interactions, disseminate information from these interactions to the appropriate NRC staff, and support technical training and workshops to build AI awareness across the NRC offices. When achieved, this goal will provide established mechanisms to (1) maintain awareness of industry plans, (2) establish communication forums to discuss future plans and regulatory needs, and (3) effectively partner with other agencies on AI topics of mutual benefit. 4.4 Str ategic Goal 4: Cultivate an AI-Proficient Workforce The NRC recognizes the value of acquiring, developing, and retaining a skilled workforce in the area of AI. The term AI is often used generically to encompass a wide range of applications, from data analysis to fully autonomous systems."
  },
  {
    "id": "ML23132A305_chunk_37",
    "text": "Source: 14 ML23132A305.pdf\n\n(3) effectively partner with other agencies on AI topics of mutual benefit. 4.4 Str ategic Goal 4: Cultivate an AI-Proficient Workforce The NRC recognizes the value of acquiring, developing, and retaining a skilled workforce in the area of AI. The term AI is often used generically to encompass a wide range of applications, from data analysis to fully autonomous systems. The NRC will develop a common understanding of AI by providing the NRC staff with seminars, workshops, and training. This goal focuses on developing the technical information, knowledge, and tools to prepare the staff to review AI applications. The NRC must have the right number of people with the right skills at the right time to conduct effective and efficient regulatory 4-5 reviews and oversight activities to accomplish its safety and security mission. Given the competitive marketplace for AI talent, the NRC will establish and stabilize a pipeline for AI talent by using the Strategic Workforce Planning and Competency Models to meet this strategic goal and support NRC needs. A primary mechanism for building this pipeline is leveraging existing hiring processes (e.g., NRC Integrated University Program, internships and cooperative education programs, the Nuclear Regulator Apprenticeship Network program, and the Information Technology Fellows or Graduate Fellows programs)."
  },
  {
    "id": "ML23132A305_chunk_38",
    "text": "Source: 14 ML23132A305.pdf\n\na pipeline for AI talent by using the Strategic Workforce Planning and Competency Models to meet this strategic goal and support NRC needs. A primary mechanism for building this pipeline is leveraging existing hiring processes (e.g., NRC Integrated University Program, internships and cooperative education programs, the Nuclear Regulator Apprenticeship Network program, and the Information Technology Fellows or Graduate Fellows programs). In addition, the NRC will fully use Federal retention authorities to maintain a skilled AI workforce and allow talented experts to contribute to AI research and development activities. The NRC will cultivate the talent of its existing highly skilled workforce by investing in comprehensive training for NRC staff and managers working on use cases (AI Strategic Goal 5). The NRC AI training program will use a tiered approach, providing training ranging from basic to advanced concepts, applications, and AI tools tailored to the needs of the agency and staff development objectives. The goal is to adopt the appropriate training programs and tools to develop the requisite skills in the NRC workforce. A successful outcome of this goal is to ensure appropriate qualifications, training, expertise, and access to tools exist for the workforce to review and evaluate AI usage in NRC-regulated activities effectively, efficiently and in a timely manner."
  },
  {
    "id": "ML23132A305_chunk_39",
    "text": "Source: 14 ML23132A305.pdf\n\nstaff development objectives. The goal is to adopt the appropriate training programs and tools to develop the requisite skills in the NRC workforce. A successful outcome of this goal is to ensure appropriate qualifications, training, expertise, and access to tools exist for the workforce to review and evaluate AI usage in NRC-regulated activities effectively, efficiently and in a timely manner. 4.5 Str ategic Goal 5: Pursue Use Cases to Build an AI Foundation Across the NRC AI technologies may pose novel challenges for the NRC regulatory framework. As the NRC prepares for regulatory decision-making, internal uses of AI tools will increase staff knowledge and experience for future regulatory reviews and oversight, especially when those same tools may be used in external AI applications. This goal focuses on developing and pursuing use cases, consistent with priority question two of the agency evidence-building plan (as discussed in Appendix B of this AI Strategic Plan), to build technical expertise for reviewing the use of AI in NRC-regulated activities. To build this expertise, the NRC needs to create an ecosystem that supports data science, assessment and integration of emerging AI tools, and hands-on talent development for reviewing the use of AI in NRC-regulated activities. To better understand how AI algorithms, models, and claims are validated and tested, the NRC needs to undertake research to develop use cases with data from various sources and in multiple forms."
  },
  {
    "id": "ML23132A305_chunk_40",
    "text": "Source: 14 ML23132A305.pdf\n\nto create an ecosystem that supports data science, assessment and integration of emerging AI tools, and hands-on talent development for reviewing the use of AI in NRC-regulated activities. To better understand how AI algorithms, models, and claims are validated and tested, the NRC needs to undertake research to develop use cases with data from various sources and in multiple forms. These use cases will help the staff gain AI expertise that could be used in performing regulatory reviews or assessments for a wide range of potential AI 4-6 4-7applications. In addition, the NRC is planning to investigate engaging collaboratively with the nuclear industry to pursue potential pilot studies and proofs of concept to serve as a foundation for reviewing the use of AI in NRC-regulated activities. These pilots and proofs of concept, which would rely on industry feedback and engagement, may help in identifying challenges associated with getting the AI applications through the AI framework. Lastly, the NRC will investigate improving staff access to software-based AI tools as part of the AI ecosystem which may be required to review and evaluate AI applications in NRC-regulated activities. Additionally, providing access to training and development with respect to the tools under the AI ecosystem facilitates staff engagement in training exercises that may mimic future regulatory reviews using such tools."
  },
  {
    "id": "ML23132A305_chunk_41",
    "text": "Source: 14 ML23132A305.pdf\n\nNRC will investigate improving staff access to software-based AI tools as part of the AI ecosystem which may be required to review and evaluate AI applications in NRC-regulated activities. Additionally, providing access to training and development with respect to the tools under the AI ecosystem facilitates staff engagement in training exercises that may mimic future regulatory reviews using such tools. This will allow staff to develop expertise and identify and address potential gaps in future regulatory reviews. For this goal, a successful outcome is one in which the NRC staff possesses an ecosystem that supports AI analysis, integration of emerging AI tools, and hands-on talent development for reviewing AI applications from the nuclear industry. McGuire Nuclear Station, Units 1 and 2 CONCLUSION The NRC remains committed to ensuring that the use of new technologies is safe and secure. New technologies, like AI, have the potential to enhance the safety and security of nuclear facilities. This AI Strategic Plan presents the vision and goals for the NRC to cultivate an AI-proficient workforce, keep pace with AI technological innovations, and ensure the safe and secure use of AI in NRC-regulated activities. 5-1 REFERENCES 1. NRC, “U.S. Nuclear Regulatory Commission Strategic Plan: Fiscal Years 2022- 2026,” Washington, DC, NUREG-1614, Vol. 8, ML22067A170, 2022. 2. 116th U.S."
  },
  {
    "id": "ML23132A305_chunk_42",
    "text": "Source: 14 ML23132A305.pdf\n\nfacilities. This AI Strategic Plan presents the vision and goals for the NRC to cultivate an AI-proficient workforce, keep pace with AI technological innovations, and ensure the safe and secure use of AI in NRC-regulated activities. 5-1 REFERENCES 1. NRC, “U.S. Nuclear Regulatory Commission Strategic Plan: Fiscal Years 2022- 2026,” Washington, DC, NUREG-1614, Vol. 8, ML22067A170, 2022. 2. 116th U.S. Congress, “H.R.6395 - National Defense Authorization Act for Fiscal Year 2021: National Artificial Intelligence Initiative Act of 2020,” 2021. [Online]. Available: https://www.congress.gov/bill/116th-congress/house-bill/6395/text. 3. NRC, “International Strategy: 2021-2025,” Washington, DC, ML21236A120, https://www.nrc.gov/docs/ML2123/ML21236A120.pdf, 2021. 4. NRC, “Information Technology and Information Management Strategic Plan: Fiscal Years 2020-2024,” U.S. Nuclear Regulatory Commission, Washington, DC, NUREG-1908, Vol. 4, ML19323D858, https://www.nrc.gov/docs/ML1932/ML19323D858.pdf, 2019. 5. O. Osagie, “medium.com,” Medium, 21 February 2021. [Online]. Available: https:// medium.com/swlh/the-ai-hierarchy-of-needs-9b015d061f29. [Accessed January 2022]. 6. A. N. J. P. a. R. S. Andy Ho, “A Data Science Approach to Defining a Data Scientist,” SMU Data Science Review, vol. 2, no. 3, 2019. 7. NRC, “Exploring Advanced Computational Tools and Techniques with Artificial Intelligence and Machine Learning in Operating Nuclear Plants,” U.S."
  },
  {
    "id": "ML23132A305_chunk_43",
    "text": "Source: 14 ML23132A305.pdf\n\nOsagie, “medium.com,” Medium, 21 February 2021. [Online]. Available: https:// medium.com/swlh/the-ai-hierarchy-of-needs-9b015d061f29. [Accessed January 2022]. 6. A. N. J. P. a. R. S. Andy Ho, “A Data Science Approach to Defining a Data Scientist,” SMU Data Science Review, vol. 2, no. 3, 2019. 7. NRC, “Exploring Advanced Computational Tools and Techniques with Artificial Intelligence and Machine Learning in Operating Nuclear Plants,” U.S. Nuclear Regulatory Commission, Washington, DC, NUREG/CR-7294, ML22042A662, https://www.nrc.gov/docs/ML2204/ML22042A662.pdf, 2022. 8. NRC, “Evidence Building Plan, Fiscal Year 2022,” U.S. Nuclear Regulatory Commission, Rockville, MD, https://www.nrc.gov/docs/ML2206/ML22066B056.pdf, ML22066B056, 2022. 9. 115th U.S. Congress, “H.R.4174 - Foundations for Evidence-Based Policymaking Act of 2018,” 2021. [Online]. Available: https://www.congress.gov/bill/115th-congress/house-bill/4174/text. 6-1 Calvert Cliffs Nuclear Power Plant, Units 1 and 2 APPENDIX A GLOSSARY • ARTIFICIAL INTELLIGENCE (AI): The term AI refers to a machine-based system that can go beyond defined results and scenarios and has the ability to emulate human-like perception, cognition, planning, learning, communication, or physical action. For a given set of human-defined objectives, AI can make predictions, recommendations, or decisions influencing real or virtual environments."
  },
  {
    "id": "ML23132A305_chunk_44",
    "text": "Source: 14 ML23132A305.pdf\n\n1 and 2 APPENDIX A GLOSSARY • ARTIFICIAL INTELLIGENCE (AI): The term AI refers to a machine-based system that can go beyond defined results and scenarios and has the ability to emulate human-like perception, cognition, planning, learning, communication, or physical action. For a given set of human-defined objectives, AI can make predictions, recommendations, or decisions influencing real or virtual environments. AI systems use machine- and human-based inputs to perceive real and virtual environments, abstract such perceptions into models through analysis in an automated manner, and use model inference to formulate options for information or action (adapted from [1]). • AI APPLICATION: An AI application represents a use case, project, plan, or other topic area that uses various AI technology and tools to conduct research and development or create a production product, service, or goal. • AI TECHNOLOGY: AI technology represents the algorithms and methods that are used within the available machine learning and AI software tool sets. • AI TOOLS: AI tools represent the computer software, code, information technology infrastructure, and service provider utilities (e.g., Azure Cognitive Service, IBM Watson Studio) that are used to facilitate AI applications. • DATA ARCHITECTURE: Data architecture is defined by where the data resides; how it is collected, managed, secured, and accessed; and who has access to it."
  },
  {
    "id": "ML23132A305_chunk_45",
    "text": "Source: 14 ML23132A305.pdf\n\nsoftware tool sets. • AI TOOLS: AI tools represent the computer software, code, information technology infrastructure, and service provider utilities (e.g., Azure Cognitive Service, IBM Watson Studio) that are used to facilitate AI applications. • DATA ARCHITECTURE: Data architecture is defined by where the data resides; how it is collected, managed, secured, and accessed; and who has access to it. This architecture is constructed using purpose-built repositories, tools, and techniques, and it is controlled through the implementation of governance standards and policies. A-1 • DATA SCIENCE: Data science is a multidisciplinary field that involves computer programming codes, such as Python and R; collaboration with other technical disciplines; and communication using charts, graphs, or dashboards and by transforming data into insights using techniques in statistics, analytics, and machine learning [2]. Data scientists use computer programming languages, such as Python, to develop algorithms that classify, predict, and suggest outcomes from data. In comparison, data analysts use historical data to create visualizations and predictions using dashboard development tools, such as Tableau and PowerBI. • DATA ANALYTICS: The goal of data analytics is to derive and effectively communicate actionable insights from a vast quantity and variety of data."
  },
  {
    "id": "ML23132A305_chunk_46",
    "text": "Source: 14 ML23132A305.pdf\n\nlanguages, such as Python, to develop algorithms that classify, predict, and suggest outcomes from data. In comparison, data analysts use historical data to create visualizations and predictions using dashboard development tools, such as Tableau and PowerBI. • DATA ANALYTICS: The goal of data analytics is to derive and effectively communicate actionable insights from a vast quantity and variety of data. It covers a broad spectrum of activities, including data management and quality, mathematical and statistical methods for data modeling, and techniques for visualizing data in support of enterprise-wide decision-making [2]. Data analysts use historical data to create visualizations and predictions using dashboard development tools, such as Tableau and PowerBI. In comparison, data scientists use computer programming languages, such as Python, to develop algorithms that classify, predict, and suggest outcomes from data. • DEEP LEARNING: Deep learning is a subset of machine learning in which multilayered neural networks, modeled to work like the human brain, “learn” from large amounts of data. Within each layer of the neural network, deep learning algorithms perform calculations and make predictions repeatedly, progressively “learning” and gradually improving the accuracy of the outcome over time. Deep learning is differentiated in that it can ingest and process unstructured, unlabeled data [3]."
  },
  {
    "id": "ML23132A305_chunk_47",
    "text": "Source: 14 ML23132A305.pdf\n\nwhich multilayered neural networks, modeled to work like the human brain, “learn” from large amounts of data. Within each layer of the neural network, deep learning algorithms perform calculations and make predictions repeatedly, progressively “learning” and gradually improving the accuracy of the outcome over time. Deep learning is differentiated in that it can ingest and process unstructured, unlabeled data [3]. • MACHINE LEARNING: Machine learning means an application of AI that is characterized by providing systems with the ability to automatically learn and improve on the basis of data or experience, without being explicitly programmed [1]. A-2 • NATURAL LANGUAGE PROCESSING: Natural language processing is the use of algorithms to determine properties of natural, human language so that computers can understand what humans have written or said. It includes teaching computer systems how to extract data from bodies of written text, translate from one language to another, and recognize printed or handwritten words [4]. • USE CASE: A use case is a specific situation in which a product or service could potentially be used. A-3 REFERENCES 1. 116th U.S. Congr ess, “H.R.6395 - National Defense Authorization Act for Fiscal Year 2021: National Artificial Intelligence Initiative Act of 2020,” 2021. [Online]. Available: https://www.congress.gov/bill/116th-congress/house-bill/6395/text. 2. North Car olina State University, “Institute for Advanced Analytics,” [Online]."
  },
  {
    "id": "ML23132A305_chunk_48",
    "text": "Source: 14 ML23132A305.pdf\n\n[4]. • USE CASE: A use case is a specific situation in which a product or service could potentially be used. A-3 REFERENCES 1. 116th U.S. Congr ess, “H.R.6395 - National Defense Authorization Act for Fiscal Year 2021: National Artificial Intelligence Initiative Act of 2020,” 2021. [Online]. Available: https://www.congress.gov/bill/116th-congress/house-bill/6395/text. 2. North Car olina State University, “Institute for Advanced Analytics,” [Online]. Available: https://analytics.ncsu.edu/?page_id=2. [Accessed May 2022]. 3. IBM, “What is Deep Learning?, ” [Online]. Available: https://www.ibm.com/cloud/ learn/deep-learning. [Accessed May 2022]. 4. DeepAI, “Machine Learning Gl ossary and Terms,” [Online]. Available: https:// deepai.org/machine-learning-glossary-and-terms/natural-language-processing. [Accessed May 2022]. A-4 APPENDIX B USING ARTIFICIAL INTELLIGENCE TOOLS TO ENHANCE NRC ACTIVITIES The U.S. Nuclear Regulatory Commission (NRC) may pursue internal opportunities for the use of artificial intelligence (AI) tools for business process automation and knowledge mining. The NRC continues to build a flexible, agile, and innovative information technology and information management environment that is prepared for the rapid development of new technologies and changes in the nuclear industry. Technological advances continue to change the way the agency works and interacts with stakeholders."
  },
  {
    "id": "ML23132A305_chunk_49",
    "text": "Source: 14 ML23132A305.pdf\n\nthe use of artificial intelligence (AI) tools for business process automation and knowledge mining. The NRC continues to build a flexible, agile, and innovative information technology and information management environment that is prepared for the rapid development of new technologies and changes in the nuclear industry. Technological advances continue to change the way the agency works and interacts with stakeholders. The increased use of data analytics, cloud computing, and AI may improve efficiency and provide support for the workforce. These activities increase dependency on a robust and resilient network and information technology infrastructure. While AI Strategic Goals 4 and 5 principally support agency preparation for external AI usage in NRC-regulated activities, they may also benefit the agency in preparing for internal agency AI usage. In conjunction with AI Strategic Goals 4 and 5, the NRC will gain knowledge and expertise in a wide range of skills and capabilities such as artificial intelligence and data literacy, that could support expanding the use of data for decision-making in the agency. Several actions taken by Congress or executive branch agencies are prompting the NRC to further consider the best way to strategically integrate AI technology into agency internal processes and work products in addition to the regulatory oversight functions discussed in the AI Strategic Plan."
  },
  {
    "id": "ML23132A305_chunk_50",
    "text": "Source: 14 ML23132A305.pdf\n\nand data literacy, that could support expanding the use of data for decision-making in the agency. Several actions taken by Congress or executive branch agencies are prompting the NRC to further consider the best way to strategically integrate AI technology into agency internal processes and work products in addition to the regulatory oversight functions discussed in the AI Strategic Plan. The AI Strategic Plan aligns with and supports the provisions of the following: • Administrative Conference of the United States, Statement #20, “Agency Use of Artificial Intelligence” [1] • Foundations for Evidence-Based Policymaking Act of 2018 (Evidence Act) [2] • National Artificial Intelligence Initiative Act of 2020 [3] • Office of Management and Budget M-21-06, “Guidance for Regulation of Artificial Intelligence Applications” [4] AI tools may be used to enhance internal NRC activities, which could better allocate agency resources to higher value activities and emerging mission priorities. However, AI tools are highly dependent on the quantity and quality of the data that support them. In carrying out the agency’s mission, the NRC captures, creates, manages, and uses data from a variety of sources and in a variety of forms. These data inform the B-1 agency’s operational and regulatory decision-making and support all Federal reporting requirements."
  },
  {
    "id": "ML23132A305_chunk_51",
    "text": "Source: 14 ML23132A305.pdf\n\nmission priorities. However, AI tools are highly dependent on the quantity and quality of the data that support them. In carrying out the agency’s mission, the NRC captures, creates, manages, and uses data from a variety of sources and in a variety of forms. These data inform the B-1 agency’s operational and regulatory decision-making and support all Federal reporting requirements. As part of the NRC’s Information Technology/Information Management Strategic Plan, the agency will provide future enhancements to identify and collect data more effectively and efficiently [5]. The NRC has also developed an agency evidence-building plan, as required by the Evidence Act, for identifying and addressing priority questions relevant to the agency’s programs, policies, and regulations [6]. As part of the evidence-building plan, the agency may identify what NRC decision-making processes could benefit from AI tools and prioritize the data collections that would have the most significant impact on agency decision-making, AI tool use, and stakeholder use to improve efficiency. The evidence-building plan also discusses how processes and procedures are vital to ensure consistency, clear expectations, performance measurement, and established roles and responsibilities consistent with established policy."
  },
  {
    "id": "ML23132A305_chunk_52",
    "text": "Source: 14 ML23132A305.pdf\n\nwhat NRC decision-making processes could benefit from AI tools and prioritize the data collections that would have the most significant impact on agency decision-making, AI tool use, and stakeholder use to improve efficiency. The evidence-building plan also discusses how processes and procedures are vital to ensure consistency, clear expectations, performance measurement, and established roles and responsibilities consistent with established policy. As part of the evidence-building plan, the NRC will assess the agency’s processes to determine what improvements can be implemented to continue our journey to become a more modern, risk informed regulator. When assessing processes for improvement, the NRC will include in its assessment, potential ways AI tools could be incorporated into processes, as well as for continuous process monitoring and optimization. B-2 REFERENCES 1. Adminis trative Conference of the United States, “Agency Use of Artificial Intelligence,” 2021. [Online]. Available: https://www.acus.gov/research-projects/ agency-use-artificial-intelligence. 2. 115th U.S. Congr ess, “H.R.4174 - Foundations for Evidence-Based Policymaking Act of 2018,” 2021. [Online]. Available: https://www.congress.gov/bill/115th-congress/house-bill/4174/text. 3. 116th U.S. Congr ess, “H.R.6395 - National Defense Authorization Act for Fiscal Year 2021: National Artificial Intelligence Initiative Act of 2020,” 2021. [Online]."
  },
  {
    "id": "ML23132A305_chunk_53",
    "text": "Source: 14 ML23132A305.pdf\n\n1. Adminis trative Conference of the United States, “Agency Use of Artificial Intelligence,” 2021. [Online]. Available: https://www.acus.gov/research-projects/ agency-use-artificial-intelligence. 2. 115th U.S. Congr ess, “H.R.4174 - Foundations for Evidence-Based Policymaking Act of 2018,” 2021. [Online]. Available: https://www.congress.gov/bill/115th-congress/house-bill/4174/text. 3. 116th U.S. Congr ess, “H.R.6395 - National Defense Authorization Act for Fiscal Year 2021: National Artificial Intelligence Initiative Act of 2020,” 2021. [Online]. Available: https://www.congress.gov/bill/116th-congress/house-bill/6395/text. 4. OMB, “Guidanc e for Regulation of Artificial Intelligence Applciations,” Office of Management and Budget, Washington, DC, https://www.whitehouse.gov/wp-content/uploads/2020/11/M-21-06.pdf, 2020. 5. NR C, “Information Technology and Information Management Strategic Plan: Fiscal Years 2020-2024,” U.S. Nuclear Regulatory Commission, Washington, DC, NUREG-1908, Vol. 4, ML19323D858, https://www.nrc.gov/docs/ML1932/ML19323D858.pdf, 2019. 6. NR C, “Evidence Building Plan, Fiscal Year 2022,” U.S. Nuclear Regulatory Commission, Rockville, MD, https://www.nrc.gov/docs/ML2206/ML22066B056.pdf, ML22066B056, 2022. B-3 NRC staff demonstrate X-energy’s reactor facility virtual reality mockup NUREG -2261 M. Dennis, T. Lalain, L. Betancourt, A. Hathaway, R. Anzalone Division of System Analysis Office of Nuclear Regulatory Researc h U.S."
  },
  {
    "id": "ML23132A305_chunk_54",
    "text": "Source: 14 ML23132A305.pdf\n\nCommission, Washington, DC, NUREG-1908, Vol. 4, ML19323D858, https://www.nrc.gov/docs/ML1932/ML19323D858.pdf, 2019. 6. NR C, “Evidence Building Plan, Fiscal Year 2022,” U.S. Nuclear Regulatory Commission, Rockville, MD, https://www.nrc.gov/docs/ML2206/ML22066B056.pdf, ML22066B056, 2022. B-3 NRC staff demonstrate X-energy’s reactor facility virtual reality mockup NUREG -2261 M. Dennis, T. Lalain, L. Betancourt, A. Hathaway, R. Anzalone Division of System Analysis Office of Nuclear Regulatory Researc h U.S. Nuclear Regulatory Commission Washington, DC 20555-0001 Division of System Analysis Office of Nu clear Re gulatory Re search U.S. Nu clear Re gulatory Co mmission Washington, DC 20555-000 1 The U.S . Nuclear Re gulatory Co mmission (N RC) recogniz es that interes t in artificial intelligence (AI) is growing rapidly in both the public and private sec tors and anticipates in creased use of AI in NRC-reg ulated activities. AI ge nerally refers to a machine-bas ed system th at ca n and has the ability to emulate hum an-like perception, co gnition, planning, le arning, co mmunication, or physical action. For a given set of hu man- defined objectives, AI c an make predictions, re comm endations, or de cisions in fluencing real or vi rtual environments."
  },
  {
    "id": "ML23132A305_chunk_55",
    "text": "Source: 14 ML23132A305.pdf\n\nactivities. AI ge nerally refers to a machine-bas ed system th at ca n and has the ability to emulate hum an-like perception, co gnition, planning, le arning, co mmunication, or physical action. For a given set of hu man- defined objectives, AI c an make predictions, re comm endations, or de cisions in fluencing real or vi rtual environments. The AI Strategic P lan fo cuses on a broad spectrum of sub-spe cialties (e .g., na tural language processing, ma chine le arning, deep learning, et c.) wh ich could encompass va rious algorithms and application examples wh ich the NRC ha s not prev iously re viewed and evaluated. Anticipating th e indus try’s potential ap plication of AI to NRC-reg ulated activities, th e NRC has developed an AI Stra tegic Plan to ensure th e agenc y’s readiness to review su ch uses. Th e AI Stra tegic Plan includes fi ve goals: (1 ) ensure NRC re adiness fo r regulatory de cision-m aking, (2 ) establish an organizational framework to review AI applications, (3 ) strengthen and expand A I partnerships , (4) cultivate an AI proficient wo rkforce, and (5) pursue us e cases to build an AI foundation acros s the NRC. Th e overall go al of this AI Stra tegic Plan is to ensure continued st aff re adiness to review an d evaluate A I applications effectively and efficiently. Artificial In telligence, AI , Machine Learning, ML , Natural La nguage Processing, NLP, St rategic Plan May 2023 Technical Artificial Intelligence Strategic Plan Fiscal Years 2023 –2027 U.S."
  },
  {
    "id": "ML23132A305_chunk_56",
    "text": "Source: 14 ML23132A305.pdf\n\nNRC. Th e overall go al of this AI Stra tegic Plan is to ensure continued st aff re adiness to review an d evaluate A I applications effectively and efficiently. Artificial In telligence, AI , Machine Learning, ML , Natural La nguage Processing, NLP, St rategic Plan May 2023 Technical Artificial Intelligence Strategic Plan Fiscal Years 2023 –2027 U.S. Nuclear Regulatory Commission NUREG-2261 May 2023 www.nrc.gov STAY CONNECTED"
  },
  {
    "id": "files_chunk_0",
    "text": "Source: 15 files.pdf\n\nU.S. General Services Administration (GSA) GSA Order: Use of Artificial Intelligence at GSA CIO 2185.1A GSA-IT caio@gsa.gov Purpose This directive establishes the governing policies regarding the controlled access and responsible use of artificial intelligence (AI) technologies and platforms. It addresses the assessment, procurement, usage, monitoring, and governance of AI systems and software within the GSA network, in conjunction with all existing security , privacy , policies, directives, ethics regulations, and laws. Background The AI in Government Act of 2020 (Public Law 116-260), AI Training Act of 2023 (Public Law 117–207), Executive Order 13859, Executive Order 13960, Executive Order 14110, Executive Order 14091, M-21-06, M-24-10, OMB Circular No. A-119, and the AI Bill of Rights direct all Federal agencies to: 1. Ensure that all AI and automated systems comply with applicable Federal law in a manner that advances equity , safety , and privacy; 2. Establish or update processes to measure, monitor , evaluate, and report on AI activities, use-cases, their ongoing performance, and manage the risks of using AI through regular risk assessments as required, especially for safety-impacting and rights-impacting AI; 3."
  },
  {
    "id": "files_chunk_1",
    "text": "Source: 15 files.pdf\n\nall AI and automated systems comply with applicable Federal law in a manner that advances equity , safety , and privacy; 2. Establish or update processes to measure, monitor , evaluate, and report on AI activities, use-cases, their ongoing performance, and manage the risks of using AI through regular risk assessments as required, especially for safety-impacting and rights-impacting AI; 3. Prioritize appropriate uses of AI that improve their agency’ s mission, advance equity and identify and remove barriers to the responsible use of AI in the agency , including through the advancement of AI-enabling enterprise infrastructure, workforce development measures, policy , and other resources for AI innovation; 4. Ensure adequate infrastructure and capacity is available to sufficiently curate agency datasets for AI usage, including the requisite data governance and management practices as they relate to data curation, labeling, and stewardship; 1 5. Initiate measures and procedures to regularly assess the agency’ s AI workforce capacities and its projected AI workforce needs; 6. Support interagency coordination bodies related to AI activities and AI standards-setting initiatives, and encourage agency adoption of voluntary consensus standards for AI. Applicability This order applies to: 1. All GSA employees and contractors that may have a need to access or share data, as well as system-to-system data exchanges; 2."
  },
  {
    "id": "files_chunk_2",
    "text": "Source: 15 files.pdf\n\nAI workforce capacities and its projected AI workforce needs; 6. Support interagency coordination bodies related to AI activities and AI standards-setting initiatives, and encourage agency adoption of voluntary consensus standards for AI. Applicability This order applies to: 1. All GSA employees and contractors that may have a need to access or share data, as well as system-to-system data exchanges; 2. IT systems owned and operated by or on the behalf of any of the GSA Service and Staff Offices (SSOs), including Regional Offices; 3. GSA or Federal data contained on or processed by IT systems owned and operated by or on the behalf of any of the GSA SSOs, including Regional Offices; 4. The Office of Inspector General (OIG) to the extent that the OIG determines it is consistent with the OIG’s independent authority under the Inspector General Act of 1978 (5 U.S.C. App. 3) and does not conflict with other OIG policies or the OIG mission; and 5. The Civilian Board of Contract Appeals (CBCA) only to the extent that it is consistent with the CBCA's requisite independence as defined by the Contract Disputes Act (CDA) and its legislative history . 41 U.S.C. §§ 7101-7109 (2012) and S. Rep. No. 95-1118 (1978). Cancellation This directive cancels the Security Policy for Generative Artificial Intelligence (AI) Large Language Models (LLMs) (Number: CIO IL-23-01) . Roles and Responsibilities 1."
  },
  {
    "id": "files_chunk_3",
    "text": "Source: 15 files.pdf\n\nto the extent that it is consistent with the CBCA's requisite independence as defined by the Contract Disputes Act (CDA) and its legislative history . 41 U.S.C. §§ 7101-7109 (2012) and S. Rep. No. 95-1118 (1978). Cancellation This directive cancels the Security Policy for Generative Artificial Intelligence (AI) Large Language Models (LLMs) (Number: CIO IL-23-01) . Roles and Responsibilities 1. Chief AI Officer (CAIO) : in addition to the responsibilities defined in Section 8(c) of EO 13960 and Section 4(b) of EO 14091, the CAIO must: a. Maintain awareness of AI activities within GSA, including how the systems work, how they were designed, and what specific purposes they serve; b. Establish and update processes to measure, monitor , and evaluate the performance, accessibility , equity , cost, and outcomes of AI applications; 2 c. Establish, maintain, and chair AI oversight governing bodies; d. Issue AI compliance plans and oversee agency compliance with the AI Executive Order 14110; e. Oversee the development of GSA’s AI inventory and other necessary reporting; and f. Identify and convene external individuals or organizations with AI expertise who can provide expert input to agency officials that is relevant to GSA mission functions. g. Issue waivers for individual applications of AI, in coordination with other officials responsible for those AI applications, from elements of Section 5 of M-24-10. h."
  },
  {
    "id": "files_chunk_4",
    "text": "Source: 15 files.pdf\n\nGSA’s AI inventory and other necessary reporting; and f. Identify and convene external individuals or organizations with AI expertise who can provide expert input to agency officials that is relevant to GSA mission functions. g. Issue waivers for individual applications of AI, in coordination with other officials responsible for those AI applications, from elements of Section 5 of M-24-10. h. Establish, and maintain over time, criteria for categories of individual applications of AI that do not require disposition through the AI Governance Board or AI Safety Team. 2. AI Governance Board : co-chaired by the CAIO and the Deputy Administrator of GSA, shall include representation from senior agency officials responsible for key enablers of AI adoption and risk management, including at least IT, cybersecurity , data, human capital, legal, procurement, budget, agency management, customer experience, performance evaluation, statistics, risk management, equity , privacy , civil rights and civil liberties, the Office of the Inspector General, and officials responsible for implementing AI within an agency’ s program office. The AI Governance Board Charter will define the roles and responsibilities of the AI Governance Board. 3. AI Safety Team : The working group reporting to the Chief AI Officer in their role as co-chair of the AI Governance board, responsible for adjudicating use cases, developing draft guidance, policy , and standards."
  },
  {
    "id": "files_chunk_5",
    "text": "Source: 15 files.pdf\n\nimplementing AI within an agency’ s program office. The AI Governance Board Charter will define the roles and responsibilities of the AI Governance Board. 3. AI Safety Team : The working group reporting to the Chief AI Officer in their role as co-chair of the AI Governance board, responsible for adjudicating use cases, developing draft guidance, policy , and standards. The AI Safety Team will comply with existing Federal and agency Security and Privacy policies when making use case dispositions. The AI Safety Team shall be populated by delegated representatives of the AI Governance Board and the CAIO. a. The AI Safety team will be composed of individuals who can provide diverse perspectives on the use of AI, including developers, architects, data scientists, user experience/customer experience experts, privacy , security and both internal and public mission staff. 3 b. The AI Safety Team will be empowered to independently adjudicate Familiarization, Pre-Acquisition, and Research and Development use cases. i. The AI Safety team is responsible for providing disposition recommendations for Production or Production-Intent use cases. ii. All determined Rights or Safety Impacting use cases must be ultimately adjudicated by the AI Governance Board. c. The AI Safety Team shall enforce all GSA-authorized security , privacy, and audit policies to protect CUI and ensur e GSA IT systems oper ate within acceptable levels of residual risk. These include, but are not limited to: i."
  },
  {
    "id": "files_chunk_6",
    "text": "Source: 15 files.pdf\n\nuse cases. ii. All determined Rights or Safety Impacting use cases must be ultimately adjudicated by the AI Governance Board. c. The AI Safety Team shall enforce all GSA-authorized security , privacy, and audit policies to protect CUI and ensur e GSA IT systems oper ate within acceptable levels of residual risk. These include, but are not limited to: i. Privacy Threshold Assessments (PTAs); ii. Privacy Impact Assessments (PIAs); iii. Privacy Act Statements; iv. System of Recor ds Notices (SORNs); v. Authorizations to Oper ate (ATOs); and vi. FedRAMP authorizations; d. The CAIO must review and approve all production or production-intent use cases. The CAIO and the AI Governance Board maintain full access to all use cases registered with the AI Safety Team and can review any use case at any point. e. AI use cases deemed to have significant implications for rights or safety by the AI Safety Team, the CAIO, or the AI Governance Board will be adjudicated as Rights-Impacting or Safety-Impacting, and the AI use will be subject to additional monitoring, reporting, and review processes. 4. System Owner : Shall be responsible for reporting all AI use cases for review by the AI Safety Team and providing updates should any significant modifications to the AI system occur or if the AI system is decommissioned. 5."
  },
  {
    "id": "files_chunk_7",
    "text": "Source: 15 files.pdf\n\nbe adjudicated as Rights-Impacting or Safety-Impacting, and the AI use will be subject to additional monitoring, reporting, and review processes. 4. System Owner : Shall be responsible for reporting all AI use cases for review by the AI Safety Team and providing updates should any significant modifications to the AI system occur or if the AI system is decommissioned. 5. Executive Sponsor : Shall be named sponsors for AI use cases, and ensure alignment with the strategic objectives, risk posture, and resourcing priorities of the AI Governance Board. Executive Sponsors are not required for familiarization use cases. 4 6. Authorized Users of IT Resources : a. General Practitioner: Shall be responsible for protecting federal nonpublic information, reporting any potential IT security incident, adhering to GSA’s Information Technology (IT) General Rules of Behavior and all provisions in this directive. All AI users also have a responsibility to report any use of AI to the AI Safety Team if they believe the use case has not already been registered by the System Owner . b. Specialized Practitioner: In addition to all responsibilities of a general AI practitioner , a specialized practitioner shall be responsible for implementing and maintaining all GSA IT software development and security standards when supporting the development and implementation processes of AI software and solutions."
  },
  {
    "id": "files_chunk_8",
    "text": "Source: 15 files.pdf\n\nif they believe the use case has not already been registered by the System Owner . b. Specialized Practitioner: In addition to all responsibilities of a general AI practitioner , a specialized practitioner shall be responsible for implementing and maintaining all GSA IT software development and security standards when supporting the development and implementation processes of AI software and solutions. Signature /S/ ______________________ 6/7/2024 ________ David Shive Date Chief Information Officer Office of GSA IT 5 THIS PAGE IS INTENTIONALL Y LEFT BLANK 6 Table of Contents 1. Introduction 9 1.1 Objectives 9 1.2 Scope 9 1.3 Principles 10 2. Policy 10 2.1 General AI usage 10 2.2 New or Proposed AI Use Cases 12 2.3 Existing AI Use Cases 13 2.4 AI Code and Models 14 2.5 Data assets and sources 15 2.5.1 Internal Data Assets 15 2.5.2 External Data Assets 16 2.5.3 AI-Generated Data Products 16 2.5.4 Data Dissemination Requirements 17 2.6 Responsible Procurement of AI 17 2.6.1. Pre-Acquisition 17 2.6.2. Procuring AI 17 2.6.3 Procurement policy updates 17 2.7 Tool or Product AI Enhancements 17 2.8 Publication Requirements 18 2.9 Minimum Requirements for Either Safety-Impacting or Rights-Impacting AI 18 2.9.1 Additional Requirements for Rights-Impacting AI 20 2.9.2 Excepted scenarios for Rights-Impacting or Safety-Impacting AI use cases 20 2.9.3 Use-Case Waivers 20 2.10 Organizational Risk Tolerance and Use Case Risk Rubric 21 3. Legal and Programmatic Authorities 21 4."
  },
  {
    "id": "files_chunk_9",
    "text": "Source: 15 files.pdf\n\n2.7 Tool or Product AI Enhancements 17 2.8 Publication Requirements 18 2.9 Minimum Requirements for Either Safety-Impacting or Rights-Impacting AI 18 2.9.1 Additional Requirements for Rights-Impacting AI 20 2.9.2 Excepted scenarios for Rights-Impacting or Safety-Impacting AI use cases 20 2.9.3 Use-Case Waivers 20 2.10 Organizational Risk Tolerance and Use Case Risk Rubric 21 3. Legal and Programmatic Authorities 21 4. Definitions 22 5. Appendix A: Presumed Rights-Impacting and Safety Impacting Use Cases 27 5.1 Rights-Impacting Use Case Examples 27 5.2 Safety-Impacting Use Case Examples 29 6. Appendix B: AI Impact Statement Guidance 30 7. Appendix C: Additional Documents 31 7 1. Introduction As Artificial Intelligence (AI) technologies continue to evolve and expand into the workflows of the federal government, it is crucial that the use of these technologies are managed to maximize effectiveness while minimizing potential harm and managing or mitigating potential risks. AI has the potential to augment or improve mission delivery , service offerings, and productivity across all GSA equities. However , without oversight, controls, and human intervention protocols in place, AI can also cause harm by introducing or reinforcing discriminatory practices, invading people’ s privacy , or enabling disinformation to propagate at scale."
  },
  {
    "id": "files_chunk_10",
    "text": "Source: 15 files.pdf\n\nharm and managing or mitigating potential risks. AI has the potential to augment or improve mission delivery , service offerings, and productivity across all GSA equities. However , without oversight, controls, and human intervention protocols in place, AI can also cause harm by introducing or reinforcing discriminatory practices, invading people’ s privacy , or enabling disinformation to propagate at scale. To mitigate these potential issues safely while capitalizing on the potential benefits of these emerging technologies, policy controls must be established for the safe, secure, equitable, and trustworthy development and use of AI. This directive outlines the controls for AI usage within GSA, the governance and oversight infrastructure required to enable the responsible use of AI, the processes available to GSA employees in developing AI use cases for mission work, and the disclosure requirements for all AI implementations. 1.1 Objectives The objectives of this order are to: a. Define AI governance model and procedures necessary to promote the safe, equitable, and responsible use of AI technologies while managing its associated risks for GSA business activities; a. Enable use of AI that improves service delivery and public trust in government; b. Establish the roles, responsibilities, and reporting structures of the requisite oversight and governing groups; c."
  },
  {
    "id": "files_chunk_11",
    "text": "Source: 15 files.pdf\n\nare to: a. Define AI governance model and procedures necessary to promote the safe, equitable, and responsible use of AI technologies while managing its associated risks for GSA business activities; a. Enable use of AI that improves service delivery and public trust in government; b. Establish the roles, responsibilities, and reporting structures of the requisite oversight and governing groups; c. Outline the requirements of all AI systems, with noted focus on rights-impacting and safety-impacting AI systems; and d. Define core AI terms and concepts. 1.2 Scope This order provides guidance for the program operations of GSA that have direct or indirect responsibility for or control over any action, activity or program that relates to AI systems, including the procurement, management, or development activities. This policy is designed to work with existing IT security and privacy policies. 8 1.3 Principles This directive is based on the principles of public trust, scientific integrity , risk management, equity , transparency , safety , and collaboration. AI systems must be developed and deployed in a manner that prioritizes the public good while also taking into account the potential risks and benefits. These principles are essential to ensure the safe, responsible, and ethical development and deployment of AI systems across GSA. 2. Policy AI use cases in GSA are categorized as follows: 1."
  },
  {
    "id": "files_chunk_12",
    "text": "Source: 15 files.pdf\n\nsafety , and collaboration. AI systems must be developed and deployed in a manner that prioritizes the public good while also taking into account the potential risks and benefits. These principles are essential to ensure the safe, responsible, and ethical development and deployment of AI systems across GSA. 2. Policy AI use cases in GSA are categorized as follows: 1. Familiarization : working with AI for professional development and training using non-sensitive, public information and publicly available tools. These use cases are relegated for individual uses, with the specific goal of gaining familiarity with market offerings, and are most closely aligned with professional training activities; 2. Pre-acquisition activity : assessing or piloting the capabilities of an AI system or performing market analyses before acquiring the technology . This includes Request for Information (RFIs), industry days, or any scenario where third party developers or vendors provide demonstration products outside of GSA’s network or infrastructure. These use cases can not use non-public Federal Controlled Unclassified Information (CUI) data or interface with internal GSA systems; 3. Research and Development : work involving the development of a capability using internal systems, processes, and data, but without the immediate intent to promote the research output to a production environment or workflow ."
  },
  {
    "id": "files_chunk_13",
    "text": "Source: 15 files.pdf\n\noutside of GSA’s network or infrastructure. These use cases can not use non-public Federal Controlled Unclassified Information (CUI) data or interface with internal GSA systems; 3. Research and Development : work involving the development of a capability using internal systems, processes, and data, but without the immediate intent to promote the research output to a production environment or workflow . These use cases can not support GSA business activities directly and may only take place in the Enterprise Data Solution environment or approved research environments; and 4. Production or production-intent : use cases involving the incorporation of AI for deployment into production environments or workflows. The work products of these use cases directly support GSA business activities. 2.1 General AI usage For all use cases, individuals acting on behalf of GSA must register every proposed use case via GSA's AI Request Form. Use case requests are assessed by the AI Safety Team, which identifies each use case's risk profile and adjudicates use cases classified 9 as Familiarization, Pre-Acquisition, Research and Development, and Production or Production-Intent. The AI Safety Team may request additional guidance from the Chief AI Officer (CAIO) and AI Governance Board as necessary . a. General access to publicly available, approved third-party AI endpoints and tools shall be blocked from the GSA network and GFE devices. i."
  },
  {
    "id": "files_chunk_14",
    "text": "Source: 15 files.pdf\n\nand adjudicates use cases classified 9 as Familiarization, Pre-Acquisition, Research and Development, and Production or Production-Intent. The AI Safety Team may request additional guidance from the Chief AI Officer (CAIO) and AI Governance Board as necessary . a. General access to publicly available, approved third-party AI endpoints and tools shall be blocked from the GSA network and GFE devices. i. Access will be made available upon completion of GSA’s AI request form, detailing intended usage and acknowledgment of the requirements of this Directive and GSA’s IT General Rules of Behavior . ii. Only endpoints and tools approved by the CAIO, the CISO, and the AI Governance Board will be made available. iii. Access to public interfaces will only be approved for uses that involve publicly available data and are for familiarization purposes only. No output from publicly available products or tools may be introduced as a GSA production work product without approval from the AI Governance Board. iv. Federal nonpublic information (including work products, emails, photos, videos, audio, and conversations that are meant to be pre-decisional or internal to GSA), such as controlled unclassified information (CUI), personally identifiable information (PII), and Business Identifiable Information (BII), shall not be used as inputs (e.g. prompts or training data) to any AI system without prior authorization from the AI Governance Board . b."
  },
  {
    "id": "files_chunk_15",
    "text": "Source: 15 files.pdf\n\ninformation (including work products, emails, photos, videos, audio, and conversations that are meant to be pre-decisional or internal to GSA), such as controlled unclassified information (CUI), personally identifiable information (PII), and Business Identifiable Information (BII), shall not be used as inputs (e.g. prompts or training data) to any AI system without prior authorization from the AI Governance Board . b. Any work product outputs materially modified by or solely produced by generative AI systems must be labeled or watermarked in a manner that makes the recipient aware of the system(s) involved and whether they edited or authored the work. Content types include: i. Data; ii. Code; iii. Text (e.g. temporary and permanent records); iv. Applications (e.g. chatbots, recommendation engines, etc.); v. Audio; vi. Imagery; and 10 vii. Video. c. All production systems using AI capabilities that provide direct interface with the public must include: i. Notice and explanation of its services written in plain language ; and ii. Human alternatives or fallback options where practicable. d. All AI software must have a valid Authorization to Operate prior to use for Research and Development and Production use cases. e."
  },
  {
    "id": "files_chunk_16",
    "text": "Source: 15 files.pdf\n\nc. All production systems using AI capabilities that provide direct interface with the public must include: i. Notice and explanation of its services written in plain language ; and ii. Human alternatives or fallback options where practicable. d. All AI software must have a valid Authorization to Operate prior to use for Research and Development and Production use cases. e. Any output from LLMs used to generate code or content to be published on federal internet or intranet pages or to be used in Agency Official Communications (as defined in 36 CFR 1194 E205.3), shall be manually reviewed to ensure that code or the content conforms to Section 508 of the Rehabilitation Act of 1973 and to the Section 508 Technical Standards for ICT Accessibility . 2.2 New or Proposed AI Use Cases All AI use case requests must be submitted to the AI Safety Team via the AI Request Form. If a model that is not currently authorized is being requested, the use case must also submit an AI Model Request Form. Research and Development use case requests shall also submit an Experimental Design Statement . All applicants must include in their submission the following information: a. Category of use case type (i.e., familiarization, pre-acquisition, research and development, or production); and b. Intended purpose for the AI and the expected benefit; c. The creator of the AI system; d."
  },
  {
    "id": "files_chunk_17",
    "text": "Source: 15 files.pdf\n\nModel Request Form. Research and Development use case requests shall also submit an Experimental Design Statement . All applicants must include in their submission the following information: a. Category of use case type (i.e., familiarization, pre-acquisition, research and development, or production); and b. Intended purpose for the AI and the expected benefit; c. The creator of the AI system; d. The environment(s) the AI system will be located in; Pre-acquisition, research and development, and production AI use cases are required to provide additional information, including: e. What specific metrics or qualitative measures will be used to assess impact, employing performance measurement or program evaluation methods; f. Intended user/audience of the AI system or AI capability; 11 g. Justification for how the AI is better suited to accomplish the relevant task than alternative methods; h. What risks are associated with the use of an AI in the requested use-case and what measures should be employed to reduce or mitigate the risks; and i. What data will be used by the AI in the use case. The AI Request Form may be modified to require additional or different information as deemed necessary by the AI Governance Board. 2.3 Existing AI Use Cases Every year, all existing use cases are required to re-register with the AI Safety Team via the AI Request Form, with the exception of familiarization use cases. Use cases must also submit the same form to report ceasing operations."
  },
  {
    "id": "files_chunk_18",
    "text": "Source: 15 files.pdf\n\nbe modified to require additional or different information as deemed necessary by the AI Governance Board. 2.3 Existing AI Use Cases Every year, all existing use cases are required to re-register with the AI Safety Team via the AI Request Form, with the exception of familiarization use cases. Use cases must also submit the same form to report ceasing operations. The specific requirements are as follows: a. All existing AI use cases, with the exception of familiarization use cases, shall be reported to the AI Governance Board on an annual basis. b. Any use case that undergoes a significant modification must be re-submitted to the AI Governance board for reassessment. c. Any use case where there has been a cybersecurity or privacy incident must be re-submitted to the AI Governance board for reassessment within 30 days of the reported incident; d. AI systems that use nonpublic information shall be conducted within approved secure enterprise systems, such as the Enterprise Data Solution (EDS). e. All AI systems are subject to independent system reviews and assessments of the use case, the system and its architecture, the security protocols, and privacy measures upon request by the: i. CAIO; ii. AI Governance Group or designee; iii. Chief Information Security Officer; iv. Chief Technology Officer; and v. Chief Privacy Officer. 12 2.4 AI Code and Models All internally developed AI code shall be shared for internal consumption as well as open sourced in public repositories."
  },
  {
    "id": "files_chunk_19",
    "text": "Source: 15 files.pdf\n\nand its architecture, the security protocols, and privacy measures upon request by the: i. CAIO; ii. AI Governance Group or designee; iii. Chief Information Security Officer; iv. Chief Technology Officer; and v. Chief Privacy Officer. 12 2.4 AI Code and Models All internally developed AI code shall be shared for internal consumption as well as open sourced in public repositories. All code shall adhere to GSA’s Open Source Software (OSS) Policy (2107.1 CIO) before sharing code. a. All custom-developed code - including models and model weights - for AI applications shall be: i. shared internally; and ii. open-sourced to the public; b. Code and models no longer in active use may be archived and do not need to be maintained. c. Use of Open Source or COTS models: i. Shall be approved for use by the AI Safety Team through link to AI Model Request Form; ii. Shall be treated as a system integration; and iii. Shall adhere to standard architectural protocols and requirements. d. Exceptions to this provision include: i. the sharing of code is restricted by law or regulation; ii. sharing of code would create an identifiable risk to national security , confidentiality of Government information, individual privacy , or the rights or safety of the public; iii. the code or models were used for Research and Development use cases; iv. contractual obligations that prevent the sharing of code; and v."
  },
  {
    "id": "files_chunk_20",
    "text": "Source: 15 files.pdf\n\nof code is restricted by law or regulation; ii. sharing of code would create an identifiable risk to national security , confidentiality of Government information, individual privacy , or the rights or safety of the public; iii. the code or models were used for Research and Development use cases; iv. contractual obligations that prevent the sharing of code; and v. the sharing of code would create an identifiable risk to agency mission, programs, or operations, or the stability , security , or integrity of an agency’ s system or personnel. 13 2.5 Data assets and sources System owners of research and development or production AI systems shall report on the data used in the design, development, training, testing, and operation of an AI system. This includes: a. what data are being used; b. the purpose of the data being used within the AI system; c. who are the owners of the data being used; d. how the data are relevant to the task being automated; and e. what is the sensitivity level of the data required for the AI use case. The AI Safety Team or CAIO may request additional information about the data being used, including: a. documentation on the data collection and preparation process, including the data provenance; b. measures of the quality and representativeness of the data for its intended purpose; c. how the data will be used for the AI’s development, testing, and operation; and d."
  },
  {
    "id": "files_chunk_21",
    "text": "Source: 15 files.pdf\n\ncase. The AI Safety Team or CAIO may request additional information about the data being used, including: a. documentation on the data collection and preparation process, including the data provenance; b. measures of the quality and representativeness of the data for its intended purpose; c. how the data will be used for the AI’s development, testing, and operation; and d. measures that demonstrate that the data adequately cover real-world scenarios, and how shortcomings are being addressed. All data used in Research and Development or Production use cases for an AI system’ s design, development, training, testing, and operation shall be: a. registered and published in the EDS catalog; and b. adhere to the Internal Data Sharing Directive and its data categorization framework. 2.5.1 Internal Data Assets All internal data assets are subject to the following specific requirements: a. no internal data assets may be used as input for public AI systems; and 14 b. no sensitive data (e.g. PII, CUI, Procurement Sensitive) may be used with AI systems without clearance from the AI Safety Team, a submission of an AI impact statement, and a valid ATO. 2.5.2 External Data Assets For data sources proposed to be used by an AI system that are generated from external sources (i.e., non-GSA owned and maintained data assets), the AI system manager shall report on the following: a."
  },
  {
    "id": "files_chunk_22",
    "text": "Source: 15 files.pdf\n\nused with AI systems without clearance from the AI Safety Team, a submission of an AI impact statement, and a valid ATO. 2.5.2 External Data Assets For data sources proposed to be used by an AI system that are generated from external sources (i.e., non-GSA owned and maintained data assets), the AI system manager shall report on the following: a. The originator , collection methodology , and preparation process of all external data sources shall be registered with the AI Safety Team. These specifics shall be resubmitted: i. during the annual resubmission process to continue usage; and ii. if any significant modification occurs to the use case. b. The data sources shall be maintained, indexed, and made available via the Enterprise Data Solution. 2.5.3 AI-Generated Data Products All AI-generated data outputs or products must be labeled as such in its metadata, and indexed and cataloged in the EDS system for internal discovery purposes. This includes any generated modification to existing data products. Datasets that have undergone augmentation from an AI system, such as data imputation or field creation and population, must include notice in the metadata holdings as to which records were modified or created, and by what system, including the AI systems version information. All AI-generated data must adhere to existing data, privacy , and security policies. Exceptions to AI-generated content notice may include, but are not limited to: 1."
  },
  {
    "id": "files_chunk_23",
    "text": "Source: 15 files.pdf\n\nsuch as data imputation or field creation and population, must include notice in the metadata holdings as to which records were modified or created, and by what system, including the AI systems version information. All AI-generated data must adhere to existing data, privacy , and security policies. Exceptions to AI-generated content notice may include, but are not limited to: 1. Metadata, including field titles, descriptions, and domain associations; 2. Classification or tagging labels for discovery or findability purposes; and 3. Domain association for general data ontology management purposes. 4. Data authored by humans or non-AI systems which may contain generated content that does not fundamentally challenge the authorship of the data, such as emails or chats which contain auto-completed text. 15 2.5.4 Data Dissemination Requirements Data used in the development of AI models or applications shall be qualified as a data asset under the definition of the Open, Public, Electronic, and Necessary (OPEN) Government Act, and shall be publicly released as an open government data asset on data.gov . Exceptions for this provision would follow the safety and security considerations in Section 4.7 of EO 14110. All existing risk mitigation and privacy process controls remain in force for all data products identified for dissemination. 2.6 Responsible Procurement of AI 2.6.1."
  },
  {
    "id": "files_chunk_24",
    "text": "Source: 15 files.pdf\n\nand Necessary (OPEN) Government Act, and shall be publicly released as an open government data asset on data.gov . Exceptions for this provision would follow the safety and security considerations in Section 4.7 of EO 14110. All existing risk mitigation and privacy process controls remain in force for all data products identified for dissemination. 2.6 Responsible Procurement of AI 2.6.1. Pre-Acquisition For a GSA-funded procurement, market research should be used to determine if AI will be offered as a solution or potential solution to the planned procurement. If it is determined during market research that AI may be proposed by an offeror as part of their total solution, acquisition teams must coordinate the acquisition plan and solicitation with the CAIO. Any procurement considerations regarding AI usage at GSA must be submitted to the CAIO and reviewed by the AI Safety Team before proceeding. In accordance with General Services Acquisition Manual (GSAM) 507.104(a)(6) , a cquisition plans contemplating the procurement of AI for use at GSA must be coordinated and approved by the CAIO. All plans shall be submitted to the AI Safety Team. 2.6.2. Procuring AI In accordance with GSAM 507.104(a)(6) and 511.170, prior to release of a solicitation for AI for use at GSA, the acquisition team must ensure the requirements document (Performance work Statement (PWS)/Statement of Objective (SOO)/Statement of Work (SOW)) has been coordinated and approved by the CAIO."
  },
  {
    "id": "files_chunk_25",
    "text": "Source: 15 files.pdf\n\nthe CAIO. All plans shall be submitted to the AI Safety Team. 2.6.2. Procuring AI In accordance with GSAM 507.104(a)(6) and 511.170, prior to release of a solicitation for AI for use at GSA, the acquisition team must ensure the requirements document (Performance work Statement (PWS)/Statement of Objective (SOO)/Statement of Work (SOW)) has been coordinated and approved by the CAIO. Submit solicitations to the AI Safety Team. A solicitation can not be released until the CAIO has provided written approval. 2.6.3 Procurement policy updates The procurement policy for AI will be updated over time in alignment with GSA guidelines and directives, and will maintain compliance with federal acquisition standards. 16 2.7 Tool or Product AI Enhancements In many cases, products or tools that have already been procured and have an active Authority to Operate (ATO) will be enhanced with AI. a. All existing tools with ATO that receive AI enhancements must: i. be submitted by the System Owner to the Authorizing Official for assessment and receive a reauthorization prior to bringing the new functionality into the ATO boundary; and ii. report the AI capability as a procurement via the AI Request Form. b. The application of the AI enhancement will be reviewed and dispositioned by the AI Safety Team. c. Should the AI enhancement violate policy outlined in this directive, the enhancement will be required to be turned off or the software be reverted to version that does not contain the enhancement."
  },
  {
    "id": "files_chunk_26",
    "text": "Source: 15 files.pdf\n\nAI capability as a procurement via the AI Request Form. b. The application of the AI enhancement will be reviewed and dispositioned by the AI Safety Team. c. Should the AI enhancement violate policy outlined in this directive, the enhancement will be required to be turned off or the software be reverted to version that does not contain the enhancement. If it is not possible to revert the AI enhancement, process controls and policy will be required to be submitted by the system owner to the CAIO, proving the enhancement is not used in the applicable use cases. 2.8 Publication Requirements All research and development and production or production-intent AI systems currently in use will be publicly disclosed pursuant to Section 3(a) of M-24-10, “Advancing Governance, Innovation, and Risk Management for Agency Use of Artificial Intelligence.” These use cases will be included in the AI use case inventory and hosted on gsa.gov . All use cases shall provide the data elements required by OMB and its Integrated Data Collection process or any OMB-designated superseding processes. Exceptions for publication include AI systems whose disclosure would be inconsistent with applicable law and governmentwide policy . Aggregated statistics of all use cases will be disclosed publicly , to include but not limited to: a. the number of rights-impacting and safety-impacting use cases currently in operation; b. the compliance status of all use cases; and c. all use case waivers currently in force."
  },
  {
    "id": "files_chunk_27",
    "text": "Source: 15 files.pdf\n\nAI systems whose disclosure would be inconsistent with applicable law and governmentwide policy . Aggregated statistics of all use cases will be disclosed publicly , to include but not limited to: a. the number of rights-impacting and safety-impacting use cases currently in operation; b. the compliance status of all use cases; and c. all use case waivers currently in force. 17 2.9 Minimum Requirements for Either Safety-Impacting or Rights-Impacting AI All AI use cases that match the definitions of “safety-impacting AI” or “rights-impacting AI” are subject to the additional requirements in this section because of the potential risk they can pose, for example, discrimination and other harms to people. Recognizing both the risks and opportunities presented by potential “safety-impacting AI” or “rights-impacting AI” capabilities, the CAIO is establishing transparent governance and compliance processes that responsibly address the full scope of these potential risks. System owners and their designees are responsible for enacting these minimum requirements. Appendix A identifies use cases that would be presumed as covered AI (e.g. either rights-impacting or safety-impacting). Waivers from minimum practices may be requested. All requests must be made to the CAIO and AI Governing Board who will adjudicate the request. Any covered AI not in compliance by December 1, 2024 shall cease operations until compliant with the following controls."
  },
  {
    "id": "files_chunk_28",
    "text": "Source: 15 files.pdf\n\nAppendix A identifies use cases that would be presumed as covered AI (e.g. either rights-impacting or safety-impacting). Waivers from minimum practices may be requested. All requests must be made to the CAIO and AI Governing Board who will adjudicate the request. Any covered AI not in compliance by December 1, 2024 shall cease operations until compliant with the following controls. All rights-impacting and safety-impacting use cases must follow these practices before employing the AI into any use case: a. Complete an AI Impact Statement ; b. Submit an AI system test plan that demonstrates real-world context testing, and contestability as necessary; c. Submit to an independent evaluation of the AI system from the CAIO or their designee; All rights-impacting and safety-impacting use cases must follow these practices while employing the AI into any use case: d. Conduct ongoing monitoring of the AI system and establish thresholds for periodic human review; e. Mitigate emergent risks to rights and safety identified through routine testing, continuous monitoring protocols, or third-party findings; f. Ensure all system practitioners have taken requisite AI training requirements; g. Include human validation and intervention protocols to ensure all output decisions made by AI systems are regularly evaluated by system practitioners; and 18 h."
  },
  {
    "id": "files_chunk_29",
    "text": "Source: 15 files.pdf\n\nestablish thresholds for periodic human review; e. Mitigate emergent risks to rights and safety identified through routine testing, continuous monitoring protocols, or third-party findings; f. Ensure all system practitioners have taken requisite AI training requirements; g. Include human validation and intervention protocols to ensure all output decisions made by AI systems are regularly evaluated by system practitioners; and 18 h. Provide public notice and plain language documentation regarding the rights- or safety-impacting use case through the public interface, in public disclosure statements, and the AI use case inventory . 2.9.1 Additional Requirements for Rights-Impacting AI AI use cases deemed as Rights-Impacting must follow these additional requirements before implementation: a. Proactively identify and mitigate algorithmic discrimination or bias; b. Assess and mitigate disparate impacts for protected classes; c. Conduct direct user testing of system interactions; and d. Solicit comments from the user community and conduct post-transaction customer feedback activities in coordination with the Office of Customer Experience or equivalent. AI use cases deemed as Rights-Impacting must follow these additional requirements while employing the AI into any use case: e. Conduct ongoing monitoring studies for AI-enabled discrimination; f. Notify any negatively affected individuals; g. Provide fallback and escalation options for AI processes or outcomes; and h."
  },
  {
    "id": "files_chunk_30",
    "text": "Source: 15 files.pdf\n\npost-transaction customer feedback activities in coordination with the Office of Customer Experience or equivalent. AI use cases deemed as Rights-Impacting must follow these additional requirements while employing the AI into any use case: e. Conduct ongoing monitoring studies for AI-enabled discrimination; f. Notify any negatively affected individuals; g. Provide fallback and escalation options for AI processes or outcomes; and h. Provide opt-out alternatives where practicable. 2.9.2 Excepted scenarios for Rights-Impacting or Safety-Impacting AI use cases The following Rights-Impacting or Safety-Impacting AI use cases do not need to follow the requirements set out in 2.9 and 2.9.1 above: a. Evaluation of a potential vendor , commercial capability , or freely available AI capability that is not otherwise used in agency operations, solely for the purpose of making a procurement or acquisition decision; b. Evaluation of a particular AI application because the AI provider is the target or potential target of a regulatory enforcement action; and c. Research and development purposes. 19 2.9.3 Use-Case Waivers a. The CAIO may waive one or more of the stated requirements for specific covered AI applications with conditions in scenarios where one or more of the requirements would increase risks to safety or rights overall or would create an unacceptable impediment to critical agency operations. i."
  },
  {
    "id": "files_chunk_31",
    "text": "Source: 15 files.pdf\n\nregulatory enforcement action; and c. Research and development purposes. 19 2.9.3 Use-Case Waivers a. The CAIO may waive one or more of the stated requirements for specific covered AI applications with conditions in scenarios where one or more of the requirements would increase risks to safety or rights overall or would create an unacceptable impediment to critical agency operations. i. Appeals for waivers may be submitted by System Owners or delegates with written justifications to the CAIO. ii. All waivers must be centrally tracked and are subject to publication requirements outlined in Publication Requirements . iii. All waivers will be reassessed on an annual basis. 2.10 Organizational Risk Tolerance and Use Case Risk Rubric The AI Governance Board shall establish the enterprise's AI risk tolerance, prioritization, and risk management strategic approach. All risk management activities shall comport with Enterprise Risk and Strategic Initiatives (ERSI) Board reporting requirements, under GSA's Enterprise Risk Management (ERM) Policy . This includes: a. Establishing likelihood and impact ranking criteria and thresholds; b. Defining the considered factors for the use case risk rubric; and c. Establishing the risk management practices and processes that are required for AI systems; The AI Safety team is responsible for assessing use cases based on the guidance provided by the AI Governance Board."
  },
  {
    "id": "files_chunk_32",
    "text": "Source: 15 files.pdf\n\n(ERM) Policy . This includes: a. Establishing likelihood and impact ranking criteria and thresholds; b. Defining the considered factors for the use case risk rubric; and c. Establishing the risk management practices and processes that are required for AI systems; The AI Safety team is responsible for assessing use cases based on the guidance provided by the AI Governance Board. Each System Owner is responsible for implementing the risk management processes defined by the AI Governance Board. 3. Legal and Programmatic Authorities a. Executive Order 14110. Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence. October 30, 2023. b. Executive Order 14091. Further Advancing Racial Equity and Support for Underserved Communities Through the Federal Government. February 2023. c. Executive Order 13960. Promoting the Use of Trustworthy Artificial Intelligence in the Federal Government. December 2020. 20 d. Executive Order 13859. Maintaining American Leadership in AI. February 2019. e. The AI in Government Act of 2020 (Public Law 116-260). f. AI Training Act of 2023 (Public Law 117–207). g. Generative AI and Specialized Computing Infrastructure Acquisition Resource Guide. 4. Definitions 1. AI Use Case : The application of artificial intelligence technology to address specific challenges or improve existing processes within the agency ."
  },
  {
    "id": "files_chunk_33",
    "text": "Source: 15 files.pdf\n\nLeadership in AI. February 2019. e. The AI in Government Act of 2020 (Public Law 116-260). f. AI Training Act of 2023 (Public Law 117–207). g. Generative AI and Specialized Computing Infrastructure Acquisition Resource Guide. 4. Definitions 1. AI Use Case : The application of artificial intelligence technology to address specific challenges or improve existing processes within the agency . This can include automating repetitive tasks, improving data analysis and decision-making, and enhancing customer service through chatbots or virtual assistants. Examples of AI use cases within GSA could include using machine learning algorithms to optimize procurement processes, or leveraging natural language processing to improve search functionality on the agency's website. 2. System Owner : System Owners are GSA management officials with responsibility for the acquisition, development, maintenance, implementation, and operation of GSA's IT systems. System Owners cannot be Information System Security Officers (ISSOs) or Information System Security Managers ( ISSMs). System Owners represent the interests of the system throughout its lifecycle. Primary responsibility for managing risk should rest with the System Owners. 3. Algorithmic discrimination : The term “algorithmic discrimination” has the meaning established in Section 10(f) of Executive Order 14091 of February 16, 2023. 4."
  },
  {
    "id": "files_chunk_34",
    "text": "Source: 15 files.pdf\n\ncannot be Information System Security Officers (ISSOs) or Information System Security Managers ( ISSMs). System Owners represent the interests of the system throughout its lifecycle. Primary responsibility for managing risk should rest with the System Owners. 3. Algorithmic discrimination : The term “algorithmic discrimination” has the meaning established in Section 10(f) of Executive Order 14091 of February 16, 2023. 4. Artificial Intelligence (AI) : The term “artificial intelligence” has the meaning established in Section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019, which states that “the term ‘artificial intelligence’ includes the following”: a. Any artificial system that performs tasks under varying and unpredictable circumstances without significant human oversight, or that can learn from experience and improve performance when exposed to data sets. 21 b. An artificial system developed in computer software, physical hardware, or other context that solves tasks requiring human-like perception, cognition, planning, learning, communication, or physical action. c. An artificial system designed to think or act like a human, including cognitive architectures and neural networks. d. A set of techniques, including machine learning, that is designed to approximate a cognitive task. e."
  },
  {
    "id": "files_chunk_35",
    "text": "Source: 15 files.pdf\n\nAn artificial system developed in computer software, physical hardware, or other context that solves tasks requiring human-like perception, cognition, planning, learning, communication, or physical action. c. An artificial system designed to think or act like a human, including cognitive architectures and neural networks. d. A set of techniques, including machine learning, that is designed to approximate a cognitive task. e. An artificial system designed to act rationally , including an intelligent software agent or embodied robot that achieves goals using perception, planning, reasoning, learning, communicating, decision-making, and acting. f. This definition of AI encompasses, but is not limited to, the AI technical subfields of machine learning (including, but not limited to, deep learning as well as supervised, unsupervised, and semi-supervised approaches), reinforcement learning, transfer learning, and generative AI. g. This definition of AI does not include robotic process automation or other systems whose behavior is defined only by human-defined rules or that learn solely by repeating an observed practice exactly as it was conducted. h. For this definition, no system should be considered too simple to qualify as a covered AI system due to a lack of technical complexity (e.g. the smaller number of parameters in a model, the type of model, or the amount of data used for training purposes). i."
  },
  {
    "id": "files_chunk_36",
    "text": "Source: 15 files.pdf\n\nlearn solely by repeating an observed practice exactly as it was conducted. h. For this definition, no system should be considered too simple to qualify as a covered AI system due to a lack of technical complexity (e.g. the smaller number of parameters in a model, the type of model, or the amount of data used for training purposes). i. This definition includes systems that are fully autonomous, partially autonomous, and not autonomous, and it includes systems that operate both with and without human oversight. 5. Contestability : the ability to effectively challenge a decision made or augmented by AI. 6. Covered AI : AI that has been adjudicated to be Safety-Impacting or Rights-Impacting. 22 7. Data Asset : The term “data asset” has the meaning provided in 44 U.S.C § 3502. 8. Equity : Has the meaning established in Section 10(a) of Executive Order 14091.40 9. Federal Information : Has the meaning established in OMB Circular A-130. 10. Generative AI (GenAI ): Has the meaning established in Section 3(p) of AI Executive Order 14110. 11. Production Work Product : any deliverable or tangible outcome produced as a result of work activities within a project or task. This can include documents, emails, software, presentations, reports, designs, models, and other artifacts that demonstrate progress or completion of work, measure performance, ensure quality , or facilitate communication among stakeholders. Examples of work products include, but are not limited to: a."
  },
  {
    "id": "files_chunk_37",
    "text": "Source: 15 files.pdf\n\nProduct : any deliverable or tangible outcome produced as a result of work activities within a project or task. This can include documents, emails, software, presentations, reports, designs, models, and other artifacts that demonstrate progress or completion of work, measure performance, ensure quality , or facilitate communication among stakeholders. Examples of work products include, but are not limited to: a. Documentation: manuals, user guides, project plans, technical specifications, meeting notes, and progress reports; b. Software: code, scripts, and applications. c. Designs and models: architectural blueprints, wireframes, prototypes, diagrams, and simulations; d. Presentations: slide decks, infographics, dashboards, and visual aids; e. Data: databases, datasets, spreadsheets, and data analysis reports; f. Other deliverables: external communications, training materials, marking collateral, and audit findings. 12. Research and Development : As in OMB Circular No. A-11, Preparation Submission, and Execution of the Budget (2023), research and development is defined as creative and systematic work undertaken in order to increase the stock of knowledge—including knowledge of people, culture, and society—and to devise new applications using available knowledge. 23 13. Rights-Impacting AI : Has the meaning established in Section 6 of M-24-10: Advancing Governance, Innovation, and Risk Management for Agency Use of Artificial Intelligence . 14."
  },
  {
    "id": "files_chunk_38",
    "text": "Source: 15 files.pdf\n\nresearch and development is defined as creative and systematic work undertaken in order to increase the stock of knowledge—including knowledge of people, culture, and society—and to devise new applications using available knowledge. 23 13. Rights-Impacting AI : Has the meaning established in Section 6 of M-24-10: Advancing Governance, Innovation, and Risk Management for Agency Use of Artificial Intelligence . 14. Risks from the Use of AI : Risks related to efficacy , safety , equity , fairness, transparency , accountability , appropriateness, or lawfulness of a decision or action resulting from the use of AI to inform, influence, decide, or execute that decision or action. This includes such risks regardless of whether: a. the AI merely informs the decision or action, partially automates it, or fully automates it; b. there is or is not human oversight for the decision or action; c. it is or is not easily apparent that a decision or action took place, such as when an AI application performs a background task or silently declines to take an action; or d. the humans involved in making the decision or action or that are affected by it are or are not aware of how or to what extent the AI influenced or automated the decision or action. While the particular forms of these risks continue to evolve, at least the following factors can create, contribute to, or exacerbate these risks: a. AI outputs that are inaccurate or misleading; b."
  },
  {
    "id": "files_chunk_39",
    "text": "Source: 15 files.pdf\n\nor action or that are affected by it are or are not aware of how or to what extent the AI influenced or automated the decision or action. While the particular forms of these risks continue to evolve, at least the following factors can create, contribute to, or exacerbate these risks: a. AI outputs that are inaccurate or misleading; b. AI outputs that are unreliable, ineffective, or not robust; c. AI outputs that are discriminatory or have a discriminatory effect; d. AI outputs that contribute to actions or decisions resulting in harmful or unsafe outcomes, including AI outputs that lower the barrier for people to take intentional and harmful actions; e. AI being used for tasks to which it is poorly suited or being inappropriately repurposed in a context for which it was not intended; 24 f. AI being used in a context in which affected people have a reasonable expectation that a human is or should be primarily responsible for a decision or action; and g. the adversarial evasion or manipulation of AI, such as an entity purposefully inducing AI to misclassify an input. 15. Safety-Impacting AI : Has the meaning established in Section 6 of M-24-10: Advancing Governance, Innovation, and Risk Management for Agency Use of Artificial Intelligence . 16."
  },
  {
    "id": "files_chunk_40",
    "text": "Source: 15 files.pdf\n\na human is or should be primarily responsible for a decision or action; and g. the adversarial evasion or manipulation of AI, such as an entity purposefully inducing AI to misclassify an input. 15. Safety-Impacting AI : Has the meaning established in Section 6 of M-24-10: Advancing Governance, Innovation, and Risk Management for Agency Use of Artificial Intelligence . 16. Significant Modification : An update to an AI application or to the conditions or context in which it is used that meaningfully alters the AI’s impact on rights or safety , such as through changing its functionality , underlying structure, or performance such that prior evaluations, training, or documentation become misleading to users, overseers, or individuals affected by the system. This includes significantly changing the context, scope, or intended purpose in which the AI is used. Examples of significant modifications include, but are not limited to, changes in: a. production status, including but not limited to: i. Any change to the use case type that involves a change in production status (e.g. a research and development use case that will be promoted to a production environment); ii. any change to the software release life cycle; b. if the target audience for the AI use case changes (e.g. from internal to external users); a. significant human-ai configuration changes (e.g. major changes in the content provided to users that may significantly change behavior; c."
  },
  {
    "id": "files_chunk_41",
    "text": "Source: 15 files.pdf\n\na research and development use case that will be promoted to a production environment); ii. any change to the software release life cycle; b. if the target audience for the AI use case changes (e.g. from internal to external users); a. significant human-ai configuration changes (e.g. major changes in the content provided to users that may significantly change behavior; c. if the use case’ s output type changes (e.g. from text to imagery); d. if the solution architecture undergoes significant modification, including new system connections or process models; e. major or minor update changes to underlying models as per Semantic Versioning standards; and 25 f. Any other modifications that meet the definition of 'significant modification' put forth by the National Institute of Standards and Technology’ s Risk Management Framework for Information Systems and Organizations: A System Life Cycle Approach for Security and Privacy . 17. Underserved Communities : Has the meaning established in Section 10(b) of Executive Order 14091. 18. Use Case Register : a registry of all non-excluded AI use cases within GSA. 5. Appendix A: Presumed Rights-Impacting and Safety Impacting Use Cases 5.1 Rights-Impacting Use Case Examples The following examples will be adjudicated as rights-impacting if used to control or meaningfully influence the outcomes of any of the following non-exhaustive list of activities or decisions: a. Blocking, removing, hiding, or limiting the reach of protected speech; b."
  },
  {
    "id": "files_chunk_42",
    "text": "Source: 15 files.pdf\n\nAI use cases within GSA. 5. Appendix A: Presumed Rights-Impacting and Safety Impacting Use Cases 5.1 Rights-Impacting Use Case Examples The following examples will be adjudicated as rights-impacting if used to control or meaningfully influence the outcomes of any of the following non-exhaustive list of activities or decisions: a. Blocking, removing, hiding, or limiting the reach of protected speech; b. In law enforcement contexts, producing risk assessments about individuals; predicting criminal recidivism; predicting criminal offenders; identifying criminal suspects or predicting perpetrators' identities; predicting victims of crime; forecasting crime; detecting gunshots; tracking personal vehicles over time in public spaces, including license plate readers; conducting biometric identification (e.g. iris, facial, fingerprint, or gait matching); sketching faces; reconstructing faces based on genetic information; monitoring social media; monitoring prisons; forensically analyzing criminal evidence; conducting forensic genetics; conducting cyber intrusions in the course of an investigation; conducting physical location-monitoring or tracking of individuals; or making determinations related to sentencing, parole, supervised release, probation, bail, pretrial release, or pretrial detention; c."
  },
  {
    "id": "files_chunk_43",
    "text": "Source: 15 files.pdf\n\n(e.g. iris, facial, fingerprint, or gait matching); sketching faces; reconstructing faces based on genetic information; monitoring social media; monitoring prisons; forensically analyzing criminal evidence; conducting forensic genetics; conducting cyber intrusions in the course of an investigation; conducting physical location-monitoring or tracking of individuals; or making determinations related to sentencing, parole, supervised release, probation, bail, pretrial release, or pretrial detention; c. Deciding or providing risk assessments related to immigration, asylum, or detention status; providing immigration-related risk assessments about individuals who intend to travel to, or have already entered, the U.S. or its territories; determining individuals’ border access or access to Federal immigration related services through biometrics or through monitoring social media and other online activity; monitoring individuals’ physical location for 26 immigration and detention-related purposes; or forecasting the migration activity of individuals; d. Conducting biometric identification for one-to-many identification in publicly accessible spaces; e. Detecting or measuring emotions, thought, impairment, or deception in humans; f. Replicating a person’ s likeness or voice without express consent; g."
  },
  {
    "id": "files_chunk_44",
    "text": "Source: 15 files.pdf\n\nor through monitoring social media and other online activity; monitoring individuals’ physical location for 26 immigration and detention-related purposes; or forecasting the migration activity of individuals; d. Conducting biometric identification for one-to-many identification in publicly accessible spaces; e. Detecting or measuring emotions, thought, impairment, or deception in humans; f. Replicating a person’ s likeness or voice without express consent; g. In education contexts, detecting student cheating or plagiarism; influencing admissions processes; monitoring students online or in virtual-reality; projecting student progress or outcomes; recommending disciplinary interventions; determining access to educational resources or programs; determining eligibility for student aid or Federal education; or facilitating surveillance (whether online or in-person); h. Screening tenants; monitoring tenants in the context of public housing; providing valuations for homes; underwriting mortgages; or determining access to or terms of home insurance; i. Determining the terms or conditions of employment, including pre-employment screening, reasonable accommodation, pay or promotion, performance management, hiring or termination, or recommending disciplinary action; performing time-on-task tracking; or conducting workplace surveillance or automated personnel management; j."
  },
  {
    "id": "files_chunk_45",
    "text": "Source: 15 files.pdf\n\nmonitoring tenants in the context of public housing; providing valuations for homes; underwriting mortgages; or determining access to or terms of home insurance; i. Determining the terms or conditions of employment, including pre-employment screening, reasonable accommodation, pay or promotion, performance management, hiring or termination, or recommending disciplinary action; performing time-on-task tracking; or conducting workplace surveillance or automated personnel management; j. Carrying out the medically relevant functions of medical devices; providing medical diagnoses; determining medical treatments; providing medical or insurance health-risk assessments; providing drug-addiction risk assessments or determining access to medication; conducting risk assessments for suicide or other violence; detecting or preventing mental-health issues; flagging patients for interventions; allocating care in the context of public insurance; or controlling health-insurance costs and underwriting; k. Allocating loans; determining financial-system access; credit scoring; determining who is subject to a financial audit; making insurance determinations and risk assessments; determining interest rates; or determining financial penalties (e.g. garnishing wages or withholding tax returns); l. Making decisions regarding access to, eligibility for, or revocation of critical government resources or services; allowing or denying access—through 27 biometrics or other means (e.g."
  },
  {
    "id": "files_chunk_46",
    "text": "Source: 15 files.pdf\n\nloans; determining financial-system access; credit scoring; determining who is subject to a financial audit; making insurance determinations and risk assessments; determining interest rates; or determining financial penalties (e.g. garnishing wages or withholding tax returns); l. Making decisions regarding access to, eligibility for, or revocation of critical government resources or services; allowing or denying access—through 27 biometrics or other means (e.g. signature matching)—to IT systems for accessing services for benefits; detecting fraudulent use or attempted use of government services; assigning penalties in the context of government benefits; m. Translating between languages for the purpose of official communication to an individual where the responses are legally binding; providing live language interpretation or translation, without a competent interpreter or translator present, for an interaction that directly informs an agency decision or action; or n. Providing recommendations, decisions, or risk assessments about adoption matching, child protective actions, recommending child custody , whether a parent or guardian is suitable to gain or retain custody of a child, or protective actions for senior citizens or disabled persons. 5.2 Safety-Impacting Use Case Examples The following examples will be adjudicated as safety-impacting if used to control or meaningfully influence the outcomes of any of the following non-exhaustive list of activities or decisions: a."
  },
  {
    "id": "files_chunk_47",
    "text": "Source: 15 files.pdf\n\ncustody , whether a parent or guardian is suitable to gain or retain custody of a child, or protective actions for senior citizens or disabled persons. 5.2 Safety-Impacting Use Case Examples The following examples will be adjudicated as safety-impacting if used to control or meaningfully influence the outcomes of any of the following non-exhaustive list of activities or decisions: a. Controlling the safety-critical functions within dams, emergency services, electrical grids, the generation or movement of energy , fire safety systems, food safety mechanisms, traffic control systems and other systems controlling physical transit, water and wastewater systems, or nuclear reactors, materials, and waste; b. Maintaining the integrity of elections and voting infrastructure; c. Controlling the physical movements of robots or robotic appendages within a workplace, school, housing, transportation, medical, or law enforcement setting; d. Applying kinetic force; delivering biological or chemical agents; or delivering potentially damaging electromagnetic impulses; e. Autonomously or semi-autonomously moving vehicles, whether on land, underground, at sea, in the air, or in space; f. Controlling the transport, safety , design, or development of hazardous chemicals or biological agents; g. Controlling industrial emissions and environmental impacts; h. Transporting or managing of industrial waste or other controlled pollutants; 28 i."
  },
  {
    "id": "files_chunk_48",
    "text": "Source: 15 files.pdf\n\nagents; or delivering potentially damaging electromagnetic impulses; e. Autonomously or semi-autonomously moving vehicles, whether on land, underground, at sea, in the air, or in space; f. Controlling the transport, safety , design, or development of hazardous chemicals or biological agents; g. Controlling industrial emissions and environmental impacts; h. Transporting or managing of industrial waste or other controlled pollutants; 28 i. Designing, constructing, or testing of industrial equipment, systems, or structures that, if they failed, would pose a significant risk to safety; j. Carrying out the medically relevant functions of medical devices; providing medical diagnoses; determining medical treatments; providing medical or insurance health-risk assessments; providing drug-addiction risk assessments or determining access to medication; conducting risk assessments for suicide or other violence; detecting or preventing mental-health issues; flagging patients for interventions; allocating care in the context of public insurance; or controlling health-insurance costs and underwriting; k. Detecting the presence of dangerous weapons or a violent act; l. Choosing to summon first responders to an emergency; m. Controlling access to or security of government facilities; or n. Determining or carrying out enforcement actions pursuant to sanctions, trade restrictions, or other controls on exports, investments, or shipping. 6."
  },
  {
    "id": "files_chunk_49",
    "text": "Source: 15 files.pdf\n\nof public insurance; or controlling health-insurance costs and underwriting; k. Detecting the presence of dangerous weapons or a violent act; l. Choosing to summon first responders to an emergency; m. Controlling access to or security of government facilities; or n. Determining or carrying out enforcement actions pursuant to sanctions, trade restrictions, or other controls on exports, investments, or shipping. 6. Appendix B: AI Impact Statement Guidance AI impact statements are necessary for any Safety-Impacting or Rights-Impacting use cases. A template for an impact statement may be found here: . In AI impact statements, all system owners must AI Impact Statement - Template document the following: a. The intended purpose for the AI and its expected benefit, supported by specific metrics or qualitative analysis. Metrics should be quantifiable measures of positive outcomes for the agency’ s mission – for example, to reduce costs, increase adoption, reduce wait time for customers, reduce risk to human life, or to meet compliance requirements – that can be measured using performance measurement or program evaluation methods after the AI is deployed to demonstrate the value of using AI. Where quantification is not feasible, qualitative analysis should demonstrate an expected positive outcome, such as for improvements to customer experience, and it should demonstrate that AI is better suited to accomplish the relevant task as compared to alternative strategies. b."
  },
  {
    "id": "files_chunk_50",
    "text": "Source: 15 files.pdf\n\nmeasured using performance measurement or program evaluation methods after the AI is deployed to demonstrate the value of using AI. Where quantification is not feasible, qualitative analysis should demonstrate an expected positive outcome, such as for improvements to customer experience, and it should demonstrate that AI is better suited to accomplish the relevant task as compared to alternative strategies. b. The potential risks of using AI, as well as what, if any, additional mitigation measures, beyond these minimum practices, the agency will take to help reduce these risks. System owners should document the stakeholders who will be most 29 impacted by the use of the system and assess the possible failure modes of the AI and of the broader system, both in isolation and as a result of human users and other likely variables outside the scope of the system itself. System owners should be especially attentive to the potential risks to underserved communities. The expected benefits of the AI functionality should be considered against its potential risks, and if the benefits do not meaningfully outweigh the risks, system owners should not use the AI. c. The quality and appropriateness of the relevant data, or documentation on why those data are not available and what mitigations are in place. System owners must assess the quality of the data used in the AI’s design, development, training, testing, and operation and its fitness to the AI’s intended purpose."
  },
  {
    "id": "files_chunk_51",
    "text": "Source: 15 files.pdf\n\nthe risks, system owners should not use the AI. c. The quality and appropriateness of the relevant data, or documentation on why those data are not available and what mitigations are in place. System owners must assess the quality of the data used in the AI’s design, development, training, testing, and operation and its fitness to the AI’s intended purpose. In conducting assessments, if the system owner cannot obtain such data after a reasonable effort to do so, it must obtain sufficient descriptive information from the vendor (e.g. AI or data provider) to satisfy the reporting requirements in this paragraph. At a minimum, system owners must document: i. the data collection and preparation process, which must also include the provenance of any data used to train, fine-tune, or operate the AI; ii. the quality and representativeness of the data for its intended purpose; iii. how the data is relevant to the task being automated and may reasonably be expected to be useful for the AI’s development, testing, and operation; iv. whether the data contains sufficient breadth to address the range of real-world inputs the AI might encounter and how data gaps and shortcomings have been addressed either by the agency or vendor; and v. if the data is maintained by the Federal Government, whether that data is publicly disclosable as an open government data asset, in accordance with applicable law and policy . 7. Appendix C: Additional Documents a. Use Case Request Form b."
  },
  {
    "id": "files_chunk_52",
    "text": "Source: 15 files.pdf\n\nAI might encounter and how data gaps and shortcomings have been addressed either by the agency or vendor; and v. if the data is maintained by the Federal Government, whether that data is publicly disclosable as an open government data asset, in accordance with applicable law and policy . 7. Appendix C: Additional Documents a. Use Case Request Form b. AI Model Request Form c. AI Governance Board Charter d. AI Safety Team Charter e. Impact Statement Template f. Experimental Design Statement Template 30"
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_0",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nCompliance Plan for OMB Memorandum M-24-10 Advancing Governance, Innovation, and Risk Management for Agency Use of Artificial Intelligence – September 2024 SBA Office of the CIO Page 2 of 17Contents I. STRENGTHENING AI GOVERNANCE ..................................................................................................... 3 1. General ................................................................................................................................................. 3 2. Trustworthy AI Framework .................................................................................................................. 3 3. AI Governance Bodies .......................................................................................................................... 5 4. AI Use Case Inventories ........................................................................................................................ 9 5. Reporting on AI Use Cases Not Subject to Inventory .......................................................................... 9 II. ADVANCING RESPONSIBLE AI INNOVATION ......................................................................................... 10 1. AI Strategy .......................................................................................................................................... 10 2. Removing Barriers to the Responsible Use of AI .............................................................................. 10 3."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_1",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\n3 1. General ................................................................................................................................................. 3 2. Trustworthy AI Framework .................................................................................................................. 3 3. AI Governance Bodies .......................................................................................................................... 5 4. AI Use Case Inventories ........................................................................................................................ 9 5. Reporting on AI Use Cases Not Subject to Inventory .......................................................................... 9 II. ADVANCING RESPONSIBLE AI INNOVATION ......................................................................................... 10 1. AI Strategy .......................................................................................................................................... 10 2. Removing Barriers to the Responsible Use of AI .............................................................................. 10 3. Generative AI ...................................................................................................................................... 11 4. AI Talent .............................................................................................................................................. 12 5."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_2",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\n3 3. AI Governance Bodies .......................................................................................................................... 5 4. AI Use Case Inventories ........................................................................................................................ 9 5. Reporting on AI Use Cases Not Subject to Inventory .......................................................................... 9 II. ADVANCING RESPONSIBLE AI INNOVATION ......................................................................................... 10 1. AI Strategy .......................................................................................................................................... 10 2. Removing Barriers to the Responsible Use of AI .............................................................................. 10 3. Generative AI ...................................................................................................................................... 11 4. AI Talent .............................................................................................................................................. 12 5. AI Sharing and Collaboration ............................................................................................................. 13 6. Harmonization of Artificial Intelligence Requirements .................................................................... 14 III."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_3",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nReporting on AI Use Cases Not Subject to Inventory .......................................................................... 9 II. ADVANCING RESPONSIBLE AI INNOVATION ......................................................................................... 10 1. AI Strategy .......................................................................................................................................... 10 2. Removing Barriers to the Responsible Use of AI .............................................................................. 10 3. Generative AI ...................................................................................................................................... 11 4. AI Talent .............................................................................................................................................. 12 5. AI Sharing and Collaboration ............................................................................................................. 13 6. Harmonization of Artificial Intelligence Requirements .................................................................... 14 III. MANAGING RISKS FROM THE USE OF ARTIFICIAL INTELLIGENCE ....................................................... 15 1."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_4",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nII. ADVANCING RESPONSIBLE AI INNOVATION ......................................................................................... 10 1. AI Strategy .......................................................................................................................................... 10 2. Removing Barriers to the Responsible Use of AI .............................................................................. 10 3. Generative AI ...................................................................................................................................... 11 4. AI Talent .............................................................................................................................................. 12 5. AI Sharing and Collaboration ............................................................................................................. 13 6. Harmonization of Artificial Intelligence Requirements .................................................................... 14 III. MANAGING RISKS FROM THE USE OF ARTIFICIAL INTELLIGENCE ....................................................... 15 1. Determining Which Artificial Intelligence Is Presumed to Be Safety -Impacting or Rights -Impacting ................................................................................................................................................................ 15 2. Implementation of Risk Management Practices and Termination of Non- Compliant AI ................ 16 3."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_5",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nTalent .............................................................................................................................................. 12 5. AI Sharing and Collaboration ............................................................................................................. 13 6. Harmonization of Artificial Intelligence Requirements .................................................................... 14 III. MANAGING RISKS FROM THE USE OF ARTIFICIAL INTELLIGENCE ....................................................... 15 1. Determining Which Artificial Intelligence Is Presumed to Be Safety -Impacting or Rights -Impacting ................................................................................................................................................................ 15 2. Implementation of Risk Management Practices and Termination of Non- Compliant AI ................ 16 3. Minimum Risk Management Practices .............................................................................................. 16 SB A Office of the CIO Page 3 of 17I. STRENGTHENING AI GOVERNANCE The US Small Business Administration is small but mighty and we proud of what we have accomplished as we manage our agency’s use Artificial Intelligence. 1. General Describe any planned or current efforts within your agency to update any existing internal AI principles, guidelines, or policy to ensure consistency with M -24-10."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_6",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nCIO Page 3 of 17I. STRENGTHENING AI GOVERNANCE The US Small Business Administration is small but mighty and we proud of what we have accomplished as we manage our agency’s use Artificial Intelligence. 1. General Describe any planned or current efforts within your agency to update any existing internal AI principles, guidelines, or policy to ensure consistency with M -24-10. As a CFO -Act agency, the US Smal Business Administration (SBA) is a covered per 44 U.S.C. § 3502(1). Prior to the release of OMB Memo M-24-10 (PDF, 33-pages, 518KB), the SBA had begun developing internal guidance related to the use AI. That existing guidance is being reviewed for consistency with M -24-10. 2. Trustworthy AI Framework In December 2022, SBA had its Chief Enterprise Architect take on the role Responsible AI Official (RAIO) for the agency. As the official at the agency tasked with providing a long- term strategic approach to align agency goals and objectives with business processes and technology. The RAIO works closely with SBA’s Chief AI Officer to develop a framework that e ncourages AI innovation while balancing compliance and risk management consistent IT investment methodologies. Together they are w orking to ensure that the US Small Business Admi nistration is able to meet the requirements of all Executive Orders and Memorandum and ensure that the six Trustworthy AI principles would be used to as key components of SBA AI governance activities ."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_7",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nncourages AI innovation while balancing compliance and risk management consistent IT investment methodologies. Together they are w orking to ensure that the US Small Business Admi nistration is able to meet the requirements of all Executive Orders and Memorandum and ensure that the six Trustworthy AI principles would be used to as key components of SBA AI governance activities . Steps that we have taken include the following: • In February 2024, placed guard rails on employee use of AI by issu ing policy document (Information Notice 9000-852330) which directed SBA personnel to “refrain from using these AI capabilities for official and sensitive government business as it violates Executive Order 13960 “Promoting the Use of Trustworthy Artificial Intelligence in the Federal Government” and Executive Order 14110 “Safe, Secure, and Trustworthy Development and U se of Artificial Intelligence.” • In May 2024, our Chief Information Security Officer (CISO) while distributing a draft standard operating procedure for “ Artificial Intelligence Implementation ” for review, he reminded staff that “SBA recognizes that AI's responsible and ethical use can drive economic growth by enhancing decision-making, improving efficiency, and expanding access to resources for small businesses .” • SBA convened an Open Data Working Group, led by the Chief Data Officer, to modernize the agency’s Open Data Program."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_8",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nprocedure for “ Artificial Intelligence Implementation ” for review, he reminded staff that “SBA recognizes that AI's responsible and ethical use can drive economic growth by enhancing decision-making, improving efficiency, and expanding access to resources for small businesses .” • SBA convened an Open Data Working Group, led by the Chief Data Officer, to modernize the agency’s Open Data Program. The primary goal of the working group is to SBA O ffice of the CIO Page 4 of 17modernize SBA Standard Operating Procedure (SOP) 90-81 (Open Data Program) and to ensure SBA’s continued compliance with the OPEN Government Data Act and key supplemental guidelines such as M-19-23 and M-24-10. • SBA’s CDO has written a draft Open Data Plan to comply with the Evidence Act and subsequent federal guidance on making data open, improving the quality of open government data assets, engaging the public on understanding the use and value of the Agency’s data, and establishing and maintaining data inventories and catalogs, including designating priority data assets. Additionally, the Open Data Plan builds on prior federal efforts to make data more open and transparent and attempts to capture the Agency’s compliance with those prior requirements, laying the foundation for collaboration and streamlining work efforts across the Agency when appropriate."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_9",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nvalue of the Agency’s data, and establishing and maintaining data inventories and catalogs, including designating priority data assets. Additionally, the Open Data Plan builds on prior federal efforts to make data more open and transparent and attempts to capture the Agency’s compliance with those prior requirements, laying the foundation for collaboration and streamlining work efforts across the Agency when appropriate. The Open Data Plan is to be updated and published at least annually and made a part of the Agency’s strategic information resources management plan, with awareness and adoption promulgated through the Data Governance Board and various Agency campaigns to help assure enterprise knowledge and compliance. St eps that are planned include the following: • In FY2025, the RAIO will work with its Office of Diversity, Inclusion & Civil Rights exploring ways to integrate its SBA Trustworthy AI Framework and AI guidance into key offices that evaluate equitable outcomes . • In FY2025, our entrepreneurial outreach offices will have developed an AI Toolkit for Small Businesses that is consistent with M -24-10 and that advances our customers and stakeholders ability to anticipate and mitigate risks to rights and safety from the use of AI. • In FY2025, the CAIO with input from the governance council will work with its Senior Procurement Executive to develop contracting language for responsible AI, which is being piloted in a few contracts. SBA Office of the CIO Page 5 of 173."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_10",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\ncustomers and stakeholders ability to anticipate and mitigate risks to rights and safety from the use of AI. • In FY2025, the CAIO with input from the governance council will work with its Senior Procurement Executive to develop contracting language for responsible AI, which is being piloted in a few contracts. SBA Office of the CIO Page 5 of 173. AI Governance Bodies Identify the offices that are represented on your agency’s AI governance body. SBA ’s AI Governance Council (AIGC) is chaired by the SBA Chief Information Officer (Acting) and Chief AI Officer and co -vice- chaired by SBA ’s Deputy Chief Financial Officer. The AIGC is comprised of two groups: 1) voting members; and 2) advisory (AI and technology stakeholders) members. The Chief AI Officer serves as the Council Chair and appoints voting members of the Council as desired from within SBA. Council voting membership may be changed at any time by the Administrator. The voting membership is comprised of senior- level staff in major SBA program offices, technology, innovation, workforce, and financial management. The council has broad SBA Program Office representation for the purpose of engaging SBA senior officials from all relevant functional disciplines in enterprise -level decisions on the development and use of AI."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_11",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nbe changed at any time by the Administrator. The voting membership is comprised of senior- level staff in major SBA program offices, technology, innovation, workforce, and financial management. The council has broad SBA Program Office representation for the purpose of engaging SBA senior officials from all relevant functional disciplines in enterprise -level decisions on the development and use of AI. The following are member organizations of the council: Council voting membership includes the following members: • Chair: Chief Artificial Intelligence (AI) Officer • Deputy Chair: Deputy Chief Financial Officer Voting Members: 1. Chief Data Officer 2. Chief Technology Officer 3. Statistical Officer 4. Chief Financial Officer 5. Chief Information Officer 6. General Counsel 7. Chief Information Security Officer 8. Chief Privacy Officer 9. SAO for Records Management 10. Deputy Associate Administrator, Office of Capital Access 11. Deputy Associate Administrator, Office of Disaster Recovery & Resilience 12. Deputy Associate Administrator, Office of Entrepreneurial Development 13. Deputy Associate Administrator, Office of Government Contracting and Business Development 14. Deputy Associate Administrator, Office of Investment and Innovation 15. Deputy Chief Human Capital Officer, Office of the Chief Human Capital Officer 16. Senior Procurement Executive 17."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_12",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nOffice of Capital Access 11. Deputy Associate Administrator, Office of Disaster Recovery & Resilience 12. Deputy Associate Administrator, Office of Entrepreneurial Development 13. Deputy Associate Administrator, Office of Government Contracting and Business Development 14. Deputy Associate Administrator, Office of Investment and Innovation 15. Deputy Chief Human Capital Officer, Office of the Chief Human Capital Officer 16. Senior Procurement Executive 17. Deputy Associate Administrator, Office of Field Operations SBA Office of the CIO Page 6 of 17Membership (Non-Voting Members) The Council will also include AI stakeholders across the agency who will serve as advisory members and are not voting members. Council advisory membership includes the following members: 1. Representative of the Office of Diversity, Inclusion & Civil Rights 2. Chief Enterprise Architect 3. Representative from Office of Field Operations 4. Representative from Office of International Trade 5. Representative from Office of Veterans Business Development 6. Representative from Chief Human Capital Officer (ER/LR ) 7. Representative from Chief Information Officer (IT Governance) 8. Representative from Office of Advocacy 9. Representative from Office of Disaster Recovery & Resilience 10. Representative from Office of the Chief Financial Officer 11. Representative from, Office of Capital Access 12. Representative of the Office of Executive Management, Installations & Support Services 13."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_13",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nRepresentative from Chief Human Capital Officer (ER/LR ) 7. Representative from Chief Information Officer (IT Governance) 8. Representative from Office of Advocacy 9. Representative from Office of Disaster Recovery & Resilience 10. Representative from Office of the Chief Financial Officer 11. Representative from, Office of Capital Access 12. Representative of the Office of Executive Management, Installations & Support Services 13. Representative from the Enterprise Risk Program Management 14. Representative from the Office of the Administrator 15. Representative from the SBA Inspector General 16. Representative from the Office of Communications & Public Liaison 17. Representative from the Office of Congressional & Legislative Affairs 18. Representative from the Office of Office of Hearings & Appeals 19. Representative from the Office of Native American Affairs These a dvisory members will participate in Council meetings and may serve on Council subcommittees or working groups. Advisory council membership will be determined by the Council Chair. Describe the expected outcomes for the AI governance body and your agency’s plan to achieve them. The purpose of the SBA AI Governance Council (AIGC) is to serve as SBA ’s principal governing body for AI innovation, governance, safety, privacy, and security oversight. The council’s immediate goal is to oversee the implementation of OMB M -24-10."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_14",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nby the Council Chair. Describe the expected outcomes for the AI governance body and your agency’s plan to achieve them. The purpose of the SBA AI Governance Council (AIGC) is to serve as SBA ’s principal governing body for AI innovation, governance, safety, privacy, and security oversight. The council’s immediate goal is to oversee the implementation of OMB M -24-10. Expected outcomes include education, transparency, wide participation, shared understanding, and risk management for AI across the agency. The AIGC will facilitate Generative AI solution development efforts within the US Small Business Administration. This cross-agency council will work towards innovation and collaboration while ensuring responsible implementation and continuous monitoring of the solutions in production. SBA Office of the CIO Page 7 of 17The AI Governance Council has the following objectives: 1. Foster innovation within the Small Business Administration 2. Ensure the SBA uses AI in a secure, efficient and responsible manner in support of the agency’s mission. 3. Guide small businesses, entrepreneurs, lenders, and other external stakeholders in the ethical, transparent, unbiased and fearless use of AI solutions. AI G overnance Council work products will support the 3 main objectives above : 1. Establishing the framework for evaluating and authorizing the use of AI technology (e.g., architecture frameworks, security, software, infrastructure, and relevant tools). 2."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_15",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nagency’s mission. 3. Guide small businesses, entrepreneurs, lenders, and other external stakeholders in the ethical, transparent, unbiased and fearless use of AI solutions. AI G overnance Council work products will support the 3 main objectives above : 1. Establishing the framework for evaluating and authorizing the use of AI technology (e.g., architecture frameworks, security, software, infrastructure, and relevant tools). 2. Developing and maintaining a cross-agency repository that captures approved AI use cases. 3. Informing the legal and contractual requirements for the use of third- party AI services, contracts, licenses, agreements. 4. Directing the establishment of and the ongoing use of an agencywide sandbox environment to safely explore the use of AI to enhance the experience of the SBA workforce, small business, entrepreneurs and stakeholders. 5. Documenting protocols and procedures for assessing and handling inquiries or incidents regarding AI system anomalies. 6. Auditing AI current and future solutions to ensure alignment with agencywide policy requirements. 7. Examining the social, economic, and legal impacts of AI adoption on the SBA workforce and our internal business operations. 8. Vetting AI-related educational material developed for entrepreneurs, lenders and small businesses to ensure a balance between fostering innovation and risk awareness."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_16",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nregarding AI system anomalies. 6. Auditing AI current and future solutions to ensure alignment with agencywide policy requirements. 7. Examining the social, economic, and legal impacts of AI adoption on the SBA workforce and our internal business operations. 8. Vetting AI-related educational material developed for entrepreneurs, lenders and small businesses to ensure a balance between fostering innovation and risk awareness. SBA Office of the CIO Page 8 of 17Describe how, if at all, your agency’s AI governance body plans to consult with external experts as appropriate and consistent with applicable law. External experts are characterized as individuals outside your agency, which may include individuals from ot her agencies, federally funded research and development centers, academic institutions, think tanks, industry, civil society, or labor unions. SBA regularly engages with external experts in the federal government on AI topics. The AIGC has not does the outreach as a body, but individuals on the governance board have had these specific interactions: • Participation in the General Services Administration (GSA) AI Community of Practice."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_17",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nresearch and development centers, academic institutions, think tanks, industry, civil society, or labor unions. SBA regularly engages with external experts in the federal government on AI topics. The AIGC has not does the outreach as a body, but individuals on the governance board have had these specific interactions: • Participation in the General Services Administration (GSA) AI Community of Practice. • Work with these subgroups of the Chief AI Council:  CAIO Council's Procurement Working Group  CAIO Council's Minimum Risk Management Working  CAIO Council's Generative AI Working Group • Engagement with various interagency groups and councils including the RAIO Council, the C hief D ata O fficer (CDO) council, the Chief Human Capital Officer (CHCO) council, the Office of Personnel Management (OPM) AI Talent Task Force, CISA subgroups, and Partnership for Public Service AI Federal Leadership Program . • Additionally, SBA participates in the public-private AI working group of the Advanced Technology Academic Research Center (ATARC) and assisting in developing one of their user group surveys. • Leveraging a long collaboration that SBA has with the University of Virginia School of Data Science, member of the AIGC mentored , four students in their Capstone project to create a machine-learning model to predict which of 600- plus Federal agencies would be the best target for a new -entrant small business seeking to contract with the Federal government."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_18",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\n• Leveraging a long collaboration that SBA has with the University of Virginia School of Data Science, member of the AIGC mentored , four students in their Capstone project to create a machine-learning model to predict which of 600- plus Federal agencies would be the best target for a new -entrant small business seeking to contract with the Federal government. • Following George Mason University’s announcement concerning their new Center for AI Innovation for Economic Competitiveness, a member of the AIGC reached out to discuss a partnership. • There is a p lan to engage with SBA ’s labor union on AI and AI workforce topics. SBA Office of the CIO Page 9 of 174. AI Use Case Inventories Describe your agency’s process for soliciting and collecting AI use cases across all sub- agencies, components, or bureaus for the inventory. In particular, address how your agency plans to ensure your inventory is comprehensive, complete, and encompasses updates to existing use cases. At the end of March 2024, the RAIO created an AI Use Case Submission Form. This was following the distribution of the February 2024 agency directive banning generative AI at SBA which cause many employees and program office to inquiry about when they could use AI. The response from the CAIO was, “Submit a U se Case.” Communication of this new form and its purpose was first delivered to technology leader s in SBA Program Offices that already had IT investments ."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_19",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nFebruary 2024 agency directive banning generative AI at SBA which cause many employees and program office to inquiry about when they could use AI. The response from the CAIO was, “Submit a U se Case.” Communication of this new form and its purpose was first delivered to technology leader s in SBA Program Offices that already had IT investments . The AI Use Case Submission Form was publicized throughout the Summer of 2024 at the “all hands” of large program offices as well as the quarterly Town Hall meeting of the SBA Administrator in June 2024, and at the Tech Talent Town hall in May and September 2024. To ensure that we are not overlooking any AI -related technology, SBA contacted all conceptual AI use case owners from the 2022 and 2023 use case inventories for updates on their concepts . Addi tionally , following a July 10 th presentation of the 6 best use case to the Business Technology Investment Council, the agency’s investment review board, the CAIO asked the portfolio management team to look at existing investments in the agency’s portfolio. The RAIO meet s a few times a month with SBA’s internal marketing and communications to determine other methods for getting the word out. 5. Reporting on AI Use Cases Not Subject to Inventory Describe your agency’s process for soliciting and collecting AI use cases that meet the criteria for exclusion from being individually inventoried, as required by Section 3(a)(v) of M-24-10."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_20",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nmeet s a few times a month with SBA’s internal marketing and communications to determine other methods for getting the word out. 5. Reporting on AI Use Cases Not Subject to Inventory Describe your agency’s process for soliciting and collecting AI use cases that meet the criteria for exclusion from being individually inventoried, as required by Section 3(a)(v) of M-24-10. In particular, explain the process by which your agency determine s whether a use case should be excluded from being individually inventoried and the criteria involved for such a determination. Identify how your agency plans to periodically revisit and validate these use cases. In particular, describe the criteria that your agency intends to use to determine whether an AI use case that previously met the exclusion criteria for individual inventor ying should subsequently be added to the agency’s public inventory. SBA does not expect to have many use cases where sharing would be inconsistent with applicable law and governmentwide policy. SBA intends to assess and triage AI use cases according to applicable law and policy, and exclusions in this category will be handled on a case-by-case basis. SBA O ffice of the CIO Page 10 of 17II. ADVANCING RESPONSIBLE AI INNOVATION 1. AI Strategy SBA will release an updated AI strategy as a separate document by Q3FY2025 ."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_21",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\ngovernmentwide policy. SBA intends to assess and triage AI use cases according to applicable law and policy, and exclusions in this category will be handled on a case-by-case basis. SBA O ffice of the CIO Page 10 of 17II. ADVANCING RESPONSIBLE AI INNOVATION 1. AI Strategy SBA will release an updated AI strategy as a separate document by Q3FY2025 . Broadly, SBA sees significant opportunity for AI, when implemented responsibly, to contribute to our mission and has been executing across four main AI workstreams: AI policy and risk management, AI workforce development, AI infrastructure, and AI priority use cases. 2. Removing Barriers to the Responsible Use of AI Describe any barriers to the responsible use of AI that your agency has identified, as well as any steps your agency has taken (or plans to take) to mitigate or remove these identified barriers. In particular, elaborate on whether your agency is addressing access to the necessary software tools, open-source libraries, and deployment and monitoring capabilities to rapidly develop, test, and maintain AI applications. • SBA has identified and is addressing several barriers to responsible building of AI, including access to authoritative data sources for training, testing and validation of AI models and ensuring that these data sources have documentation describing how the y are cleaned and refined to support model audits. • SBA currently supports several enterprise cloud and data platforms."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_22",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nAI applications. • SBA has identified and is addressing several barriers to responsible building of AI, including access to authoritative data sources for training, testing and validation of AI models and ensuring that these data sources have documentation describing how the y are cleaned and refined to support model audits. • SBA currently supports several enterprise cloud and data platforms. These platforms are crucial for limiting access control, providing FedRAMPed and secure AI capabilities, enabling monitoring and observability, and ensuring the accuracy and precision of A I, ML, and GenAI systems. Examples of different cloud and data platforms in use at SBA are Amazon Web Services, Azure, Oracle Cloud, Google Cloud Platform, and Salesforce. • SBA’s cloud and data platforms also have multiple capabilities that are important for model testing and deployment, utilize some open-source libraries, and enable model iteration, with the goal of meeting the agency’s need for efficacy, scalability, sustainability, data control, security, governance, privacy , reliability , cost -effectiveness , and ethics . SBA Office of the CIO Page 11 of 173. Generative AI Identify whether your agency has developed (or is in the process of developing) internal guidance for the use of generative AI. In particular, elaborate on how your agency has established adequate safeguards and oversight mechanisms that allow generative AI to be used in the agency without posing undue risk."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_23",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nSBA Office of the CIO Page 11 of 173. Generative AI Identify whether your agency has developed (or is in the process of developing) internal guidance for the use of generative AI. In particular, elaborate on how your agency has established adequate safeguards and oversight mechanisms that allow generative AI to be used in the agency without posing undue risk. On February 27, 2024, SBA ’s Chief Information Security Officer issued the following guidance for the use of AI and posted it on an internal website as Information Notice 9000-852330, entitled, “ Temporary Ban on Publicly Available Generative Artificial Intelligence Tools ” • “SBA recognizes the potential benefits of using public generative artificial intelligence (AI) tools (ex. ChatGPT) to improve efficiency and productivity within the agency by rapidly generating viable text, reports, analytics, media, audio, program code, and business strategies."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_24",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nposted it on an internal website as Information Notice 9000-852330, entitled, “ Temporary Ban on Publicly Available Generative Artificial Intelligence Tools ” • “SBA recognizes the potential benefits of using public generative artificial intelligence (AI) tools (ex. ChatGPT) to improve efficiency and productivity within the agency by rapidly generating viable text, reports, analytics, media, audio, program code, and business strategies. However, these capabilities present significant risks to SBA such as data breaches and unauthorized disclosure or exposure of government information.” • “All SBA personnel must refrain from using these capabilities for official and sensitive government business as it violates Executive Order 13960 “Promoting the Use of Trustworthy Artificial Intelligence in the Federal Government” and Executive Order 14110 “Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence.” Until SBA can provide an approved and safe association to generative AI tools, network access to applicable AI tools will be blocked.” SBA Office of the CIO Page 12 of 174. AI Talent Describe any planned or in- progress initiatives from your agency to increase AI talent. In particular, reference any hiring authorities that your agency is leveraging, describe any AI - focused teams that your agency is establishing or expanding, and identif y the skillsets or skill- levels that your agency is looking to attract."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_25",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nCIO Page 12 of 174. AI Talent Describe any planned or in- progress initiatives from your agency to increase AI talent. In particular, reference any hiring authorities that your agency is leveraging, describe any AI - focused teams that your agency is establishing or expanding, and identif y the skillsets or skill- levels that your agency is looking to attract. If your agency has designated an AI Talent Lead, identify which office they are assigned to. SBA is focused on recruiting talent that can contribute to our goal of operationalizing trustworthy AI across SBA using the following strategies: • SBA has created an AI workforce working group, with representatives from across the agency led by the Chief Huma n Capital Officer and the Chief of Enterprise HC Initiatives . They, along with the Chief Learning Officer are developing a comprehensive AI workforce hiring and training strategy, and is actively investing in recruiting AI and AI-enabling talent, including by doing the following: • Designating an AI Talent Lead from the Office of Human Resources Solutions ( OHRS) to serve on OPM’s AI talent interagency working group and to be accountable for reporting to agency leadership and tracking AI hiring."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_26",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\na comprehensive AI workforce hiring and training strategy, and is actively investing in recruiting AI and AI-enabling talent, including by doing the following: • Designating an AI Talent Lead from the Office of Human Resources Solutions ( OHRS) to serve on OPM’s AI talent interagency working group and to be accountable for reporting to agency leadership and tracking AI hiring. • Seeking candidates via the White House Presidential Innovation Fellowship, White House Presidential Management Fellowship, United States Digital Corps, Technical Career Field Programs, Science and Technology Policy Fellowships with the American Association for the Advance of Science, pooled hiring actions and Tech to Gov career fairs. • Utilizing Direct Hire Authority when appropriate for the following approved AI -related occupations, series , and parentheticals. • Exploring additional hiring authorities including Schedule A authority when appropriate. • Using various incentives including other recruitment, relocation, and retention incentives. • Sending staff to the Partnership for Public Service ’s AI Federal Leadership Program SBA Office of the CIO Page 13 of 17If applicable, describe your agency’s plans to provide any resources or training to develop AI talent internally and increase AI training opportunities for Federal employees."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_27",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nwhen appropriate. • Using various incentives including other recruitment, relocation, and retention incentives. • Sending staff to the Partnership for Public Service ’s AI Federal Leadership Program SBA Office of the CIO Page 13 of 17If applicable, describe your agency’s plans to provide any resources or training to develop AI talent internally and increase AI training opportunities for Federal employees. In particular, reference any role-based AI training tracks that your agency is in terested in, or actively working to develop (e.g., focusing on leadership, acquisition workforce, hiring teams, software engineers, administrative personnel, or others). • SBA’s CSOD learning platform known as the Talent Management Center (TMC) has thousands of active AI related content types such as benchmarks, audio books, online books, labs, videos, and courses. Most content is available through SBA’s Skillsoft Percipio content library, and available to all employees for their professional development. • We also share AI training and education opportunities from other federal agencies, such as GAO’s Centers for Excellence training series with tracks in Acquisition, Leadership & Policy, and AI Technologies. • The SBA AI Community of Practice (AICOP) is an online community of practice designed to share AI information, news, and training; encourage collaboration; and provide a platform for inquiry for AI practitioners and those interested in AI."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_28",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nfrom other federal agencies, such as GAO’s Centers for Excellence training series with tracks in Acquisition, Leadership & Policy, and AI Technologies. • The SBA AI Community of Practice (AICOP) is an online community of practice designed to share AI information, news, and training; encourage collaboration; and provide a platform for inquiry for AI practitioners and those interested in AI. • Senior s taff have attended the Partnership for Public Service AI Federal Leadership Program 5. AI Sharing and Collaboration Describe your agency’s process for ensuring that custom -developed AI code— including models and model weights — for AI applications in active use is shared consistent with Section 4(d) of M-24-10. Elaborate on your agency’s efforts to encourage or incentivize the sharing of code, models, and data with the public. Include a description of the relevant offices that are responsible for coordinating this work. SBA’s AI inventory and review process will point AI use case owners to both SBA’s Open Data Initiative process and to resources for open-sourcing their software code, in the event their project is suitable for open-sourcing. The in-house AI inventory also includes tethering model cards and data sheets on its development roadmap which will increase the transparency and reusability of models internally and foster the internal developer ecosystem."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_29",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nAI use case owners to both SBA’s Open Data Initiative process and to resources for open-sourcing their software code, in the event their project is suitable for open-sourcing. The in-house AI inventory also includes tethering model cards and data sheets on its development roadmap which will increase the transparency and reusability of models internally and foster the internal developer ecosystem. SBA has had several prominent open-source projects for many years following the SBA Open - Source guidelines at https://github.com/USSBA/open -source from the Office of the Chief Information Officer. SBA Office of the CIO Page 14 of 17SBA’s Responsible AI Official (RAIO) manages the agency’s AI portal that houses the on-going inventory. SBA also has other mechanisms for sharing data with approved parties, such as the SBA Data Commons which provides researchers access to relevant de- identified SBA data for medical research purposes. 6. Harmonization of Artificial Intelligence Requirements Explain any steps your agency has taken to document and share best practices regarding AI governance, innovation, or risk management. Identify how these resources are shared and maintained across the agency. SBA documents and shares best practices on AI via a variety of platform s. These include: • Centralized web resources: o SBA has created a centralized intranet page for AI -related information."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_30",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nyour agency has taken to document and share best practices regarding AI governance, innovation, or risk management. Identify how these resources are shared and maintained across the agency. SBA documents and shares best practices on AI via a variety of platform s. These include: • Centralized web resources: o SBA has created a centralized intranet page for AI -related information. This page includes a description of SBA ’s AI program, an overview of our governance process, Federal policies, agency guidance, and points of contact . o SBA ’s Use Case Submission Form is available to every employee and contractor to submit a U se Case, and all Use Cases submitted are viewable to everyone in the agency. • SBA communicates employee- focused AI training to agency wide as described in the training section of this document. • SBA and its partners provide training and presentations focused on small business use of AI. These trainings, which take place on -line are tool -specific and often convey information regarding risks of each type of AI technology. • In September 2024, SBA launched a virtual AI Community of Practice . This e- mail distribution list is currently used to announce AI training and development opportunities for SBA staff. In FY25, SBA will update its communication plan to leverage this resource more . SBA Office of the CIO Page 15 of 17III. MANAGING RISKS FROM THE USE OF ARTIFICIAL INTELLIGENCE 1."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_31",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\n2024, SBA launched a virtual AI Community of Practice . This e- mail distribution list is currently used to announce AI training and development opportunities for SBA staff. In FY25, SBA will update its communication plan to leverage this resource more . SBA Office of the CIO Page 15 of 17III. MANAGING RISKS FROM THE USE OF ARTIFICIAL INTELLIGENCE 1. Determining Which Artificial Intelligence Is Presumed to Be Safety - Impacting or Rights -Impacting Explain the process by which your agency determines which AI use cases are rights - impacting or safety-impacting. In particular, describe how your agency is reviewing or planning to review each current and planned use of AI to assess whether it matches the definition of safety -impacting AI or rights -impacting AI, as defined in Section 6 of M-24-10. Identify whether your agency has created additional criteria for when an AI use is safety-impacting or rights -impacting and describe such supplementary criteria . SBA has adopted the OMB definitions of safety-impacting and rights- impacting A I and plans to elaborate upon these definitions in an “AI Questions and Considerations” document that will be presented to SBA AI Governance Council. This document will serve as the primary reference to for making safety-impacting and rights-impacting decisions for AI at SBA ."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_32",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nsuch supplementary criteria . SBA has adopted the OMB definitions of safety-impacting and rights- impacting A I and plans to elaborate upon these definitions in an “AI Questions and Considerations” document that will be presented to SBA AI Governance Council. This document will serve as the primary reference to for making safety-impacting and rights-impacting decisions for AI at SBA . If your agency has developed its own distinct criteria to guide a decision to waive one or more of the minimum risk management practices for a particular use case, describe the criteria . SBA has not yet developed these criteria Our plan for FY25 is to bring subject matter experts from the Office Diversity Inclusion & Civil Rights, Office of Human Resources Solutions (Employee Relations / Labor Divisions) and Enterprise Risk Management to participate in our review process to ensure that nothing we develop at SBA (including AI) impacts the safety or rights of our staff or the public. Describe your agency’s process for issuing, denying, revoking, tracking, and certifying waivers for one or more of the minimum risk management practices. SBA has not developed a waiver process . SBA Office of the CIO Page 16 of 172. Implementation of Risk Management Practices and Termination of Non-Compliant AI Elaborate on the controls your agency has put in place to prevent non- compliant safety - impacting or rights -impacting AI from being deployed to the public."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_33",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nof the minimum risk management practices. SBA has not developed a waiver process . SBA Office of the CIO Page 16 of 172. Implementation of Risk Management Practices and Termination of Non-Compliant AI Elaborate on the controls your agency has put in place to prevent non- compliant safety - impacting or rights -impacting AI from being deployed to the public. Describe your agency’s intended process to terminate, and effectuate that termination of, any non -compliant AI. Currently, all the AI Use Cases under review within SBA are internally focused to provide operational efficiency to individual SBA Program Offices. Nothing is being a deployed to the public. For internally focused technology, we rely primarily on network surveillance by our cybersecurity teams . For n on-compliant technology, our process is to immediately remove it from the network, notify applicable management, and counsel the developer as appropriate. 3. Minimum Risk Management Practices Identify how your agency plans to document and validate implementation of the minimum risk management practices. In addition, discuss how your agency assigns responsibility for the implementation and oversight of these requirements. The AI Governance Council is responsible for the implementation and oversight of requirements for rights -impacting and safety -impacting AI. AI Use Case owners are responsible for implementing requirements within their own projects, with guidance from the AIGC as needed."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_34",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\nminimum risk management practices. In addition, discuss how your agency assigns responsibility for the implementation and oversight of these requirements. The AI Governance Council is responsible for the implementation and oversight of requirements for rights -impacting and safety -impacting AI. AI Use Case owners are responsible for implementing requirements within their own projects, with guidance from the AIGC as needed. SBA is developing internal guidance on risk management for rights- impacting and safety - impacting AI . This guidance will incorporate OMB M-24-10 requirements and risk management guidance. A brief outline of the planned process is below: • To provide oversight and ensure compliance, AI Use Case owners will be required to seek approval from the AI Governance Council before implementing any potentially rights- impacting or safety -impacting AI Use Cases. • AI Use Case o wners will be required to implement the risk management practices mandated by the SBA’s policy before and after approval. • AI Use Case owners will then document and certify their compliance with the minimum risk management practices annually through the AI Use Case Inventory process. • If the AIGC determines that an AI Use Case is non -compliant, the AI Use Case owner must terminate the AI Use Case and to restart the AI Use Case, the owner of that use case must develop a compliance plan ."
  },
  {
    "id": "Final_508-Compliant_SBA_M-24-10_Implementation_Plan_for_AI_-_September_2024_chunk_35",
    "text": "Source: 16 Final 508-Compliant SBA M-24-10 Implementation Plan for AI - September 2024.pdf\n\ncertify their compliance with the minimum risk management practices annually through the AI Use Case Inventory process. • If the AIGC determines that an AI Use Case is non -compliant, the AI Use Case owner must terminate the AI Use Case and to restart the AI Use Case, the owner of that use case must develop a compliance plan . • Additionally, SBA will require AI Use Case owners to submit updates on their compliance when a significant change occurs to the AI or the context in which the AI operates, including independent reviews and evaluation by the AI Governance Council. SBA O ffice of the CIO Page 17 of 17www.sba.gov"
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_0",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\n1 U.S. Department of the Interior Compliance Plan for OMB Memoranda M -24-10 September 2024 Prepared by Joan M. Mooney Chief Artiﬁcial Intelligence Oﬃcer 2 Table of Contents 1. Strengthening AI Governance ............................................................................................................... 3 1.1 General ................................................................................................................................................ 3 1.2 AI Governance Bodies ......................................................................................................................... 3 1.3 AI Use Case Inventories ....................................................................................................................... 4 1.4 Reporting on AI Use Cases Not Subject to Inventory .......................................................................... 4 2. Advancing Responsible AI Innovation ................................................................................................... 5 2.1 Removing Barriers to the Responsible Use of AI ................................................................................. 5 2.2 AI Talent .............................................................................................................................................. 6 2.3 AI Sharing and Collaboration .............................................................................................................."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_1",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\n............................................................................................................... 3 1.1 General ................................................................................................................................................ 3 1.2 AI Governance Bodies ......................................................................................................................... 3 1.3 AI Use Case Inventories ....................................................................................................................... 4 1.4 Reporting on AI Use Cases Not Subject to Inventory .......................................................................... 4 2. Advancing Responsible AI Innovation ................................................................................................... 5 2.1 Removing Barriers to the Responsible Use of AI ................................................................................. 5 2.2 AI Talent .............................................................................................................................................. 6 2.3 AI Sharing and Collaboration .............................................................................................................. 7 2.4 Harmonization of AI Requirements ..................................................................................................... 8 3."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_2",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nBodies ......................................................................................................................... 3 1.3 AI Use Case Inventories ....................................................................................................................... 4 1.4 Reporting on AI Use Cases Not Subject to Inventory .......................................................................... 4 2. Advancing Responsible AI Innovation ................................................................................................... 5 2.1 Removing Barriers to the Responsible Use of AI ................................................................................. 5 2.2 AI Talent .............................................................................................................................................. 6 2.3 AI Sharing and Collaboration .............................................................................................................. 7 2.4 Harmonization of AI Requirements ..................................................................................................... 8 3. Managing Risks From the Use of AI ....................................................................................................... 9 3.1 Determining Which AI Is Presumed to Be Safety -Impacting or Rights -Impacting .............................. 9 3.2 Implementation of Risk Management Practices and Termination of Non -Compliant AI .................."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_3",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nAI ................................................................................. 5 2.2 AI Talent .............................................................................................................................................. 6 2.3 AI Sharing and Collaboration .............................................................................................................. 7 2.4 Harmonization of AI Requirements ..................................................................................................... 8 3. Managing Risks From the Use of AI ....................................................................................................... 9 3.1 Determining Which AI Is Presumed to Be Safety -Impacting or Rights -Impacting .............................. 9 3.2 Implementation of Risk Management Practices and Termination of Non -Compliant AI .................. 10 3.3 Minimum Risk Management Practices ............................................................................................. 10 3 1. Strengthening AI Governance 1.1 General The Department of the Interior (The Department; Interior; or DOI) is committed to establishing an open, innovative approach to expanding the safe, secure, and responsible use of A rtiﬁcial Intelligence (AI) , consistent with the principles laid out in EO 14110 on Safe, Secure, and Trustworthy Development and Use of Artiﬁcial Intelligence and with OMB Memorandum M- 24- 10."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_4",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nGeneral The Department of the Interior (The Department; Interior; or DOI) is committed to establishing an open, innovative approach to expanding the safe, secure, and responsible use of A rtiﬁcial Intelligence (AI) , consistent with the principles laid out in EO 14110 on Safe, Secure, and Trustworthy Development and Use of Artiﬁcial Intelligence and with OMB Memorandum M- 24- 10. The Department previously provided guidelines on Risk Managed Use of Generative AI (August 2023) ; these guidelines will remain in eﬀect as the Department reﬁnes additional guidance in alignment with M- 24-10. The Department does not have existing policies or guidelines regarding the use of other forms of AI, including machine and deep learning applications. To date , Interior does not have any safety or rights impacting use cases . As the Department’s AI maturity continues to develop, Interior , through the leadership of the Chief Artiﬁcial Intelligence Oﬃcer (CAIO), will consistently review guidelines, policy, and principles and update as needed to ensure the application of AI tools enhance our mission and se rve the American people. 1.2 AI Governance Bodies The Department of the Interior’s Management Initiatives Team (MIT) Executive Council serves as the Department ’s AI Governance Board . The Board is chaired by the Deputy Secretary (Acting) and Vice -Chaired by the CAIO ."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_5",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nand update as needed to ensure the application of AI tools enhance our mission and se rve the American people. 1.2 AI Governance Bodies The Department of the Interior’s Management Initiatives Team (MIT) Executive Council serves as the Department ’s AI Governance Board . The Board is chaired by the Deputy Secretary (Acting) and Vice -Chaired by the CAIO . Oﬃces represented on the Board include: Solicitor ; Assistant Secretary – Fish, Wildlife and Park s; Assistant Secretary – Water and Science; Assistant Secretary – Indian Aﬀairs; Assistant Secretary – Land and Minerals Management; Assistant Secretary – Policy, Management and Budget; Oﬃce of the Chief Information Oﬃcer (including the C hief Information Oﬃcer ( CIO) / Privacy Oﬃcial and Chief Data Oﬃcer) , and Oﬃce of Diversity, Inclusion and Civil Rights . The AI Governance Board will carry out Interior’s regulatory responsibilities related to AI including how to incorporate transparency with partners; integrate Indigenous Knowledge into systems and models; the importance of accurate, relevant data – and the public’s perception of the accuracy of that data – to inform decision -making; and how to support the Department’s workforce and our partners . At the initial meeting in May 2024, t he Governance Board agreed to remain coordinated on implementation activities and create an approach that ensures appropriate structure is in place to govern AI while encouraging innovation ."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_6",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\npublic’s perception of the accuracy of that data – to inform decision -making; and how to support the Department’s workforce and our partners . At the initial meeting in May 2024, t he Governance Board agreed to remain coordinated on implementation activities and create an approach that ensures appropriate structure is in place to govern AI while encouraging innovation . The Department will look to partner with the federal family , academia, and Congress on best practices and sharing knowledge. In addition to the AI Governance Board, the MIT has chartered a sub -group representing Interior’s Bureaus and relevant operations portfolios, including science, information management and technology, human capital, budget, public safety and emergency management, the Oﬃce of Diversity, Inclusion and Civil Rights, and the Solicitor. The sub -group will guide the development of AI policies , establish best practices , consult external experts as 4 needed, and serve as a venue to exchange information to enable coordination of research, development, and deployment of use cases. The Department is committed to taking an open and transparent approach to accelerating the responsible use of AI by consulting with external experts and stakeholders , as appropriate, to enhance the development and use of AI tools."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_7",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nexperts as 4 needed, and serve as a venue to exchange information to enable coordination of research, development, and deployment of use cases. The Department is committed to taking an open and transparent approach to accelerating the responsible use of AI by consulting with external experts and stakeholders , as appropriate, to enhance the development and use of AI tools. DOI will continue to work with research partners across the government and in academic institutions to develop AI -enabled tools that enhance Interior’s science and research mission areas . Additionally , the Department is actively collaborating with other Federal agencies to develop tools to increase eﬃciencies in processes, including ongoing initiatives to enhance processing of public comments, environmental assessments, and reduce burdens in grant reporting. 1.3 AI Use Case Inventories Interior has launched an AI use case collection and intake process to allow all employees to submit potential uses of AI . The application is integrat ed with the review and approval processes: the AI use case system will track AI use cases through the entirety of the AI lifecycle, from conception to production to retirement. To ensure the Department’s AI inventory is comprehensive, accurate , complete and encompasses updates to existing use cases, th e AI use case inventory will be veriﬁed against additional knowledge maintained by the Oﬃce of the Chief Information Oﬃcer (OCIO) and the Chief Data Oﬃcer ."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_8",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\ncases through the entirety of the AI lifecycle, from conception to production to retirement. To ensure the Department’s AI inventory is comprehensive, accurate , complete and encompasses updates to existing use cases, th e AI use case inventory will be veriﬁed against additional knowledge maintained by the Oﬃce of the Chief Information Oﬃcer (OCIO) and the Chief Data Oﬃcer . Bureau and Oﬃce Directors will be held accountable for the accuracy and completeness of the AI Inventory. Any discovered or reported use of covered AI by the Department that is not included in the AI Inventory will be stopped until all necessary reviews and approvals have been completed. 1.4 Reporting on AI Use Cases Not Subject to Inventory The Department anticipates limited use cases will meet the exclusion criteria based upon current mission objectives. However, t he AI use case intake process will be the same for use cases that may be excluded from being individually inventoried . If, in consultation with the AI Governance Board, the CAIO determines that a use case meets the requirements for exclusion , the information will not be reported on the public DOI use case inventory. The Department will still have record and tracking of these exceptions and will perform periodic audits to ensure that the designations are still valid . The CAIO and AI G overnance Board will review new use cases on a routine basis."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_9",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nmeets the requirements for exclusion , the information will not be reported on the public DOI use case inventory. The Department will still have record and tracking of these exceptions and will perform periodic audits to ensure that the designations are still valid . The CAIO and AI G overnance Board will review new use cases on a routine basis. If any use case potentially meets the criteria for exclusions from the public inventory , additional information will be collected from the requestor and the Board will determine if the criteria are met and if the use case should be excluded. The CAIO will review the inventory of existing use cases at least annually to demine if those already reviewed should be brought to the AI Board ’s attention for further consideration. 5 2. Advancing Responsible AI Innovation 2.1 Removing Barriers to the Responsible Use of AI To adopt respon sible AI, the Department must utilize data of documented quality and ensure equitable access to tools and data. Findable, Accessible, Interoperable, and R eusable (FAIR) Data Interior will continue to implement the Department’s Data Strategy expressed as Goal 5 in the Department’s Information Management and Technology Strategic Plan, 202 4-2029, to “create a data -centric ecosystem that allows the DOI workforce, people, community, organizations, and the public appropriate access to data on our land, water, cultural, and natural resources."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_10",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nAccessible, Interoperable, and R eusable (FAIR) Data Interior will continue to implement the Department’s Data Strategy expressed as Goal 5 in the Department’s Information Management and Technology Strategic Plan, 202 4-2029, to “create a data -centric ecosystem that allows the DOI workforce, people, community, organizations, and the public appropriate access to data on our land, water, cultural, and natural resources. ” The Data Strategy highlights that “ establish ing Findable, Accessible, Interoperable, and Reusable (FAIR) and OPEN data as a strategic asset for DOI will enable reliable and traceable AI solutions .” The Data Strategy also calls on DOI to “strengthen data protection and support evidence -based decisions through data analytics, artiﬁcial intelligence, and data science to increase transparency, improve government operations, and build public trust.” Achieving this goal will provide a foundati on of high- quality data that can be used for development, training, and use of AI tools by Interior and external partners. DOI will continue to align resources to improving the management and stewardship of priority data assets necessary to inform evidence -based decisions. Equitable Access A critical challenge in Interior’s adoption of AI is overcoming barriers such as access to high - performance computing and network bandwidth for remote users to have responsive access to AI tools and the underlying data."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_11",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nDOI will continue to align resources to improving the management and stewardship of priority data assets necessary to inform evidence -based decisions. Equitable Access A critical challenge in Interior’s adoption of AI is overcoming barriers such as access to high - performance computing and network bandwidth for remote users to have responsive access to AI tools and the underlying data. The Department is mitigating the bandwidth challenges through its Zero Trust architecture program - remote oﬃces and ﬁeld stations can increase their bandwidth securely at lower costs through commodity internet . The Department is also exploring partner ships with federal agencies such as the National Science Foundation, the Department of Energ y and the National Oceanic and Atmospheric Administration (NOAA) to access their existing high performance co mputing infrastructures . As Interior expands adoption of AI -enabled tools, the Department will continue to remove barriers to ensur e necessary IT infrastructure, reliable data, and training is available . This will be accomplished by working together across Bureaus and Oﬃces to identify eﬃciencies, share knowledge, leverage existing tools , support training, and provide access to AI resources which meet the dynamic needs and expectations of the federal community in a rapidly evolving market."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_12",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nto remove barriers to ensur e necessary IT infrastructure, reliable data, and training is available . This will be accomplished by working together across Bureaus and Oﬃces to identify eﬃciencies, share knowledge, leverage existing tools , support training, and provide access to AI resources which meet the dynamic needs and expectations of the federal community in a rapidly evolving market. Interior is securely making both open source and commercial AI resources available to everyone across the Department through oﬀering open and equitable access to AI tools and training . In doing so, DOI is advanc ing and promoti ng opportunities for all employees to beneﬁt from the use of AI. The CAIO , in partnership with the Oﬃce of Human Capital and DOI’s expanding evidence and science communities , will continue to promote and develop a culture of learning . 6 Access to tools Interior provides multiple avenues for staﬀ to securely access open source and commercial oﬀ - the-shelf software and the computing resources necessary to safely harness the power of AI. DOI has test and development environments on the major commercial cloud platforms for staﬀ to experiment with AI technology . In addition, the U.S. Geological Survey (USGS) maintains a high -performance computing environment and a team of AI practitioners who assist USGS scientis ts in using the environment."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_13",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nand the computing resources necessary to safely harness the power of AI. DOI has test and development environments on the major commercial cloud platforms for staﬀ to experiment with AI technology . In addition, the U.S. Geological Survey (USGS) maintains a high -performance computing environment and a team of AI practitioners who assist USGS scientis ts in using the environment. The OCIO is safely deploy ing Fedramp approved Generative AI in internal applications in collaboration with mission partners . In addition, the CIO’s oﬃce is establishing a hands -on Generative AI training program to share knowledge and build capacity across the Department. These applications , and the code that supports them , are subjected to the same enterprise privacy, security , and monitoring as other applications in DOI’s enterprise cloud environment. Data and access controls to these applications , when applicable, leverage Interior ’s existing access and identity systems. In August 2024, the OCIO issued guidelines on Risk Managed Use of Generative AI for the Department , which set forth how to use generative AI tools in the workplace safely and securely. Interior is currently developing internal reference guides for the use of generative AI to expand the reﬁne this initial guidance. The reference guides will allow Bureaus and Oﬃces ﬂexibility to experiment and innovate new AI applications while continuing to leverage existing enterprise role-based security and privacy practices."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_14",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nforth how to use generative AI tools in the workplace safely and securely. Interior is currently developing internal reference guides for the use of generative AI to expand the reﬁne this initial guidance. The reference guides will allow Bureaus and Oﬃces ﬂexibility to experiment and innovate new AI applications while continuing to leverage existing enterprise role-based security and privacy practices. As Interior’s AI maturity increases, additional guidelines or policies may be developed. Additionally, some components of Interior may choose to provide additional guidance regarding the use of generative AI such as in external communications, scientiﬁc integrity , and human resources. The Department has also provided access to “DOI ChatGPT” a pre -trained commercial large language model that provides the necessary security and controls to protect DOI data from traveling over the public internet and is not retained or used to train commer cial AI products. 2.2 AI Talent A diverse AI -ready workforce – through both training of current employees and the hiring of an AI-enabling workforce – is essential for the long -term implementation of AI across Interior. On March 15, 2024, the Department of Interior issued Personnel Bulletin 24 -02, authorizing the use of the Direct Hiring Authority and Schedule A hiring authority for positions with major duties and responsibilities supporting the integration of AI."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_15",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nof current employees and the hiring of an AI-enabling workforce – is essential for the long -term implementation of AI across Interior. On March 15, 2024, the Department of Interior issued Personnel Bulletin 24 -02, authorizing the use of the Direct Hiring Authority and Schedule A hiring authority for positions with major duties and responsibilities supporting the integration of AI. The includes positions in the occupations of Information Technology Specialist, Computer Scientist, Computer Engineer, and Management and Program Analyst. The diﬀerent Bureaus and Oﬃces of the Department are currently implementing diﬀerent recruitment strategies for the development of AI programs. There are plans to recruit AI position s in upcoming hiring events “Back to Business Career Fair hosted by the VA”, “Military Spouse Cyber Workforce Virtual Hiring Fair”, and “Historically Black College and Universities (HBCU) Week Career Fair and Hiring Event”. 7 The Department launched the “DOI ChatGPT ” program to keep developing the DOI workforce into one that is “AI -ready .” Showing support for the use of AI spurs greater interest from the Interior workforce in the development of AI tools , and more employees are interested in AI - related positions. Additionally, the Department will implement comprehensive skill development and other training programs aimed at equipping employees with the expertise and knowledge needed to leverage AI ethically and eﬀectively."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_16",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\n.” Showing support for the use of AI spurs greater interest from the Interior workforce in the development of AI tools , and more employees are interested in AI - related positions. Additionally, the Department will implement comprehensive skill development and other training programs aimed at equipping employees with the expertise and knowledge needed to leverage AI ethically and eﬀectively. Training will support employees in developing an AI competency that includes knowledge of available tools, understanding the role of quality data, responsible use of AI, and mitigation for anticipated risks associated with AI tools, including bias. To date, the Department has made over 500 AI focused training s available to the workforce to assist in building skills related to the future needs of the Department. Interior , through DOI University, has developed an AI Framework for upskilling the workforce . The ﬁrst Foundational level courses were rolled out in July 2024 and included participants from both DOI and other Federal agencies. This training supports employees in developing an AI competency that includes knowledge of available tools, understanding the role of quality data, responsible use of AI, and mitigation for anticipated risks associated with AI tools, including bias. Additional courses will be added i n Fiscal Year 20 25 (FY25) that continue to build on more advanced AI topics , allowing diﬀerent kinds of AI users the ability to adapt to this rapidly evolving issue area."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_17",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\ntools, understanding the role of quality data, responsible use of AI, and mitigation for anticipated risks associated with AI tools, including bias. Additional courses will be added i n Fiscal Year 20 25 (FY25) that continue to build on more advanced AI topics , allowing diﬀerent kinds of AI users the ability to adapt to this rapidly evolving issue area. Information about external AI training resources is also promoted to employees, such as those oﬀered by the Oﬃce of Personnel Management (OPM) and the S enior Executive Service (SES) AI Leadership Program sponsored by the Partnership for Public Service. The Department will also continue to support employee -driven knowledge sharing through communities of practice, providing venues for sharing and discussion, and providing access to information on the Department’s use of AI. To date, there have been eﬀorts through the Interior Training Directors Council (ITDC) to build awareness around the topic and the importance for the training community to be actively involved in leading workforce upskilling. The Department also has an active group of over 630 individuals who come together through MS Teams to share information about AI trainings, safety, machine learning and data analysis, and Gen erative AI prompts and use cases."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_18",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nCouncil (ITDC) to build awareness around the topic and the importance for the training community to be actively involved in leading workforce upskilling. The Department also has an active group of over 630 individuals who come together through MS Teams to share information about AI trainings, safety, machine learning and data analysis, and Gen erative AI prompts and use cases. In FY25, the Department will look to leverage the expertise of this growing AI community to host regular learning events such as brown bag sessions to share expertise more broadly across the Department’s workforce. 2.3 AI Sharing and Collaboration The Department continues to support transparency and collaboration and serve s as a leader in the sharing of open data and open code, inclusive of code used to develop government funded AI. Open data used to train AI models and applications will be shared through the Department’s Enterprise Data Inventory and be made available and accessible to the public. The Department’s CDO and CIO will continue eﬀorts to incentivize the publication and documentation of open data and open code through the respective governance boards and 8 reiterate existing policies related to open data and open code with regards to AI. The CDO and CIO, in messaging the value of open data and open code, will continue to highlight the beneﬁts to enabling mission outcomes , including opportunities to increase mission eﬃ ciency and eﬀectiveness, and improving transparency."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_19",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nopen code through the respective governance boards and 8 reiterate existing policies related to open data and open code with regards to AI. The CDO and CIO, in messaging the value of open data and open code, will continue to highlight the beneﬁts to enabling mission outcomes , including opportunities to increase mission eﬃ ciency and eﬀectiveness, and improving transparency. Additionally, The Department also remains committed to the philosophy and practice of Open Science through the leadership of USGS Director and Science Advisors. A key component of open scie nce is making sure the scientiﬁc results are valid and reproducible , enabled by sharing the underlying methods, data and code. The DOI GitHub Enterprise Community (DGEC) provides a central environment where DOI developers , technologists, and data scientists can develop , interact with contributors and collaborators , and safely store, share , and access software code and projects. The DGEC environment fosters a ‘ community ﬁrst ’ philosophy by focusing on mission enablement (e.g., cost avoidance, increased velocity, quality, and risk management) through exceptional customer service values. This platform will be used to document and share code used in the development and deployment of AI across the Department. DOI is also plannin g to launch an internal Department -wide AI seminar series highlighting innovate applications of AI aligned to key mission objectives."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_20",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nenablement (e.g., cost avoidance, increased velocity, quality, and risk management) through exceptional customer service values. This platform will be used to document and share code used in the development and deployment of AI across the Department. DOI is also plannin g to launch an internal Department -wide AI seminar series highlighting innovate applications of AI aligned to key mission objectives. These seminars will provide opportunities for employees to show case positive examples of the responsible uses of AI across mission areas while educating the workforce on new and exciting possibilities for applying AI. Through this series, Interior hopes to incentivize knowledge sharing and best practices by lifting up and acknowledging the innovative AI use cases happening across the entirety of the organization. 2.4 Harmonization of AI Requirements Interior’s AI Governance Board , MIT, and AI Sub -Group includes representatives from across the Department to ensure consistency and foster sharing and collaboration in development of Department -wide policies and guidelines. The CAIO will collaborate with other executive leaders to leverage their statutory and executive authorities to the extent possible to manage risk associated with AI. Existing management bodies and governance boards for components impacted by AI will work with the AI Sub -group to review and make recommendations to update existing policies to account for any gaps or additional policies that are needed ."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_21",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nwith other executive leaders to leverage their statutory and executive authorities to the extent possible to manage risk associated with AI. Existing management bodies and governance boards for components impacted by AI will work with the AI Sub -group to review and make recommendations to update existing policies to account for any gaps or additional policies that are needed . For example, the CIO will ensure that CIO authorities and existing Departmental policies with regards to cybersecurity, privacy, IT procurement, records management, and IT management apply to AI use cases. The Department has also established an internal employee resource webpage to provide centralized access to policies, guidelines, tools, and training opportunities that are available. A “Frequently Asked Questions” section (in development) will include additional information regarding AI, including on governance and risk management practices. The webpage also provides links to the Department’s AI use case inventory and is an opportunity to “spotlight” use cases across DOI. The website provides links to join Interior’s AI Community of Practice and an email address for employees to submit questions or suggestions to the Department’s AI 9 team, which includes staﬀ from the Oﬃce of the Chief Information Oﬃcer ; Policy, Management, and Budget; and the Oﬃce of Communications. 3."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_22",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nand is an opportunity to “spotlight” use cases across DOI. The website provides links to join Interior’s AI Community of Practice and an email address for employees to submit questions or suggestions to the Department’s AI 9 team, which includes staﬀ from the Oﬃce of the Chief Information Oﬃcer ; Policy, Management, and Budget; and the Oﬃce of Communications. 3. Managing Risks From the Use of AI Understanding how, where and when AI may potentially impact our employees and the American public’s safety and liberties is foundational for managing and mitigating the risks associated with potential AI usage across the Department. To date, Interior has not implemented any AI use case that are considered rights or safety impacting. The Department is committed to have the proper safeguards in place to evaluate its AI use cases and existing applications of AI to mitigate risks to safety and rights impacting AI moving forward. 3.1 Determining Which AI Is Presumed to Be Safety -Impacting or Rights -Impacting Each potential AI use case, based on information gathered through the Department’s use case intake process, is reviewed with the core values and principles of safety, and protecting civil rights and civil liberties in mind."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_23",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nAI to mitigate risks to safety and rights impacting AI moving forward. 3.1 Determining Which AI Is Presumed to Be Safety -Impacting or Rights -Impacting Each potential AI use case, based on information gathered through the Department’s use case intake process, is reviewed with the core values and principles of safety, and protecting civil rights and civil liberties in mind. Currently, a small group of subject matter experts – including the Chief Data Oﬃcer and attorneys from the Solicitor’s Oﬃce – review use cases consistent with the deﬁnitions of “safety -impacting AI” or “rights -impacting AI” as deﬁned in Section 6 of Executive Order 14110 . As the Department’s AI maturity increases, and more use cases are developed and implemented, Interior will implement a more systematic approach to review use cases : AI uses cases will be tracked via the intake system and regularly reviewed for changes to the risk proﬁle. If DO I identiﬁes a use case as potentially being safety or rights impacting AI, the CAIO or the MIT AI sub -group will collect suﬃcient information to determine if the use case ﬁts the deﬁnitions in Section 6. For any use -case that ﬁts deﬁnitions in Section 6, the CAIO , in consultation with the AI Governance Board , will determine if the use case should proceed or should be terminated."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_24",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nrights impacting AI, the CAIO or the MIT AI sub -group will collect suﬃcient information to determine if the use case ﬁts the deﬁnitions in Section 6. For any use -case that ﬁts deﬁnitions in Section 6, the CAIO , in consultation with the AI Governance Board , will determine if the use case should proceed or should be terminated. For those safety or rights impacting use cases that are approved to proceed , the Department will require at least the minimum risk management practices prescribed in M -24-10 Section 5 (C) iv . The CAIO and AI Governance Board will review Federal requirements and standards for AI , including those set by other Federal agencies, to guide risk identiﬁcation, analysis , and required risk management actions. In addition, in conjunction with the Department’s enterprise ris k management (ERM) activities, consultations with relevant community members to ensure safety and rights -related risks are identiﬁed, documented, and incorporated into the review process for AI use cases. The AI Subgroup, in coordination with the E nterprise Risk Management team, will establish protocols for assess the likelihood a proposed use case will be safety and/or rights impacting. The AI Governance Board will routinely review the status of the AI use cases from the inventory and, if necessary, require additional information on any use case to determine potential risk prior to approving the use case for production."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_25",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nnterprise Risk Management team, will establish protocols for assess the likelihood a proposed use case will be safety and/or rights impacting. The AI Governance Board will routinely review the status of the AI use cases from the inventory and, if necessary, require additional information on any use case to determine potential risk prior to approving the use case for production. 10 3.2 Implementation of Risk Management Practices and Termination of Non -Compliant AI The AI use case inventory will be regularly reviewed, with ongoing assessment and monitoring for use cases that meet the criteria for being safety and/or rights impacting. In ensuring the completeness of the use case inventory through monitoring of additional knowledge bases , the OCIO and Chief Data Oﬃcer will identify use cases in production that have not been reviewed via the intake process and/or have been deemed non-compliant. The Department will establish low tolerance for failure to comply with mandated risk management practices . Within programs, leaders will be accountable for ensuring AI uses meet minimum established requirements and risk management practices, if necessary. Non - compliance will result in immediate suspension of the aﬀected activity and immediate deployment of corrective action plans. Departmental policies will be established addressing violations ."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_26",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nestablish low tolerance for failure to comply with mandated risk management practices . Within programs, leaders will be accountable for ensuring AI uses meet minimum established requirements and risk management practices, if necessary. Non - compliance will result in immediate suspension of the aﬀected activity and immediate deployment of corrective action plans. Departmental policies will be established addressing violations . An additional mechanism for ensuring that non-compliant AI is not utilized by the Department is through robust communication and training available to all employees . The CAIO, in coordination with the AI Governance Board, will identify key messages and training needs related to AI as a tool, AI risks, complying with AI policies, and potential consequences to the public, the Government, the Department, and personally. These key messages and trainings will be shared with employees through existing internal communications channels, including the AI employee resource website, AI community of practices, and learning sessions. 3.3 Minimum Risk Management Practices No later than December 1, 2024, the Department will issue guidance that all safety and or rights impacting AI must adhere to the risk management practices required in M -24-10 Section 5. The guidance or other management controls will also describe the Department’s plans to document and validate the implementation of these minimum risk management practices ."
  },
  {
    "id": "Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final_chunk_27",
    "text": "Source: 17 Interior_www_doi_gov_sites_default_files_documents_2024-09_2024-doi-ai-compliance-plan-final.pdf\n\nRisk Management Practices No later than December 1, 2024, the Department will issue guidance that all safety and or rights impacting AI must adhere to the risk management practices required in M -24-10 Section 5. The guidance or other management controls will also describe the Department’s plans to document and validate the implementation of these minimum risk management practices . Additionally, AI risk has been identiﬁed as a mandatory element in the Department’s approach to Enterprise Risk Management (ERM) program, and – as such – will be integrated into Interior’s risk register. AI risk will be managed through established protocols and at all appropriate levels within the Department and periodically reviewed by a senior level risk management council. The risk management council will ensure accountability, across all levels of the Department, in ensuring risks related to AI are known, quantiﬁed, reduced to acceptable levels, and prio ritized in decision -making."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_0",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\nCompliance Plan for OMB Memorandum M-24-10 October 2024 1 Table of Contents 1. STRENGTHENING AI GOVERNANCE ......................................................... 2 GENERAL ................................................................................................................. 2 AI GOVERNANCE BODIES ........................................................................................ 3 AI USE CASE INVENTORIES ...................................................................................... 5 REPORTING ON AI USE CASES NOT SUBJECT TO INVENTORY .................................. 5 2. ADVANCING RESPONSIBLE AI INNOVATION ......................................... 6 REMOVING BARRIERS TO THE RESPONSIBLE USE OF AI ........................................... 6 AI TALENT ............................................................................................................... 6 AI SHARING AND COLLABORATION ......................................................................... 7 HARMONIZATION OF AI REQUIREMENTS .................................................................. 8 3. MANAGING RISKS FROM THE USE OF AI ................................................ 8 DETERMINING WHICH AI IS PRESUMED TO BE SAFETY -IMPACTING OR RIGHTS - IMPACTING ..............................................................................................................."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_1",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\nINVENTORY .................................. 5 2. ADVANCING RESPONSIBLE AI INNOVATION ......................................... 6 REMOVING BARRIERS TO THE RESPONSIBLE USE OF AI ........................................... 6 AI TALENT ............................................................................................................... 6 AI SHARING AND COLLABORATION ......................................................................... 7 HARMONIZATION OF AI REQUIREMENTS .................................................................. 8 3. MANAGING RISKS FROM THE USE OF AI ................................................ 8 DETERMINING WHICH AI IS PRESUMED TO BE SAFETY -IMPACTING OR RIGHTS - IMPACTING ............................................................................................................... 8 IMPLEMENTATION OF RISK MANAGEMENT PRACTICES AND TERMINATION OF NON- COMPLIANT AI ......................................................................................................... 9 MINIMUM RISK MANAGEMENT PRACTICES ............................................................10 2 1. Strengthening AI Governance General • The U.S. Department of Justice (DOJ or Department ) uses AI to advance its mission of upholding the rule of law, keeping our country safe, and protecting civil rights."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_2",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\nOR RIGHTS - IMPACTING ............................................................................................................... 8 IMPLEMENTATION OF RISK MANAGEMENT PRACTICES AND TERMINATION OF NON- COMPLIANT AI ......................................................................................................... 9 MINIMUM RISK MANAGEMENT PRACTICES ............................................................10 2 1. Strengthening AI Governance General • The U.S. Department of Justice (DOJ or Department ) uses AI to advance its mission of upholding the rule of law, keeping our country safe, and protecting civil rights. • The Attorney General has designated a Chief AI Officer (CAIO) with primary responsibility for coordinating DOJ’s use of AI, efforts to promote AI innovation, and management of risks from the use of AI, consistent with EO 14110 and M -24-10. The CAIO coordinates with components across DOJ and reports to the Deputy Attorney General. • In addition, the Deputy Attorney General has established an Emerging Technology Board (ETB), which serves as DOJ’s AI Governance Board under EO 14110 and M-24-10. • The CAIO and ETB are subject to the overall Department governance structure, including 28 U.S.C. § 509 and 28 C.F.R. § 0.15(a), including as to CAIO and ETB determinations set forth below. • The U.S."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_3",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\naddition, the Deputy Attorney General has established an Emerging Technology Board (ETB), which serves as DOJ’s AI Governance Board under EO 14110 and M-24-10. • The CAIO and ETB are subject to the overall Department governance structure, including 28 U.S.C. § 509 and 28 C.F.R. § 0.15(a), including as to CAIO and ETB determinations set forth below. • The U.S. Department of Justice is establishing rigorous D epartment -wide processes for AI governance and risk management under its Chief AI Officer (CAIO) and Emerging Technology Board (ETB), which serves as DOJ’s AI governance body under M -24-10, subject to the overall Department governance structure. • DOJ’s AI governance and risk management processes begin with identifying uses of AI — existing , new, and planned—across the Department. Components will report AI use cases, and DOJ will also review procurement, privacy governance, and IT governance records to ensure comprehensiveness. The responses below provide additional detail about how DOJ will comprehensively inventory AI use cases. • For rights - and safety -impacting AI use cases that are subject to heightened procedures under M-24- 10, DOJ is standing up a new AI Impact Assessment process. This process, modeled on DOJ’s longstanding privacy compliance process , will be coordinated by the Department’s Office of Privacy and Civil Liberties in collaboration with the ETB and CAIO."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_4",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\nuse cases. • For rights - and safety -impacting AI use cases that are subject to heightened procedures under M-24- 10, DOJ is standing up a new AI Impact Assessment process. This process, modeled on DOJ’s longstanding privacy compliance process , will be coordinated by the Department’s Office of Privacy and Civil Liberties in collaboration with the ETB and CAIO. • DOJ is also launching a new program of quantitatively evaluating rights - and safety -impacting uses of AI in real -world settings. • In addition to establishing overall AI governance processes, DOJ is examining possible policies for particular rights - and safety -impacting uses of AI. The Department issued an interim policy on Facial Recognition Technology (FRT) in December 2023, and the Department is working toward a final FRT policy that incorporates M -24-10 guidance and other developments since issuance of the interim policy. 3 • DOJ is updating its existing Initial Privacy Assessment, Privacy Impact Assessment, and Authorization to Operate processes to integrate with the new D epartment -wide AI governance processes. AI Governance Bodies • The ETB is chaired by the CAIO or by the Deputy Attorney General , when in attendance."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_5",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\nguidance and other developments since issuance of the interim policy. 3 • DOJ is updating its existing Initial Privacy Assessment, Privacy Impact Assessment, and Authorization to Operate processes to integrate with the new D epartment -wide AI governance processes. AI Governance Bodies • The ETB is chaired by the CAIO or by the Deputy Attorney General , when in attendance. • The following components of DOJ are represented on the ETB : o Antitrust Division o Bureau of Alcohol, Tobacco, Firearms, and Explosives o Bureau of Prisons o Civil Division o Civil Rights Division o Criminal Division o Drug Enforcement Administration o Environment and Natural Resources Division o Executive Office for Organized Crime Drug Enforcement Task Forces o Executive Office for United States Attorneys o Federal Bureau of Investigation o Justice Management Division , which includes the Office of the Chief Information Officer and Cybersecurity Services Staff o National Institute of Justice o National Security Division o Office for Access to Justice o Office of Justice Programs o Office of Legal Policy o Office of the Pardon Attorney o Office of Privacy and Civil Liberties o U.S."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_6",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\nof Investigation o Justice Management Division , which includes the Office of the Chief Information Officer and Cybersecurity Services Staff o National Institute of Justice o National Security Division o Office for Access to Justice o Office of Justice Programs o Office of Legal Policy o Office of the Pardon Attorney o Office of Privacy and Civil Liberties o U.S. Marshals Service • In addition, the following components regularly participate in ETB meetings: o Office of the Attorney General o Office of the Deputy Attorney General o Office of the Associate Attorney General o Office of Legislative Affairs o Office of Public Affairs • The ETB is a leadership forum that develops policy, implements governance, and coordinates activities related to AI and other emerging technologies that have the potential to significantly affect the Department’s mission. • The Board has the following goals: 4 o Advance the Department’s mission of upholding the rule of law, keeping our country safe, and protecting civil rights by enabling the strategic use of AI and other emerging technologies. o Support the Department’s interpretation and application of legal authorities to AI and other emerging technologies. o Ensure that the Department’s use of AI and other emerging technologies is consistent with our values , our mission , and the law. o Coordinate the development and implementation of policies related to executive branch guidance on emerging technologies, including artificial intelligence."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_7",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\ntechnologies. o Support the Department’s interpretation and application of legal authorities to AI and other emerging technologies. o Ensure that the Department’s use of AI and other emerging technologies is consistent with our values , our mission , and the law. o Coordinate the development and implementation of policies related to executive branch guidance on emerging technologies, including artificial intelligence. o Provide leader ship, across and outside government, at the intersection of emerging technologies and law. • The Board works to achieve these goals in the following ways : o Acting as a leadership forum within the Department on emerging technology matters. o Providing subject -matter expertise on emerging technology and related legal and policy issues. o Coordinating emerging technology activities across components and with other agencies. o Promoting knowledge sharing and other interaction across components related to emerging technology. o Implementing governance processes for Department uses of emerging technology. o Providing regular updates to Department leadership on emerging technology matters. • Board members are the principal liaisons between components of the Department and the ETB."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_8",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\no Coordinating emerging technology activities across components and with other agencies. o Promoting knowledge sharing and other interaction across components related to emerging technology. o Implementing governance processes for Department uses of emerging technology. o Providing regular updates to Department leadership on emerging technology matters. • Board members are the principal liaisons between components of the Department and the ETB. Board members are responsible for keeping components apprised of ETB activities and representing components in all aspects of the Board’s activities, including parti cipating in meetings, participating in and designating representatives for working groups, preparing materials, and voting on matters. • Working groups of the ETB focus on particular aspects of emerging technology. • The Deputy Attorney General launched a 2024 roundtable series, Justice AI, to engage with external stakeholders on a broad range of AI topics, including civil rights, privacy, consumer protection, corporate compliance, cybersecurity, child sexual abuse mat erial, and nonconsensual intimate imagery. • The Civil Rights Division has launched regular convenings on AI with F ederal, state, local, and T ribal civil rights agencies. • The Antitrust Division is consulting on competition aspects of AI with other competition enforcers, federal agencies, market participants , and the public ."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_9",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\nconsumer protection, corporate compliance, cybersecurity, child sexual abuse mat erial, and nonconsensual intimate imagery. • The Civil Rights Division has launched regular convenings on AI with F ederal, state, local, and T ribal civil rights agencies. • The Antitrust Division is consulting on competition aspects of AI with other competition enforcers, federal agencies, market participants , and the public . 5 • In addition, DOJ leadership and staff have ongoing engagement on AI issues with civil society groups, academic researchers, firms developing and using AI, and other F ederal agencies . • Going forward, the Department will stand up a process for consistent engagement with external perspectives on the Department’s use of AI. This engagement will take the form of institutionalized recurring events with external stakeholders, building on the J ustice AI series, with the goal of informing departmental policies and practices. This process will gather feedback on the Department’s overall approach to AI governance and risk management, as well as particular types of AI use cases (such as FRT). AI Use Case Inventories • The ETB is designing and implementing a process for comprehensive D epartment -wide data collection."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_10",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\nustice AI series, with the goal of informing departmental policies and practices. This process will gather feedback on the Department’s overall approach to AI governance and risk management, as well as particular types of AI use cases (such as FRT). AI Use Case Inventories • The ETB is designing and implementing a process for comprehensive D epartment -wide data collection. • The 2024 inventory process involves the following steps to obtain data about AI use cases from components: o Developing a uniform template and instructions for components to report AI use cases, based on M -24-10, OMB inventory guidance, and the Department’s experience with prior inventories. o Issuing a leadership memorandum to component heads describing the inventory process and requirements. o Meeting with component representatives in focus groups to explain and answer questions about the inventory. o Integrating component responses into an AI governance database. o Reviewing components ’ responses through working groups , ETB, and CAIO, for completeness and consistency. • In addition, the ETB will review purchasing, IT governance, and privacy governance records to ensure completeness. Reporting on AI Use Cases Not Subject to Inventory • When reporting AI use cases, DOJ components will be required to report all AI use cases, except specifically enumerated cases identified by the ETB and the CAIO."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_11",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\nand CAIO, for completeness and consistency. • In addition, the ETB will review purchasing, IT governance, and privacy governance records to ensure completeness. Reporting on AI Use Cases Not Subject to Inventory • When reporting AI use cases, DOJ components will be required to report all AI use cases, except specifically enumerated cases identified by the ETB and the CAIO. • The ETB and CAIO will set and apply uniform criteria for when AI use cases are not subject to individual inventory. The CAIO will certify that every use case omitted from the inventory meets these criteria. 6 • The inventory inclusion criteria will follow M -24-10 and OMB instructions, will include specific examples, and will be published alongside the inventory. • In addition to annual inventory data collection, using the process described above, DOJ is integrating AI governance into existing IT and privacy governance processes. When an AI use materially changes, or the operational context for an AI use materially changes, the Department will reevaluate its inclusion or exclusion from the inventory using the same criteria and process. 2. Advancing Responsible AI Innovation Removing Barriers to the Responsible Use of AI • The Department is committed to ensuring the responsible use of AI and other emerging technologies. An important component of meeting this goal is ensuring sufficient resources and personnel."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_12",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\nchanges, the Department will reevaluate its inclusion or exclusion from the inventory using the same criteria and process. 2. Advancing Responsible AI Innovation Removing Barriers to the Responsible Use of AI • The Department is committed to ensuring the responsible use of AI and other emerging technologies. An important component of meeting this goal is ensuring sufficient resources and personnel. The Department is committed to seeking resources and workforce authorities necessary to carry out this goal. • The Department is working towards piloting new uses of AI in support of its mission as well as ideation competitions to explore possible new responsible uses of AI. • The Cybersecurity Services Staff within the Office of the C hief Information O fficer is nearing issuance of D epartment -wide guidance on cybersecurity aspects of generative AI, complementing the Department’s existing cybersecurity requirements. This guidance will include transparency, human review, and other controls to address the risk of inaccurate output. • The AI Impact Assessment review process, described above, will also involve use -specific requirements to mitigate risks of generative AI uses. AI Talent • The Department has established a new team of technologists and other professionals engaged in technology- focused work, which is led by the Chief Science and Technology Advisor / CAIO within the Office of Legal Policy ."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_13",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\nThe AI Impact Assessment review process, described above, will also involve use -specific requirements to mitigate risks of generative AI uses. AI Talent • The Department has established a new team of technologists and other professionals engaged in technology- focused work, which is led by the Chief Science and Technology Advisor / CAIO within the Office of Legal Policy . This team advises Department and component leadership, as well as collaborates and coordinates across the Department and with federal partners , on AI, cyber, and other technology issues . • This team is pursuing a comprehensive initiative to level up the Department’s cyber and AI workforce. This initiative includes seeking new hiring authorities, streamlining existing 7 authorities, comprehensively mapping technical capacity within DOJ, and cultivating new resources. • The Department’s ability to build out an AI workforce is limited by resource constraints and current hiring authorities . Addressing these interrelated resource and personnel constraints is a priority for the Department. • Department components continue to build out their expertise on AI. For example, t he Civil Rights Division recently appointed its first Chief Technologist to address AI-related bias and discrimination issues, and the Antitrust Division is building new data science capacity with support from the Technology Modernization Fund."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_14",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\nthese interrelated resource and personnel constraints is a priority for the Department. • Department components continue to build out their expertise on AI. For example, t he Civil Rights Division recently appointed its first Chief Technologist to address AI-related bias and discrimination issues, and the Antitrust Division is building new data science capacity with support from the Technology Modernization Fund. • The ETB is curating and developing materials about AI for the Department’s litigating and law enforcement components. • In addition, the Department’s AI Community of Interest (AI CoI ), under OCIO, facilitates AI training and knowledge exchange for DOJ personnel. The AI CoI maintains an AI Knowledge Hub and hosts both AI learning groups and bi -monthly meetings to share resources. These resources include internal DOJ courses, events, and guidance, as well as opportunities through the OMB/GSA Community of Practice, other agencies, and other non-federal organizations. • Numerous components have also established resource and training initiatives to support workforce engagement with AI, including the Federal Bureau of Investigation ( FBI), the Drug Enforcement Administration ( DEA) , the Criminal Division , and the Executive Office for U.S. Attorneys. AI Sharing and Collaboration • The majority of systems involving AI that are in use at DOJ are commercial products and services."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_15",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\nalso established resource and training initiatives to support workforce engagement with AI, including the Federal Bureau of Investigation ( FBI), the Drug Enforcement Administration ( DEA) , the Criminal Division , and the Executive Office for U.S. Attorneys. AI Sharing and Collaboration • The majority of systems involving AI that are in use at DOJ are commercial products and services. The Department accordingly generally does not have access to code, models, model weights, or data for these systems . The ETB will consider how to gain greater access through procurement, consistent with M-24-10 and OMB guidance on AI procurement. • For the small number of systems involving AI where the Department does possess these types of information, as part of the 2024 inventory process described above, the Department will seek opportunities to share code, models, and data with the public. • In addition, the Department has existing efforts to implement the OPEN Government Data Act, OMB Memorandum M-16-21, and other requirements for sharing code and data. DOJ will apply these existing initiatives to systems that involve AI and data that is used by AI. • The CAIO is responsible for coordinating implementation of M -24-10, including AI sharing and collaboration. The CIO , as the designated Chief Data Officer, is responsible for IT and 8 data governance, and the Data Governance Board under OCIO coordinates policy and strategy for the Department’s data assets ."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_16",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\nthat involve AI and data that is used by AI. • The CAIO is responsible for coordinating implementation of M -24-10, including AI sharing and collaboration. The CIO , as the designated Chief Data Officer, is responsible for IT and 8 data governance, and the Data Governance Board under OCIO coordinates policy and strategy for the Department’s data assets . Harmonization of AI Requirements • The CAIO, ETB, working groups, and OPCL are collaborating on comprehensive documentation for the Department’s AI governance and risk management processes. This documentation will be, to the greatest extent possible, made available to the public at https://www.justice.gov/ai. In addition to providing transparency about DOJ’s policies, we intend to provide resources to other organizations that reflect best practices for governance of rights- or safety -impacting AI uses. 3. Managing Risks from the Use of AI Determining Which AI Is Presumed to Be Safety -Impacting or Rights- Impacting • The Department will determine whether an AI use case is rights - or safety -impacting through the following steps, which are designed to ensure D epartment -wide consistency and comprehensive implementation of M-24-10: o When a component reports a new or changed AI use, it will provide its perspective on whether the use has rights or safety impact. o The ETB will review these submissions and consult with the component."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_17",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\nrights - or safety -impacting through the following steps, which are designed to ensure D epartment -wide consistency and comprehensive implementation of M-24-10: o When a component reports a new or changed AI use, it will provide its perspective on whether the use has rights or safety impact. o The ETB will review these submissions and consult with the component. o Next, the ETB will review AI use case categorizations, prioritizing assessment of use cases that present new questions about the category definitions and presumptions in M - 24-10. o Based on component submissions and ETB advice, the CAIO will make determinations about AI use case categorization. • The Department will iteratively develop guidance on the appropriate categorization of AI use cases. DOJ does not presently have supplemental criteria for categorization under M-24-10. • The Department will categorize the use cases described in Appendix I of M -24-10 as rights - or safety -impacting, absent unusual facts about a particular use case that significantly reduce risks in comparison to a typical instance of that type of use case. • The Department will publicly share its guidance on use case categorization to the greatest extent possible. 9 • The Department has not developed distinct criteria for waiving the minimum practices in M - 24-10. Should that ever change, the Department will document the additional criteria and publicly share them."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_18",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\nto a typical instance of that type of use case. • The Department will publicly share its guidance on use case categorization to the greatest extent possible. 9 • The Department has not developed distinct criteria for waiving the minimum practices in M - 24-10. Should that ever change, the Department will document the additional criteria and publicly share them. • Our objective is to fully implement the minimum practices and make minimal use of the waiver process under M-24-10. • The Department aims to complete implementation of impact assessments for prioritized rights- or safety -impacting use cases in 2024 and all rights- or safety -impacting use cases in 2025. The Department also aim s to complete pilot quantitative testing for select use cases in 2024 and implement quantitative testing for all rights- or safety -impacting use cases in 2025. The Department anticipate s using the extension process in M-24- 10 to meet these timeline s. • The DOJ AI use case inventory includes tracking for implementation of the minimum risk management practices in M -24-10. • Waiver determinations will be made in a similar process to categorization determinations . • Consistent with section 5.c.iii of M -24-10, the CAIO will make determinations on issuing, denying, and revoking waivers and will certify waivers to OMB. The CAIO will document the rationale for each decision and will issue guidance when a decision presents a significant new technical, legal, or policy issue."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_19",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\nbe made in a similar process to categorization determinations . • Consistent with section 5.c.iii of M -24-10, the CAIO will make determinations on issuing, denying, and revoking waivers and will certify waivers to OMB. The CAIO will document the rationale for each decision and will issue guidance when a decision presents a significant new technical, legal, or policy issue. • The CAIO will document waiver status in the Department’s AI governance database and will publicly report waiver status and guidance to the greatest extent possible. Implementation of Risk Management Practices and Termination of Non- Compliant AI • The Department has existing processes for ensuring that new and materially changed technology capabilities comply with governance requirements, including cybersecurity and privacy evaluation s, prior to deployment. The Department is adding AI -specific steps into these processes to identify new and changed uses of AI, and to ensure proper assessment and compliance prior to deployment. • The Department will track AI use cases through the inventory process, as described above. • If a rights - or safety -impacting AI use does not incorporate minimum risk management practices as provided in M -24-10, and it is not covered by a waiver, the Department will take the following steps consistent with sections 3 and 5 of M-24-10: o If the AI has not been deployed yet, the CAIO will direct suspension of deployment."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_20",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\nIf a rights - or safety -impacting AI use does not incorporate minimum risk management practices as provided in M -24-10, and it is not covered by a waiver, the Department will take the following steps consistent with sections 3 and 5 of M-24-10: o If the AI has not been deployed yet, the CAIO will direct suspension of deployment. o If the AI has been deployed, the CAIO will direct termination of the non- compliant AI . • DOJ has existing processes for effectuating the suspension of a pending technology use or termination of a deployed technology when it is non- compliant with privacy or IT governance. 10 The CAIO will use these existing processes to address any possible instances of non- compliance with AI governance. Minimum Risk Management Practices • Components are responsible for implementing the minimum requirements for rights - and safety -impacting AI and documenting the implementation via the inventory and impact assessment processes. • Consistent with sections 3 and 5 of M -24-10, the CAIO is responsible for determining whether an AI use complies with minimum requirements and whether to permit or direct the suspension or termination of an AI use. • The ETB and OPCL have additional validation and oversight responsibility for implementation of the minimum risk management practices. • Components are developing complementary processes to document, validate, and provide oversight for implementation of risk management practices."
  },
  {
    "id": "DOJ_M-24-10_Compliance_Plan_-_Final_20241009_chunk_21",
    "text": "Source: 18 DOJ M-24-10 Compliance Plan - Final (2024.10.09).pdf\n\ndetermining whether an AI use complies with minimum requirements and whether to permit or direct the suspension or termination of an AI use. • The ETB and OPCL have additional validation and oversight responsibility for implementation of the minimum risk management practices. • Components are developing complementary processes to document, validate, and provide oversight for implementation of risk management practices. For example, FBI has established an AI Ethics Council, and DEA has established an Emerging Technology Board. These component initiatives provide additional resources for implementing and validating risk management practices. Consistent with M -24-10, component AI governance initiatives inform but do not displace D epartment -wide AI governance. • The Department will publicly share its processes for minimum practice oversight and governance, as well as documentation for how the minimum practices have been implemented for particular AI uses, to the greatest extent possible."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_0",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n1 Artificial Intelligence and Criminal Justice Final Report December 3, 2024 2 Table of Contents Foreword ....................................................................................................................................................... 3 I. Introduction ........................................................................................................................................... 4 Background ................................................................................................................................... 5 The Use of AI in the Criminal Justice System .............................................................................. 9 II. Identification & Surveillance .............................................................................................................. 12 Introduction ................................................................................................................................. 12 Biometrics ................................................................................................................................... 13 Focusing on FRT for Identification in Law Enforcement Investigations .................................... 17 Automated License Plate Recognition ........................................................................................ 26 III."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_1",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nFinal Report December 3, 2024 2 Table of Contents Foreword ....................................................................................................................................................... 3 I. Introduction ........................................................................................................................................... 4 Background ................................................................................................................................... 5 The Use of AI in the Criminal Justice System .............................................................................. 9 II. Identification & Surveillance .............................................................................................................. 12 Introduction ................................................................................................................................. 12 Biometrics ................................................................................................................................... 13 Focusing on FRT for Identification in Law Enforcement Investigations .................................... 17 Automated License Plate Recognition ........................................................................................ 26 III. Forensic Analysis ................................................................................................................................"
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_2",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n3, 2024 2 Table of Contents Foreword ....................................................................................................................................................... 3 I. Introduction ........................................................................................................................................... 4 Background ................................................................................................................................... 5 The Use of AI in the Criminal Justice System .............................................................................. 9 II. Identification & Surveillance .............................................................................................................. 12 Introduction ................................................................................................................................. 12 Biometrics ................................................................................................................................... 13 Focusing on FRT for Identification in Law Enforcement Investigations .................................... 17 Automated License Plate Recognition ........................................................................................ 26 III. Forensic Analysis ................................................................................................................................ 29 Introduction ................................................................................................................................."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_3",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nTable of Contents Foreword ....................................................................................................................................................... 3 I. Introduction ........................................................................................................................................... 4 Background ................................................................................................................................... 5 The Use of AI in the Criminal Justice System .............................................................................. 9 II. Identification & Surveillance .............................................................................................................. 12 Introduction ................................................................................................................................. 12 Biometrics ................................................................................................................................... 13 Focusing on FRT for Identification in Law Enforcement Investigations .................................... 17 Automated License Plate Recognition ........................................................................................ 26 III. Forensic Analysis ................................................................................................................................ 29 Introduction ................................................................................................................................. 29 Current Uses of AI in Forensic Analysis ....................................................................................."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_4",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n4 Background ................................................................................................................................... 5 The Use of AI in the Criminal Justice System .............................................................................. 9 II. Identification & Surveillance .............................................................................................................. 12 Introduction ................................................................................................................................. 12 Biometrics ................................................................................................................................... 13 Focusing on FRT for Identification in Law Enforcement Investigations .................................... 17 Automated License Plate Recognition ........................................................................................ 26 III. Forensic Analysis ................................................................................................................................ 29 Introduction ................................................................................................................................. 29 Current Uses of AI in Forensic Analysis ..................................................................................... 31 Future Uses of AI in Forensic Analysis ......................................................................................"
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_5",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nthe Criminal Justice System .............................................................................. 9 II. Identification & Surveillance .............................................................................................................. 12 Introduction ................................................................................................................................. 12 Biometrics ................................................................................................................................... 13 Focusing on FRT for Identification in Law Enforcement Investigations .................................... 17 Automated License Plate Recognition ........................................................................................ 26 III. Forensic Analysis ................................................................................................................................ 29 Introduction ................................................................................................................................. 29 Current Uses of AI in Forensic Analysis ..................................................................................... 31 Future Uses of AI in Forensic Analysis ...................................................................................... 33 Challenges for AI in Forensic Analysis ......................................................................................"
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_6",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n& Surveillance .............................................................................................................. 12 Introduction ................................................................................................................................. 12 Biometrics ................................................................................................................................... 13 Focusing on FRT for Identification in Law Enforcement Investigations .................................... 17 Automated License Plate Recognition ........................................................................................ 26 III. Forensic Analysis ................................................................................................................................ 29 Introduction ................................................................................................................................. 29 Current Uses of AI in Forensic Analysis ..................................................................................... 31 Future Uses of AI in Forensic Analysis ...................................................................................... 33 Challenges for AI in Forensic Analysis ...................................................................................... 36 Recommendations ....................................................................................................................... 40 IV."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_7",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n................................................................................................................................. 12 Biometrics ................................................................................................................................... 13 Focusing on FRT for Identification in Law Enforcement Investigations .................................... 17 Automated License Plate Recognition ........................................................................................ 26 III. Forensic Analysis ................................................................................................................................ 29 Introduction ................................................................................................................................. 29 Current Uses of AI in Forensic Analysis ..................................................................................... 31 Future Uses of AI in Forensic Analysis ...................................................................................... 33 Challenges for AI in Forensic Analysis ...................................................................................... 36 Recommendations ....................................................................................................................... 40 IV. Predictive Policing .............................................................................................................................."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_8",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n................................................................................................................................... 13 Focusing on FRT for Identification in Law Enforcement Investigations .................................... 17 Automated License Plate Recognition ........................................................................................ 26 III. Forensic Analysis ................................................................................................................................ 29 Introduction ................................................................................................................................. 29 Current Uses of AI in Forensic Analysis ..................................................................................... 31 Future Uses of AI in Forensic Analysis ...................................................................................... 33 Challenges for AI in Forensic Analysis ...................................................................................... 36 Recommendations ....................................................................................................................... 40 IV. Predictive Policing .............................................................................................................................. 42 Introduction ................................................................................................................................."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_9",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\non FRT for Identification in Law Enforcement Investigations .................................... 17 Automated License Plate Recognition ........................................................................................ 26 III. Forensic Analysis ................................................................................................................................ 29 Introduction ................................................................................................................................. 29 Current Uses of AI in Forensic Analysis ..................................................................................... 31 Future Uses of AI in Forensic Analysis ...................................................................................... 33 Challenges for AI in Forensic Analysis ...................................................................................... 36 Recommendations ....................................................................................................................... 40 IV. Predictive Policing .............................................................................................................................. 42 Introduction ................................................................................................................................. 42 Uses of Predictive Policing ........................................................................................................."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_10",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nEnforcement Investigations .................................... 17 Automated License Plate Recognition ........................................................................................ 26 III. Forensic Analysis ................................................................................................................................ 29 Introduction ................................................................................................................................. 29 Current Uses of AI in Forensic Analysis ..................................................................................... 31 Future Uses of AI in Forensic Analysis ...................................................................................... 33 Challenges for AI in Forensic Analysis ...................................................................................... 36 Recommendations ....................................................................................................................... 40 IV. Predictive Policing .............................................................................................................................. 42 Introduction ................................................................................................................................. 42 Uses of Predictive Policing ......................................................................................................... 43 Risks of Predictive Policing ........................................................................................................"
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_11",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nPlate Recognition ........................................................................................ 26 III. Forensic Analysis ................................................................................................................................ 29 Introduction ................................................................................................................................. 29 Current Uses of AI in Forensic Analysis ..................................................................................... 31 Future Uses of AI in Forensic Analysis ...................................................................................... 33 Challenges for AI in Forensic Analysis ...................................................................................... 36 Recommendations ....................................................................................................................... 40 IV. Predictive Policing .............................................................................................................................. 42 Introduction ................................................................................................................................. 42 Uses of Predictive Policing ......................................................................................................... 43 Risks of Predictive Policing ........................................................................................................ 46 Recommendations ......................................................................................................................."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_12",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n26 III. Forensic Analysis ................................................................................................................................ 29 Introduction ................................................................................................................................. 29 Current Uses of AI in Forensic Analysis ..................................................................................... 31 Future Uses of AI in Forensic Analysis ...................................................................................... 33 Challenges for AI in Forensic Analysis ...................................................................................... 36 Recommendations ....................................................................................................................... 40 IV. Predictive Policing .............................................................................................................................. 42 Introduction ................................................................................................................................. 42 Uses of Predictive Policing ......................................................................................................... 43 Risks of Predictive Policing ........................................................................................................ 46 Recommendations ....................................................................................................................... 49 V."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_13",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nForensic Analysis ................................................................................................................................ 29 Introduction ................................................................................................................................. 29 Current Uses of AI in Forensic Analysis ..................................................................................... 31 Future Uses of AI in Forensic Analysis ...................................................................................... 33 Challenges for AI in Forensic Analysis ...................................................................................... 36 Recommendations ....................................................................................................................... 40 IV. Predictive Policing .............................................................................................................................. 42 Introduction ................................................................................................................................. 42 Uses of Predictive Policing ......................................................................................................... 43 Risks of Predictive Policing ........................................................................................................ 46 Recommendations ....................................................................................................................... 49 V. Risk Assessment ................................................................................................................................."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_14",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n29 Introduction ................................................................................................................................. 29 Current Uses of AI in Forensic Analysis ..................................................................................... 31 Future Uses of AI in Forensic Analysis ...................................................................................... 33 Challenges for AI in Forensic Analysis ...................................................................................... 36 Recommendations ....................................................................................................................... 40 IV. Predictive Policing .............................................................................................................................. 42 Introduction ................................................................................................................................. 42 Uses of Predictive Policing ......................................................................................................... 43 Risks of Predictive Policing ........................................................................................................ 46 Recommendations ....................................................................................................................... 49 V. Risk Assessment ................................................................................................................................. 54 Uses of Risk Assessment ............................................................................................................."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_15",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nof AI in Forensic Analysis ..................................................................................... 31 Future Uses of AI in Forensic Analysis ...................................................................................... 33 Challenges for AI in Forensic Analysis ...................................................................................... 36 Recommendations ....................................................................................................................... 40 IV. Predictive Policing .............................................................................................................................. 42 Introduction ................................................................................................................................. 42 Uses of Predictive Policing ......................................................................................................... 43 Risks of Predictive Policing ........................................................................................................ 46 Recommendations ....................................................................................................................... 49 V. Risk Assessment ................................................................................................................................. 54 Uses of Risk Assessment ............................................................................................................. 55 Risk Assessment Design ............................................................................................................."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_16",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n..................................................................................... 31 Future Uses of AI in Forensic Analysis ...................................................................................... 33 Challenges for AI in Forensic Analysis ...................................................................................... 36 Recommendations ....................................................................................................................... 40 IV. Predictive Policing .............................................................................................................................. 42 Introduction ................................................................................................................................. 42 Uses of Predictive Policing ......................................................................................................... 43 Risks of Predictive Policing ........................................................................................................ 46 Recommendations ....................................................................................................................... 49 V. Risk Assessment ................................................................................................................................. 54 Uses of Risk Assessment ............................................................................................................. 55 Risk Assessment Design ............................................................................................................. 58 Potential Benefits for a More Effective, Equitable, and Efficient Criminal Justice System ......."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_17",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nin Forensic Analysis ...................................................................................... 36 Recommendations ....................................................................................................................... 40 IV. Predictive Policing .............................................................................................................................. 42 Introduction ................................................................................................................................. 42 Uses of Predictive Policing ......................................................................................................... 43 Risks of Predictive Policing ........................................................................................................ 46 Recommendations ....................................................................................................................... 49 V. Risk Assessment ................................................................................................................................. 54 Uses of Risk Assessment ............................................................................................................. 55 Risk Assessment Design ............................................................................................................. 58 Potential Benefits for a More Effective, Equitable, and Efficient Criminal Justice System ....... 60 The Risks of Risk Assessment ...................................................................................................."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_18",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n40 IV. Predictive Policing .............................................................................................................................. 42 Introduction ................................................................................................................................. 42 Uses of Predictive Policing ......................................................................................................... 43 Risks of Predictive Policing ........................................................................................................ 46 Recommendations ....................................................................................................................... 49 V. Risk Assessment ................................................................................................................................. 54 Uses of Risk Assessment ............................................................................................................. 55 Risk Assessment Design ............................................................................................................. 58 Potential Benefits for a More Effective, Equitable, and Efficient Criminal Justice System ....... 60 The Risks of Risk Assessment .................................................................................................... 62 Recommendations ......................................................................................................................."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_19",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nPolicing .............................................................................................................................. 42 Introduction ................................................................................................................................. 42 Uses of Predictive Policing ......................................................................................................... 43 Risks of Predictive Policing ........................................................................................................ 46 Recommendations ....................................................................................................................... 49 V. Risk Assessment ................................................................................................................................. 54 Uses of Risk Assessment ............................................................................................................. 55 Risk Assessment Design ............................................................................................................. 58 Potential Benefits for a More Effective, Equitable, and Efficient Criminal Justice System ....... 60 The Risks of Risk Assessment .................................................................................................... 62 Recommendations ....................................................................................................................... 67 VI."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_20",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n42 Introduction ................................................................................................................................. 42 Uses of Predictive Policing ......................................................................................................... 43 Risks of Predictive Policing ........................................................................................................ 46 Recommendations ....................................................................................................................... 49 V. Risk Assessment ................................................................................................................................. 54 Uses of Risk Assessment ............................................................................................................. 55 Risk Assessment Design ............................................................................................................. 58 Potential Benefits for a More Effective, Equitable, and Efficient Criminal Justice System ....... 60 The Risks of Risk Assessment .................................................................................................... 62 Recommendations ....................................................................................................................... 67 VI. Conclusion & Best Practices..............................................................................................................."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_21",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nUses of Predictive Policing ......................................................................................................... 43 Risks of Predictive Policing ........................................................................................................ 46 Recommendations ....................................................................................................................... 49 V. Risk Assessment ................................................................................................................................. 54 Uses of Risk Assessment ............................................................................................................. 55 Risk Assessment Design ............................................................................................................. 58 Potential Benefits for a More Effective, Equitable, and Efficient Criminal Justice System ....... 60 The Risks of Risk Assessment .................................................................................................... 62 Recommendations ....................................................................................................................... 67 VI. Conclusion & Best Practices............................................................................................................... 70 Foundations for AI Governance .................................................................................................."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_22",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nRisks of Predictive Policing ........................................................................................................ 46 Recommendations ....................................................................................................................... 49 V. Risk Assessment ................................................................................................................................. 54 Uses of Risk Assessment ............................................................................................................. 55 Risk Assessment Design ............................................................................................................. 58 Potential Benefits for a More Effective, Equitable, and Efficient Criminal Justice System ....... 60 The Risks of Risk Assessment .................................................................................................... 62 Recommendations ....................................................................................................................... 67 VI. Conclusion & Best Practices............................................................................................................... 70 Foundations for AI Governance .................................................................................................. 71 Pre-Deployment Measures .........................................................................................................."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_23",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n........................................................................................................ 46 Recommendations ....................................................................................................................... 49 V. Risk Assessment ................................................................................................................................. 54 Uses of Risk Assessment ............................................................................................................. 55 Risk Assessment Design ............................................................................................................. 58 Potential Benefits for a More Effective, Equitable, and Efficient Criminal Justice System ....... 60 The Risks of Risk Assessment .................................................................................................... 62 Recommendations ....................................................................................................................... 67 VI. Conclusion & Best Practices............................................................................................................... 70 Foundations for AI Governance .................................................................................................. 71 Pre-Deployment Measures .......................................................................................................... 73 Post-Deployment Measures ........................................................................................................."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_24",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n49 V. Risk Assessment ................................................................................................................................. 54 Uses of Risk Assessment ............................................................................................................. 55 Risk Assessment Design ............................................................................................................. 58 Potential Benefits for a More Effective, Equitable, and Efficient Criminal Justice System ....... 60 The Risks of Risk Assessment .................................................................................................... 62 Recommendations ....................................................................................................................... 67 VI. Conclusion & Best Practices............................................................................................................... 70 Foundations for AI Governance .................................................................................................. 71 Pre-Deployment Measures .......................................................................................................... 73 Post-Deployment Measures ......................................................................................................... 75 Legal Disclaimer ........................................................................................................................................."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_25",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n................................................................................................................................. 54 Uses of Risk Assessment ............................................................................................................. 55 Risk Assessment Design ............................................................................................................. 58 Potential Benefits for a More Effective, Equitable, and Efficient Criminal Justice System ....... 60 The Risks of Risk Assessment .................................................................................................... 62 Recommendations ....................................................................................................................... 67 VI. Conclusion & Best Practices............................................................................................................... 70 Foundations for AI Governance .................................................................................................. 71 Pre-Deployment Measures .......................................................................................................... 73 Post-Deployment Measures ......................................................................................................... 75 Legal Disclaimer ......................................................................................................................................... 77 3 Foreword Dear Mr."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_26",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nAssessment ............................................................................................................. 55 Risk Assessment Design ............................................................................................................. 58 Potential Benefits for a More Effective, Equitable, and Efficient Criminal Justice System ....... 60 The Risks of Risk Assessment .................................................................................................... 62 Recommendations ....................................................................................................................... 67 VI. Conclusion & Best Practices............................................................................................................... 70 Foundations for AI Governance .................................................................................................. 71 Pre-Deployment Measures .......................................................................................................... 73 Post-Deployment Measures ......................................................................................................... 75 Legal Disclaimer ......................................................................................................................................... 77 3 Foreword Dear Mr. President, The Department of Justice (DOJ), in consultation with the Department of Homeland Security (DHS) and the White House Office of Science and Technology Policy (OSTP), submits this report in response to Executive Order 14110, Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence (EO 14110)."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_27",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n73 Post-Deployment Measures ......................................................................................................... 75 Legal Disclaimer ......................................................................................................................................... 77 3 Foreword Dear Mr. President, The Department of Justice (DOJ), in consultation with the Department of Homeland Security (DHS) and the White House Office of Science and Technology Policy (OSTP), submits this report in response to Executive Order 14110, Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence (EO 14110). Pursuant to the requirements set forth in EO 14110, this report satisfies the EO’s directive in Section 7.1(b) that the Attorney General: submit to the President a report that addresses the use of AI in the criminal justice system, including any use in: (A)sentencing; (B)parole, supervised release, and probation; (C)bail, pretrial release, and pretrial detention; (D)risk assessments, including pretrial, earned time, and early release or transfer to home -confinement determinations; (E)police surveillance; (F)crime forecasting and predictive policing, including the ingestion of historical crime data into AI systems to predict high -density “hot spots”; (G)prison- management tools; and (H)forensic analysis."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_28",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nincluding any use in: (A)sentencing; (B)parole, supervised release, and probation; (C)bail, pretrial release, and pretrial detention; (D)risk assessments, including pretrial, earned time, and early release or transfer to home -confinement determinations; (E)police surveillance; (F)crime forecasting and predictive policing, including the ingestion of historical crime data into AI systems to predict high -density “hot spots”; (G)prison- management tools; and (H)forensic analysis. In each o f those areas of the criminal justice system, this report “identif[ies] areas where AI can enhance law enforcement efficiency and accuracy, consistent with protections for privacy, civil rights, and civil liberties” and “recommend[s] best practices for law enforcement agencies, including safeguards and appropriate use limits for AI” and addresses the concerns set forth in both EO 14110 and Executive Order 14074, Advancing Effective, Accountable Policing and Criminal Justice Practices to Enhance Pub lic Trust and Public Safety (EO 14074). In addition, c hapter IV of this report —Predictive Policing —is submitted in fulfillment of Section 13(e) of Executive Order 14074. This report satisfies EO 14074’s directive that “the Attorney General, the Secretary of Homeland Security, and the Director of OSTP . . ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_29",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nAccountable Policing and Criminal Justice Practices to Enhance Pub lic Trust and Public Safety (EO 14074). In addition, c hapter IV of this report —Predictive Policing —is submitted in fulfillment of Section 13(e) of Executive Order 14074. This report satisfies EO 14074’s directive that “the Attorney General, the Secretary of Homeland Security, and the Director of OSTP . . . jointly lead an interagency process regarding the use by [Law Enforcement Agencies] of facial recognition technology, other technologies using biometric information, and predictive algorithms.” 4 I. Introduction Artificial intelligence (AI) use is rapidly transforming the criminal justice system and has the potential to make it more effective, equitable, and efficient. AI use also has the potential to cause harms, amplify disparities, and misdirect resources. Today, AI in criminal justice predominantly involves conventional statistical analysis, such as regression models.1 But that is changing. The accelerating pace of AI innovation is leading to increased use of computer vision, natural language processing, and other types of AI across the criminal justice system. Organizations and officials in the criminal justice system are also beginning to deploy generative AI systems. The policy and technology choices that law enforcement agencies, pretrial and probation services, prison systems, and other criminal justice stakeholders make in the near term will affect millions of Americans."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_30",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nvision, natural language processing, and other types of AI across the criminal justice system. Organizations and officials in the criminal justice system are also beginning to deploy generative AI systems. The policy and technology choices that law enforcement agencies, pretrial and probation services, prison systems, and other criminal justice stakeholders make in the near term will affect millions of Americans. These choices will also set the trajectory for rapid expansion in the scope and scale of AI use throughout the criminal justice system . On October 30, 2023, President Biden issued Executive Order 14110 on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence (EO 14110).2 EO 14110 advances a coordinated governmentwide approach to responsible adoption of AI. It emphasizes that AI must advance equity and civil rights, respect privacy and civil liberties, and meet government performance objectives."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_31",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ncriminal justice system . On October 30, 2023, President Biden issued Executive Order 14110 on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence (EO 14110).2 EO 14110 advances a coordinated governmentwide approach to responsible adoption of AI. It emphasizes that AI must advance equity and civil rights, respect privacy and civil liberties, and meet government performance objectives. In order to “promote the equitable treatment of individuals and adhere to the Federal Government’s fundamental obligation to ensure fair and impartial justice for all,” section 7.1(b) of EO 14110 directs the Attorney General, in consultation with the Secretary of Homeland Security and Director of the Office of Science and Technology Policy (OSTP), to submit a report to the President on “the use of AI in the criminal justice system.” The EO enumerates types of AI uses in criminal justice to address, and it f urther directs that the report “identify areas where AI can enhance law enforcement efficiency and accuracy, consistent with protections for privacy, civil 1 This report uses a broad definition of the term “artificial intelligence,” consistent with Section 238(g) of the John S.M cCain National Defense Authorization Act for Fiscal Year 2019, Pub. L. No. 115 -232, and the elaboratio n pr ovided by OMB Memoranda M -24-10 and M -24-18 in implementing Executive Order 14110."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_32",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\naccuracy, consistent with protections for privacy, civil 1 This report uses a broad definition of the term “artificial intelligence,” consistent with Section 238(g) of the John S.M cCain National Defense Authorization Act for Fiscal Year 2019, Pub. L. No. 115 -232, and the elaboratio n pr ovided by OMB Memoranda M -24-10 and M -24-18 in implementing Executive Order 14110. The definiti on e ncompasses “[a]ny artificial system that performs tasks under varying and unpredictable circumstances without significant human oversight, or that can learn from experience and improve performance when exposed to data sets,” as well as “[a]n artificial system developed in computer software, physical hardware, or other context that solves tasks requiring human- like perception, cognition, planning, learning, communication, or physical act ion,” among other types of systems. Furthermore, “no system [is] too simple to qualify as covered AI due to a lack oftechnical complexity (e.g., the smaller number of parameters in a model, the type of model, or the amount of dataused for training purpos es).” M EM. FROM SHALANDA D. YOUNG , DIR., OFF. MGMT. & BUDGET , EXEC. OFF. OF THE PRESIDENT , TO HEADS OF EXEC. DEP’TS & AGENCIES (Mar. 28, 2024), available at https://www.whitehouse.gov/wp - content/uploads/2024/03/M -24-10-Advancing- Governance -Innovation- and-Risk-Management -for-Agency -Use-of- Artificial- Intelligence.pdf ; MEM. FROM SHALANDA D. YOUNG , DIR., OFF. MGMT. & BUDGET , EXEC. OFF."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_33",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ntraining purpos es).” M EM. FROM SHALANDA D. YOUNG , DIR., OFF. MGMT. & BUDGET , EXEC. OFF. OF THE PRESIDENT , TO HEADS OF EXEC. DEP’TS & AGENCIES (Mar. 28, 2024), available at https://www.whitehouse.gov/wp - content/uploads/2024/03/M -24-10-Advancing- Governance -Innovation- and-Risk-Management -for-Agency -Use-of- Artificial- Intelligence.pdf ; MEM. FROM SHALANDA D. YOUNG , DIR., OFF. MGMT. & BUDGET , EXEC. OFF. OF THE PRESIDENT , TO HEADS OF EXEC. DEP’TS & AGENCIES (Sept 24, 2024), available at https://www.whitehouse.gov/wp - content/uploads/2024/10/M -24-18-AI-Acquisition -Memorandum.pdf. 2 Exec. Order No. 14110, 88 Fed. Reg. 75191 (Oct. 2023), https://www.federalregister.gov/d/2023 -24283 . 5 rights, and civil liberties” and “recommend best practices for law enforcement agencies, including safeguards and appropriate use limits for AI.” The Department of Justice submitted an Executive Report in conformity with these requirements on October 29, 2024. T his final report address es these issues in richer detail and provides particularized recommendations. Background This report benefits from substantial input from stakeholders inside and outside of the federal government."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_34",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nfor law enforcement agencies, including safeguards and appropriate use limits for AI.” The Department of Justice submitted an Executive Report in conformity with these requirements on October 29, 2024. T his final report address es these issues in richer detail and provides particularized recommendations. Background This report benefits from substantial input from stakeholders inside and outside of the federal government. Throughout 2024, Deputy Attorney General Lisa Monaco convened Justice AI, a series of six roundtable conversations that brought together law enforce ment agencies and groups, civil society organizations, companies that develop AI products and services, and academic researchers who study AI use in criminal justice. In addition, the Civil Rights Division hosted four quarterly information exchanges with f ederal, state, and local agencies addressing civil rights issues associated with AI. The National Institute of Justice received comments for this report through a public request for input, and Department of Justice staff met with stakeholders throughout the process of preparing this report. The Department is grateful to the many experts who shared their valuable perspectives. This report builds on a decade of U.S. Government initiatives that aim to ensure that AI use is effective, transparent, and respectful of privacy and civil liberties. • In May 2014, the White House released a report entitled Big Data: Seizing Opportunities, Preserving Values ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_35",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nthis report. The Department is grateful to the many experts who shared their valuable perspectives. This report builds on a decade of U.S. Government initiatives that aim to ensure that AI use is effective, transparent, and respectful of privacy and civil liberties. • In May 2014, the White House released a report entitled Big Data: Seizing Opportunities, Preserving Values . 3 The report touched on how algorithmic analysis of large datasets could have “tremendous” benefits for law enforcement activities, while also posing privacy and civil liberties issues. • In May 2016, the White House issued the follow -up report, Big Data: Algorithmic Systems, Opportunity, and Civil Rights . 4 In a section on criminal justice, the report noted that uses of algorithms could advance public safety and public trust, but they must be “designed and deployed carefully” to prevent “exacerbat[ing] unwarranted disparities.” The report also cautioned that “criminal justice data is notoriously poor” and often “inherently subjective.” • In October 2016, the National Science and Technology Council released the report Preparing for the Future of Artificial Intelligence , which summarized the state of AI in the government and made recommendations about AI governance and safety, noting 3 EXEC. OFF. OF THE PRESIDENT , BIG DATA: SEIZING OPPORTUNITIES , PRESERVING VALUES (May 2014), https://obamawhitehouse.archives.gov/sites/default/files/docs/big_data_privacy_report_may_1_2014.pdf . 4 EXEC. OFF."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_36",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n• In October 2016, the National Science and Technology Council released the report Preparing for the Future of Artificial Intelligence , which summarized the state of AI in the government and made recommendations about AI governance and safety, noting 3 EXEC. OFF. OF THE PRESIDENT , BIG DATA: SEIZING OPPORTUNITIES , PRESERVING VALUES (May 2014), https://obamawhitehouse.archives.gov/sites/default/files/docs/big_data_privacy_report_may_1_2014.pdf . 4 EXEC. OFF. OF THE PRESIDENT , BIG DATA: A REPORT ON ALGORITHMIC SYSTEMS , OPPORTUNITY , AND CIVIL RIGHTS (May 2016), https://obamawhitehouse.archives.gov/sites/default/files/microsites/ostp/2016_0504_data_discrimination.pdf ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_37",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nwhich summarized the state of AI in the government and made recommendations about AI governance and safety, noting 3 EXEC. OFF. OF THE PRESIDENT , BIG DATA: SEIZING OPPORTUNITIES , PRESERVING VALUES (May 2014), https://obamawhitehouse.archives.gov/sites/default/files/docs/big_data_privacy_report_may_1_2014.pdf . 4 EXEC. OFF. OF THE PRESIDENT , BIG DATA: A REPORT ON ALGORITHMIC SYSTEMS , OPPORTUNITY , AND CIVIL RIGHTS (May 2016), https://obamawhitehouse.archives.gov/sites/default/files/microsites/ostp/2016_0504_data_discrimination.pdf . 6 that the lack of complete quality data in the criminal justice system risked “exacerbat[ing] problems of bias.”5 • In December 2020, Executive Order 13960, Promoting the Use of Trustworthy Artificial Intelligence in the Federal Government, directed federal agencies to adhere to principles when using AI, including ensuring that AI applications are “consistent with the Constitution and all other applicable laws and policies, including those addressing privacy, civil rights, and civil liberti es.” 6 EO 13960 further directed that AI uses be “accurate, reliable, and effective” as well as “safe, secure, and resilient,” “understandable,” “regularly monitored,” “transparent,” and “accountable” through the implementation of “appropriate safeguards.” • Also in December 2020, Congress enacted the AI in Government Act, which required the Director of the Office of Management and Budget (OMB) to issue a memorandum that “identif[ies] best practices for identifying, assessing, and mitigating any discriminatory impact or bias on the basis of any classification protected under Federal nondiscrimination laws, or any unintended consequence of the use of artificial intelligence.” 7 • In January 2021, Congress enacted the National Artificial Intelligence Initiative Act of 2020, which established a National AI Advisory Committee under the Department of Commerce."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_38",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nbest practices for identifying, assessing, and mitigating any discriminatory impact or bias on the basis of any classification protected under Federal nondiscrimination laws, or any unintended consequence of the use of artificial intelligence.” 7 • In January 2021, Congress enacted the National Artificial Intelligence Initiative Act of 2020, which established a National AI Advisory Committee under the Department of Commerce. 8 • In May 2022, President Biden signed EO 14074, Advancing Effective, Accountable Policing and Criminal Justice Practices to Enhance Public Trust and Public Safety . 9 EO 14074 directed the Attorney General to commission a National Academy of Sciences (NAS) study on facial recognition, other biometric identification, and predictive algorithms used by law enforcement. NAS issued a report on facial recognition in January 2024 and convened a workshop on predictive policing in June 2024. 10 5 NAT’L Sci. & TECH. COUNCIL , COMM . ON TECH., EXEC. OFF. OF THE PRESIDENT , PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE 30 (Oct. 2016), https://obamawhitehouse.archives.gov/sites/default/files/whitehouse_files/microsites/ostp/NSTC/preparing_for_the_ future_of_ai.pdf . 6 Exec. Order No. 13960, 85 Fed. Reg. 78939 , (Dec. 2020), https://www.federalregister.gov/documents/2020/12/08/2020 -27065/promoting- the-use-of-trustworthy- artificial- intelligence -in-the-federal -government . 7 Pub. L. No. 116 -260, div. U, title 1, § 104 (codified at 40 U.S.C."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_39",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n, COMM . ON TECH., EXEC. OFF. OF THE PRESIDENT , PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE 30 (Oct. 2016), https://obamawhitehouse.archives.gov/sites/default/files/whitehouse_files/microsites/ostp/NSTC/preparing_for_the_ future_of_ai.pdf . 6 Exec. Order No. 13960, 85 Fed. Reg. 78939 , (Dec. 2020), https://www.federalregister.gov/documents/2020/12/08/2020 -27065/promoting- the-use-of-trustworthy- artificial- intelligence -in-the-federal -government . 7 Pub. L. No. 116 -260, div. U, title 1, § 104 (codified at 40 U.S.C. § 11301 note), https://www.congress.gov/116/plaws/publ260/PLAW -116publ260.pdf . 8 Pub. L. No. 11 6-617, div. C, title LI § 5104, https://www.congress.gov/116/crpt/hrpt617/CRPT - 116hrpt617.pdf#page=1216 . 9 Exec. Order No. 14074, 87 Fed. Reg. 32945 (May. 202 2), https://www.federalregister.gov/d/2022 -11810 . 10 NAT’L ACAD. OF SCIS., ENG’G, & MED., FACIAL RECOGNITION TECHNOLOGY : CURRENT CAPABILITIES , FUTURE PROSPECTS , AND GOVERNANCE (Jan. 2024), https://nap.nationalacademies.org/catalog/27397/facial- recognition - technology- current -capabilities -future -prospects -and-governance ; NAT’L ACAD. OF SCIS., ENG’G, & MED., LAW ENFORCEMENT USES OF PREDICTIVE POLICING APPROACHES (Nov. 2024) , https://nap.nationalacademies.org/catalog/28037/law -en forcement -use-of-person -based -predictive -policing - approaches -proceedings .."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_40",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n10 NAT’L ACAD. OF SCIS., ENG’G, & MED., FACIAL RECOGNITION TECHNOLOGY : CURRENT CAPABILITIES , FUTURE PROSPECTS , AND GOVERNANCE (Jan. 2024), https://nap.nationalacademies.org/catalog/27397/facial- recognition - technology- current -capabilities -future -prospects -and-governance ; NAT’L ACAD. OF SCIS., ENG’G, & MED., LAW ENFORCEMENT USES OF PREDICTIVE POLICING APPROACHES (Nov. 2024) , https://nap.nationalacademies.org/catalog/28037/law -en forcement -use-of-person -based -predictive -policing - approaches -proceedings .. 7 • In October 2022, the White House Office of Science and Technology Policy (OSTP) published the Blueprint for an AI Bill of Rights , which recommended a set of principles for responsible AI use, including ensuring safety and efficacy, protecting against algorithmic discrimination, respecting privacy, providing notice and explanation, and establishing human oversight."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_41",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n-predictive -policing - approaches -proceedings .. 7 • In October 2022, the White House Office of Science and Technology Policy (OSTP) published the Blueprint for an AI Bill of Rights , which recommended a set of principles for responsible AI use, including ensuring safety and efficacy, protecting against algorithmic discrimination, respecting privacy, providing notice and explanation, and establishing human oversight. The report noted that “[d]esigners, developers, and deployers of automated systems should take proactive and continuous measures to protect individuals and communities from algorithmic discrimination and to use and design systems in an equitable way.” 11 • In December 2022, Congress enacted the Advancing American AI Act, which directed the Secretary of Homeland Security to “issue policies and procedures … to ensure that full consideration is given to … the privacy, civil rights, and civil liberties impacts of artificial intelligence -enabled systems.” 12 The Act also requires federal agencies to publish their AI use case inventories. • In May 2023, the National Science and Technology Council released a revised National Artificial Intelligence Research and Development Strategic Plan to coordinate and focus federal investments in AI."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_42",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nis given to … the privacy, civil rights, and civil liberties impacts of artificial intelligence -enabled systems.” 12 The Act also requires federal agencies to publish their AI use case inventories. • In May 2023, the National Science and Technology Council released a revised National Artificial Intelligence Research and Development Strategic Plan to coordinate and focus federal investments in AI. The plan emphasized the importance of developing AI systems “in a manner that mitigates bias and harm and is done in accordance with the civil rights, civil liberties, and interests of those affected by the system.” 13 • In October 2023, President Biden signed EO 14110, which set out policy priorities and a whole -of-government approach for responsible AI development and implementation.14 EO 14110 includes over 100 directives to agencies, including tasking the Attorney General with submitting this report. • In March 2024, OMB issued Memorandum M -24-10, Advancing Governance, Innovation, and Risk Management for Agency Use of Artificial Intelligence . The memo fulfills a statutory requirement of the AI in Government Act of 2020 and a directive of EO 14110, and establishes baseline AI governance requirements for federal agencies, including governance structures, inventories, impact assessments, testing in real -world contexts, independent evaluation, consultation with impacted communities, and ongoing monitoring and risk mitigation. 15 11 EXEC. OFF."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_43",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nof Artificial Intelligence . The memo fulfills a statutory requirement of the AI in Government Act of 2020 and a directive of EO 14110, and establishes baseline AI governance requirements for federal agencies, including governance structures, inventories, impact assessments, testing in real -world contexts, independent evaluation, consultation with impacted communities, and ongoing monitoring and risk mitigation. 15 11 EXEC. OFF. OF THE PRESIDENT , BLUEPRINT FOR AN AI BILL OF RIGHTS 5 (Oct. 2022), https://www.whitehouse.gov/wp- content/uploads/2022/10/Blueprint -for-an-AI-Bill-of-Rights.pdf . 12 Pub. L. No. 117 -263, div. G, title LXXII, subtitle B, §§ 7224(a), 7224(d)(1)(B), and 7225 (codified at 40 U.S.C. 11301 note), https://www.congress.gov/117/plaws/publ263/PLAW -117publ263.pdf . 13 NAT’L SCI. & TECH. COUNCIL , SELECT COMM . ON A.I., EXEC. OFF. OF THE PRESIDENT , NATIONAL ARTIFICIAL INTELLIGENCE RESEARCH AND DEVELOPMENT STRATEGIC PLAN 2023 UPDATE 14 (May 2023), https://www.whitehouse.gov/wp- content/uploads/2023/05/National -Artificial- Intelligence -Research -and- Development -Strategic -Plan-2023- Update.pdf . 14 Exec. Order No. 14110, 88 Fed. Reg. 75191 . 15 MEMORANDUM FROM SHALANDA D. YOUNG , DIR., OFF. MGMT. & BUDGET , EXEC. OFF. OF THE PRESIDENT , TO HEADS OF EXEC. DEP'TS & AGENCIE s, (Mar."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_44",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nINTELLIGENCE RESEARCH AND DEVELOPMENT STRATEGIC PLAN 2023 UPDATE 14 (May 2023), https://www.whitehouse.gov/wp- content/uploads/2023/05/National -Artificial- Intelligence -Research -and- Development -Strategic -Plan-2023- Update.pdf . 14 Exec. Order No. 14110, 88 Fed. Reg. 75191 . 15 MEMORANDUM FROM SHALANDA D. YOUNG , DIR., OFF. MGMT. & BUDGET , EXEC. OFF. OF THE PRESIDENT , TO HEADS OF EXEC. DEP'TS & AGENCIE s, (Mar. 28, 2024), available at https://www.whitehouse.gov/wp- content/uploads/2024/03/M -24-10-Advancing- Governance -Innovation- and-Risk-Management -for-Agency -Use-of- Artificial- Intelligence.pdf . 8 • In September 2024, OMB issued Memorandum M -24-18, Advancing the Responsible Acquisition of Artificial Intelligence in Government.16 The memo complements M -24- 10 with further acquisition guidance, including on how to enable testing of AI and ensure data sources are consistent with privacy and civil liberties protections , in fulfillment of section 7224(d) of the Advancing American AI Act. This report also builds on work within the Department that has been central to the U.S. government’s continuing efforts to ensure the responsible use of AI in criminal justice. • In November 2023, Deputy Attorney General Monaco announced the establishment of DOJ’s Emerging Technology Board (ETB), based on recommendations in the Deputy Attorney General’s Comprehensive Cyber Review."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_45",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nAmerican AI Act. This report also builds on work within the Department that has been central to the U.S. government’s continuing efforts to ensure the responsible use of AI in criminal justice. • In November 2023, Deputy Attorney General Monaco announced the establishment of DOJ’s Emerging Technology Board (ETB), based on recommendations in the Deputy Attorney General’s Comprehensive Cyber Review. 17 • In February 2024, Attorney General Merrick Garland announced the designation of the Department’s first Chief AI Officer (CAIO). 18 The CAIO and ETB are charged with developing and overseeing a comprehensive program of AI governance for DOJ, including implementation of EO 14110, the accompanying OMB Memoranda M -24- 10 and M -24-18, and the National Security Memorandum on Advancing the United States’ Leadership in Artificial Intelligence; Harnessing Artificial Intelligence to Fulfill National Security Objectives; and Fostering the Safety, Security, and Trustworthiness of Artificial Intelligence . • In April 2024, the Chief of the Computer Crime and Intellectual Property Section within the Criminal Division sent a letter to the Copyright Office expressing support for a safe harbor for researchers who conduct independent bias testing on AI systems. 19 The letter noted that the Department benefits from this type of research in its work, including in the context of enforcement actions by the Civil Rights Division that are informed by this research. 16 MEMORANDUM FROM SHALANDA D."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_46",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nletter to the Copyright Office expressing support for a safe harbor for researchers who conduct independent bias testing on AI systems. 19 The letter noted that the Department benefits from this type of research in its work, including in the context of enforcement actions by the Civil Rights Division that are informed by this research. 16 MEMORANDUM FROM SHALANDA D. YOUNG , DIR., OFF. MGMT. & BUDGET , EXEC. OFF. OF THE PRESIDENT , TO HEADS OF EXEC. DEP'TS & AGENCIES , (Sept. 24, 2024), available at https://www.whitehouse.gov/wp- content/uploads/2024/10/M -24-18-AI-Acquisition -Memorandum.pdf . 17 Press Release, U.S. Dep’t Just., Readout of Deputy Attorney General Lisa Monaco’s Trip to New York and Connecticut (Nov. 9, 2023), https://www.justice.gov/opa/pr/readout -deputy -attorney -general -lisa-monacos -trip-new- york- and-connecticut . 18 Press Release, U.S. Dep’t Just ., Attorney General Merrick B. Garland Designates Jonathan Mayer to Serve as the Justice Department’s First Chief Science and Technology Advisor and Chief AI Officer ( Feb. 22, 2024), https://www.justice.gov/opa/pr/attorney -general -merrick -b-garland -designates -jonathan -mayer -serve -justice - departments -first. 19 Letter from John T. Lynch, Jr., Chief, Comput . Crime & Intell. Prop . Section, Crim. Div., Dep’t Just., to Suzanne V . Wilson, Gen . Couns. & Assoc . Reg. Copyrights, Copyright Off ., Libr . Cong, (Apr."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_47",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nand Chief AI Officer ( Feb. 22, 2024), https://www.justice.gov/opa/pr/attorney -general -merrick -b-garland -designates -jonathan -mayer -serve -justice - departments -first. 19 Letter from John T. Lynch, Jr., Chief, Comput . Crime & Intell. Prop . Section, Crim. Div., Dep’t Just., to Suzanne V . Wilson, Gen . Couns. & Assoc . Reg. Copyrights, Copyright Off ., Libr . Cong, (Apr. 15, 2024), https://www.copyright.gov/1201/2024/USCO - letters/Letter%20from%20Department%20of%20Justice%20Criminal%20Division.pdf . 9 • Also in April 2024, DOJ joined five cabinet -level federal agencies in a pledge to uphold a national commitment to core principles of fairness, equality, and justice as use of AI and other emerging technologies continues to increase.20 • In September 2024, the Criminal Division released an update to its guidance on evaluating corporate compliance programs, setting an expectation that programs will address the role of AI in creating and identifying compliance risks. 21 • In October 2024, the Criminal Division hosted a symposium on AI. The Principal Deputy Assistant Attorney General for the Division announced that the Department will be convening AI researchers and companies to understand how DOJ can best support independent AI accountability research. 22 This initiative follows steps the Department has previously taken to support security research, including a charging policy for good-faith research and guidance to industry."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_48",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\na symposium on AI. The Principal Deputy Assistant Attorney General for the Division announced that the Department will be convening AI researchers and companies to understand how DOJ can best support independent AI accountability research. 22 This initiative follows steps the Department has previously taken to support security research, including a charging policy for good-faith research and guidance to industry. • In October 2024, DOJ issued its plan for implementing a comprehensive AI governance program, consistent with OMB Memorandum M -24-10. 23 The plan describes DOJ’s AI governance program, beginning with a thorough inventory of AI uses across the Department. For AI uses with heightened potential for impact on individuals’ rights and safety, it provides for qualitative impact assessments, quant itative testing and ongoing monitoring for performance and biases, risk mitigation, and departmentwide coordinated decision-making. The Use of AI in the Criminal Justice System The types of AI uses in criminal justice described in EO 14110 fall into f our categories , set forth below.24 This report addresses each in turn, provides recommendations, and addresses the establishment of AI governance programs. • Identification and Surveillance. From recognizing faces, fingerprints, and other biometric identifiers, to tracking license plates and locating gunshots, AI has a wide range of existing and potential applications for identification and surveillance in 20 Press Release, U.S."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_49",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nour categories , set forth below.24 This report addresses each in turn, provides recommendations, and addresses the establishment of AI governance programs. • Identification and Surveillance. From recognizing faces, fingerprints, and other biometric identifiers, to tracking license plates and locating gunshots, AI has a wide range of existing and potential applications for identification and surveillance in 20 Press Release, U.S. Dep’t Just ., Five New Federal Agencies Join Justice Department in Pledge to Enforce Civil Rights Laws in Artificial Intelligence (Apr. 4, 2024), https://www.justice.gov/opa/pr/five -new-federal -agencies -join- justice -department -pledge -enforce -civil- rights -laws. 21 U.S. Dep’t Just., Crim. Div., Evaluation of Corporate Compliance Program (Sept. 2024), https://www.justice.gov/criminal/criminal- fraud/page/file/937501/dl . 22 Press Release, U.S. Dep’t Just ., Readout of the Criminal Division’s Symposium on Artificial Intelligence in the Justice Department (Oct. 3, 2024), https://www.justice.gov/opa/pr/readout- criminal -divisions -symposium- artificial- intelligence -justice -department . 23 U.S. Dep’t Just., Compliance Plan for OMB Memorandum M -24-10 (Oct. 2024), available at https://www.justice.gov/media/1373026/dl . 24 Identification and Surveillance addresses “police surveillance” and “prison- management tools,” as directed by EO 14110 sections 7.1(b)(i)(E) and (G)."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_50",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nthe Criminal Division’s Symposium on Artificial Intelligence in the Justice Department (Oct. 3, 2024), https://www.justice.gov/opa/pr/readout- criminal -divisions -symposium- artificial- intelligence -justice -department . 23 U.S. Dep’t Just., Compliance Plan for OMB Memorandum M -24-10 (Oct. 2024), available at https://www.justice.gov/media/1373026/dl . 24 Identification and Surveillance addresses “police surveillance” and “prison- management tools,” as directed by EO 14110 sections 7.1(b)(i)(E) and (G). Forensic Analysis covers “forensic analysis,” as required by section 7.1(b)(i)(H). Predictive Policing ad dresses “crime forecasting and predictive policing, including the ingestion of historical crime data into AI systems to predict high -density ‘hot spots ,’” as required by section 7.1(b)(i)(F). Risk Assessment covers “sentencing,” “parole, supervised release, and probation, “bail, pretrial release, and pretrial detention,” and “risk assessments, including pretrial, earned time, and early release or transfer to home -confinement determinations” as required by sections 7.1(b)(i)(A) through (D). 10 criminal justice contexts. These uses of AI can be significantly more accurate25 and efficient than human observations and comparisons, and they can provide entirely new capabilities. But these AI uses also pose concerns, especially related to errors, bias, and privacy."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_51",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\npretrial, earned time, and early release or transfer to home -confinement determinations” as required by sections 7.1(b)(i)(A) through (D). 10 criminal justice contexts. These uses of AI can be significantly more accurate25 and efficient than human observations and comparisons, and they can provide entirely new capabilities. But these AI uses also pose concerns, especially related to errors, bias, and privacy. When harms associated with these AI uses occur, they can be serious , including mistaken arrests, with a potential for disproportionate impact on certain communities. There is substantial nationwide variation in policies about whether and how AI may be used for identification and surveillance in criminal justice contexts. • Forensic Analysis. AI can improve the capabilities, speed, and accuracy of forensic analysis. It is already being used to enhance DNA comparison, facilitate tracing of seized drugs, and prioritize electronic evidence, among other applications. Ongoing research suggests that future uses could include analysis of physical and trace evidence, medical evaluations, and assessing crime scenes. Forensic analysis must continue to meet exacting standards of accuracy and transparency to ensure due process and satisfy evidentiary requirements."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_52",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nis already being used to enhance DNA comparison, facilitate tracing of seized drugs, and prioritize electronic evidence, among other applications. Ongoing research suggests that future uses could include analysis of physical and trace evidence, medical evaluations, and assessing crime scenes. Forensic analysis must continue to meet exacting standards of accuracy and transparency to ensure due process and satisfy evidentiary requirements. Uses of AI may pose distinct challenges for meeting these requirements because of the complexity of validating and explaining AI -based forensic analysis, as well as the limitations of the data necessary for enabling these types o f analys es. • Predictive Policing. Law enforcement agencies use historical data to forecast the places where crime is likely to cluster and people who are at a higher risk of engaging in or being victims of criminal activity. Fundamental police work includes tracking where and when crimes occur, who is involved, and how crimes and people involved with crimes are connected. Developing accurate predictive models based on these types of data may help more efficiently direct resources —including non- law enforcement resources, such as social services —preventing crimes and decreasing response times. But t here are also significant risks associated with predictive policing. The data used for predictive policing may have significant gaps and errors, and it may reflect human biases."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_53",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nDeveloping accurate predictive models based on these types of data may help more efficiently direct resources —including non- law enforcement resources, such as social services —preventing crimes and decreasing response times. But t here are also significant risks associated with predictive policing. The data used for predictive policing may have significant gaps and errors, and it may reflect human biases. Use of models based on that data may entrench existing disparities and result in unintended consequences and unjust outcomes, such as over -policing of certain individuals and communities. Successful place -based predictive policing programs integrate a ran ge of strategies and interventions to promote public safety. At the same time, s ome law enforcement agencies have shifted away from person -based predictive policing, citing limited value and impact on privacy and civil liberties. • Risk Assessment. Risk assessment tools estimate the likelihood that a certain individual outcome will occur in the criminal justice system, such as recidivating or failing to appear in court . These tools are widely used to inform pretrial release, sentencing, prison classification, probation, parole, and supervision. Used properly, risk assessment tools can be more accurate than human judgment alone and can enabl e more targeted use of various tools within the criminal justice system. Risk assessment tools can also be more transparent and equitable than human judgments."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_54",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nin court . These tools are widely used to inform pretrial release, sentencing, prison classification, probation, parole, and supervision. Used properly, risk assessment tools can be more accurate than human judgment alone and can enabl e more targeted use of various tools within the criminal justice system. Risk assessment tools can also be more transparent and equitable than human judgments. There are, however, significant risks associated with these tools . Risk assessment tools can be inaccurate, especially when they are not validated on local data or fail to take into 25 This report uses the terms “ accurate” and “reliable ” as shorthand for the predictive performance of an AI system. The report uses more precise terminology when referring to specific performance metrics and measures, such as the precision or false positive rate of an AI system. 11 account relevant factors . They may be designed to estimate outcomes that are not directly relevant to the decision being made and thus fail to properly inform decision- makers . Risk assessment tools can perpetuate bias and inequality, since the data used in building models may reflect errors or biases and the development process may not incorporate input from affected communities. Models may also be unnecessarily complex , lack transparency, and apply substantially different categorizations to similar people. 12 II."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_55",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nmade and thus fail to properly inform decision- makers . Risk assessment tools can perpetuate bias and inequality, since the data used in building models may reflect errors or biases and the development process may not incorporate input from affected communities. Models may also be unnecessarily complex , lack transparency, and apply substantially different categorizations to similar people. 12 II. Identification & Surveillance Introduction AI has the potential to enable agencies across the criminal justice system to more effectively and efficiently identify people based on biometrics, i.e., the measurement and analysis of individual physical characteristics.1 Advances in computer vision, data mining, and complex pattern comparison tools, combined with decreasing costs of cameras and sensors as well as improvements in computation and data storage, have made AI -based biometric identification less expensive and m ore widely available.2 Some agencies with law enforcement, correctional, and community supervision responsibilities now routinely use AI for biometrics.3 The use of AI for biometric identification also has risks. AI could misidentify individuals , which can misdirect law enforcement efforts and impact the civil rights and civil liberties of affected individuals. The performance of AI for biometric identification may also differ across demographic groups."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_56",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nagencies with law enforcement, correctional, and community supervision responsibilities now routinely use AI for biometrics.3 The use of AI for biometric identification also has risks. AI could misidentify individuals , which can misdirect law enforcement efforts and impact the civil rights and civil liberties of affected individuals. The performance of AI for biometric identification may also differ across demographic groups. There have been public reports of seven instances of mistaken arrests associated with the use of facial recognition technology, almost all involving Black individuals.4 The collection and use of biometric data also poses privacy risks, especially when it involves personal information that people have shared in unrelated contexts. The first part of the chapter opens with a description of biometric applications of AI in criminal justice, including automated fingerprint identification systems (AFIS), facial recognition technology (FRT), and iris scanning. The chapter then focuses on F RT use in criminal investigations to demonstrate the nuance s of evaluating AI -based identification systems for accuracy and biases, as well as the importance of establishing policy frameworks and addressing impacts on privacy, civil rights, and civil liber ties. The second part of the chapter addresses uses of AI in the conduct of law enforcement surveillance."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_57",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nfocuses on F RT use in criminal investigations to demonstrate the nuance s of evaluating AI -based identification systems for accuracy and biases, as well as the importance of establishing policy frameworks and addressing impacts on privacy, civil rights, and civil liber ties. The second part of the chapter addresses uses of AI in the conduct of law enforcement surveillance. It focuses on automated license plate recognition (ALPR), an increasingly common practice for identifying vehicles that may be involved in criminal activity , including in ongoing emergencies. 1 See INTERNATIONAL ORGANIZATION FOR STANDARDIZATION , Biometrics, in INFORMATION TECHNOLOGY - VOCABULARY (3rd ed. Int'l Org. for Standardization 2022), https://www.iso.org/standard/73514.html (“automated recognition of individuals based on their biological and behavioural characteristics”). 2 Consistent with the definition of artificial intelligence in OMB Memoranda M -24-10 and M -24-18, this chapter categorizes identification and surveillance methods that involve algorithms or statistical analysis as AI. 3 The following discussion of different biometric approaches includes references to examples of how these technologies are used by federal, state, and local agencies. 4 U.S. COMM ’N CIV. RTS., THE CIVIL RIGHTS IMPLICATIONS OF THE FEDERAL USE OF FACIAL RECOGNITION TECHNOLOGY 25 (2024) , https://www.usccr.gov/files/2024 -09/civil- rights -implications -of-frt_0.pdf ; see also NAT’L ACADS ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_58",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nstatistical analysis as AI. 3 The following discussion of different biometric approaches includes references to examples of how these technologies are used by federal, state, and local agencies. 4 U.S. COMM ’N CIV. RTS., THE CIVIL RIGHTS IMPLICATIONS OF THE FEDERAL USE OF FACIAL RECOGNITION TECHNOLOGY 25 (2024) , https://www.usccr.gov/files/2024 -09/civil- rights -implications -of-frt_0.pdf ; see also NAT’L ACADS . SCIS., ENG’G, & MED., Facial Recognition Technology: Current Capabilities, Future Prospects, and Governance 83 (2024), https://doi.org/10.17226/27397 (“NAS 2024 Report ”) (describing six then-known cases of mistaken arrests) . 13 Biometrics a. Automated Fingerprint Identification Systems Law enforcement has used forms of fingerprint analysis for over a century.5 The two common types of analysis today involve : (1) fingerprints collected from a known source in a controlled environment, commonly referred to as ten- prints, and (2) fingerprints from an unknown source collected from a surface or object, commonly referred to as latent fingerprints.6 Analysis generally involves capturing friction ridge patterns on a person’s skin, observing features including the locations and types of ridges (minutiae), and then comparing features across fingerprints for similarity."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_59",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nknown source in a controlled environment, commonly referred to as ten- prints, and (2) fingerprints from an unknown source collected from a surface or object, commonly referred to as latent fingerprints.6 Analysis generally involves capturing friction ridge patterns on a person’s skin, observing features including the locations and types of ridges (minutiae), and then comparing features across fingerprints for similarity. 7 Automated methods for fingerprint comparison became practical in the 1970s and entered widespread use by the 1990s.8 Live scan systems, which capture digital images of fingerprints without applying ink, developed in parallel. While identification based on fingerprints generally involves specialized scanning hardware or high -resolution digital cameras, technology may eventually enable ordinary smartphone cameras to capture latent prints. 9 Machine learning methods may also enable more advanced forms of fingerprint analysis in the future, such as comparing fingerprints for whether they may be from different fingers of the same person. 10 Comparison of ten -prints is highly automated in practice today, often not involving a human examiner unless fingerprints will be offered as forensic evidence in a prosecution. Analysis 5 See Press Release, Fed. Bureau Investigation, Crim . Just. Info. Serv."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_60",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nin the future, such as comparing fingerprints for whether they may be from different fingers of the same person. 10 Comparison of ten -prints is highly automated in practice today, often not involving a human examiner unless fingerprints will be offered as forensic evidence in a prosecution. Analysis 5 See Press Release, Fed. Bureau Investigation, Crim . Just. Info. Serv. Div., FBI’s Criminal Justice Information Services Division Celebrates 100th Anniversary of National Fingerprint Repository (July 10, 2024 ), https://www.fbi.gov/news/press -releases/fbi -s-criminal- justice -information -services -division -celebrates -100th- anniversary -of-national -fingerprint -repository ( “In 1924 , the FBI established an Identification Division informally called ‘ident ’ for many years. ‘ Ident ’ gathered prints from police agencies nationwide and manually searched them upon request for matches to criminals and crime evidence.”) . 6 Fingerprints may include impressions of palms, in addition to individual fingers. 7 See John R. Vanderkolk, Chapter 9: Examination Process, in N ATIONAL INSTITUTE OF JUSTICE , THE FINGERPRINTING SOURCEBOOK 9-13 (Nat’l Inst. of Justice 2011), https://www.ojp.gov/pdffiles1/nij/225329.pdf (“The direct or side -by-side comparison of friction ridge details to determine whether the details in two prints are in agreement based upon similarity, sequence, and spatial relationship occurs in the comparison phase.”). 8 See generally Kenneth R."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_61",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nVanderkolk, Chapter 9: Examination Process, in N ATIONAL INSTITUTE OF JUSTICE , THE FINGERPRINTING SOURCEBOOK 9-13 (Nat’l Inst. of Justice 2011), https://www.ojp.gov/pdffiles1/nij/225329.pdf (“The direct or side -by-side comparison of friction ridge details to determine whether the details in two prints are in agreement based upon similarity, sequence, and spatial relationship occurs in the comparison phase.”). 8 See generally Kenneth R. Moses, Chapter 6: Automated Fingerprint Identification System (AFIS) , in NATIONAL INSTITUTE OF JUSTICE , THE FINGERPRINTING SOURCEBOOK 6-1 (Nat’l Inst. Of Justice 2011), https://www.ojp.gov/pdffiles1/nij/225326.pdf . 9 Robert Pitts et al., Empirical Comparison of DSLRs and S martphone Cameras for L atent Prints Photography , 3 WIRE S FORENSIC SCI. (2021), https://wires.onlinelibrary.wiley.com/doi/epdf/10.1002/wfs2.1391 (“argu[ing] that the cameras equipped in current and future mobile devices are adequate for the purpose of latent print documentation and identification , making it a useful complement, if not a replacement , to DSLRs currently used by crime scene investigators and fingerprint examiners.”); Maryah E. M. Haertel, Eduardo J. Linhares & Andre L. de Melo, Smartphones for L atent Fingerprint Processing and Photography : A Revolution in Forensic Science, 3 WIRE S FORENSIC SCI."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_62",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\npurpose of latent print documentation and identification , making it a useful complement, if not a replacement , to DSLRs currently used by crime scene investigators and fingerprint examiners.”); Maryah E. M. Haertel, Eduardo J. Linhares & Andre L. de Melo, Smartphones for L atent Fingerprint Processing and Photography : A Revolution in Forensic Science, 3 WIRE S FORENSIC SCI. 2 (2021), https://wires.onlinelibrary.wiley.com/doi/epdf/10.1002/wfs2.1410 (“The use of smartphones in the search and acquisition of latent fingerprints is still new, but various studies show its possibilities .”). 10 Gabe Guo et al., Unveiling Intra-person Fingerprint Similarity via D eep Contrastive Learning, 10 S CI. ADVANCES (2024), https://www.science.org/doi/10.1126/sciadv.adi0329 (stating that “fingerprints from different fingers of the same person share very strong similarities ” and suggesting that intra -person fingerprint similarities “can also help narrow down the candidate list generated by automated fingerprint identification systems.” ). 14 of latent prints, by contrast, usually involves review by a trained examiner because prints may be incomplete or degraded.11 Automated methods may generate possible leads for subsequent analysis and support examiners in comparing fingerprints. Fingerprint comparison is widely used for other purposes in the criminal justice system."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_63",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nnarrow down the candidate list generated by automated fingerprint identification systems.” ). 14 of latent prints, by contrast, usually involves review by a trained examiner because prints may be incomplete or degraded.11 Automated methods may generate possible leads for subsequent analysis and support examiners in comparing fingerprints. Fingerprint comparison is widely used for other purposes in the criminal justice system. Fingerprint- based checks are the standard for background checks in criminal justice, as well as for other positions of public trust, including teachers, childcare workers, and those in other sensitive occupations. Fingerprints are also the standard for identification based on criminal history record information in the United States. Fingerprint -based verification using 1- 2 fingers may be used in certain applications to confirm the identity of an authorized user, track chain-of- custody of certain types of evidence, or limit access to sensitive areas. 12 The FBI’s Next Generation Identification (NGI) system provides fingerprint services to law enforcement agencies nationwide.13 NGI contains over 217 million unique fingerprint identity records, over 28 million unique palm print identity records, and over 1.2 million unidentified latent prints. Almost every (if not every) state has its own automated fingerprint identification syst em, and these systems are also common at local law enforcement agencies.14 b."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_64",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n(NGI) system provides fingerprint services to law enforcement agencies nationwide.13 NGI contains over 217 million unique fingerprint identity records, over 28 million unique palm print identity records, and over 1.2 million unidentified latent prints. Almost every (if not every) state has its own automated fingerprint identification syst em, and these systems are also common at local law enforcement agencies.14 b. Facial Recognition Technology Facial recognition technology uses methods from computer vision and other areas of AI to isolate and compare faces in photos or video. FRT became available for criminal justice use in the 2000s and became more widely used in the 2010s.15 Algorithms have rapidly advanced in recent 11 There is ongoing research and debate about statistical models to estimate the likelihood of fingerprint features from population base rates and validation of fingerprint comparison as practiced in particular laboratories. See PRESIDENT ’S COUNCIL OF ADVISORS ON SCI. & TECH., FORENSIC SCIENCE IN CRIMINAL COURTS : ENSURING SCIENTIFIC VALIDITY OF FE ATUR E -COMPARISON METHODS (Sept. 2016), https://obamawhitehouse.archives.gov/sites/default/files/microsites/ostp/PCAST/pcast_forensic_science_report_fina l.pdf ; William Thompson et al., L atent Fingerprint Examination , in AAAS, FORENSIC SCIENCE ASSESSMENTS : A QUALITY AND GAP ANALYSIS (AAAS 2017), https://www.aaas.org/sites/default/files/reports/Latent%20Fingerprint%20Report%20FINAL%209_14.pdf ; Bradford T."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_65",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\npracticed in particular laboratories. See PRESIDENT ’S COUNCIL OF ADVISORS ON SCI. & TECH., FORENSIC SCIENCE IN CRIMINAL COURTS : ENSURING SCIENTIFIC VALIDITY OF FE ATUR E -COMPARISON METHODS (Sept. 2016), https://obamawhitehouse.archives.gov/sites/default/files/microsites/ostp/PCAST/pcast_forensic_science_report_fina l.pdf ; William Thompson et al., L atent Fingerprint Examination , in AAAS, FORENSIC SCIENCE ASSESSMENTS : A QUALITY AND GAP ANALYSIS (AAAS 2017), https://www.aaas.org/sites/default/files/reports/Latent%20Fingerprint%20Report%20FINAL%209_14.pdf ; Bradford T. Ulery et al., Accuracy and Reliability of Forensic Latent Fingerprint Decisions , 108 P ROC S. NAT’L ACAD. SCIS. 7733 (2011) , https://www.pnas.org/doi/full/10.1073/pnas.1018707108 . 12 The fingerprint readers used in these applications often lack the resolution necessary for criminal investigative uses of fingerprint analysis. As discussed below, there is a significant distinction between the 1:N matching that is common in investigations and the 1:1 matching that is common for these applications. 13 FBI, FY 2025 President’s Budget Request 55 (Mar. 2024), https://www.justice.gov/d9/2024 - 03/fbi_fy_2025_presidents_budget_narrative_3 -5-24_final_1.pdf (“T he NGI System services connectivity for 106,981 Federal, State, local, and Tribal law enforcement customers."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_66",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nof fingerprint analysis. As discussed below, there is a significant distinction between the 1:N matching that is common in investigations and the 1:1 matching that is common for these applications. 13 FBI, FY 2025 President’s Budget Request 55 (Mar. 2024), https://www.justice.gov/d9/2024 - 03/fbi_fy_2025_presidents_budget_narrative_3 -5-24_final_1.pdf (“T he NGI System services connectivity for 106,981 Federal, State, local, and Tribal law enforcement customers. These customers have existing statutory authorization to conduct background checks using the NGI System; however, only about one third (38,108) of those regularly do. ”). 14 Nat’l Inst. of Justice, Latent Fingerprint Interoperability Survey: A National Study of Automated Fingerprint Information Systems (AFIS) Maintained by Law Enforcement Agencies 36 (2014), https://www.ojp.gov/pdffiles1/nij/247910.pdf . (showing a map of AFIS vendor information for state agencies which excluded Vermont (did not provide an answer) , Minnesota and the District of Columbia (did not participate )). 15 See generally Nat’l Inst. of Justice, History of NIJ Support for Face Recognition Technology ( Mar. 5, 2020 ) at https://nij.ojp.gov/topics/articles/history -nij-support -face- recognition- technology (discussing NIJ role in face algorithm research and development); Statement of Jerome M. Pender Before the Senate Judiciary Committee, Subcommittee on Privacy, Technology, and the Law 112 Cong."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_67",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nof Columbia (did not participate )). 15 See generally Nat’l Inst. of Justice, History of NIJ Support for Face Recognition Technology ( Mar. 5, 2020 ) at https://nij.ojp.gov/topics/articles/history -nij-support -face- recognition- technology (discussing NIJ role in face algorithm research and development); Statement of Jerome M. Pender Before the Senate Judiciary Committee, Subcommittee on Privacy, Technology, and the Law 112 Cong. (2012), https://archives.fbi.gov/archives/news/testimony/what- f acial -recognition -technology- means -for-privacy -and-civil- 15 years, significantly increasing the ability of FRT systems used in criminal justice to correctly match faces.16 In the usual design of an FRT system, an algorithm first detects a person’s face in a photo or video and extracts the relevant region.17 Next, it computes a quantitative representation of the face (the “template”). Finally, the algorithm compares templates, producing a “similarity score” for pairs of templates. Some recent FRT systems use deep learning models that integrate these steps. 18 There are, broadly, two types of FRT uses. One -to-one (“1:1”) FRT compares a captured (“probe”) image to a single other image or template, typically to verify a person’s identity. One - to-many (also called “one- to-n” or “1:N”) FRT compares a captured image to a database (“gallery”) of known images.19 In the criminal justice system, one -to-one FRT has several applications."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_68",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nbroadly, two types of FRT uses. One -to-one (“1:1”) FRT compares a captured (“probe”) image to a single other image or template, typically to verify a person’s identity. One - to-many (also called “one- to-n” or “1:N”) FRT compares a captured image to a database (“gallery”) of known images.19 In the criminal justice system, one -to-one FRT has several applications. The Federal Bureau of Prisons uses one -to-one FRT to confirm employees’ identities before entering secure areas of a facility.20 Probation services may use FRT to allow individuals under court -ordered supervision to verify their identity via smartphone rather than requiring physical contact with a probation or pretrial officer. 21 Similarly, Customs and Border Protection and the Transportation Security Administration use one- to-one FRT to confirm traveler identities.22 liberties (discussing advances in the NGI program through July 2012); U.S. Gov. Facial Recognition Legal Series (Aug. 31, 2011), https://ucr.fbi.gov/fingerprints_biometrics/biometric -cen ter-of- excellence/files/Forum_1_Minutes.pdf ; W illiam Casey et al., Facial Recognition Technology — Baselining Uses and Legal Challenges: Meeting Minutes, in U.S. GOVERNMENT FACIAL RECOGNITION LEGAL SERIES (2011), https://ucr.fbi.gov/fingerprints_biometrics/biometric -center -of-excellence/files/Forum_1_Minutes.pdf (noting advances made in facial recognition technology through August 2011) ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_69",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nadvances in the NGI program through July 2012); U.S. Gov. Facial Recognition Legal Series (Aug. 31, 2011), https://ucr.fbi.gov/fingerprints_biometrics/biometric -cen ter-of- excellence/files/Forum_1_Minutes.pdf ; W illiam Casey et al., Facial Recognition Technology — Baselining Uses and Legal Challenges: Meeting Minutes, in U.S. GOVERNMENT FACIAL RECOGNITION LEGAL SERIES (2011), https://ucr.fbi.gov/fingerprints_biometrics/biometric -center -of-excellence/files/Forum_1_Minutes.pdf (noting advances made in facial recognition technology through August 2011) . The FBI, for example, began developing the NGI-IPS system in 2008 and began using and providing access to the system in 2011. NGI -IPS became fully operational in 2015, at which point 7 states had access to the system. See GOV’T ACCOUNTABILITY OFF., PUB. NO. GAO- 19-579T FACE RECOGNITION TECHNOLOGY : DOJ AND FBI HAVE TAKEN SOME ACTIONS IN RESPONSE TO GAO RECOMMENDATIONS TO ENSURE PRIVACY AND ACCURACY , BUT ADDITIONAL WORK REMAINS (June 2019) , https://www.gao.gov/assets/gao -19-579t.pdf . 16 The National Institute of Standards and Technology has performed FRT algorithm evaluations for over 30 years, and currently publishes FRT algorithm evaluations on an ongoing basis through the Facial Recognition Technical Evaluation (FRTE) program. In 2024, FRT algorithms commonly have a below 1% false negative rate with a false positive rate of 3 in 1,000."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_70",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n, https://www.gao.gov/assets/gao -19-579t.pdf . 16 The National Institute of Standards and Technology has performed FRT algorithm evaluations for over 30 years, and currently publishes FRT algorithm evaluations on an ongoing basis through the Facial Recognition Technical Evaluation (FRTE) program. In 2024, FRT algorithms commonly have a below 1% false negative rate with a false positive rate of 3 in 1,000. By comparison, the best performing algorithm in NIST’s 2017 challenge had a 22% false negative rate with a false positive rate of 1 in 1000. Face Technology Evaluation – FTRE/F ATE, Nat’l Inst. Standards & Tech, https://www.nist.gov/programs -projects/face- technology- evaluations -frtefate . 17 See NAS 2024 Report supra note 4, at 32-34. 18 See Mei Wang & Weihong Deng, Deep Face Recognition: A Survey, 429 N EUROCOMPUTING 215 (2021) , https://doi.org/10.1016/j.neucom.2020.10.081 (discussing the emergence of deep learning models in FRT in 2012). 19 One-to-one and one -to-many FRT systems are closely related, because one- to-many FRT systems are often based on one -to-one comparisons. The acceptable levels of performance and demographic differences for these systems may significantly differ by use case. 20 GOV’T ACCOUNTABILITY OFF., PUB. NO. GAO- 21-518 FACIAL RECOGNITION TECHNOLOGY : FEDERAL LAW ENFORCEMENT AGENCIES SHOULD BETTER ASSESS PRIVACY AND OTHER RISKS 20, https://www.gao.gov/assets/gao - 21-518.pdf . 21 Id. at 19. 22 Id."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_71",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nFRT systems are often based on one -to-one comparisons. The acceptable levels of performance and demographic differences for these systems may significantly differ by use case. 20 GOV’T ACCOUNTABILITY OFF., PUB. NO. GAO- 21-518 FACIAL RECOGNITION TECHNOLOGY : FEDERAL LAW ENFORCEMENT AGENCIES SHOULD BETTER ASSESS PRIVACY AND OTHER RISKS 20, https://www.gao.gov/assets/gao - 21-518.pdf . 21 Id. at 19. 22 Id. at 19 –20; see also DHS Directive 026 -11, Use of Face Recognition and Face Capture Technologies , https://www.dhs.gov/sites/default/files/2023 -09/23_0913_mgmt_026- 11-use-face-recognition- face- capture - technologies.pdf . 16 One-to-many FRT is used by law enforcement agencies to identify or match people in images and video. These systems usually return a fixed number of candidate matches or candidate matches above a threshold similarity score. The results may be ordered by score and may show a numerical score or a score category. While there is not comprehensive public data on FRT use by law enforcement nationwide, surveys indicate that FRT is widely used by federal, state, and local agencies.23 A number of agencies operate their own FRT systems, based on photos from driver’s licenses, arrests, and other government interactions. Agencies commonly have access to FRT systems maintained by other agencies, such as FBI’s Next Generation Identification -Interstate Photo System (NGI -IPS), which can in turn incorporate results from other agencies."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_72",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nis widely used by federal, state, and local agencies.23 A number of agencies operate their own FRT systems, based on photos from driver’s licenses, arrests, and other government interactions. Agencies commonly have access to FRT systems maintained by other agencies, such as FBI’s Next Generation Identification -Interstate Photo System (NGI -IPS), which can in turn incorporate results from other agencies. NGI -IPS, for example, incorporates results from 17 state agencies and two federal agencies and encompasses over 67 million arrest photos.24 Commercial vendors also offer FRT services to law enforcement agencies which, as discussed further below, can heighten privacy impacts. At the federal level, law enforcement agencies use FRT in support of their missions and pursuant to applicable policies. The FBI, for instance, uses one -to-many FRT to help identify perpetrators, victims, and witnesses as part of authorized investigations of criminal offenses. 25 The FBI also uses FRT to help identify and locate missing persons or other at -risk individuals , such as abducted children, or victims of child sexual abuse or human trafficking, and to identify deceased or incapacitated individuals. These uses of FRT can be faster and more efficient than other investigative methods, and they can provide unique leads that may not have been available or may have been impractical to obtain through other avenues ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_73",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n-risk individuals , such as abducted children, or victims of child sexual abuse or human trafficking, and to identify deceased or incapacitated individuals. These uses of FRT can be faster and more efficient than other investigative methods, and they can provide unique leads that may not have been available or may have been impractical to obtain through other avenues . The FBI also uses FRT to structure and organize large volumes of lawfully obtained photo or video data, allowing investigators to more efficiently interpret the collected data. 26 Under the Department of Justice interim FRT policy, uses of FRT must be lawful and consistent with other DOJ policies ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_74",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nor may have been impractical to obtain through other avenues . The FBI also uses FRT to structure and organize large volumes of lawfully obtained photo or video data, allowing investigators to more efficiently interpret the collected data. 26 Under the Department of Justice interim FRT policy, uses of FRT must be lawful and consistent with other DOJ policies . Among other requirements , FRT results alone may not be relied upon as the sole proof of a person’s identity ; activity protected by the First Amendment may not be the sole basis for using FRT ; and personnel who use or approve FRT systems must receive relevant training ; among other requirements.27 23 See GAO- 21-518 supra note 20 (finding that, in a GAO survey of 42 federal agencies with law enforcement responsibilities, 20 used FRT between 2015 and 2020); CLARE GARVIE , ALVARO BEDOYA & JONATHAN FRANKLE , THE PERPETUAL LINE-UP (2016) 93, 97 https://www.perpetuallineup.org/sites/default/files/2016 - 12/The%20Perpetual%20Line -Up%20- %20Center%20on%20Privacy%20and%20Technology%20at%20Georgetown%20Law%20- %20121616.pdf (reporting that, based on records requests to 106 state and local law enforcement agencies, at least 53 used, previously used, or planned to use FRT). There is limited data available about FRT use by Tribal law enforcement agencies. 24 U.S."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_75",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nGARVIE , ALVARO BEDOYA & JONATHAN FRANKLE , THE PERPETUAL LINE-UP (2016) 93, 97 https://www.perpetuallineup.org/sites/default/files/2016 - 12/The%20Perpetual%20Line -Up%20- %20Center%20on%20Privacy%20and%20Technology%20at%20Georgetown%20Law%20- %20121616.pdf (reporting that, based on records requests to 106 state and local law enforcement agencies, at least 53 used, previously used, or planned to use FRT). There is limited data available about FRT use by Tribal law enforcement agencies. 24 U.S. Dep’t Just., Written Testimony in Connection with the United States Commission on Civil Rights’ Examination of Civil Rights Implications of the Federal Use of Facial Recognition Technology (Mar. 21, 2024). 25 The FBI’s use of FRT is governed by the Department of Justice’s interim FRT policy, which, among other requirements , mandates that FRT results alone may not be relied upon as sole proof of identity. Rather, an individual’s identity must be confirmed through other analysis and/or investigation. 26 This use case is a variation of 1:N FRT, where the gallery of images is drawn from the collected evidence in an investigation rather than from an established repository. The use case supports organizing and triaging media that has been collected in an investigation, which may be voluminous and unorganized. 27 U.S."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_76",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nbe confirmed through other analysis and/or investigation. 26 This use case is a variation of 1:N FRT, where the gallery of images is drawn from the collected evidence in an investigation rather than from an established repository. The use case supports organizing and triaging media that has been collected in an investigation, which may be voluminous and unorganized. 27 U.S. Dep’t Just., Written Testimony in Connection with the United States Commission on Civil Rights’ Examination of Civil Rights Implications of the Federal Use of Facial Recognition Technology (Mar. 21, 2024). 17 State and local law enforcement agencies similarly use FRT to support investigations. There is wide variation in applicable state laws, local ordinances, and law enforcement agency policies.28 Differences include whether and when FRT may be used, protections for expressive activities, quality reviews of results from FRT, how the results from FRT may be used, which probe images may be used, which databases may be searched, what training is necessary, what information is recorded and audited, what information must be disclosed in discovery, and what public transparency must be provided. At one end of the spectrum, some agencies may use FRT under generally applicable laws and policies, but without a law or policy specific to FRT. At the other end, some jurisdictions have entirely prohibited law enforcement agencies from using FRT. c."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_77",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nis recorded and audited, what information must be disclosed in discovery, and what public transparency must be provided. At one end of the spectrum, some agencies may use FRT under generally applicable laws and policies, but without a law or policy specific to FRT. At the other end, some jurisdictions have entirely prohibited law enforcement agencies from using FRT. c. Iris Scanning Iris scanning examines the unique tissue patterns in the donut -shaped part of an eye surrounding the pupil. Iris patterns do not appear to meaningfully change over time, and are protected by the cornea, limiting the potential for damage or mutilation. 29 Iris as a biometric modality is relatively new compared with FRT and other biometric modalities, with national- level matching capabilities coming online at the FBI in just the last 5 years.30 The FBI’s NGI Iris Service has over 3 million sets of iris images from over 2 million people.31 Iris scans are well -suited for identity confirmation in custodial settings, because they are highly accurate when collected properly and can be taken either from a short stand -off distance or without removing handcuffs. Iris scans can also be an effective supplement to other identification modalities for immigration and border screening."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_78",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nsets of iris images from over 2 million people.31 Iris scans are well -suited for identity confirmation in custodial settings, because they are highly accurate when collected properly and can be taken either from a short stand -off distance or without removing handcuffs. Iris scans can also be an effective supplement to other identification modalities for immigration and border screening. Focusing on FRT for Identification in Law Enforcement Investigations While FRT use by law enforcement agencies has significant benefits in developing leads, it also poses challenges for responsible use and governance of technology in criminal justice. FRT poses significant p rivacy concern s because of the quantity, and likely long retention period, of data required for the system to be effective. FRT enables identifying people without 28 See generally Mailyn Fidler & Justin (Gus) Hurwitz, An Overview of Facial Recognition Technology Regulation in the United States , in CAMBRIDGE HANDBOOK OF FACIAL RECOGNITION IN THE MODERN STATE (Rita Matulionyte & Monika Zalieriute, eds., 2024 ), https://doi.org/10.1017/9781009321211.018 ; GARVIE ET AL ., supra note 23 at 121–50; Jameson Spivack & Clare Garvie, A Taxonomy of Legislative Approaches to Face Recognition in the United States , in R EGULATING BIOMETRICS : GLOBAL APPROACHES AND OPEN QUESTIONS (Amba Kak ed., 2023), https://ainowinstitute.org/wp -content/uploads/2023/09/regulatingbiometrics -spivack -garvie.pdf ; JAKE LAPERRUQUE , CEN. DEM."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_79",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nMatulionyte & Monika Zalieriute, eds., 2024 ), https://doi.org/10.1017/9781009321211.018 ; GARVIE ET AL ., supra note 23 at 121–50; Jameson Spivack & Clare Garvie, A Taxonomy of Legislative Approaches to Face Recognition in the United States , in R EGULATING BIOMETRICS : GLOBAL APPROACHES AND OPEN QUESTIONS (Amba Kak ed., 2023), https://ainowinstitute.org/wp -content/uploads/2023/09/regulatingbiometrics -spivack -garvie.pdf ; JAKE LAPERRUQUE , CEN. DEM. & TECH., LIMITING FACE RECOGNITION SURVEILLANCE : PROGRESS AND PATHS FORWARD , (Aug. 23, 2022), https://cdt.org/insights/limiting -face- recognition -surveillance -progress -and-paths -forward/ . 29 Iris Recognition, NEC (Sept. 22, 2021) , https://www.nec.com/en/global/solutions/biometrics/iris/index.html (“A person’s iris pattern is unique and remains unchanged throughout life . Also, covered by the cornea, the iris is well protected from damage, making it a suitable body part for biometric authentication.”) . 30 The Eyes Have It: Iris Bio metric Added to Next Generation Identification System (Dec. 11, 2020), https ://www.fbi.gov/news/stories/fbi- adds-iris-biometric -to-next-generation- identification -system -121120 . 31 FBI, FY 2025 Budget Request supra note 13 at 57 (“ As of November 30, 2023, the NGI Iris Service consists of over 3.3 million sets of iris images representing more than 2.6 million unique identities .”). 18 interacting with them or an object on which they left their fingerprints or DNA ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_80",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nadds-iris-biometric -to-next-generation- identification -system -121120 . 31 FBI, FY 2025 Budget Request supra note 13 at 57 (“ As of November 30, 2023, the NGI Iris Service consists of over 3.3 million sets of iris images representing more than 2.6 million unique identities .”). 18 interacting with them or an object on which they left their fingerprints or DNA . The scale of FRT databases can be large, and the effort and cost of running FRT searches can be low. Civil liberties are another area of concern. For instance, FRT could be misused to enable identif ication of people engaged solely in protected expressive activity. Going back to the Founding era, the United States has a rich tradition of anonymous civic discourse and protest, where privacy facilitates the expression of ideas and the assembly of groups. As the Supreme Court has recognized, there is a “vital relationship between freedom to associate and privacy in one's associations.”32 Civil rights are another significant issue , in part due to possible biases in FRT systems and how they are used."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_81",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ntradition of anonymous civic discourse and protest, where privacy facilitates the expression of ideas and the assembly of groups. As the Supreme Court has recognized, there is a “vital relationship between freedom to associate and privacy in one's associations.”32 Civil rights are another significant issue , in part due to possible biases in FRT systems and how they are used. For example, as noted above, public reporting indicates that there have been seven documented instances of mistaken arrests associated with the use of facial recognition technology, almost all involving Black individuals .33 Many FRT systems deployed in the United States have higher false match (i.e., false positive) rates when applied to racial minorities, including people who are Black, Native American, Asian American, and Pacific Islanders.34 Research has also demonstrated that FRT systems tend to perform worse on women, children, and the elderly , and some FRT algorithms used in the United States have biases also associated with eyewear, hairstyle, and other attributes.35 Testing by the National Institute of Standards and Technology (NIST), discussed further below, indicates that in the last five years, some FRT developers have made significant progress in addressing differences in performance associated with demographics."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_82",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nwomen, children, and the elderly , and some FRT algorithms used in the United States have biases also associated with eyewear, hairstyle, and other attributes.35 Testing by the National Institute of Standards and Technology (NIST), discussed further below, indicates that in the last five years, some FRT developers have made significant progress in addressing differences in performance associated with demographics. L ow absolute false match rates and lower relative rates —at least in the controlled settings of NIST’s testing of recent algorithms —now exist across demographics, which include gender, age, and race. The data used to train FRT systems is an important contributing factor. An FRT system generally performs best on faces that are similar to the faces used when training the system. Race, gender, age, and other attributes are often readily apparent from faces, unlike fingerprints and irises, which compounds the risk that these types of biometric systems will reflect demographic biases from training data. Research has demonstrated an “other -race” effect in FRT systems where, for example, systems built in the United States can perform better on white faces and systems 32 NAACP v. Alabama ex rel. Patterson , 357 U.S. 449, 462 (1958). 33 NAS 2024 Report supra note 4. 34 NAS 2024 Report supra note 4; Face Technology Evaluation – FTRE/FATE , NAT’L INST. STANDARDS & TECH, https://www.nist.gov/programs -projects/face- technology- evaluations -frtefate ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_83",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nfor example, systems built in the United States can perform better on white faces and systems 32 NAACP v. Alabama ex rel. Patterson , 357 U.S. 449, 462 (1958). 33 NAS 2024 Report supra note 4. 34 NAS 2024 Report supra note 4; Face Technology Evaluation – FTRE/FATE , NAT’L INST. STANDARDS & TECH, https://www.nist.gov/programs -projects/face- technology- evaluations -frtefate . 35 E.g., NAS 2024 Report supra note 4; NIST supra note 34; Cynthia M. Cook et al., Demographic Effects in Facial Recognition and Their Dependence on Image Acquisition: An Evaluation of Eleven Commercial Systems , 1 IEEE TRANSACTIONS ON BIOMETRICS , BEHAV ., & IDENTITY SCI. 32, 32- 41 (2019), https://ieeexplore.ieee.org/document/8636231 ; Pawel Drozdowski et al., Demographic Bias in Biometrics: A Survey on an Emerging Challenge , 1 IEEE TRANSACTIONS ON TECH. & SOC’Y 89 (2020), https://ieeexplore.ieee.org/document/9086771 ; Philipp Terhörst et al., A Comprehensive Study on Face Recognition Biases Beyond Demographics , 3 IEEE TRANSACTIONS ON TECH. & SOC’Y. 16, 16 -30 (2022), https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534882 . Related research has demonstrated similar disparities in other computer vision applications, such as gender classification. E.g., Joy Buolamwini & Timnit Gebru, Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification, 81 P ROCEEDINGS MACH. LEARNING RSCH. 1, 1 (2018), https://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_84",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nFace Recognition Biases Beyond Demographics , 3 IEEE TRANSACTIONS ON TECH. & SOC’Y. 16, 16 -30 (2022), https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534882 . Related research has demonstrated similar disparities in other computer vision applications, such as gender classification. E.g., Joy Buolamwini & Timnit Gebru, Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification, 81 P ROCEEDINGS MACH. LEARNING RSCH. 1, 1 (2018), https://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf . 19 developed in Asia can perform better on Asian faces.36 Balancing the demographics of training datasets can be a valuable step in improving performance disparities, though additional possible sources of bias remain in both FRT systems and how they are used.37 Agencies considering use of FRT must grapple with difficult policy decisions. Agencies should develop and enforce policies regarding the use of FRT and set clear rules for how and when the technology may be used, including guardrails that protect civil rights and liberties. Policies should, among other things, be transparent, be reflected in public documentation to the extent possible, include requirements for evaluating FRT uses, and provide for ongoing monitoring and mitigation of risks. In particular, policies should address the topics and uses described in greater detail below. 38 a."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_85",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nthe technology may be used, including guardrails that protect civil rights and liberties. Policies should, among other things, be transparent, be reflected in public documentation to the extent possible, include requirements for evaluating FRT uses, and provide for ongoing monitoring and mitigation of risks. In particular, policies should address the topics and uses described in greater detail below. 38 a. Algorithm Evaluation Before a law enforcement agency begins using an FRT system, it is essential to understand whether the benefits and risks of the system are appropriate for the intended use. Evaluating the algorithms in an FRT system is an important step and includes quantifying how well the system correctly matches faces when a match exists in the database, how well it rejects incorrect matches, and how these types of performance differ across demographic groups. 39 An FRT system with better performance can provide greater value in investigations and reduce the likelihood of harmful consequences. NIST’s ongoing Face Recognition Technology Evaluation (FRTE) program provides valuable algorithm performance benchmarks. The program includes one -to-many performance testing on over 350 FRT algorithms and one -to-one demographic testing (race, gender, and a ge) on over 500 algorithms.40 The results of NIST’s testing can help law enforcement agencies understand and compare algorithms. As valuable as it is, the NIST testing program has important limitations."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_86",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nEvaluation (FRTE) program provides valuable algorithm performance benchmarks. The program includes one -to-many performance testing on over 350 FRT algorithms and one -to-one demographic testing (race, gender, and a ge) on over 500 algorithms.40 The results of NIST’s testing can help law enforcement agencies understand and compare algorithms. As valuable as it is, the NIST testing program has important limitations. The datasets used in testing predominantly consist of images from a controlled or semi -controlled environment, where the subject is close to the camera, the subject is looking at or near the camera, and lighting is adequate. These datasets may be sufficiently representative for some criminal justice 36 See PATRICK GROTHER ET AL ., NAT’L INST. STANDARDS & TECH, FACE RECOGNITION VENDOR TEST (FRVT) PART 3: DEMOGRAPHIC EFFECTS (2019) https://doi.org/10.6028/NIST.IR.8280 ; P. Jonathan Phillips et al., An Other -race Effect for Face Recognition Algorithms , 8 ACM TRANSACTIONS ON APPLIED PERCEPTION 1 (201 1), https://dl.acm.org/doi/10.1145/1870076.1870082; NIST supra note 34. 37 See Valeriia Cherepanova et al. , A Deep Dive into Dataset Imbalance and Bias in Face Identification, AIES (2023) https://dl.acm.org/doi/fullHtml/10.1145/3600211.3604691 . 38 Law enforcement agencies can use existing templates to guide policy development, including the FRT Policy Development Template. Face Recognition Policy Development Template , BUREAU JUST. ASSISTANCE (Dec."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_87",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nAPPLIED PERCEPTION 1 (201 1), https://dl.acm.org/doi/10.1145/1870076.1870082; NIST supra note 34. 37 See Valeriia Cherepanova et al. , A Deep Dive into Dataset Imbalance and Bias in Face Identification, AIES (2023) https://dl.acm.org/doi/fullHtml/10.1145/3600211.3604691 . 38 Law enforcement agencies can use existing templates to guide policy development, including the FRT Policy Development Template. Face Recognition Policy Development Template , BUREAU JUST. ASSISTANCE (Dec. 2017), https://bja.ojp.gov/sites/g/files/xyckuh186/files/Publications/Face -Recognition- Policy -Development -Template -508- compliant.pdf . 39 In NIST’s 1:N FRTE program, the core metrics are the false negative identification rate and the false positive identification rate. There are many other possible performance and bias metrics to compute for FRT systems, beyond those included in NIST’s valuable program, like for other AI systems. There are also other types of bias to consider, such as people with disabilities. Testing with other metrics and for other types of biases may be appropriate depending on the intended use. 40 See NIST supra note 34. As NIST explains in its demographic testing methods, it is possible for many FRT algorithms to extrapolate one -to-many demographic results from one -to-one results. 20 applications where test results may be indicative of the system’s performance, such as FRT use to match booking photos to driver’s license photos."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_88",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ndepending on the intended use. 40 See NIST supra note 34. As NIST explains in its demographic testing methods, it is possible for many FRT algorithms to extrapolate one -to-many demographic results from one -to-one results. 20 applications where test results may be indicative of the system’s performance, such as FRT use to match booking photos to driver’s license photos. The datasets used in NIST’s current testing may, however, not be representative of law enforcement investigative uses of FRT. These uses often involve images that are not from controlled environments, such as still images from surveillance camera footage . The subject may be distant, looking away, dimly or unevenly lit, or located below the camera. The camera may be of low quality or introduce distortions, and the image or the subject’s face may be occluded. These significant differences in context make it difficult to generalize the results of NIST’s current testing to FRT performance and biases when used in law enforcement investigations. NIST is in the process of reestablishing a line of performance testing for FRT use on images from videos, including from surveillance cameras. This type of testing, the Face In Video Evaluation (FIVE), may be more representative of law enforcement investigation settings.41 Law enforcement agencies considering use of FRT should establish testing requirements for performance and biases."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_89",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nlaw enforcement investigations. NIST is in the process of reestablishing a line of performance testing for FRT use on images from videos, including from surveillance cameras. This type of testing, the Face In Video Evaluation (FIVE), may be more representative of law enforcement investigation settings.41 Law enforcement agencies considering use of FRT should establish testing requirements for performance and biases. This testing should, to the extent possible, be representative of real - world deployment contexts and follow standardized methodologies. NIST’s testing program is an important starting point, and the ISO/IEC 19795 standards on biometric performance testing also provide valuable guidance. Agency policies should specify the nature of and benchmarks for testing and should ensure retention and disclosure of testing results to the extent feasible. Policies should also require that that vendors provide evaluation results for the system version that is procured by agencies, not results for a previous or adjusted versions of the system, and that the docum entation and results from vendors be sufficient to allow for independent evaluation and/or auditing. Continuous monitoring, discussed further below, can provide additional information about the real -world performance and biases of FRT systems. When pre -deployment testing is not fully representative of how an FRT system will be used, post -deployment monitoring is especially important."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_90",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nsystem, and that the docum entation and results from vendors be sufficient to allow for independent evaluation and/or auditing. Continuous monitoring, discussed further below, can provide additional information about the real -world performance and biases of FRT systems. When pre -deployment testing is not fully representative of how an FRT system will be used, post -deployment monitoring is especially important. At the federal level, OMB Memorandum M -24-10 identifies law investigative uses of FRT as AI use cases that presumptively require heightened risk management practices, including performance and bias testing in real -world conditions. OMB Memorandum M -24-18 further directs federal agencies that procure FRT capabilities to ensure that they have been tested by NIST, where practicable. State, local, Tribal, and territorial law enforcement agencies should also implement these practices, and federal grantmaking agencies should require these practices when providing financial support for the procurement or use of FRT , accounting for the differing missions and resources of grant recipients . 42 41 FIVE will report performance measurements for FRT algorithms but, importantly, may not include measurements of demographic differences."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_91",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nand territorial law enforcement agencies should also implement these practices, and federal grantmaking agencies should require these practices when providing financial support for the procurement or use of FRT , accounting for the differing missions and resources of grant recipients . 42 41 FIVE will report performance measurements for FRT algorithms but, importantly, may not include measurements of demographic differences. 42 For example, in some instances, it may be appropriate for a state, local, Tribal , or territorial law enforcement agency to evaluate a prospective FRT use on the basis of real -world FRT testing conducted by , on behalf of , or in coordination with other law enforcement agencies, provided that the testing is representative of the agency’s FRT uses. 21 b. Database Selection Agencies may have access to multiple FRT systems with different databases, and some FRT systems have the capability to run searches against multiple databases. Depending on the agency and use case, searches can be run against criminal records, driver’s license photographs, other agencies’ databases, or commercial databases. While the likelihood of developing a useful investigative lead generally increases with an expanded search, so too does the likelihood of an FRT system returning candidate matches with high similarity scores —and possibly high visual similarity for human re viewers —that are not the person to be identified."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_92",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nagainst criminal records, driver’s license photographs, other agencies’ databases, or commercial databases. While the likelihood of developing a useful investigative lead generally increases with an expanded search, so too does the likelihood of an FRT system returning candidate matches with high similarity scores —and possibly high visual similarity for human re viewers —that are not the person to be identified. A larger set of databases or data can also increase the risk that a user may unintentionally exceed their authority by searching a dataset or accessing a photo for an unauthorized purpose. Agency policies should clearly articulate to users what datasets are available for each type of search, as well as the purposes for which a search of a given dataset is authorized. Agency agreements to access external data sources should also contain appro priate restrictions on the use of the data being accessed. Agencies should establish processes to log FRT uses, enabling auditing to ensure that searches have been conducted for authorized purposes. In selecting databases to use, agencies should give careful consideration to how the underlying data was collected. Some commercial FRT services make use of databases that contain millions, or even billions of images scraped from social media and other onl ine services and websites."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_93",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nto log FRT uses, enabling auditing to ensure that searches have been conducted for authorized purposes. In selecting databases to use, agencies should give careful consideration to how the underlying data was collected. Some commercial FRT services make use of databases that contain millions, or even billions of images scraped from social media and other onl ine services and websites. This repurposing of personal photographs, in a context different from the ones in which they were originally created and shared —potentially without consent and contrary to expectations —potentially raises questions of law, policy, and ethics. These types of commercial services also generally have less reliable, less complete, and less current information associated with photos than do FRT systems based on government identification records, which can misdirect investigative efforts. Some law enforcement agencies prohibit the use of these types of systems, and others permit their use only in certain types of investigations. OMB Memoranda M -24-10 and M-24-18 specifically direct federal agencies to carefully consider whether and when us e of these types of FRT systems is appropriate. Law enforcement agencies should not use FRT systems trained on photos or built with other information that was collected in violation of laws, f ederal government guidance, or agency policy."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_94",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ncertain types of investigations. OMB Memoranda M -24-10 and M-24-18 specifically direct federal agencies to carefully consider whether and when us e of these types of FRT systems is appropriate. Law enforcement agencies should not use FRT systems trained on photos or built with other information that was collected in violation of laws, f ederal government guidance, or agency policy. Agencies should also specifically articulate the authority that permits the collection of FRT biometric data or associated personally identifiable information, which should be reflected in public documentation whenever possible. c. Use of Facial Recognition Law enforcement agencies substantially differ in their policies regarding when an investigation may make use of facial recognition. At some agencies, facial recognition is available for all criminal investigations. At others, only certain types of investigations may make use of FRT, such as for violent crimes and child safety. As noted above, at some law enforcement agencies, FRT use is prohibited. 22 There is further divergence in the predication standards that law enforcement agencies implement for using facial recognition. At some agencies, investigators have discretion about turning to FRT. At others, investigators must meet a reasonable suspicion s tandard. And at some agencies, investigators must have probable cause to conduct an FRT search. Real-time use of FRT is another area where law enforcement agencies have differing policies."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_95",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nthe predication standards that law enforcement agencies implement for using facial recognition. At some agencies, investigators have discretion about turning to FRT. At others, investigators must meet a reasonable suspicion s tandard. And at some agencies, investigators must have probable cause to conduct an FRT search. Real-time use of FRT is another area where law enforcement agencies have differing policies. Some prohibit it, while others allow it but restrict use directed at protected speech activities. Law enforcement agencies that use FRT should establish policies that clearly specify when FRT may be used. These policies should be public and easily accessible to the greatest extent possible. Agency policies should describe the types of investigations in which FRT use is appropriate, taking into account factors such as the type of the criminal offense, the likelihood of generating a true match, the evaluated performance of the FRT system, and the quality of relevant data. Agency policies should also delineate t he circumstances in which it is appropriate to conduct FRT searches, such as to provide a lead for identifying a witness, perpetrator, victim, or a person who is missing or otherwise belie ved to be at risk of harm. Policies should additionally specify what predication is necessary to take the step of an FRT search. A policy should also describe the level of supervisory review, if any, necessary before conducting a search."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_96",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nas to provide a lead for identifying a witness, perpetrator, victim, or a person who is missing or otherwise belie ved to be at risk of harm. Policies should additionally specify what predication is necessary to take the step of an FRT search. A policy should also describe the level of supervisory review, if any, necessary before conducting a search. Policies should also distinguish between the different types of FRT use and account for the varying levels of risk of harm. For example, using FRT to identify an unknown perpetrator need not be treated the same as using FRT to organize and triage collected media. In addition to specifying when FRT may be used, policies should specify when it may not be used. At minimum, policies should prohibit the use of FRT solely based on constitutionally protected activities (e.g., a First Amendment- protected protest), to facil itate unlawful discrimination, or in any other way that would be inconsistent with legal requirements or other policies. d. Image Quality The quality of the probe image submitted to an FRT system is a critical factor in whether the system can return a match. Many factors can affect the performance and biases of an FRT system, including photo resolution and clarity; the subject’s pose and att ire; lighting; occlusions; and the camera’s position, sensor, and lens. Additionally, modifications to the probe image — including to size, aspect ratio, or coloration—could potentially have an adverse impact on FRT results."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_97",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nthe system can return a match. Many factors can affect the performance and biases of an FRT system, including photo resolution and clarity; the subject’s pose and att ire; lighting; occlusions; and the camera’s position, sensor, and lens. Additionally, modifications to the probe image — including to size, aspect ratio, or coloration—could potentially have an adverse impact on FRT results. In general, searches with lower -quality images are less likely to return matches. In a law enforcement investigation, however, only lower -quality images may be available. Law enforcement agencies can mitigate risks associated with probe photo selection by establishing minimum quality criteria. 43 Where possible, these criteria should be set by an 43 The Facial Identification Scientific Working Group (FISWG) —a consortium of state, local, federal, and international law enforcement agencies as well as FRT vendors and academics —provides voluntary image quality 23 independent entity with expertise in FRT, such as a testing or standards -setting organization. These criteria may differ depending on the type of use, the feasibility of alternative investigative steps, and agency resources. An agency might conclude, for e xample, that the minimum quality criteria for locating a missing person or identifying a victim of child sex trafficking should be different from the criteria for identifying a witness to a nonviolent crime."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_98",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n-setting organization. These criteria may differ depending on the type of use, the feasibility of alternative investigative steps, and agency resources. An agency might conclude, for e xample, that the minimum quality criteria for locating a missing person or identifying a victim of child sex trafficking should be different from the criteria for identifying a witness to a nonviolent crime. The policies that law enforcement agencies establish for FRT should also address use of probe images that are not photographs of the person to be identified. These images may include sketch drawings, generated images, or images of people who are “lookalikes” for the subject. Searches with these types of images can be more prone to incorrect matches,44 so a policy should establish when (if ever) they are permitted and should require heightened safeguards when they are used. Law enforcement agencies should also implement policies that prohibit the use of FRT with probe images that were collected in violation of law or another applicable policy. e. Quality Control for Results The FRT systems used in law enforcement investigations are inexact, and a system may return candidate matches that are not the subject.45 Law enforcement agencies should apply a minimum similarity threshold for candidate results, which may vary depending on the nature of the investigation and should only be overridden in exigent circumstances. Human review is also essential."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_99",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nControl for Results The FRT systems used in law enforcement investigations are inexact, and a system may return candidate matches that are not the subject.45 Law enforcement agencies should apply a minimum similarity threshold for candidate results, which may vary depending on the nature of the investigation and should only be overridden in exigent circumstances. Human review is also essential. Law enforcement agencies should require that an examiner who is trained to compare faces and mitigate bias —and who ideally is independent of the case team —manually reviews results before they are used in an investigation. When there are multiple candidate results from an FRT system, an examiner should review all top results, and similarly a case team should consider all candidates returned by an examiner before focusing on one candidate result for further investigation. standards. Image Factors to Consider in Facial Image Comparison, FACIAL IDENTIFICATION SCI. WORKING GRP. (May 28, 2021), https://fiswg.org/fiswg_image_factors_to_consider_in_facial_img_comparison_v1.0_2021.05.28.pdf . The International Standardization Organization has worked with other organizations to develop the ISO/IEC 30137 series, which outlines effective video system performance for FRT and other uses. See generally ISO/IEC JTC 1/SC 37: Biometrics , INT’L STANDARDIZATION ORG. & INT’L ELECTROTECHNICAL COMM ’N, https://www.iso.org/committee/313770.html ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_100",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nto Consider in Facial Image Comparison, FACIAL IDENTIFICATION SCI. WORKING GRP. (May 28, 2021), https://fiswg.org/fiswg_image_factors_to_consider_in_facial_img_comparison_v1.0_2021.05.28.pdf . The International Standardization Organization has worked with other organizations to develop the ISO/IEC 30137 series, which outlines effective video system performance for FRT and other uses. See generally ISO/IEC JTC 1/SC 37: Biometrics , INT’L STANDARDIZATION ORG. & INT’L ELECTROTECHNICAL COMM ’N, https://www.iso.org/committee/313770.html . ISO/IEC 30137 -1:2024: Information technology — Use of biometrics in video surveillance systems , INT’L STANDARDIZATION ORG. & INT’L ELECTROTECHNICAL COMM ’N (2024), https://www.iso.org/standard/87734.html . 44 See, e.g., NAT’L INST. STANDARDS & TECH, NIST INTERAGENCY REPORT 8009, FACE RECOGNITION VENDOR TEST 4 (2014) , https://nvlpubs.nist.gov/nistpubs/ir/2014/NIST.IR.8009.pdf (documenting high error rates in sketch recognition); Christian Galea & Reuben A. Farrugia, Forensic Face Photo- Sketch Recognition Using a Deep Learning- Based Architecture, 24 IEEE SIGNAL PROCESSING LETTERS 1586 (2017) , https://ieeexplore.ieee.org/document/8025793 (discussing performance deep learning for face photo -sketch recognition) ; CLARE GARVIE , GARBAGE IN, GARBAGE OUT (2019), https://www.flawedfacedata.com/ (“Even the most detailed sketches make poor face recognition probe images . . . ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_101",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nChristian Galea & Reuben A. Farrugia, Forensic Face Photo- Sketch Recognition Using a Deep Learning- Based Architecture, 24 IEEE SIGNAL PROCESSING LETTERS 1586 (2017) , https://ieeexplore.ieee.org/document/8025793 (discussing performance deep learning for face photo -sketch recognition) ; CLARE GARVIE , GARBAGE IN, GARBAGE OUT (2019), https://www.flawedfacedata.com/ (“Even the most detailed sketches make poor face recognition probe images . . . . The most likely outcome of using a forensic sketch as a probe photo is that the system fails to find a match—even when the suspect is in the photo database available to law enforcement.”). 45 See NAS 2024 Report supra note 4, at 1,6. 24 Law enforcement agencies should take steps to minimize the risks of automation bias (i.e., examiner deference to system output) and confirmation bias (i.e., reinforcing an examiner’s beliefs about a subject or the system). These steps could include removing similarity scores or ranking information from the results shown to examiners, reminding examiners of the limitations of FRT systems, and providing appropriate training on facial comparison and mitigating biases (discussed further below). f. Uses of FRT Results In addition to specifying when and how investigators can use FRT, law enforcement agency policies should establish permissible uses of results."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_102",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ninclude removing similarity scores or ranking information from the results shown to examiners, reminding examiners of the limitations of FRT systems, and providing appropriate training on facial comparison and mitigating biases (discussed further below). f. Uses of FRT Results In addition to specifying when and how investigators can use FRT, law enforcement agency policies should establish permissible uses of results. Because of the limitations of FRT, policies should specify that FRT search results should be considered a lead and not sufficient to establish probable cause or a positive identification without corroboration. Policies should describe when and how FRT can support probable cause. This can be a complex issue where FRT plays a role in witness identification , which may also involve comparing faces. At least one law enforcement agency prohibits conducting a lineup based solely on an FRT investigative lead without independent and reliable evidence linking the suspect to the crime . 46 g. End-to-End Evaluation and Continuous Monitoring When law enforcement agencies use FRT systems in investigations, it is essential to understand the technical performance and biases of these systems, as noted above. It is also important to understand the broader context for and impacts of FRT use, includi ng why investigators use it, how it affects investigations, and how it affects the people who appear in results."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_103",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nWhen law enforcement agencies use FRT systems in investigations, it is essential to understand the technical performance and biases of these systems, as noted above. It is also important to understand the broader context for and impacts of FRT use, includi ng why investigators use it, how it affects investigations, and how it affects the people who appear in results. This type of “end- to-end” operational evaluation is a best practice for AI governance and, at the federal level, encouraged by OMB Memorandum M-24-10. Law enforcement agencies should consider implementing end- to-end evaluation for uses of FRT. This evaluation could address questions like: What are the types of cases where investigators turn to FRT, and why do they use FRT instead of other investigative methods? How valuable are the leads from FRT in advancing investigations? How often does FRT generate a lead for investigators that could not have been developed otherwise, or that would have taken considerably more time or resources otherwise? How often does FRT lead investigators to focus on a person who is later determined to not be relevant to an investigation? Answering basic questions like these can be important for evaluating the benefits and risks of FRT use, and can help reinforce community trust by demonstrating the practical impacts of FRT. Continuous monitoring is another form of evaluation that law enforcement agencies should consider."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_104",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ninvestigators to focus on a person who is later determined to not be relevant to an investigation? Answering basic questions like these can be important for evaluating the benefits and risks of FRT use, and can help reinforce community trust by demonstrating the practical impacts of FRT. Continuous monitoring is another form of evaluation that law enforcement agencies should consider. An FRT system’s behavior is affected by both probe and gallery photos. If there are changes in either type of photo—for example, if a law enforcement agency starts focusing on a particular type of photo as evidence or if a state changes its driver’s license photo format —that can impact the performance and biases of the system. FRT vendors also update their algorithms, which can also affect performance and bias es. Continuously keeping track of real -world 46 U.S. COMM ’N CIV. RTS., THE CIVIL RIGHTS IMPLICATIONS OF THE FEDERAL USE OF FACIAL RECOGNITION TECHNOLOGY 112-13 (2024) , https://www.usccr.gov/files/2024 -09/civil- rights -implications -of-frt_0.pdf (Stmt. of Vice Chair Nourse) (discussing Detroit Police Department pr actices and policies). 25 performance and bias statistics can substantiate a system’s ongoing value and can alert an agency if there are changes that need attention. OMB Memorandum M -24-10 requires federal law enforcement agencies to implement continuous monitoring for FRT uses. h."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_105",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n(2024) , https://www.usccr.gov/files/2024 -09/civil- rights -implications -of-frt_0.pdf (Stmt. of Vice Chair Nourse) (discussing Detroit Police Department pr actices and policies). 25 performance and bias statistics can substantiate a system’s ongoing value and can alert an agency if there are changes that need attention. OMB Memorandum M -24-10 requires federal law enforcement agencies to implement continuous monitoring for FRT uses. h. Restrictions on FRT Use and Logging Policies should prohibit the use of FRT systems unless the agency has approved the system, the user, and the use. Policies and procedures should prohibit and establish consequences for unauthorized or improper use of a FRT biometric system (including examples discussed above, such as use based solely on constitutionally protected activity). Agencies should retain detailed internal logs of FRT system use for auditing and ensuring compliance with requirements. i. Transparency Regarding FRT Use As feasible, law enforcement agencies should adopt policies that require them to publicly disclose their use of FRT use, including details of the system in use, and the nature and purpose of the use. Agencies should also engage with community stakeholders about FRT and, to the extent possible, provide transparent responses about how they use FRT. At the federal level, OMB Memorandum M -24-10 requires these practices for law enforcement uses of FRT ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_106",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ntheir use of FRT use, including details of the system in use, and the nature and purpose of the use. Agencies should also engage with community stakeholders about FRT and, to the extent possible, provide transparent responses about how they use FRT. At the federal level, OMB Memorandum M -24-10 requires these practices for law enforcement uses of FRT . Federal law enforcement agencies must provide public transparency about FRT uses in an annual AI inventory. Agencies are also required to engage with stakeholders to obtain their input. j. Data Management Law enforcement agency policies on FRT should describe the collection, management, storage, and retention requirements for requests, probe images, and results. Policies should also describe security, privacy, recordkeeping, and audit requirements. Agencies should ensure compliance with any connected system policies, including FBI’s Criminal Justice Information Services (CJIS) Security Policy. 47 k. Training Documented and effective training is critical for the successful implementation of FRT. A policy should establish training requirements for personnel who will interact with FRT or its results. Training should address all aspects of an agency’s FRT policy, including when investigators may run an FRT search and how the results may be used. Training should also provide background on the technology and its limitations, including how incorrect matches can occur and may disproportionately affect certain demographic groups."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_107",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nrequirements for personnel who will interact with FRT or its results. Training should address all aspects of an agency’s FRT policy, including when investigators may run an FRT search and how the results may be used. Training should also provide background on the technology and its limitations, including how incorrect matches can occur and may disproportionately affect certain demographic groups. 47 See generally B UREAU JUST. ASSISTANCE , FACE RECOGNITION POLICY DEVELOPMENT TEMPLATE (Dec. 2017), https://bja.ojp.gov/sites/g/files/xyckuh186/files/Publications/Face -Recognition- Policy -Development -Template -508- compliant.pdf (d iscussing best pract ices and applicable standards for security ). 26 Training related to FRT should also cover the risks of human biases, such as automation and confirmation bias, when using FRT.48 These biases can cause personnel to place undue weight on certain results, and strategies are available to mitigate the risk.49 Demographic bias (explicit or implicit) can also affect human judgment and should be addressed in training."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_108",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nsecurity ). 26 Training related to FRT should also cover the risks of human biases, such as automation and confirmation bias, when using FRT.48 These biases can cause personnel to place undue weight on certain results, and strategies are available to mitigate the risk.49 Demographic bias (explicit or implicit) can also affect human judgment and should be addressed in training. Research has shown that the innate ability to recognize faces varies widely and that people less reliably identify others from a different race.50 This bias may compound with biases in FRT algorithms.51 Training for FRT use in law enforcement should be appropriate to a person’s role and should convey the information necessary for responsibly submitting a probe image, analyzing results from an FRT system, and using the results in law enforcement activities . Roles for training that may be common across law enforcement agencies include:52 • Facial Examiner: Compares a probe photo to candidate matches from an FRT system to develop possible investigative leads. • Collector (Includes Investigators): Obtains probe images for use with an FRT system. • Facial Reviewer (Includes Investigators): Reviews results of an FRT search adjudicated by a facial examiner. • Supervisor: Oversees personnel involved with FRT and ensures compliance with law and policy."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_109",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nExaminer: Compares a probe photo to candidate matches from an FRT system to develop possible investigative leads. • Collector (Includes Investigators): Obtains probe images for use with an FRT system. • Facial Reviewer (Includes Investigators): Reviews results of an FRT search adjudicated by a facial examiner. • Supervisor: Oversees personnel involved with FRT and ensures compliance with law and policy. Failure to properly train individuals who interact with FRT systems can increase the risk of potential errors at each step of the facial recognition process, which could ultimately impact individuals’ privacy, civil rights, and civil liberties. Automated License Plate Recognition License Plate Readers (LPRs) are cameras with computer vision capabilities designed to detect and capture information from license plates within their field of view. C omputer vision is an area of AI that can identify patterns and objects in images. In the criminal justice context, LPR cameras can be mounted on patrol vehicles to identify vehicles in connection with criminal investigations, including stolen vehicles, vehicles owned by wanted persons, vehicles involved in 48 See Reva Schwartz et al. , NAT. INST. STANDARDS & TECH. SPECIAL PUBL’N 1270, TOWARDS A STANDARD FOR IDENTIFYING AND MANAGING BIAS IN ARTIFICIAL INTELLIGENCE 26 (2022), https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.1270.pdf . (discussing systemic biases, statistical and computational biases, and human biases )."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_110",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nto identify vehicles in connection with criminal investigations, including stolen vehicles, vehicles owned by wanted persons, vehicles involved in 48 See Reva Schwartz et al. , NAT. INST. STANDARDS & TECH. SPECIAL PUBL’N 1270, TOWARDS A STANDARD FOR IDENTIFYING AND MANAGING BIAS IN ARTIFICIAL INTELLIGENCE 26 (2022), https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.1270.pdf . (discussing systemic biases, statistical and computational biases, and human biases ). 49 See Samuel Peterson et al. , RAND, Finding a Broadly Practical Approach for Regulating the Use of Facial Recognition by Law Enforcement 32 (Feb. 15, 2023) , https://www.rand.org/pubs/research_reports/RRA2249- 1.html (discussing sources of bias, including human decisionmaking). 50 Jacqueline G. Cavazos et al. , Learning Context and the Other -Race Effect: Strategies for Improving Face Recognition, 157 V ISION RSCH., Apr. 2019, 169, 169– 83, https://nij.ojp.gov/library/publications/learning -context - and-other -race- effect -strategies -improving- face- recognition . 51 See Peterson et al., supra , note 49. 52 See FACIAL IDENTIFICATION SCI. WORKING GRP., GUIDE FOR ROLE-BASED TRAINING IN FACIAL COMPARISON (2020), https://fiswg.org/fiswg_guide_for_role -based_training_in_facial_comparison_v1.0_20200717.pdf (listing different roles in a facial comparison environment including assessor, reviewer, examiner, manager, supervisor, collector, technical reviewer, and trainer)."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_111",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n2019, 169, 169– 83, https://nij.ojp.gov/library/publications/learning -context - and-other -race- effect -strategies -improving- face- recognition . 51 See Peterson et al., supra , note 49. 52 See FACIAL IDENTIFICATION SCI. WORKING GRP., GUIDE FOR ROLE-BASED TRAINING IN FACIAL COMPARISON (2020), https://fiswg.org/fiswg_guide_for_role -based_training_in_facial_comparison_v1.0_20200717.pdf (listing different roles in a facial comparison environment including assessor, reviewer, examiner, manager, supervisor, collector, technical reviewer, and trainer). 27 an ongoing emergency like kidnapping, or vehicles being operated in an unlawful manner, enabling timely law enforcement action. LPR data also enables retrospectively tracking the movements of a vehicle of interest. LPR cameras can be mounted in fixed locations to identify vehicles entering or exiting sensitive locations, including prisons or other government facilities, as well as known locations of criminal activity to identify potential criminals or enable facility security activities. The collected license plate numbers can be cross -referenced against law enforcement databases to identify vehicles. That information can be used to identify vehicles that may require law enforcement action, such as stolen vehicles or suspect vehicles. 53 LPR cameras, including both fixed and vehicle mounted cameras, can assist in locating vehicles during Amber alerts, Ashanti alerts, silver alerts, or similar emergency situations."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_112",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nplate numbers can be cross -referenced against law enforcement databases to identify vehicles. That information can be used to identify vehicles that may require law enforcement action, such as stolen vehicles or suspect vehicles. 53 LPR cameras, including both fixed and vehicle mounted cameras, can assist in locating vehicles during Amber alerts, Ashanti alerts, silver alerts, or similar emergency situations. 54 Some LPR systems are operated by law enforcement agencies, using their own cameras typically on their own patrol vehicles. Other LPR systems are commercial services, with networks of participating cameras (e.g., at parking lots) that agencies can subscribe to. LPR systems are in widespread use. Almost all large local law enforcement agencies have an LPR program, as do many smaller agencies. 55 Law enforcement agencies collect billions of LPR records per year. Like biometrics used for identification, LPR systems can serve as an effective tool for monitoring vehicles in connection with criminal investigations. LPR successes include apprehending violent offenders and rescuing abducted children. 56 The use of LPR systems, however, comes with some risks. For example, LPR systems can misread plates or misidentify stolen vehicles . 57 In addition, as with all large stores of data, a gencies may create privacy risks if they do not take the necessary steps to properly secure LPR data and dispose of it after it is no longer needed."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_113",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nuse of LPR systems, however, comes with some risks. For example, LPR systems can misread plates or misidentify stolen vehicles . 57 In addition, as with all large stores of data, a gencies may create privacy risks if they do not take the necessary steps to properly secure LPR data and dispose of it after it is no longer needed. LPR systems, like FRT systems, must be accompanied by strong policy and procedural guardrails to ensure appropriate use. 53 LPR systems in the United States are operated by both law enforcement agencies as well as commercial providers who operate the system as a service. As a result, the database referenced and system data retention policies are specific to each LPR system. 54 See U.S. DEP’T JUST, BUREAU JUST. ASSISTANCE , FACT SHEET : NATIONAL ASHANTI ALERT NETWORK (2021) . https://bja.ojp.gov/sites/g/files/xyckuh186/files/media/document/National- Ashanti -Alert- Network -Fact-Sheet.pdf (“Ashanti Alerts, once implemented, can provide rapid dissemination of information to law enforcement agencies, media, and the public about adults who have been reported missing, along with suspect information in cases of abduction.”). 55 U.S. DEP’T JUST., OFF. JUST. PROGS ., BUREAU JUST. STATS., LOCAL POLICE DEPARTMENTS , 2013: EQUIPMENT AND TECHNOLOGY (2015) , https://bjs.ojp.gov/content/pub/pdf/lpd13et.pdf (“An estimated 17% (about 2,000) of departments used automated license plate readers in 2013."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_114",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ninformation to law enforcement agencies, media, and the public about adults who have been reported missing, along with suspect information in cases of abduction.”). 55 U.S. DEP’T JUST., OFF. JUST. PROGS ., BUREAU JUST. STATS., LOCAL POLICE DEPARTMENTS , 2013: EQUIPMENT AND TECHNOLOGY (2015) , https://bjs.ojp.gov/content/pub/pdf/lpd13et.pdf (“An estimated 17% (about 2,000) of departments used automated license plate readers in 2013. This total included more than three -quarters of the departments serving 100,000 or more residents. ”). 56 ANGEL DIAZ & RACHEL LEVINSON -WALDMAN , AUTOMATIC LICENSE PLATE READERS : LEGAL STATUS AND POLICY RECOMMENDATIONS FOR LAW ENFORCEMENT USE, BRENNAN CTR. (2020), https://www.brennancenter.org/our - work/research -reports/automatic -license -plate -readers -legal -status -and-policy -recommendations . 57 Id. 28 LPR Risks and Mitigation a. Procedural Risks Agencies should establish clear policies that outline where, when, and for what purpose an LPR camera can be placed to enhance criminal justice operations. Policies and procedures should also clearly address retention periods for LPR records, as well as th e circumstances, if any, in which they can be searched. b. Accuracy and Reliability Accuracy in LPR technology is critical to avoid false positives, misidentifications, and misdirected law enforcement actions. Agencies should prioritize data quality, with standards and procedures for identifying and correcting errors. c."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_115",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nand procedures should also clearly address retention periods for LPR records, as well as th e circumstances, if any, in which they can be searched. b. Accuracy and Reliability Accuracy in LPR technology is critical to avoid false positives, misidentifications, and misdirected law enforcement actions. Agencies should prioritize data quality, with standards and procedures for identifying and correcting errors. c. Safeguarding Privacy and Data Security Protecting the security of LPR data is a priority. This includes implementing robust data encryption, access restrictions, and audit mechanisms to prevent unauthorized access and misuse. Agencies should adopt strong data security protocols to reinforce public confidence in LPR technology while safeguarding sensitive information. d. LPR Data Sharing Agencies should establish data sharing protocols if LPR data is shared with other agencies or third -party organizations. Data sharing agreements should include safeguards to protect privacy, and ensure all parties uphold the same standards of data security and ethical use. e. Training Proper training for using LPR systems is essential to ensure law enforcement personnel are aware of legal, ethical, and operational standards. This training should cover privacy protections, the importance of data accuracy, and the need to prevent bias in the use of LPR technology. 29 III."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_116",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nall parties uphold the same standards of data security and ethical use. e. Training Proper training for using LPR systems is essential to ensure law enforcement personnel are aware of legal, ethical, and operational standards. This training should cover privacy protections, the importance of data accuracy, and the need to prevent bias in the use of LPR technology. 29 III. Forensic Analysis Introduction Forensic analysis of physical, digital, and multimedia evidence is central to criminal investigation and litigation. In recent years, uses of AI —including statistical techniques and machine learning1—have accelerated the trend in forensic disciplines from subjective judgment in analyzing and interpreting forensic evidence toward more objective approaches.2 This paradigm shift has potential to improve the reproducibility and accuracy of forensic methods, mitigate the possible human biases and examiner variation that may affect forensic analysis, and reinforce public trust in the criminal justice system. 3 AI may also provide new capabilities and reduce the time and cost of analysis processes."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_117",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nand interpreting forensic evidence toward more objective approaches.2 This paradigm shift has potential to improve the reproducibility and accuracy of forensic methods, mitigate the possible human biases and examiner variation that may affect forensic analysis, and reinforce public trust in the criminal justice system. 3 AI may also provide new capabilities and reduce the time and cost of analysis processes. Professionals in forensic science have a responsibility to rigorously validate methods of analysis, and that responsibility remains with uses of AI.4 Properly designed validation studies can empirically demonstrate that a forensic method is reproducible and accurate, both in principle and 1 As noted in the I ntroduction, definitions of AI vary substantially, with some broadly encompassing statistics and others emphasizing recent advances in machine learning. This chapter considers statistical and machine learning methods together because the opportunities and challenges for forensic analysis are broadly similar, and because the approach is consistent with the definition of artificial intelligence in OMB Memoranda M -24-10 and M -24-18. See R. S HUTE ET AL ., WHAT FSSP LEADERS SHOULD KNOW ABOUT ARTIFICIAL INTELLIGENCE AND ITS APPLICATION TO FORENSIC SCIENCE 4 (Nat’l Inst. Just ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_118",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nlearning methods together because the opportunities and challenges for forensic analysis are broadly similar, and because the approach is consistent with the definition of artificial intelligence in OMB Memoranda M -24-10 and M -24-18. See R. S HUTE ET AL ., WHAT FSSP LEADERS SHOULD KNOW ABOUT ARTIFICIAL INTELLIGENCE AND ITS APPLICATION TO FORENSIC SCIENCE 4 (Nat’l Inst. Just . 2023), https://forensiccoe.org/private/65cfa81c601c4 (noting that automated and semi -automated systems used in forensic analysis require similar assessment, regardless of whether they are categorized as AI). 2See EXECUTIVE OFFICE OF THE PRESIDENT , PRESIDENT ’S COUNCIL OF ADVISORS ON SCIENCE AND TECHNOLOGY , FORENSIC SCIENCE IN CRIMINAL COURTS : ENSURING SCIENTIFIC VALIDITY OF FEATURE -COMPARISON METHODS 46- 54 (2016) (“PCAST Report”) , https://obamawhitehouse.archives.gov/sites/default/files/microsites/ostp/PCAST/pcast_forensic_science_report_fina l.pdf ( describing differences between subjective and objective forensic methods and explaining that objective methods are generally preferable). See also NATIONAL RESEARCH COUNCIL , STRENGTHENING FORENSIC SCIENCE IN THE UNITED STA TES : A PATH FORWARD (2009), https://nap.nationalacademies.org/catalog/12589/strengthening- forensic -science- in-the-united -states -a-path-forward ; JOSÉ ALMIRALL ET AL ., AM."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_119",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nFEATURE -COMPARISON METHODS 46- 54 (2016) (“PCAST Report”) , https://obamawhitehouse.archives.gov/sites/default/files/microsites/ostp/PCAST/pcast_forensic_science_report_fina l.pdf ( describing differences between subjective and objective forensic methods and explaining that objective methods are generally preferable). See also NATIONAL RESEARCH COUNCIL , STRENGTHENING FORENSIC SCIENCE IN THE UNITED STA TES : A PATH FORWARD (2009), https://nap.nationalacademies.org/catalog/12589/strengthening- forensic -science- in-the-united -states -a-path-forward ; JOSÉ ALMIRALL ET AL ., AM. ASS’N ADVANCEMENT SCI., FORENSIC SCIENCE ASSESSMENTS : A QUALITY AND GAP ANALYSIS : FIRE INVESTIGATION (2017), https://www.aaas.org/sites/default/files/s3fs- public/reports/Fire%2520Investigation_0.pdf ; WILLIAM THOMPSON ET AL., AM. ASS’N ADVANCEMENT SCI., FORENSIC SCIENCE ASSESSMENTS : A QUALITY AND GAP ANALYSIS : LATENT FINGERPRINT EXAMINATION (2017), https://www.aaas.org/sites/default/files/s3fs- public/reports/Latent%2520Fingerprint%2520Report%2520FINAL%25209_14.pdf ; J onathan J. Koehler et al. , The Scientific Reinvention of Forensic Science , 120 P ROCS . NAT’L ACAD. SCIS. e2301840120 (2023), https://doi.org/10.1073/pnas.2301840120 . 3 See, e.g., Mark Barash et al., Machine Learning Applications in Forensic DNA Profiling: A Critical Review , 69 FORENSIC SCI. INT.: GENETICS 13 (2024). 4 E.g., U.S."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_120",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nLATENT FINGERPRINT EXAMINATION (2017), https://www.aaas.org/sites/default/files/s3fs- public/reports/Latent%2520Fingerprint%2520Report%2520FINAL%25209_14.pdf ; J onathan J. Koehler et al. , The Scientific Reinvention of Forensic Science , 120 P ROCS . NAT’L ACAD. SCIS. e2301840120 (2023), https://doi.org/10.1073/pnas.2301840120 . 3 See, e.g., Mark Barash et al., Machine Learning Applications in Forensic DNA Profiling: A Critical Review , 69 FORENSIC SCI. INT.: GENETICS 13 (2024). 4 E.g., U.S. DEP’T JUST., CODE OF PROFESSIONAL RESPONSIBILITY FOR THE PRAC TICE OF FORENSIC SCIENCE (2016) (“DOJ Code”) , https://www.justice.gov/sites/default/files/code_of_professional_responsibility_for - the_practice_of_forensic_science_08242016.pdf ( “5. Conduct research and forensic casework using the scientific method or agency best practices. Where validation tools are not known to exist or cannot be obtained, conduct internal or inter -laboratory validation tests in accordance with the quality management system in place.”; “8. Conduct examinations that are fair, unbiased, and fit -for-purpose .”; “10. Ensure interpretations, opinions, and conclusions are supported by sufficient data and minimize influences and biases for or against any party.”). 30 as applied in a particular case.5 Validation can also enable forensic practitioners to convey valuable context for the results of forensic analysis, such as the likelihood of results occurring by chance or reflecting errors."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_121",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nand fit -for-purpose .”; “10. Ensure interpretations, opinions, and conclusions are supported by sufficient data and minimize influences and biases for or against any party.”). 30 as applied in a particular case.5 Validation can also enable forensic practitioners to convey valuable context for the results of forensic analysis, such as the likelihood of results occurring by chance or reflecting errors. The use of AI in forensic science can add complexity to validation. Models built from data can have nuanced performance characteristics and incorporate demographic biases. Models can also be sensitive to subtle differences between the data used during development and the data encountered in real -world use, such as differences in how data is collected and prepared for forensic analysis. The implementation of AI systems can be complicated and proprietary, which can make it difficult to validate that a system implements a forensic method as intended. These possible sources of additional complexity reinforce the importance in forensic science of responsible practices for developing, validating, and revalidating methods of analysis. Explainability is also important in forensic science. 6 Practitioners have a responsibility to explain in a straightforward manner the data that they analyzed, the methods that they applied, and the interpretations, observations, and conclusions that resulted from applying the methods to the data."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_122",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nreinforce the importance in forensic science of responsible practices for developing, validating, and revalidating methods of analysis. Explainability is also important in forensic science. 6 Practitioners have a responsibility to explain in a straightforward manner the data that they analyzed, the methods that they applied, and the interpretations, observations, and conclusions that resulted from applying the methods to the data. 7 AI models may not be readily understandable by humans and may learn from correlations in data that are difficult to discern and not necessarily causal.8 Differences like these may affect how stakeholders in the criminal justice system are able to explain forensic processes that involve AI. Expert oversight is another critical dimension of forensic science.9 AI should be a complement to the expertise of forensic practitioners, such as by recommending next steps for human consideration, checking human analysis, or providing a basis on which an expert might 5 See PCAST Report, supra note 2, at 42-43 (explaining the distinction between “foundational validity” and “validity as applied”) . 6 The term “explainability” has a particular technical meaning in evaluating artificial intelligence systems. Here, this report uses it in the colloquial sense. 7 Professional codes in forensic science often address explanation of data, methods, and conclusions. E .g., DOJ Code, supra note 4 (“12."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_123",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nnote 2, at 42-43 (explaining the distinction between “foundational validity” and “validity as applied”) . 6 The term “explainability” has a particular technical meaning in evaluating artificial intelligence systems. Here, this report uses it in the colloquial sense. 7 Professional codes in forensic science often address explanation of data, methods, and conclusions. E .g., DOJ Code, supra note 4 (“12. Prepare reports and testify using clear and straightforward terminology, clearly distinguishing data from interpretations, opinions, and conclusions. Reports should disclose known limitations that are necessary to understand the significance of the findings. ”; “15. Honestly communicate with all parties (the investigator, prosecutor, defense, and other expert witnesses) about all information relating to their analyses, when communications are permitted by law and agency practice.”). See E XECUTIVE OFFICE OF THE PRESIDENT , NAT’L SCI. & TECH. COUNCIL , STRENGTHENING THE FORENSIC SCIENCES 24 (2014), https://obamawhitehouse.archives.gov/sites/default/files/microsites/ostp/NSTC/forensic_science___may_2014.pdf (noting that, in a review of “more than 45 codes of ethics in use by various forensic science organizations,” a commonality was “the need to . . . provide clear and objective testimony”). Courts may also interpret legal standards for the admissibility of expert evidence, discussed further below, to require forms of explanation. E.g. , Zenith Elecs. Corp. v. WH -TV Broad. Corp."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_124",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\na review of “more than 45 codes of ethics in use by various forensic science organizations,” a commonality was “the need to . . . provide clear and objective testimony”). Courts may also interpret legal standards for the admissibility of expert evidence, discussed further below, to require forms of explanation. E.g. , Zenith Elecs. Corp. v. WH -TV Broad. Corp. , 395 F.3d 416, 419 (7th Cir. 2005) (explaining that “[a]n expert must offer good reason to think that his approach produces an accurate estimate using professional methods, and this estimate must be testable,” such that “[s]omeone else using the same data and methods must be able to replicate the result,” and that if an expert “could or would not explain how his conclusions met [these] requirements, he was not entitled to give expert testimony”). 8 Leo Breiman, Statistical Modeling: The Two Cultures (with Comments and a Rejoinder by the Author), 16 STAT. SCI. 199-231 (2001), https://doi.org/10.1214/ss/1009213726 . 9 E.g., DOJ Code , supra note 4 (“9. Make and retain contemporaneous, clear, complete, and accurate records of all examinations, tests, measurements, and conclusions, in sufficient detail to allow meaningful review and assessment by an independent professional proficient in the discipli ne.”)."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_125",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nTwo Cultures (with Comments and a Rejoinder by the Author), 16 STAT. SCI. 199-231 (2001), https://doi.org/10.1214/ss/1009213726 . 9 E.g., DOJ Code , supra note 4 (“9. Make and retain contemporaneous, clear, complete, and accurate records of all examinations, tests, measurements, and conclusions, in sufficient detail to allow meaningful review and assessment by an independent professional proficient in the discipli ne.”). 31 arrive at a conclusion.10 Practitioners have an essential role in interpreting the output from AI systems, forming and explaining conclusions, and (when necessary and appropriate) offering expert testimony in litigation. Training for practitioners can also ensure that forensic met hods involving AI are used properly and that results from analysis are accurately characterized. The first part of this chapter describes how AI is currently being used in forensic analysis, as well as research suggesting areas of forensic science where AI may be used in the future. The breadth of use cases speaks to the immense potential of AI for fo rensic science. The second part of the chapter discusses challenges for AI use in forensic science and means of mitigating the risks associated with AI use. The chapter closes with a set of recommendations for forensic research and practice. Current Uses of AI in Forensic Analysis Several factors have limited the integration of AI into forensic analysis."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_126",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nAI for fo rensic science. The second part of the chapter discusses challenges for AI use in forensic science and means of mitigating the risks associated with AI use. The chapter closes with a set of recommendations for forensic research and practice. Current Uses of AI in Forensic Analysis Several factors have limited the integration of AI into forensic analysis. These include the complex nature of forensic science, the standards for admissibility of forensic evidence in litigation, limited availability of high -quality and real (or realistic) data from forensic analysis settings, and resource constraints on forensic researchers and practitioners. As a result, real-world use of AI in forensics is presently limited outside of a few contexts. As discussed in the Identification and Surveillance chapter, AI is widely used in biometric analysis, including fingerprint, palm print, iris, and face comparison. These methods complement other means of identification, and they are often used to retrieve candidate matches fr om a database for further forensic analysis or law enforcement investigation. In DNA analysis, probabilistic genotyping can enable analysts to interpret complex samples that contain small amounts of DNA, mixed DNA, or damaged DNA that would be challenging for traditional analysis methods."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_127",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ncomparison. These methods complement other means of identification, and they are often used to retrieve candidate matches fr om a database for further forensic analysis or law enforcement investigation. In DNA analysis, probabilistic genotyping can enable analysts to interpret complex samples that contain small amounts of DNA, mixed DNA, or damaged DNA that would be challenging for traditional analysis methods. 11 The statistical methods used for this type of forensic analysis typically estimate a likelihood ratio, comparing the probability of DNA observations given one proposition (e.g., that a defendant contributed genetic material to a sample) to the probability of observations given a stated alternative proposition (e.g., that an unknown person in a relevant population contributed to the sample). 12 The particular statistical analysis, population data, and 10 H. Swofford & C. Champod, Implementation of Algorithms in Pattern & Impression Evidence: A Responsible and Practical Roadmap, 3 FORENSIC SCI. INT’L: SYNERGY (2021), https://doi.org/10.1016/j.fsisyn.2021.100142 . 11 See Michael D. Coble & Jo -Anne Bright, Probabilistic Genotyping Software: An Overview , 38 F ORENSIC SCI. INT’L: GENETICS 219 (2019). As noted at the outset of the chapter, definitions of artificial intelligence differ. Some practitioners, for example, may not consider probabilistic genotyping to be a type of AI. See R."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_128",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nFORENSIC SCI. INT’L: SYNERGY (2021), https://doi.org/10.1016/j.fsisyn.2021.100142 . 11 See Michael D. Coble & Jo -Anne Bright, Probabilistic Genotyping Software: An Overview , 38 F ORENSIC SCI. INT’L: GENETICS 219 (2019). As noted at the outset of the chapter, definitions of artificial intelligence differ. Some practitioners, for example, may not consider probabilistic genotyping to be a type of AI. See R. SHUTE ET AL ., supra note 1, at 3 (describing disagreement about whether probabilistic genotyping is AI and noting it is at minimum part of an “automated system” that can exhibit bias). 12 See, e.g., Peter Gill et al., DNA Commission of the International Society of Forensic Genetics: Recommendations on the Evaluation of STR Typing Results That May Include Drop- out and/or Drop- in Using Probabilistic Methods , 6 FORENSIC SCI. INT’L: GENETICS 679 (2012), http://dx.doi.org/10.1016/j.fsigen.2012.06.002 ; Hannah Kelly et al., A Description of the Likelihood Ratios in the Probabilistic Genotyping Software STRmix , 2 WIRE S FORENSIC SCIENCE (2020), https://doi.org/10.1002/wfs2.1377 ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_129",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nthe International Society of Forensic Genetics: Recommendations on the Evaluation of STR Typing Results That May Include Drop- out and/or Drop- in Using Probabilistic Methods , 6 FORENSIC SCI. INT’L: GENETICS 679 (2012), http://dx.doi.org/10.1016/j.fsigen.2012.06.002 ; Hannah Kelly et al., A Description of the Likelihood Ratios in the Probabilistic Genotyping Software STRmix , 2 WIRE S FORENSIC SCIENCE (2020), https://doi.org/10.1002/wfs2.1377 . 32 assumptions underlying probabilistic genotyping methods can vary, leading to different results.13 The extent of validation research also differs by probabilistic genotyping method.14 Forensic genetic genealogy is another type of DNA analysis that can involve statistical models.15 These methods of analysis can enable the generation of leads by comparing a DNA sample to a large database of samples and estimating possible genealogical relationships. Narcotics tracing is another area of forensics where AI is in use today. The Drug Enforcement Administration (DEA), for example, uses machine learning models to classify the geographic region of origin for samples of heroin and cocaine.16 The DEA’s system was developed with authentic drug samples and can detect anomalies in analysis and low -confidence results. This program is valuable for understanding trends in drug trafficking, though the results are not presently used as evidence in court."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_130",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n(DEA), for example, uses machine learning models to classify the geographic region of origin for samples of heroin and cocaine.16 The DEA’s system was developed with authentic drug samples and can detect anomalies in analysis and low -confidence results. This program is valuable for understanding trends in drug trafficking, though the results are not presently used as evidence in court. AI features are increasingly common in tools for forensic analysis of digital and multimedia evidence. 17 Computer vision techniques, for example, can assist forensic examiners in searching large and unorganized collections of photos and videos for specific content, such as weapons, nudity, or violence, that may be helpful to an investigation. Natural language processing methods can similarly help identify files and communications that relate to particular topics. Machine translation can support examiners who are analyzing evidence that involves multiple languages. AI can be valuable, in some circumstances, fo r identifying and analyzing evidence that may have been created or modified by AI (e.g., “deepfake” images, videos, and audio). 18 These uses of AI for analysis of digital and multimedia evidence are predominantly, for now, in support of investigative steps rather than expert conclusions offered in court. 13 See John Buckleton et al., A Diagnosis of the Primary Difference Between EuroForMix and STRmix ™, 69 J. FORENSIC SCI."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_131",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ncreated or modified by AI (e.g., “deepfake” images, videos, and audio). 18 These uses of AI for analysis of digital and multimedia evidence are predominantly, for now, in support of investigative steps rather than expert conclusions offered in court. 13 See John Buckleton et al., A Diagnosis of the Primary Difference Between EuroForMix and STRmix ™, 69 J. FORENSIC SCI. 40 (2024), https://doi.org/10.1111/1556- 4029.15387 ; Peter Gill et al., A Review of Probabilistic Genotyping Systems: EuroForMix, DNAStatistX and STRmix ™, 12 G ENES 1559 (2021), https://www.mdpi.com/2073 -4425/12/10/1559 ; Susan A. Greenspoon et al. , A Tale of Two PG Systems: A Comparison of the Two Most Widely Used Probabilistic Genotyping Systems in the United States , 69 J. FORENSIC SCI. 1840 (2024), https://doi.org/10.1111/1556- 4029.15571 . 14 See the discussion below for further detail about validation of probabilistic genotyping software. 15 See FORENSIC TECH. CTR. OF EXCELLENCE ., AN INTRODUCTION TO FORENSIC GENETIC GENEALOGY TECHNOLOGY FOR FORENSIC SCIENCE SERVICE PROVIDERS (Nat’l Inst. of Just . 2022), https://forensiccoe.org/private/66291221e66ec ; U.S. DEP’T JUST., INTERIM POLICY ON FORENSIC GENETIC GENEALOGICAL DNA ANALYSIS AND SEARCHING (2019), https://www.justice.gov/olp/page/file/1204386/dl . 16 U.S. DEP’T JUST., 2023 AI USE CASE INVENTORY , https://www.justice.gov/open/file/1305831/dl ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_132",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nof probabilistic genotyping software. 15 See FORENSIC TECH. CTR. OF EXCELLENCE ., AN INTRODUCTION TO FORENSIC GENETIC GENEALOGY TECHNOLOGY FOR FORENSIC SCIENCE SERVICE PROVIDERS (Nat’l Inst. of Just . 2022), https://forensiccoe.org/private/66291221e66ec ; U.S. DEP’T JUST., INTERIM POLICY ON FORENSIC GENETIC GENEALOGICAL DNA ANALYSIS AND SEARCHING (2019), https://www.justice.gov/olp/page/file/1204386/dl . 16 U.S. DEP’T JUST., 2023 AI USE CASE INVENTORY , https://www.justice.gov/open/file/1305831/dl . 17 E.g., Inseyets, CELLEBRITE , https://cellebrite.com/en/cellebrite -inseyets/ ; Magnet Axiom, MAGNET FORENSICS , https://www.magnetforensics.com/products/magnet -axiom/ . There is a broad range of possible additional applications of AI for digital and multimedia forensics. See Johannes Fähndrich et al., Digital Forensics and Strong AI: A Structured Literature Review , 46 F ORENSIC SCI. INT’L: DIGITAL INVESTIGATIONS (2023), https://doi.org/10.1016/j.fsidi.2023.301617 . 18 E.g., Video Authentication Software, MEDEX FORENSICS , https://medexforensics.com/medex -platform/ . The performance of AI -based tools for analyzing possible AI -generated or AI -modified content varies significantly, and the value of these tools depends on the nature of the evidence and the investigative context. 33 Future Uses of AI in Forensic Analysis Recent and ongoing research has demonstrated a range of additional possible future applications of AI in forensic analysis. a."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_133",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nperformance of AI -based tools for analyzing possible AI -generated or AI -modified content varies significantly, and the value of these tools depends on the nature of the evidence and the investigative context. 33 Future Uses of AI in Forensic Analysis Recent and ongoing research has demonstrated a range of additional possible future applications of AI in forensic analysis. a. Pattern and Trace Evidence AI may be well suited for assisting experts in the comparison and categorization of some types of pattern and trace evidence.19 Recent research has shown promise in applications of AI for assisting experts in analyzing toolmarks on bullets20 and cartridges,21 impressions of footwear outsoles,22 fragments of glass,23 traces of automotive paint,24 and ignitable liquids,25 among other types of evidence. 19 Trace evidence involves material that has been transferred between objects, people, or the environment. 20 E.g., Eric Hare et al. , Algorithmic Approaches to Match Degraded Land Impressions, 16 L AW, PROBABILITY & RISK 203-21 (2017), https://doi.org/10.1093/lpr/mgx018 ; Susan Vanderplas et al., Comparison of T hree Similarity Scores for B ullet LEA M atching, 308 F ORENSIC SCI. INT’L (2020), https://www.sciencedirect.com/science/article/pii/S0379073820300293 ; Pattranit Pisantanaroj et al., Automated Firearm Classification From Bullet Markings Using Deep Learning, 8 IEEE ACCESS 78236 (2020), https://ieeexplore.ieee.org/document/9076037 . 21 E.g., Xiao Hui Tai & William F."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_134",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nAW, PROBABILITY & RISK 203-21 (2017), https://doi.org/10.1093/lpr/mgx018 ; Susan Vanderplas et al., Comparison of T hree Similarity Scores for B ullet LEA M atching, 308 F ORENSIC SCI. INT’L (2020), https://www.sciencedirect.com/science/article/pii/S0379073820300293 ; Pattranit Pisantanaroj et al., Automated Firearm Classification From Bullet Markings Using Deep Learning, 8 IEEE ACCESS 78236 (2020), https://ieeexplore.ieee.org/document/9076037 . 21 E.g., Xiao Hui Tai & William F. Eddy, A Fully Automatic Method for Comparing Cartridge Case Images, 63 J. FORENSIC SCI. 440 (201 8), https://onlinelibrary.wiley.com/doi/full/10.1111/1556 -4029.13577 ; Joseph R oth et al., Learning- based Ballistic Breech Face Impression Image Matching , 2015 IEEE 7TH INTERNATIONAL CONFERENCE ON BIOMETRICS THEORY , APPLICATIONS AND SYSTEMS (2015), https://ieeexplore.ieee.org/document/7358774 . 22 E.g., Soyoung Park & Alicia Carriquiry, An Algorithm to Compare Two- dimensional Footwear Outsole Images Using Maximum Cliques and Speeded -up Robust Feature, 13 STAT. ANALYSIS & DATA MINING : THE ASA DATA SCI. J. 188 (2020), https://onlinelibrary.wiley.com/doi/full/10.1002/sam.11449 ; Hana Lee et al., An Automated Alignment Algorithm for Identification of the Source of Footwear Impressions with Common Class Characteristics , 17 S TAT. ANALYSIS & DATA MINING : THE ASA DATA SCI. J."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_135",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nOutsole Images Using Maximum Cliques and Speeded -up Robust Feature, 13 STAT. ANALYSIS & DATA MINING : THE ASA DATA SCI. J. 188 (2020), https://onlinelibrary.wiley.com/doi/full/10.1002/sam.11449 ; Hana Lee et al., An Automated Alignment Algorithm for Identification of the Source of Footwear Impressions with Common Class Characteristics , 17 S TAT. ANALYSIS & DATA MINING : THE ASA DATA SCI. J. (2024), https://dl.acm.org/doi/10.1002/sam.11659 ; Gautham Venkatasubramanian et al., Quantitative Evaluation of Footwear E vidence: Initial W orkflow for an E nd-to-end System , 66 J. OF FORENSIC SCI. 2232 (2021), https://onlinelibrary.wiley.com/doi/full/10.1111/1556 -4029.14802 ; Gautham Venkatasubramanian et al., Comparing footwear impressions that are close non- matches using correlation- based approaches , 66 J. FORENSIC SCI. 2232 (2021), https://onlinelibrary.wiley.com/doi/10.1111/1556 -4029.14658 ; Moonsoo Jang & Soyoung Park, A Finely Tuned Deep Transfer Learning Algorithm to Compare Outsole Images , 16 STAT. ANALYSIS & DATA MINING : THE ASA DATA SCI. J. 511 (2023), https://onlinelibrary.wiley.com/doi/abs/10.1002/sam.11636 ; Zhijian Wen et al., Shoeprint Image Retrieval and Crime Scene Shoeprint Image Linking by Using Convolutional Neural Network and Normalized Cross Correlation, 63 S CI. & JUST."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_136",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nMoonsoo Jang & Soyoung Park, A Finely Tuned Deep Transfer Learning Algorithm to Compare Outsole Images , 16 STAT. ANALYSIS & DATA MINING : THE ASA DATA SCI. J. 511 (2023), https://onlinelibrary.wiley.com/doi/abs/10.1002/sam.11636 ; Zhijian Wen et al., Shoeprint Image Retrieval and Crime Scene Shoeprint Image Linking by Using Convolutional Neural Network and Normalized Cross Correlation, 63 S CI. & JUST. 439 (2023), https://doi.org/10.1016/j.scijus.2023.04.014 ; Samia Shafique et al., CriSp: Leveraging Tread Depth Maps for Enhanced Crime -Scene Shoeprint Matching , ARXIV (2024), https://arxiv.org/abs/2404.16972 . 23 E.g., Omer Kaspi et al., Toward Developing Techniques─Agnostic Machine Learning Classification Models for Forensically Relevant Glass Fragments, 63 J. CHEMICAL INFO. & MODELING 87 (2022), https://pubs.acs.org/doi/full/10.1021/acs.jcim.2c01362 ; Grzegorz Zadora, Glass Analysis for Forensic Purposes —A Comparison of Classification Methods, 21 J. CHEMOMETRICS 174 (2007), https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/10.1002/cem.1030 . 24 E.g., Francis Kwofie et al., Transmission Infrared Microscopy and Machine Learning Applied to the Forensic Examination of Original Automotive Paint , 76 APPLIED SPECTROSCOPY 118 (2021), https://journals.sagepub.com/doi/10.1177/00037028211057574 ; George P."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_137",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n63 J. CHEMICAL INFO. & MODELING 87 (2022), https://pubs.acs.org/doi/full/10.1021/acs.jcim.2c01362 ; Grzegorz Zadora, Glass Analysis for Forensic Purposes —A Comparison of Classification Methods, 21 J. CHEMOMETRICS 174 (2007), https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/10.1002/cem.1030 . 24 E.g., Francis Kwofie et al., Transmission Infrared Microscopy and Machine Learning Applied to the Forensic Examination of Original Automotive Paint , 76 APPLIED SPECTROSCOPY 118 (2021), https://journals.sagepub.com/doi/10.1177/00037028211057574 ; George P. Affadu -Danful et al., Raman Spectroscopy to Enhance Investigative Lead Information in Automotive Clearcoats , 77 A PPLIED SPECTROSCOPY 1064 (2023), https://journals.sagepub.com/doi/full/10.1177/00037028231186838 . 25 E.g., Christian Bogdal et al., Recognition of Gasoline in Fire Debris Using Machine Learning, 331 F ORENSIC SCI. INT’L (2022), https://doi.org/10.1016/j.forsciint.2021.111146 ; Michael E. Sigman et al., Validation of Ground Truth Fire Debris Classification by Supervised Machine Learning , 26 F ORENSIC CHEMISTRY (2021), https://doi.org/10.1016/j.forc.2021.100358 . 34 b. Drug Evidence Analysis of seized drug samples is another promising area."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_138",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n25 E.g., Christian Bogdal et al., Recognition of Gasoline in Fire Debris Using Machine Learning, 331 F ORENSIC SCI. INT’L (2022), https://doi.org/10.1016/j.forsciint.2021.111146 ; Michael E. Sigman et al., Validation of Ground Truth Fire Debris Classification by Supervised Machine Learning , 26 F ORENSIC CHEMISTRY (2021), https://doi.org/10.1016/j.forc.2021.100358 . 34 b. Drug Evidence Analysis of seized drug samples is another promising area. Research has demonstrated that AI can assist with classifying fentanyl analogs and related compounds,26 marijuana varieties,27 and novel psychoactive substances.28 These approaches generally combine established chemistry methods for identifying components of compounds, such as mass spectrometry, with machine learning methods to analyze the components and make categorizations. c. Forensic Medicine, Pathology, and Anthropology AI may assist with assessing injuries and injury mechanics. Analyzing a photograph of a bruise, for example, may enable estimating the date of the injury.29 AI may also be able to supplement expert analysis of human remains.30 Recent publications show that it is feasible to estimate sex,31 age,32 and population affinity33 from images and 2D and 3D computed tomography scans of skeletal and dental remains. AI may assist with identifying decedents, including through post -mortem iris recognition 34 and association of remains with 26 E.g., Travon Cooman et al."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_139",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nable to supplement expert analysis of human remains.30 Recent publications show that it is feasible to estimate sex,31 age,32 and population affinity33 from images and 2D and 3D computed tomography scans of skeletal and dental remains. AI may assist with identifying decedents, including through post -mortem iris recognition 34 and association of remains with 26 E.g., Travon Cooman et al. , Evaluation and Classification of Fentanyl -related Compounds Using EC -SERS and Machine Learning, 68 J. FORENSIC SCI. 1520 (2023), https://onlinelibrary.wiley.com/doi/10.1111/1556 -4029.15285 ; Phillip Koshute et al. , Machine Learning Model for Detecting Fentanyl Analogs from Mass Spectra, 27 F ORENSIC CHEMISTRY 100379 (2022), https://www.sciencedirect.com/science/article/abs/pii/S2468170921000758 . 27 E.g., Austin McDaniel et al., Toward the Identification of Marijuana Varieties by Headspace Chemical Forensics , 11 FORENSIC CHEMISTRY 23-31 (2018), https://doi.org/10.1016/j.forc.2018.08.004 . 28 Swee Liang Wong et al., Screening Unknown Novel Psychoactive Substances Using GC -MS based Machine Learning, 34 F ORENSIC CHEMISTRY 100499 (2023), https://www.sciencedirect.com/science/article/abs/pii/S2468170923000358?via%3Dihub . 29 E.g., Jhonatan Tirado & David Mauricio, Bruise Dating Using Deep Learning, 66 J. FORENSIC SCI. 336 (2020), https://pmc.ncbi.nlm.nih.gov/articles/PMC7821214/ ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_140",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nof Marijuana Varieties by Headspace Chemical Forensics , 11 FORENSIC CHEMISTRY 23-31 (2018), https://doi.org/10.1016/j.forc.2018.08.004 . 28 Swee Liang Wong et al., Screening Unknown Novel Psychoactive Substances Using GC -MS based Machine Learning, 34 F ORENSIC CHEMISTRY 100499 (2023), https://www.sciencedirect.com/science/article/abs/pii/S2468170923000358?via%3Dihub . 29 E.g., Jhonatan Tirado & David Mauricio, Bruise Dating Using Deep Learning, 66 J. FORENSIC SCI. 336 (2020), https://pmc.ncbi.nlm.nih.gov/articles/PMC7821214/ . 30 See Laurent Tournois et al., Artificial Intelligence in the Practice of Forensic Medicine: A Scoping Review, 138 INT’L J. LEGAL MED. 1023 (2023), https://pmc.ncbi.nlm.nih.gov/articles/PMC11003914/ ; Nicola Galante et al., Applications of Artificial Intelligence in Forensic Sciences: Current Potential Benefits, Limitations and Perspectives , 137 INT’L J. LEGAL MED. 445 (2022), https://doi.org/10.1007/s00414- 022-02928-5 ; Andrej Thurzo et al., Use of Advanced Artificial Intelligence in Forensic Medicine , Forensic Anthropology and Clinical Anatomy , 9 HEALTHCARE 1545 (2021), https://www.mdpi.com/2227 -9032/9/11/1545 ; Micayla C. Spiros & Sherry Nakhaeizadeh, We Think There’ s Been a Glitch : Artificial Intelligence and Machine Learning in Forensic Anthropology , 7 F ORENSIC ANTHROPOLOGY (2024), https://journals.upress.ufl.edu/fa/article/view/2827 ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_141",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n(2022), https://doi.org/10.1007/s00414- 022-02928-5 ; Andrej Thurzo et al., Use of Advanced Artificial Intelligence in Forensic Medicine , Forensic Anthropology and Clinical Anatomy , 9 HEALTHCARE 1545 (2021), https://www.mdpi.com/2227 -9032/9/11/1545 ; Micayla C. Spiros & Sherry Nakhaeizadeh, We Think There’ s Been a Glitch : Artificial Intelligence and Machine Learning in Forensic Anthropology , 7 F ORENSIC ANTHROPOLOGY (2024), https://journals.upress.ufl.edu/fa/article/view/2827 . 31 Javier Venema et al., Employing Deep Learning for Sex Estimation of Adult Individuals using 2D Images of the Humerus , 35 N EURAL COMPUTING & APPLICATIONS 5987 (2023 ), https://link.springer.com/article/10.1007/s00521- 022-07981-0 ; Tomoyuki Seo et al., Sex Estimation Using Skull Silhouette Images from Postmortem Computed Tomography by Deep Learning, 14 S CI. REPS. 22689 (2024), https://www.nature.com/articles/s41598 -024-74703 -y; Yongjie Cao et al., Use of Deep Learning in Forensic Sex Estimation of Virtual Pelvic Models from the Han Population, 7 F ORENSIC SCIS. RES. 540 (2022), https://academic.oup.com/fsr/article/7/3/540/6987953 . 32 Juan Carlos G ámez- Granados et al., Automating the D ecision Making Process of Todd’ s Age Estimation Method from the P ubic Symphysis with E xplainable Machine Learning, 612 I NFORMATION SCI. 514 (2022), https://www.sciencedirect.com/science/article/pii/S0020025522010301?via%3Dihub ; NICHOLAS P."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_142",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nForensic Sex Estimation of Virtual Pelvic Models from the Han Population, 7 F ORENSIC SCIS. RES. 540 (2022), https://academic.oup.com/fsr/article/7/3/540/6987953 . 32 Juan Carlos G ámez- Granados et al., Automating the D ecision Making Process of Todd’ s Age Estimation Method from the P ubic Symphysis with E xplainable Machine Learning, 612 I NFORMATION SCI. 514 (2022), https://www.sciencedirect.com/science/article/pii/S0020025522010301?via%3Dihub ; NICHOLAS P. HERRMANN ET AL., INVESTIGATION OF SUBADULT DENTAL AGE-AT-DEATH ESTIMATION USING TRANSITION ANALYSIS AND MACHINE LEARNING METHODS (Off. Just. Progs. 2023), https://www.ojp.gov/pdffiles1/nij/grants/306558.pdf . 33 David Navega et al., AncesTrees : Ancestry Estimation with Randomized Decision Trees , 129 I NT’L J. LEGAL MED. 1145, 1145 -1153 (201 5),; G. Richard Scott et al., rASUDAS: A New Web -Based Application for Estimating Ancestry from Tooth Morphology , 1 F ORENSIC ANTHROPOLOGY 18, 18- 31 (2018) ,. 34 Aidan Boyd et al., Post -Mortem Iris Recognition —A Survey and Assessment of the State of the Art , 8 IEEE ACCESS 136570, 136570 (2020) ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_143",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nMED. 1145, 1145 -1153 (201 5),; G. Richard Scott et al., rASUDAS: A New Web -Based Application for Estimating Ancestry from Tooth Morphology , 1 F ORENSIC ANTHROPOLOGY 18, 18- 31 (2018) ,. 34 Aidan Boyd et al., Post -Mortem Iris Recognition —A Survey and Assessment of the State of the Art , 8 IEEE ACCESS 136570, 136570 (2020) . 35 radiographs, dental records, photos, and 3D scans.35 Where remains are incomplete, AI may help experts impute missing measurements.36 Machine learning methods may also assist experts in categorizing and annotating images of remains,37and may be able to suggest certain causes of death, such as head trauma38 or drowning.39 The ability of AI tools to effectively support forensic analysis in these ways will be contingent on the quality of photographs or imagery, among other factors. d. Forensic Biology AI has the promise of providing experts with new capabilities in probabilistic genetic analysis. These methods may improve the accuracy of genetic sequencing,40 overcome gaps in degraded samples,41 support inference of the number of contributors to a DNA mixture,42 and enable predictions about physical appearance based on genetic information.43 35 David C. Cornett et al., Effects of Postmortem Decomposition on Face Recognition, IEEE 10TH INT’L CONF. BIOMETRICS THEORY , APPLICATIONS , AND SYS. (2019), https://ieeexplore.ieee.org/document/9185971 ; A. Valsecchi et al., Skeleton -ID: AI- driven Human Identification, IEEE CONF. ARTIFICIAL INTEL ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_144",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nthe number of contributors to a DNA mixture,42 and enable predictions about physical appearance based on genetic information.43 35 David C. Cornett et al., Effects of Postmortem Decomposition on Face Recognition, IEEE 10TH INT’L CONF. BIOMETRICS THEORY , APPLICATIONS , AND SYS. (2019), https://ieeexplore.ieee.org/document/9185971 ; A. Valsecchi et al., Skeleton -ID: AI- driven Human Identification, IEEE CONF. ARTIFICIAL INTEL . (2023), https://ieeexplore.ieee.org/abstract/document/10195123 . 36 Jinyong Pang & Xiaoming Liu, Evaluation of Missing Data Imputation Methods for Human Osteometric Measurements , 181 A M. J. BIOLOGICAL ANTHROPOLOGY 666 (2023), https://onlinelibrary.wiley.com/doi/10.1002/ajpa.24787 . 37 AUDRIS MOCKUS & DAWNIE WOLFE STEADMAN , ICPUTRD: IMAGE CLOUD PLATFORM FOR USE IN TAGGING AND RESEARCH ON DECOMPOSITION (Off. Just. Progs. 2020), https://www.ojp.gov/pdffiles1/nij/grants/255312.pdf ; Sara Mousavi et al., Machine -Assisted Annotation of Forensic Imagery, 2019 IEEE INT’L CONF. ON IMAGE PROCESSING 1595 (2019), https://ieeexplore.ieee.org/document/8803068 ; Jack Garland et al., Identifying Gross Post - mortem Organ Images Using a Pre -trained Convolutional Neural Network , 66 J. FORENSIC SCI. 630 (2021 ), https://onlinelibrary.wiley.com/doi/10.1111/1556 -4029.14608 . 38 Jack Garland et al., Identifying Fatal Head Injuries on Postmortem Computed Tomography Using Convolutional Neural Network/Deep Learning: A Feasibility Study , 65 J."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_145",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nON IMAGE PROCESSING 1595 (2019), https://ieeexplore.ieee.org/document/8803068 ; Jack Garland et al., Identifying Gross Post - mortem Organ Images Using a Pre -trained Convolutional Neural Network , 66 J. FORENSIC SCI. 630 (2021 ), https://onlinelibrary.wiley.com/doi/10.1111/1556 -4029.14608 . 38 Jack Garland et al., Identifying Fatal Head Injuries on Postmortem Computed Tomography Using Convolutional Neural Network/Deep Learning: A Feasibility Study , 65 J. FORENSIC SCIS., 2019 ( 2020) , https://onlinelibrary.wiley.com/doi/full/10.1111/1556 -4029.14502 . 39 Noriyasu Homma et al., A Deep Learning Aided Drowning Diagnosis for Forensic Investigations U sing Post - Mortem Lung CT Images , 42ND ANNUAL INT’L CONF. OF THE IEEE ENG’G MED. & BIOLOGY SOC’Y (2020), https://ieeexplore.ieee.org/document/9175731 . 40 August E. Woerner et al., Reducing Noise and Stutter in Short Tandem Repeat Loci with Unique Molecular Identifiers , 51 F ORENSIC SCI. INT’L: GENETICS 102459 (2021) , https://www.fsigenetics.com/article/S1872 - 4973(20)30231- 3/abstract ; Michael A. Marciano et al., A Hybrid Approach to Increase the Informedness of CE - based Data Using Locus -specific Thresholding and Machine Learning, 35 F ORENSIC SCI. INT’L: GENETICS 26 (2018), https://www.fsigenetics.com/article/S1872 -4973(17)30313- 7/abstract ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_146",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nin Short Tandem Repeat Loci with Unique Molecular Identifiers , 51 F ORENSIC SCI. INT’L: GENETICS 102459 (2021) , https://www.fsigenetics.com/article/S1872 - 4973(20)30231- 3/abstract ; Michael A. Marciano et al., A Hybrid Approach to Increase the Informedness of CE - based Data Using Locus -specific Thresholding and Machine Learning, 35 F ORENSIC SCI. INT’L: GENETICS 26 (2018), https://www.fsigenetics.com/article/S1872 -4973(17)30313- 7/abstract . 41 Meng Huang et al., A Machine Learning Approach for Missing Persons Cases with High Genotyping Errors , 13 FRONTIERS GENETICS 1 (2022 ) https://www.frontiersin.org/journals/genetics/articles/10.3389/fgene.2022.971242 . 42 Michael A. Marciano & Jonathan D. Adelman , PACE: Probabilistic Assessment for Contributor Estimation —A Machine Learning- based Assessment of the N umber of C ontributors in DNA M ixtures , 27 FORENSIC SCI. INT’L: GENETICS 82 (2017 ), https://pubmed.ncbi.nlm.nih.gov/28040630/ ; Hamdah Alotaibi et al. , DNA Profiling: An Investigation of Six Machine Learning Algorithms for Estimating the Number of Contributors in DNA Mixtures , 12 INT’L J. ADVANCED COMPUT . SCI. & APPLICATIONS 1 (2021 ), http://dx.doi.org/10.14569/IJACSA.2021.0121115 . 43 Maria- Alexandra Katsara et al. , Evaluation of S upervised Machine -learning Methods for Predicting Appearance Traits from DNA , 53 F ORENSIC SCI. INT’L: GENETICS 102507 (2021) , https://doi.org/10.1016/j.fsigen.2021.102507 ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_147",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nSix Machine Learning Algorithms for Estimating the Number of Contributors in DNA Mixtures , 12 INT’L J. ADVANCED COMPUT . SCI. & APPLICATIONS 1 (2021 ), http://dx.doi.org/10.14569/IJACSA.2021.0121115 . 43 Maria- Alexandra Katsara et al. , Evaluation of S upervised Machine -learning Methods for Predicting Appearance Traits from DNA , 53 F ORENSIC SCI. INT’L: GENETICS 102507 (2021) , https://doi.org/10.1016/j.fsigen.2021.102507 . 36 Analysis of other types of biological evidence may also benefit from AI. Applying AI to microscopy images, for example, may assist experts with locating sperm cells in sexual assault evidence.44 Advances in forensic biology could be particularly valuable for investigations of violent crimes, where a perpetrator or victim may be more likely to leave biological evidence. e. Forensic Toxicology In toxicological analysis, AI may enable experts to identify unknown compounds.45 Automated analysis may also be able to assess the toxicity of compounds, supporting treatment decisions made by medical professionals. 46 f. Crime Scene Analysis Complex crime scenes may involve thousands of photographs with nuanced attributes for forensic examiners to review and document. AI can support experts’ work by automatically categorizing crime scene photographs based on visible items of interest, such as drugs and weapons."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_148",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nbe able to assess the toxicity of compounds, supporting treatment decisions made by medical professionals. 46 f. Crime Scene Analysis Complex crime scenes may involve thousands of photographs with nuanced attributes for forensic examiners to review and document. AI can support experts’ work by automatically categorizing crime scene photographs based on visible items of interest, such as drugs and weapons. 47 AI may also be able to improve the quality of crime scene imagery for expert analysis, such as for scenes that are underwater.48 In some instances, automated tools may be able to aid analysts in interpreting evidence within crime scene photographs, such as categorizing the potential mechanism that caused a blood spatter pattern. 49 Challenges for AI in Forensic Analysis The preceding chapter on Identification and Surveillance and the later chapter on Risk Assessment describe several challenges that are equally applicable to uses of AI in forensic analysis. In short, high -quality and representative data, rigorous and independent testing for performance and biases, ongoing monitoring, and established policies and oversight are all critical 44 Raffael Golomingi et al., Sperm Hunting on Optical Microscope Slides for Forensic Analysis with Deep Convolutional Networks – A Feasibility Study , 56 F ORENSIC SCI. INT’L: GENETICS 102602 (2022), https://www.sciencedirect.com/science/article/pii/S1872497321001393 . 45 Toshal D."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_149",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nshort, high -quality and representative data, rigorous and independent testing for performance and biases, ongoing monitoring, and established policies and oversight are all critical 44 Raffael Golomingi et al., Sperm Hunting on Optical Microscope Slides for Forensic Analysis with Deep Convolutional Networks – A Feasibility Study , 56 F ORENSIC SCI. INT’L: GENETICS 102602 (2022), https://www.sciencedirect.com/science/article/pii/S1872497321001393 . 45 Toshal D. Wankhade et al., Artificial Intelligence in Forensic Medicine and Toxicology: The Future of Forensic Medicine , 14 C UREUS (2022), https://doi.org/10.7759/cureus.28376 ; Zhoumeng Lin & Wei -Chun Chou, Machine Learning and Artificial Intelligence in Toxicological Sciences , 189 T OXICOL . SCI. 7 (2022), https://doi.org/10.1093/toxsci/kfac075 . 46 See, e.g., Thi Tuyet Van Tran et al., Artificial Intelligence in Drug Toxicity Prediction: Recent Advances, Challenges, and Future Perspectives , 63 J. CHEM. INFO. & MODELING 2628 (2023), https://doi.org/10.1021/acs.jcim.3c00200 . 47 Joshua Abraham et al., Automatically Classifying Crime Scene Images Using Machine Learning Methodologies , 39 F ORENSIC SCI. INT’L: DIGIT AL INVESTIGATION 301273 (2021) , https://doi.org/10.1016/j.fsidi.2021.301273 ; Amaljith Sreekumar et al. , Weapons and Related Object Classification in Digital Forensic Using Machine Learning, 14TH INT’L CONF. ON COMPUTING COMM C’NS & NETWORKING TECH S."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_150",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nMODELING 2628 (2023), https://doi.org/10.1021/acs.jcim.3c00200 . 47 Joshua Abraham et al., Automatically Classifying Crime Scene Images Using Machine Learning Methodologies , 39 F ORENSIC SCI. INT’L: DIGIT AL INVESTIGATION 301273 (2021) , https://doi.org/10.1016/j.fsidi.2021.301273 ; Amaljith Sreekumar et al. , Weapons and Related Object Classification in Digital Forensic Using Machine Learning, 14TH INT’L CONF. ON COMPUTING COMM C’NS & NETWORKING TECH S. 1 (2023), https://ieeexplore.ieee.org/abstract/document/10307988 . 48 Rosella Paba et al., Optimizing Underwater Visual Records for Crime Scene Investigations in Water with Clear to Reduced Visibility, 6 FORENSIC SCI. INT’L: SYNERGY 100329 ( 2023) , https://doi.org/10.1016/j.fsisyn.2023.100329 . 49 Yu Liu et al., Automatic Classification of Bloodstain Patterns Caused by Gunshot and Blunt Impact at Various Distances , 65 J. FORENSIC SCIS. 729 ( 2020) , https://doi.org/10.1111/1556- 4029.14262 . 37 for uses of AI in criminal justice, including in support of forensic science. This section notes several challenges that could be particularly acute for the use of AI in forensic analysis. a. Datasets A large volume of high- quality data is essential for developing and evaluating AI uses in forensic analysis. If there is insufficient data, or if data has errors or gaps, that can undermine the potential value of AI for forensic science and create risks of harm from mistaken conclusions."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_151",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nacute for the use of AI in forensic analysis. a. Datasets A large volume of high- quality data is essential for developing and evaluating AI uses in forensic analysis. If there is insufficient data, or if data has errors or gaps, that can undermine the potential value of AI for forensic science and create risks of harm from mistaken conclusions. Data that is properly distributed across a range of demographics and scenarios is also critical. This helps prevent bias in AI uses, leading to more consistent and fair forensic analysis. Forensic analysis often depends on specialized data, such as data collected with dedicated equipment or from samples that are not readily available. 50 Preparing forensic datasets that are adequate for AI can also be expensive and labor intensive. Coordination by forensic experts worldwide to provide highly accurate and representative data may be essential for some uses of AI in forensic science.51 Respecting privacy is another important consideration for forensic science datasets. The data can be personal and sensitive, necessitating appropriate safeguards. b. Validation As noted earlier, analysis methods used in forensic science should be carefully studied for validity in principle, validity as applied in particular cases, and ongoing validity. Validation is essential for understanding the reliability and limitations of e vidence analysis."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_152",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nprivacy is another important consideration for forensic science datasets. The data can be personal and sensitive, necessitating appropriate safeguards. b. Validation As noted earlier, analysis methods used in forensic science should be carefully studied for validity in principle, validity as applied in particular cases, and ongoing validity. Validation is essential for understanding the reliability and limitations of e vidence analysis. Experts should be able to effectively characterize the accuracy and errors of AI used in forensic science, including the possibility of demographic disparities. When a forensic method involves AI, performance testing, bias testing, and continuous monitoring are all important steps for validation. Review of the implementation of an AI system, including the source code, can also be appropriate in some circumstances. At the federal level, OMB Memorandum M -24-10 requires testing and monitoring for certain use cases of AI used in support of forensic analysis . OMB Memorandum M -24-18 further requires use of independent testing data to the extent practicable, prohibits contractual restrictions on agency disclosure of testing methods and results, and encourages consideration of open- source AI implementations. As an example, the path to widespread adoption of probabilistic genotyping highlights the importance and value of rigorous validation for new uses of AI in forensic science."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_153",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nMemorandum M -24-18 further requires use of independent testing data to the extent practicable, prohibits contractual restrictions on agency disclosure of testing methods and results, and encourages consideration of open- source AI implementations. As an example, the path to widespread adoption of probabilistic genotyping highlights the importance and value of rigorous validation for new uses of AI in forensic science. When 50 Because forensic analysis can involve specialized data, practitioners should be especially attentive to the risks of overfitting, where a model may learn correlations in training data that do not generalize to data in real -world uses. Overfitting can degr ade performance and lead to unexpected model behaviors. At the federal level, OMB Memorandum M- 24-10 specifically cautions agencies to consider the risks of overfitting. 51 See Toshal D. Wankhade et al., Artificial Intelligence in Forensic Medicine and Toxicology : The Future of Forensic Medicine, 14 C UREUS 1, 4 (2022) , https://doi.org/10.7759/cureus.28376 . This type of data may be less necessary for certain types of analysis for digital and multimedia evidence, where the possible range of formats is determined by readily available software."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_154",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\noverfitting. 51 See Toshal D. Wankhade et al., Artificial Intelligence in Forensic Medicine and Toxicology : The Future of Forensic Medicine, 14 C UREUS 1, 4 (2022) , https://doi.org/10.7759/cureus.28376 . This type of data may be less necessary for certain types of analysis for digital and multimedia evidence, where the possible range of formats is determined by readily available software. 38 probabilistic genotyping began regularly appearing in forensic DNA analysis in the mid-2010s,52 the President’s Council of Advisors on Science and Technology (PCAST) expressed optimism that these methods could improve on prior approaches to analyzing samples with complex DNA mixtures, while also emphasizing the need for further validation.53 PCAST concluded that studies had demonstrated validity in principle, but only for some mixtures of genetic material, and that additional steps were necessary to demonstrate validity as applied by laboratories. PCAST also expressed concern that validation studies had predominantly been carried out in collaboration with the vendors of probabilistic genotyping software. Scholars criticized probabilistic genotyping software as opaque and at risk of implementation errors, and they called attention to restrictiv e licensing agreements and trade secret protections that could inhibit independent validation."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_155",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nnecessary to demonstrate validity as applied by laboratories. PCAST also expressed concern that validation studies had predominantly been carried out in collaboration with the vendors of probabilistic genotyping software. Scholars criticized probabilistic genotyping software as opaque and at risk of implementation errors, and they called attention to restrictiv e licensing agreements and trade secret protections that could inhibit independent validation. 54 The forensic science community responded with a concerted effort to further substantiate probabilistic genotyping methods through independent and collaborative research. Laboratories worldwide coordinated in studies using the data available to each, reinforcing that particular methods could, in particular circumstances, have validity as they are deployed.55 Vendors of probabilistic genotyping software improved access to their tools and source code for review by opposing legal teams.56 While there is ongoing debate about the extent of validation for probabilistic genotyping—a 2021 draft comprehensive report by NIST concluded that gaps remain, 57 and a 2024 workshop by the National Academies reflected ongoing stakeholder concerns58—these steps have been positive and important. 52 See SCIENTIFIC WORKING GROUP ON DNA ANALYSIS METHODS , GUIDELINES FOR THE VALIDATION OF PROBABILISTIC GENOTYPING SYSTEMS (2015), https://www.swgdam.org/_files/ugd/4344b0_22776006b67c4a32a5ffc04fe3b56515.pdf . 53 PCAST Report, supra note 2."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_156",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nvalidation for probabilistic genotyping—a 2021 draft comprehensive report by NIST concluded that gaps remain, 57 and a 2024 workshop by the National Academies reflected ongoing stakeholder concerns58—these steps have been positive and important. 52 See SCIENTIFIC WORKING GROUP ON DNA ANALYSIS METHODS , GUIDELINES FOR THE VALIDATION OF PROBABILISTIC GENOTYPING SYSTEMS (2015), https://www.swgdam.org/_files/ugd/4344b0_22776006b67c4a32a5ffc04fe3b56515.pdf . 53 PCAST Report, supra note 2. 54 E.g., Rebecca Wexler, Life, Liberty, and Trade Secrets: Intellectual Property in the Criminal Justice System , 70 STAN. L. REV. 1343, 1343 (2018), https://review.law.stanford.edu/wp -content/uploads/sites/3/2018/06/70- Stan. -L.- Rev.-1343.pdf ; Andrea Roth, M achine Testimony , 126 Y ALE L.J. 1972, 1972 (2017), https://www.yalelawjournal.org/pdf/RothFinal_c4o97on1.pdf . See also Rediet Abebe et al., Adversarial Scrutiny of Evidentiary Statistical Software, 2022 ACM CONF. ON FAIRNESS , ACCOUNTABILITY , & TRANSPARENCY 1733 (2022), https://doi.org/10.1145/3531146.3533228 . 55 Safia Boodoosingh et al., An Inter -laboratory Comparison of Probabilistic Genotyping Parameters and Evaluation of Performance on DNA Mixtures from Different Laboratories, 71 F ORENSIC SCI. INT’L: GENETICS 103046 (2024), https://doi.org/10.1016/j.fsigen.2024.103046 ; John M. Butler et al., NIST Interlaboratory Studies Involving DNA Mixtures (MIX05 and MIX13): Variation Observed and Lessons Learned, 37 FORENSIC SCI."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_157",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nTRANSPARENCY 1733 (2022), https://doi.org/10.1145/3531146.3533228 . 55 Safia Boodoosingh et al., An Inter -laboratory Comparison of Probabilistic Genotyping Parameters and Evaluation of Performance on DNA Mixtures from Different Laboratories, 71 F ORENSIC SCI. INT’L: GENETICS 103046 (2024), https://doi.org/10.1016/j.fsigen.2024.103046 ; John M. Butler et al., NIST Interlaboratory Studies Involving DNA Mixtures (MIX05 and MIX13): Variation Observed and Lessons Learned, 37 FORENSIC SCI. INT’L: GENETICS 81 (2018), https://doi.org/10.1016/j.fsigen.2018.07.024 ; John M. Butler et al., DNA Mixture Interpretation: A NIST Scientific Foundation Review , NAT’L INST. STANDARDS & TECH. (2021), https://nvlpubs.nist.gov/nistpubs/ir/2021/NIST.IR.8351- draft.pdf (surveying validation studies of probabilistic genotyping software ). See Jo-Anne Bright et al., Internal Validation of STRmix ™ – A Multi Laboratory Response to PCAST , 34 F ORENSIC SCI. INT’L: GENETICS 11 (2024), https://doi.org/10.1016/j.fsigen.2018.01.003 . 56 E.g., TrueAllele® Source Code Access , CYBERGENETICS , https://www.cybgen.com/support/code -access/ ; Access to STRmix ™ Software By Defence Legal Teams , STR MIX, https://www.strmix.com/assets/STRmix/STRmix - PDFs/Access -to-STRmix -Software -by-Defence- Legal -teams -March -2022 -v2.pdf . 57 John M. Butler et al., DNA Mixture Interpretation: A NIST Scientific Foundation Review , NAT’L INST. STANDARDS & TECH."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_158",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n11 (2024), https://doi.org/10.1016/j.fsigen.2018.01.003 . 56 E.g., TrueAllele® Source Code Access , CYBERGENETICS , https://www.cybgen.com/support/code -access/ ; Access to STRmix ™ Software By Defence Legal Teams , STR MIX, https://www.strmix.com/assets/STRmix/STRmix - PDFs/Access -to-STRmix -Software -by-Defence- Legal -teams -March -2022 -v2.pdf . 57 John M. Butler et al., DNA Mixture Interpretation: A NIST Scientific Foundation Review , NAT’L INST. STANDARDS & TECH. (2021), https://nvlpubs.nist.gov/nistpubs/ir/2021/NIST.IR.8351 -draft.pdf . 58 NAT’L ACADS . SCIS., ENG’G & MED., Law Enforcement Use of Probabilistic Genotyping, Forensic DNA Phenotyping, and Forensic Investigative Genetic Genealogy Technologies: Proceedings of a Workshop (2024), https://doi.org/10.17226/27887 . 39 These developments with probabilistic genotyping highlight the value of proactively carrying out large -scale interlaboratory validation for new uses of AI in forensic analysis. They also suggest that forms of access to AI implementation, such as models or source code, may be appropriate for validation. c. Explainability As noted earlier, it is important for forensics experts to be able to explain the analytical methods they apply and how they obtain results. The types of AI models that are used in forensic science today are generally interpretable, such that an expert could describe how inputs combine to arrive at an output."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_159",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nmay be appropriate for validation. c. Explainability As noted earlier, it is important for forensics experts to be able to explain the analytical methods they apply and how they obtain results. The types of AI models that are used in forensic science today are generally interpretable, such that an expert could describe how inputs combine to arrive at an output. 59 It is foreseeable, though, that forensic science may begin to involve AI models that can be more difficult to understand, such as deep neural networks. These models could possibly be less persuasive in court and could undermine public confidence in forens ic analysis. When considering models that are not interpretable, forensic practitioners should explore the feasibility of using explainability methods that can provide some understanding of model behavior. 60 Practitioners should also carefully consider possible tradeoffs between interpretability and accuracy in developing AI models for forensic science. d. Human Oversight of AI in Forensic Analysis In forensic science, it is common to have a second person review a practitioner’s work, sometimes referred to as a “technical review.” Similarly, when using AI, it is important to maintain human oversight of analysis and results to ensure that the AI was consistently applied and identify possible irregularities."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_160",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nfor forensic science. d. Human Oversight of AI in Forensic Analysis In forensic science, it is common to have a second person review a practitioner’s work, sometimes referred to as a “technical review.” Similarly, when using AI, it is important to maintain human oversight of analysis and results to ensure that the AI was consistently applied and identify possible irregularities. Human involvement is also important because, if forensic analysis involving AI will be the basis for evidence in court, a human expert must explain the AI use and interpret the results. 61 Including a human review element in the forensic analysis process comes with risks, however. Human review can introduce human biases, such as confirmation bias with respect to a subject or automation bias with respect to the reliability of analysis.62 Training for forensic 59 See Brandon L . Garrett & Cynthia Rudin, Interpretable Algorithmic Forensics , 120 P ROCS . NAT’L ACAD. SCIS. (Oct. 2023) , https://doi.org/10.1073/pnas.2301842120 . 60 See Louise Kelly et al., Explainable Artificial Intelligence for Digital Forensics: Opportunities, Challenges and a Drug Testing Case Study , DIGITAL FORENSIC SCIENCE (B. Suresh Kumar Shetty & Pavanchand Shetty eds. , 2020), https://www.intechopen.com/chapters/73078 ; Stuart W. Hall & Amin Sakzad, Explainable Artificial Intelligence for Digital Forensics , 4 WIRE S FORENSIC SCI. (2021), https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wfs2.1434 ; Marthe S."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_161",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n. 60 See Louise Kelly et al., Explainable Artificial Intelligence for Digital Forensics: Opportunities, Challenges and a Drug Testing Case Study , DIGITAL FORENSIC SCIENCE (B. Suresh Kumar Shetty & Pavanchand Shetty eds. , 2020), https://www.intechopen.com/chapters/73078 ; Stuart W. Hall & Amin Sakzad, Explainable Artificial Intelligence for Digital Forensics , 4 WIRE S FORENSIC SCI. (2021), https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wfs2.1434 ; Marthe S. Veldhuis et al., Explainable Artificial Intelligence in Forensics: Realistic Explanations for Number of Contributor Predictions of DNA Profiles , 56 F ORENSIC SCI. INT’L: GENETICS 102632 (2022), https://doi.org/10.1016/j.fsigen.2021.102632 . See generally Alejandro Barredo Arrieta et al., Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges Toward Responsible AI , 58 I NFO. FUSION 82 (2020), https://doi.org/10.1016/j.inffus.2019.12.012 . 61 See Andrea Roth, Machine Testimony , 126 Y ALE L.J. 1972 (2017), https://www.yalelawjournal.org/pdf/RothFinal_c4o97on1.pdf . 62 See S. M. Kassin et al., The Forensic Confirmation Bias: Problems, Perspectives, and Proposed Solutions , 2 J. APPLIED RSCH. MEMORY & COGNITION 42 (2013) , https://doi.org/10.1016/j.jarmac.2013.01.001 . In forensic analysis of digital and multimedia evidence, for example, examiners often rely on tools that automate elements of analysis."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_162",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nMachine Testimony , 126 Y ALE L.J. 1972 (2017), https://www.yalelawjournal.org/pdf/RothFinal_c4o97on1.pdf . 62 See S. M. Kassin et al., The Forensic Confirmation Bias: Problems, Perspectives, and Proposed Solutions , 2 J. APPLIED RSCH. MEMORY & COGNITION 42 (2013) , https://doi.org/10.1016/j.jarmac.2013.01.001 . In forensic analysis of digital and multimedia evidence, for example, examiners often rely on tools that automate elements of analysis. The automation may not be robust against changes in the format of evidence, which could result from routine software u pdates. Automation bias could cause an examiner to miss relevant information if a tool is unsuccessful at 40 practitioners who use AI should address the risks of biases affecting analysis. Forensic analysis procedures should also minimize these risks , such as by minimizing the availability of irrelevant information to forensic examiners.63 Recommendations a. Policies for Use of AI in Forensic Analysis Forensic science service providers (FSSPs), such as law enforcement laboratories, should have clear and documented policies regarding the use of AI in forensic analysis. These policies should address the types of AI that may be used, the circumstances in which AI may be used, governance requirements, and limitations."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_163",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nforensic examiners.63 Recommendations a. Policies for Use of AI in Forensic Analysis Forensic science service providers (FSSPs), such as law enforcement laboratories, should have clear and documented policies regarding the use of AI in forensic analysis. These policies should address the types of AI that may be used, the circumstances in which AI may be used, governance requirements, and limitations. FSSPs should consider using the NIST AI Risk Management Framework, NIST’s Trustworthy and Responsible Artificial Intelligence Resource Center, OMB Memoranda M -24-10 and M -24-18, and other appropriate AI guidance from federal agencies to develop guidance and establish governance programs. Consistent with accepted standards for forensic analysis, human review and interpretation of AI outputs should remain standard procedure in forensic science applications. The output of an AI system should not be the sole basis for conclusions in forensic analysis. A qualified examiner should interpret the output and apply their expert judgment to form conclusions. FSSPs should consider potential risks from using AI in forensic analysis and should design and implement processes to mitigate those risks prior to using AI. AI impact assessments may be a valuable framework for these considerations. Policies should establish rigorous validation requirements to ensure that AI uses are reliable, both as they are developed and as they are deployed by the FSSP."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_164",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nconsider potential risks from using AI in forensic analysis and should design and implement processes to mitigate those risks prior to using AI. AI impact assessments may be a valuable framework for these considerations. Policies should establish rigorous validation requirements to ensure that AI uses are reliable, both as they are developed and as they are deployed by the FSSP. Appropriate validation will often involve pre -deployment testing for performance and demographic biases, using data and contexts that are representative of real -world use, as well as post-deployment monitoring. FSSP policies should address AI interpretability and explainability and should set a general preference for interpretable models when they can meet operational needs. Regular audits of AI use can ensure that examiners are following required procedures. b. Procurement of AI Capabilities for Forensic Analysis FSSPs should only procure tools that have a demonstrated acceptable level of accuracy. FSSPs should verify that the data used to build an AI model is high quality and representative of the FSSP’s intended real -world use. extracting or parsing evidence. A possible mitigation for this risk would be to ensure that, if a tool encounters an error, it is clearly conveyed to examiners. 63 Appropriate steps to minimize risks of human biases for forensic analysis involving AI may be similar or identical to appropriate steps for minimizing bias risks for analysis that does not involve AI."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_165",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nextracting or parsing evidence. A possible mitigation for this risk would be to ensure that, if a tool encounters an error, it is clearly conveyed to examiners. 63 Appropriate steps to minimize risks of human biases for forensic analysis involving AI may be similar or identical to appropriate steps for minimizing bias risks for analysis that does not involve AI. 41 FSSPs should require information from vendors about intended uses, training data and methods, validation, potential limitations, and potential biases of products. Experts should carefully review vendor disclosures and relevant additional information, such as peer -reviewed publications and revi ews by other laboratories, for alignment with forensic analysis objectives . Partnerships with independent AI researchers may be beneficial for FSSPs in validating AI products. Where possible, FSSPs should avoid restrictive licensing agreements and other possible barriers to collaboration with third -party experts. FSSPs should ensure that biases in AI systems and uses, including for sex, race, color, disability, and age, have been adequately evaluated and mitigated. c. Datasets When possible, FSSPs should choose AI capabilities that have been trained on large, high- quality, and representative datasets. Producing these training datasets may require cooperation among practitioners and forensic experts worldwide, accounting for diff erences across jurisdictions that could affect performance or introduce biases."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_166",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nincluding for sex, race, color, disability, and age, have been adequately evaluated and mitigated. c. Datasets When possible, FSSPs should choose AI capabilities that have been trained on large, high- quality, and representative datasets. Producing these training datasets may require cooperation among practitioners and forensic experts worldwide, accounting for diff erences across jurisdictions that could affect performance or introduce biases. If an AI use depends on data that can differ in relevant ways across jurisdictions, FSSPs should consider appropriately supplementing training data with datasets from their jur isdictions. When evaluating an AI system, FSSPs should also evaluate the training data where possible to ensure that the data is accurate, complete, and representative of the intended deployment context. FSSPs should ensure that the data used to validate an AI system is separate from the data used to build the system. Reuse of training data in testing can lead to misunderstanding of the system’s performance and biases. d. Training and Education Forensic practitioners who use or interact with AI should be appropriately trained about the AI, including its design, intended use, performance, biases, and limitations. Practitioners should also receive appropriate training about applicable policies and required procedures, as well as how to mitigate the possible human biases associated with use of the AI."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_167",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nsystem’s performance and biases. d. Training and Education Forensic practitioners who use or interact with AI should be appropriately trained about the AI, including its design, intended use, performance, biases, and limitations. Practitioners should also receive appropriate training about applicable policies and required procedures, as well as how to mitigate the possible human biases associated with use of the AI. FSSPs can benefit each other by sharing information about their experiences with AI and the policies and procedures that they have implemented. Forensic leaders should stay current on emerging AI tools and monitor advancements in forensic applications to take advantage of the technology and make changes to existing use of AI tools as necessary. 42 IV. Predictive Policing Introduction Predictive policing is the use of quantitative analytical methods to identify times, places, and individuals likely to be associated with criminal activity.1 Predictive policing models do not predict that specific crimes will occur, but rather estimate a general likelihood of crime. While law enforcement agencies use predictive policing tools for purposes like informing the allocation of officers, existing tools neither recommend nor evaluate responses to their output. Those responses could extend beyond traditional policing methods and determine the efficacy of strategies incorporating predictive policing."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_168",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nmodels do not predict that specific crimes will occur, but rather estimate a general likelihood of crime. While law enforcement agencies use predictive policing tools for purposes like informing the allocation of officers, existing tools neither recommend nor evaluate responses to their output. Those responses could extend beyond traditional policing methods and determine the efficacy of strategies incorporating predictive policing. Law enforcement agencies have used predictive policing tools since at least the 1990s.2 Researchers studied “hot spots” policing with the Minneapolis Police Department and found crime reductions in patrolled areas,3 leading to further studies looking at approaches identifying crime “hot spots” to reduce drug and violent crime.4 The Department of Justice’s National Institute of Justice (NIJ) helped bring analysis tools to a wider range of U.S. law enforcement agencies by funding the development of CrimeStat software beginning in 1997. 5 By 2008, when approximately 90% of law enforcement agencies were already using some form of “hot spots” policing,6 the NIJ joined with the Department of Justice’s Bureau of Justice Assistance to fund research into new predictive models that would turn “hot spots” mapping into a forward- looking tool for crime forecasting.7 1 WALTER L."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_169",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nCrimeStat software beginning in 1997. 5 By 2008, when approximately 90% of law enforcement agencies were already using some form of “hot spots” policing,6 the NIJ joined with the Department of Justice’s Bureau of Justice Assistance to fund research into new predictive models that would turn “hot spots” mapping into a forward- looking tool for crime forecasting.7 1 WALTER L. PERRY ET AL ., RAND CORP., PREDICTIVE POLICING : THE ROLE OF CRIME FORECASTING IN LAW ENFORCEMENT OPERATIONS 1–2 (2013), https://www.rand.org/content/dam/rand/pubs/research_reports/RR200/RR233/RAND_RR233.pdf . The term “predictive policing” is something of a misnomer because it is not a policing strategy, like proactive policing, problem -oriented policing, or crime prevention through environmental design. Instead, the outputs of predictive policing inform the development and implementation of policing or other strategies to reduce crime. However, this chapter uses the term “predictive policing” given its widespread acceptance. The chapter also references predictive policing algorithms, models, and tools to emphas ize that predictive analytics are separate from the responses, which may include various forms of policing as well as community approaches to reducing crime. 2 Lawrence W. Sherman & David Weisburd, General Deterrent Effects of Police Patrol in Crime “Hot Spots”: A Randomized, Controlled Trial , 12 J UST. Q. 625, 643–46 (1995) , http://dx.doi.org/10.1080/07418829500096221 . 3 Id."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_170",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nto emphas ize that predictive analytics are separate from the responses, which may include various forms of policing as well as community approaches to reducing crime. 2 Lawrence W. Sherman & David Weisburd, General Deterrent Effects of Police Patrol in Crime “Hot Spots”: A Randomized, Controlled Trial , 12 J UST. Q. 625, 643–46 (1995) , http://dx.doi.org/10.1080/07418829500096221 . 3 Id. 4 See, e.g., Anthony A. Braga et al., The Effects of Hot Spots Policing on Crime: An Updated Systematic Review and Meta -Analysis , 31 J UST. Q. 633, 634 (2014) . 5 NED LEVINE , THE DEVELOPMENT OF A SPATIAL ANALYSIS TOOLKIT FOR USE IN A METROPOLITAN CRIME INCIDENT GEOGRAPHIC INFORMATION SYSTEM (1999) (Final Rep. to the Nat’l Inst. Just., Award No. 97- IJ-CX-0040), https://www.ojp.gov/pdffiles1/nij/grants/179282.pdf . 6 See POLICE EXEC. RSCH. F., VIOLENT CRIME IN AMERICA : WHAT WE KNOW ABOUT HOT SPOTS ENFORCEMENT , 3 (2008), https://www.policeforum.org/assets/docs/Critical_Issues_Series/violent%20crime%20in%20america%20- %20what%20we%20know%20about%20hot%20spots%20enforcement%202008.pdf ( “nearly 9 out of 10 agencies use hot spots enforcement efforts directed either at larger hotspots areas like neighborhoods, smaller hot spot places like intersections, or both”). 7 Joel Hunt, From Crime Mapping to Crime Forecasting: The Evolution of Place -Based Policing, NIJ J., no. 281, Nov. 2019, https://www.ojp.gov/pdffiles1/nij/252036.pdf ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_171",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nABOUT HOT SPOTS ENFORCEMENT , 3 (2008), https://www.policeforum.org/assets/docs/Critical_Issues_Series/violent%20crime%20in%20america%20- %20what%20we%20know%20about%20hot%20spots%20enforcement%202008.pdf ( “nearly 9 out of 10 agencies use hot spots enforcement efforts directed either at larger hotspots areas like neighborhoods, smaller hot spot places like intersections, or both”). 7 Joel Hunt, From Crime Mapping to Crime Forecasting: The Evolution of Place -Based Policing, NIJ J., no. 281, Nov. 2019, https://www.ojp.gov/pdffiles1/nij/252036.pdf . 43 While even early versions of predictive policing fall near this report’s broad definition of artificial intelligence, predictive policing today uses more advanced statistical and machine learning methods and incorporates greater volumes and new types of data. Predictive policing tools can be grouped into two categories. “Location -based” or “place -based” tools attempt to forecast locations where crime is likely to cluster.8 Location -based tools also try to identify the types of crimes likely to occur and when they are likely to occur. “Person- based” predictive policing attempts to identify individuals who are more likely to commit crimes or be victims of crime in the future, and it has many similarities to risk assessment ( see c hapter V). 9 The literature on predictive policing focuses overwhelmingly on “street crimes,” and this chapter follows that research."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_172",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nand when they are likely to occur. “Person- based” predictive policing attempts to identify individuals who are more likely to commit crimes or be victims of crime in the future, and it has many similarities to risk assessment ( see c hapter V). 9 The literature on predictive policing focuses overwhelmingly on “street crimes,” and this chapter follows that research. Predictive policing tools can help law enforcement agencies, other public services, and community -based organizations promote public safety, efficiency, and transparency by informing decisions on how to allocate limited resources. Nevertheless, these tools do not currently prescribe the actions that should be taken at the places or with the people identified—actions such as additional enforcement, place -based problem -solving, diversion programs, job training, education, or environmental design interventions—or predict the effects of those actions. Law enforcement use of predictive policing also raises significant risks, including the potential to create or entrench disparities. The data underlying predictive policing models may have significant gaps and errors, and it may reflect historical and human biases. Use of predictive policing models based on that data may also result in unintended, unjust outcomes, such as over - or under-policing of certain individuals and communities."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_173",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\npolicing also raises significant risks, including the potential to create or entrench disparities. The data underlying predictive policing models may have significant gaps and errors, and it may reflect historical and human biases. Use of predictive policing models based on that data may also result in unintended, unjust outcomes, such as over - or under-policing of certain individuals and communities. This chapter begins with descriptions of uses and risks of both place- based and person- based predictive policing tools, and it concludes with recommendations for law enforcement agencies to safely and effectively deploy these tools in a way that enhances efficiency and accuracy while protecting civil liberties, civil rights, and privacy. Uses of Predictive Policing a. Place-based Place- based or “hot spots” policing involves “focusing limited resources on a small number of high- activity crime places.”10 Also called “spatial models,” promising analyses from Minneapolis and elsewhere suggested opportunities for these methods to assist in using policing resources more effectively and spurred extensive adoption by the 2000s.11 During the 2010s, place - based predictive policing systems drew criticism about their accuracy, limitations, and reliance on historical crime.12 As discussed below, predictive policing tools often rely heavily on historic crime 8 See PERRY ET AL ., supra note 1, at 8 –9 (describing a similar taxonomy of predictive policing methods). 9 See id. 10 Anthony A."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_174",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nthe 2000s.11 During the 2010s, place - based predictive policing systems drew criticism about their accuracy, limitations, and reliance on historical crime.12 As discussed below, predictive policing tools often rely heavily on historic crime 8 See PERRY ET AL ., supra note 1, at 8 –9 (describing a similar taxonomy of predictive policing methods). 9 See id. 10 Anthony A. Braga, Effects of Hot Spots Policing on Crime , CAMPBELL SYSTEMATIC REVS. 1, 4 (2007) . 11 SHERMAN & WEISBURD , supra note 2, at 643 –46; POLICE EXEC. RSCH. F., supra note 6. 12 See, e.g., Lyria Bennett Moses & Janet Chan, Algorithmic Prediction in Policing: Assumptions, Evaluation, and Accountability , 28 POLICING & SOC’Y 806, 809– 13 (2018)(examining underlying assumptions in predictive policing 44 data, which can be problematic because the data may entrench historically discriminatory policing patterns."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_175",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n, supra note 2, at 643 –46; POLICE EXEC. RSCH. F., supra note 6. 12 See, e.g., Lyria Bennett Moses & Janet Chan, Algorithmic Prediction in Policing: Assumptions, Evaluation, and Accountability , 28 POLICING & SOC’Y 806, 809– 13 (2018)(examining underlying assumptions in predictive policing 44 data, which can be problematic because the data may entrench historically discriminatory policing patterns. Criticisms also arose surrounding the immediate value and actionability of some systems’ output for police departments.13 In 2016, the NIJ conducted the Real -Time Crime Forecasting Challenge to test the effectiveness and efficiency of predictive spatial models on crime data from Portland, Oregon.14 Although results from the Challenge should not be generalized beyond the context of that single city, comparing the performance of a wide range of algorithms there indicated that both simple and sophisticated spatial models can offer similar predictive ac curacy.15 This finding supports the principle that for producing better outcomes, the specific tool or algorithm used for prediction may matter less than the selection and implementation of responses to high -risk areas.16 For example, community engagement in the development of responses (e.g., additional police presence versus social services) could determine whether those responses are effective."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_176",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\noffer similar predictive ac curacy.15 This finding supports the principle that for producing better outcomes, the specific tool or algorithm used for prediction may matter less than the selection and implementation of responses to high -risk areas.16 For example, community engagement in the development of responses (e.g., additional police presence versus social services) could determine whether those responses are effective. 17 Since the 2010s, place -based predictive policing strategies have continued to evolve, as agencies incorporate evidence from past iterations and work with communities to respond with a wide range of interventions. Agencies are developing tools in- house, cus tomizing them to fit into their workflows, and collaborating with other public services and community- based organizations. 18 Strategies that currently make use of predictive policing include proactive policing and “hot spot” policing.19 These strategies include a range of specific approaches to prevent crime and focus limited resources geographically.20 methods); DAVID ROBINSON & LOGAN KOEPKE , UPTURN , STUCK IN A PATTERN : EARLY EVIDENCE ON “PREDICTIVE POLICING ” AND CIVIL RIGHTS 3–5 (2016), https://www.upturn.org/static/reports/2016/stuck -in-a- pattern/files/Upturn_ -_Stuck_In_a_Pattern_v.1.01.pdf ( discussing general limitations of predictive policing) . 13 See Aaron Sankin & Surya Mattu, Predictive Policing Software Terrible at Predicting Crimes , THE MARKUP (Oct."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_177",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nand focus limited resources geographically.20 methods); DAVID ROBINSON & LOGAN KOEPKE , UPTURN , STUCK IN A PATTERN : EARLY EVIDENCE ON “PREDICTIVE POLICING ” AND CIVIL RIGHTS 3–5 (2016), https://www.upturn.org/static/reports/2016/stuck -in-a- pattern/files/Upturn_ -_Stuck_In_a_Pattern_v.1.01.pdf ( discussing general limitations of predictive policing) . 13 See Aaron Sankin & Surya Mattu, Predictive Policing Software Terrible at Predicting Crimes , THE MARKUP (Oct. 2, 2023, 10:00 AM), https://themarkup.org/prediction -bias/2023/10/02/predictive -policing -software -terrible -at- predicting -crimes ( finding low success rate of a predictive policing tool) . 14 Real-Time Crime Forecasting Challenge , NAT’L INST. JUST. (July 13, 2016) , https://nij.ojp.gov/funding/real- time- crime -forecasting -challenge ( archived content). 15 See YongJei Lee et al., A Theory -Driven Algorithm for Real -Time Crime Hot Spot Forecasting , 23 POLICE Q. 174, 194– 96 (2020) (analyzing data from Portland and Cincinnati and arguing that authors’ simple model in Microsoft Excel “has demonstrated similar levels of efﬁciency and accuracy, with lower economic or ﬁscal investments and greater transparency than other more expensive, commercial models”). 16 See, e.g ., NAT’L ACAD. OF SCIS., ENG’G, & MED., LAW ENFORCEMENT USES OF PREDICTIVE POLICING APPROACHES (Nov."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_178",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n194– 96 (2020) (analyzing data from Portland and Cincinnati and arguing that authors’ simple model in Microsoft Excel “has demonstrated similar levels of efﬁciency and accuracy, with lower economic or ﬁscal investments and greater transparency than other more expensive, commercial models”). 16 See, e.g ., NAT’L ACAD. OF SCIS., ENG’G, & MED., LAW ENFORCEMENT USES OF PREDICTIVE POLICING APPROACHES (Nov. 2024) (“NAS Proceeding 2024”) , https://nap.nationalacademies.org/catalog/28037/law - enforcement -use-of-person -based -predictive -policing -approaches -proceedings . 17 NAS PROCEEDING 2024, supra note 16. 18 See Tim Lau, Predictive Policing Explained , BRENNAN CTR FOR JUST. (Apr. 1, 2020), https://www.brennancenter.org/our -work/research -reports/predictive -policing -explained (“[T]he NYPD developed its own in -house predictive policing algorithms and started to use them in 2013”). 19 See generally Albert Meijer & Martijn Wessels, Predictive Policing: Review of Benefits and Drawbacks , 42 INT’L J. PUB. ADMIN . 1031, 1033– 34 (2019) (discussing predictive policing and conventional policing methods). 20 See Practice Profile: Hot Spots Policing , NAT’L INST. JUST. https://crimesolutions.ojp.gov/ratedpractices/hot- spots -policing#1 -0 ( “Hot spots policing strategies focus on small geographic areas or places, usually in urban settings, where crime is concentrated."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_179",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nPredictive Policing: Review of Benefits and Drawbacks , 42 INT’L J. PUB. ADMIN . 1031, 1033– 34 (2019) (discussing predictive policing and conventional policing methods). 20 See Practice Profile: Hot Spots Policing , NAT’L INST. JUST. https://crimesolutions.ojp.gov/ratedpractices/hot- spots -policing#1 -0 ( “Hot spots policing strategies focus on small geographic areas or places, usually in urban settings, where crime is concentrated. Through hot spots policing strategies, law enforcement agencies can focus limited resources in areas where crime is most like ly to occur.”) 45 Recent place- based predictive policing programs include Place -Based Investigations of Violent Offender Territories (PIVOT) in Cincinnati21 and Data- Informed Community Engagement (DICE) in cities such as Dallas, Kansas City, Newark, New Orleans, and St. Louis.22 PIVOT uses “hot spot” mapping combined with problem -oriented policing strategies to identify and mitigate factors that facilitate violence,23 while DICE pairs risk terrain modeling with community engagement to address crime through place- based interventions.24 b. Person -based A person- based approach attempts to identify those most at risk for committing future crimes or being a victim of crime , either by using factors associated with individuals known to law enforcement to generate risk scores, or by identifying connections between individuals who may be linked to past crimes."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_180",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nto address crime through place- based interventions.24 b. Person -based A person- based approach attempts to identify those most at risk for committing future crimes or being a victim of crime , either by using factors associated with individuals known to law enforcement to generate risk scores, or by identifying connections between individuals who may be linked to past crimes. This approach typically generates a list of the highest -risk individuals in the jurisdiction as a whole or within a given geographic area, such as a patrol zone. With respect to violent crime, research con sistently shows that it is disproportionately concentrated among small numbers of individuals, groups, and locations at the highest risk for violence.25 In the mid -1990s, the NIJ funded an early study of one form of predictive policing, focused deterrence, in which law enforcement efforts prioritized individuals disproportionately responsible for crime. 26 In the past decade, predictive policing programs like Chicago’s Strategic Subjects List built on earlier person- focused deterrence approaches and other initiatives, such as gang databases.27 That generation of policing programs established the use of algorithms to analyze data on individuals’ criminal histories, social networks, and other risk factors in an attempt to identify those most likely to be involved in violent crime as perpetrators or victims."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_181",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nlike Chicago’s Strategic Subjects List built on earlier person- focused deterrence approaches and other initiatives, such as gang databases.27 That generation of policing programs established the use of algorithms to analyze data on individuals’ criminal histories, social networks, and other risk factors in an attempt to identify those most likely to be involved in violent crime as perpetrators or victims. By the end of the 21 Place -Based Investigations of Violent Offender Territories (PIVOT) , CITY OF CINCINNATI , https://www.cincinnati- oh.gov/police/community- involvement/pivot/ . 22 Learning Community, P UB. SAFETY COLLABORATIVE COUNCIL , https://www.diceforpublicsafety.org/learning - community.html . 23 See Tamara D. Madensen et al., Place -Based Investigations to Disrupt Crime Place Networks, THE POLICE CHIEF MAG., Apr. 2017, at 14 –15, https://www.policechiefmagazine.org/wp - content/uploads/PoliceChief_April2017_F_WEB.pdf ( describing development and implementation of PIVOT). 24 Sarah Minster, The Data- Informed Community Engagement (DICE) Approach to Public Safety Turns Analytics into Action , NAT’L LEAGUE OF CITIES (June 18, 2024), https://www.nlc.org/article/2024/06/18/the -data-informed - community -engagement -dice-approach- to-public -safety -turns -analytics -into-action . 25 Violent Crime Reduction Roadmap: Working Together to Build Safer Communities , Action 2, BUREAU JUST."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_182",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n( describing development and implementation of PIVOT). 24 Sarah Minster, The Data- Informed Community Engagement (DICE) Approach to Public Safety Turns Analytics into Action , NAT’L LEAGUE OF CITIES (June 18, 2024), https://www.nlc.org/article/2024/06/18/the -data-informed - community -engagement -dice-approach- to-public -safety -turns -analytics -into-action . 25 Violent Crime Reduction Roadmap: Working Together to Build Safer Communities , Action 2, BUREAU JUST. ASSISTANCE , https://bja.ojp.gov/violent- crime -reduction -roadmap/action- 2#0-3 (“Research consistently shows that violence disproportionately concentrates among small number of individuals , groups and locations at the highest risk for violence.”) 26 Braga et al. 2001, Problem -Oriented Policing, Deterrence, and Youth Violence: An Evaluation of Boston's Operation Ceasefire , J. RSCH. CRIME & DELINQ . 195, 198 (2001) , https://journals.sagepub.com/doi/abs/10.1177/0022427801038003001 (discussing the Boston Gun Project and Operation Ceasefire). 27 See generally Jessica Saunders et al., Predictions Put into Practice: A Quasi -Experimental Evaluation of Chicago’ s Predictive Policing Pilot , 12 J. EXPERIMENTAL CRIMINOLOGY 347 (2016) , https://link.springer.com/article/10.1007/s11292- 016-9272-0 ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_183",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nYouth Violence: An Evaluation of Boston's Operation Ceasefire , J. RSCH. CRIME & DELINQ . 195, 198 (2001) , https://journals.sagepub.com/doi/abs/10.1177/0022427801038003001 (discussing the Boston Gun Project and Operation Ceasefire). 27 See generally Jessica Saunders et al., Predictions Put into Practice: A Quasi -Experimental Evaluation of Chicago’ s Predictive Policing Pilot , 12 J. EXPERIMENTAL CRIMINOLOGY 347 (2016) , https://link.springer.com/article/10.1007/s11292- 016-9272-0 . 46 2010s, however, many of the programs from this era had halted following concerns regarding efficacy , bias , and civil rights.28 Person -based strategies predicting risk for victimization rather than criminal offending are also being used in cases of child abuse29 and gender -based violence.30 These tools raise some similar concerns to offender -centered predictive policing tools.31 Risks of Predictive Policing a. Data and Model O utput Quality Although traditional law enforcement interventions have relied on officers’ knowledge, judgments, and personal experience in their communities, predictive modeling relies on collected quantitative data as input."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_184",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nbeing used in cases of child abuse29 and gender -based violence.30 These tools raise some similar concerns to offender -centered predictive policing tools.31 Risks of Predictive Policing a. Data and Model O utput Quality Although traditional law enforcement interventions have relied on officers’ knowledge, judgments, and personal experience in their communities, predictive modeling relies on collected quantitative data as input. Predictive models depend on historic crime data, such as calls for service, crime incidents, and arrests.32 As with all data, these datasets are imperfect.33 They may underrepresent underreported crimes, such as intimate partner violence and sexual assault.34 They may also reflect past policing patterns, which can affect the certainty of the model’s output and disproportionately affect vulnerable communities. 35 Predictive models may also underrepresent the actual incidence of crime in locations where individuals are less likely to report crimes to police.36 Some scholars have pointed to historical 28 See, e.g., Annie Sweeney & Jeremy Gorner, For Years Chicago Police Rated the Risk of Tens of Thousands Being Caught Up in Violence. That Controversial Effort Has Quietly Been Ended. , CHI. TRIB. (Jan."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_185",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nalso underrepresent the actual incidence of crime in locations where individuals are less likely to report crimes to police.36 Some scholars have pointed to historical 28 See, e.g., Annie Sweeney & Jeremy Gorner, For Years Chicago Police Rated the Risk of Tens of Thousands Being Caught Up in Violence. That Controversial Effort Has Quietly Been Ended. , CHI. TRIB. (Jan. 25, 2020, 2:55 AM), https://www.chicagotribune.com/2020/01/24/for -years -chicago -police -rated -the-risk-of-tens-of-thousands -being - caught -up-in-violence -that-controversial -effort -has-quietly -been -ended/ ( discussing a findings in a report issued by the City Inspector General’s Office analyzing the use of Chicago’s Strategic Subjects List) . 29 See, e.g., ALLEGHENY CNTY. DEP’T HUM. SERVS ., SUMMARIZING RECENT RESEARCH ON PREDICTIVE RISK MODELS IN CHILD WELFARE 1 (2024), https://www.alleghenycountyanalytics.us/wp- content/uploads/2024/05/24- ACDHS -04-Predictive -Risk-Algorithms.pdf ( discussing the Allegheny Family Screening Tool, “an algorithm designed to assist child welfare call screening caseworkers in their assessment of general protective service referrals regarding potential child maltreatment.”). 30 See, e.g., ETICAS FOUND ., THE EXTERNAL AUDIT OF THE VIOGÉN SYSTEM (2022), https://eticasfoundation.org/wp- content/uploads/2024/07/ETICAS -FND -The-External -Audit -of-the-VioGen -System -1.pdf . (examining VioGén, a gender -violence risk assessment tool used by the Spanish Ministry of Interior)."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_186",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n“an algorithm designed to assist child welfare call screening caseworkers in their assessment of general protective service referrals regarding potential child maltreatment.”). 30 See, e.g., ETICAS FOUND ., THE EXTERNAL AUDIT OF THE VIOGÉN SYSTEM (2022), https://eticasfoundation.org/wp- content/uploads/2024/07/ETICAS -FND -The-External -Audit -of-the-VioGen -System -1.pdf . (examining VioGén, a gender -violence risk assessment tool used by the Spanish Ministry of Interior). 31 ALLEGHENY CNTY. DEP’T HUM. SERVS ., supra note 29. 32 See, e.g., Jeffrey Brantingham et al., Does Predictive Policing Lead to Biased Arrests? Results From a Randomized Controlled Trial , STATISTICS AND PUBLIC POLICY 5(1), 1 –6. https://doi.org/10.1080/2330443X.2018.1438940 (evaluating bias of predictive algorithms used for police patrol using arrest data). 33 Id. at 5 (discussing limitations of arrest data). 34 See U.S. DEP’T JUST, FRAMEWORK FOR PROSECUTORS TO STRENGTHEN OUR NATIONAL RESPONSE TO SEXUAL ASSAULT AND DOMESTIC VIOLENCE INVOLVING ADULT VICTIMS 2 n. 8 (May 2024), https://www.justice.gov/ovw/media/1352371/dl?inline (“Sexual assaults and domestic violence are, in large part, underreported, under -investigated and under -prosecuted”). 35 Some observers have pointed to racial disparities in policing decisions in such instances. See , e.g., AM. C. L. UNION N.J., SELECTIVE POLICING RACIALLY DISPARATE ENFORCEMENT OF LOW-LEVEL OFFENSES IN NEW JERSEY 8 (Dec."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_187",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nVIOLENCE INVOLVING ADULT VICTIMS 2 n. 8 (May 2024), https://www.justice.gov/ovw/media/1352371/dl?inline (“Sexual assaults and domestic violence are, in large part, underreported, under -investigated and under -prosecuted”). 35 Some observers have pointed to racial disparities in policing decisions in such instances. See , e.g., AM. C. L. UNION N.J., SELECTIVE POLICING RACIALLY DISPARATE ENFORCEMENT OF LOW-LEVEL OFFENSES IN NEW JERSEY 8 (Dec. 2015), https://www.aclu -nj.org/sites/default/files/field_documents/2015_12_21_aclunj_select_enf.pdf . 36 The Bureau of Justice Statistics reported that in 2022, only 41.5% of violent crimes and 31.8% of property crimes were reported to police. A LEXANDRA THOMPSON & SUSANNAH N. TAPP, BUREAU OF JUST. STATS., U.S. DEP’T JUST., NCJ 307089, CRIMINAL VICTIMIZATION , 2022 6 tbl. 4 (2023), https://bjs.ojp.gov/document/cv22.pdf ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_188",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nOFFENSES IN NEW JERSEY 8 (Dec. 2015), https://www.aclu -nj.org/sites/default/files/field_documents/2015_12_21_aclunj_select_enf.pdf . 36 The Bureau of Justice Statistics reported that in 2022, only 41.5% of violent crimes and 31.8% of property crimes were reported to police. A LEXANDRA THOMPSON & SUSANNAH N. TAPP, BUREAU OF JUST. STATS., U.S. DEP’T JUST., NCJ 307089, CRIMINAL VICTIMIZATION , 2022 6 tbl. 4 (2023), https://bjs.ojp.gov/document/cv22.pdf . 47 public health statistics as another way to estimate the underlying incidence of crime37 just like the Drug Enforcement Administration (DEA) has used public -facing CDC drug overdose data to evaluate and to more effectively address the drug threat in communities across the United States.38 Looking further afield, other crime prediction models have incorporated a wide variety of data sourced from outside law enforcement and unconnected to past criminal conduct, including “elevation; zoning and water area coverage; density of hospitals, fire departments, transportation points such as bus stops and subway entrances, and schools,” as well as variables such as the day of the week and the weather. 39 Many datasets, including data on crime incidents, may also contain some uncertainty because data features such as the time of a crime or the location of a crime may have a large range or be inaccurately reported."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_189",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nas bus stops and subway entrances, and schools,” as well as variables such as the day of the week and the weather. 39 Many datasets, including data on crime incidents, may also contain some uncertainty because data features such as the time of a crime or the location of a crime may have a large range or be inaccurately reported. Police officers typically generate data each time they conduct a stop, write a report, or do anything else that leaves a data trail. Some police actions are subject to discretion, and the discretion of individual officers thus plays a role in shaping the input data. 40 As the next section discusses, the use of AI in predictive policing runs the risk of introducing or exacerbating disparities in this input data. b. Civil R ights Perhaps the most frequent criticism of predictive policing is that it has the potential to reproduce or even amplify biases embedded in historical crime data. The risk is that historical crime data will train models to predict crime in ways that magnify biases. 41 For example, place- based models can drive increased police presence in an area with greater historical crime data. The increased presence can lead to more law enforcement activity in that area, which can result in even more officers assigned to the area."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_190",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nrisk is that historical crime data will train models to predict crime in ways that magnify biases. 41 For example, place- based models can drive increased police presence in an area with greater historical crime data. The increased presence can lead to more law enforcement activity in that area, which can result in even more officers assigned to the area. Ultimately, the models become “increasingly confident that the locations most likely to experience further criminal activity are exactly the locations they had previously believed to be high in crime.” 42 The result may be disparate outcomes, by race or other 37 See Kristian Lum & William Isaac, To Predict and Serve? , SIGNIFICANCE 15, 16– 17 (Oct. 2016) https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1740 -9713.2016.00960.x (comparing police records of drug crimes with public health survey of illegal drug use, which the authors argue is a better “ground truth” for incidence of drug crimes). 38 See, e.g., Press Release, Drug Enforcement Admin., DEA Launches New Initiative to Combat Drug- Related Violence and Overdoses in Communities Across America (Feb."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_191",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nSIGNIFICANCE 15, 16– 17 (Oct. 2016) https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1740 -9713.2016.00960.x (comparing police records of drug crimes with public health survey of illegal drug use, which the authors argue is a better “ground truth” for incidence of drug crimes). 38 See, e.g., Press Release, Drug Enforcement Admin., DEA Launches New Initiative to Combat Drug- Related Violence and Overdoses in Communities Across America (Feb. 7, 2022), https://www.dea.gov/press - releases/2022/02/07/dea -launches -new-initiative -combat -drug-related -violence -and-overdoses -0 ( “DEA initiated a data-driven approach using national crime statistics and CDC data to identify hot spots of drug- related violence and overdose deaths across the country, in order to devote its law enforcement resources where they will have the most impac t: the communities where criminal drug networks are causing most harm .”); DEA Administrator Anne Milgram Remarks as Delivered Press Conference (Dec. 16, 2021) https://www.dea.gov/sites/default/files/2021 - 12/DEA%20Administrator%20Anne%20Milgram%20Remarks%20as%20Delivered- Dec%2016%202021.pdf (discussing CDC data on drug overdose deaths and criminal drug network activities). 39 Jerry H. Ratcliffe et al., The Philadelphia Predictive Policing Experiment, 17 J."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_192",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nwhere they will have the most impac t: the communities where criminal drug networks are causing most harm .”); DEA Administrator Anne Milgram Remarks as Delivered Press Conference (Dec. 16, 2021) https://www.dea.gov/sites/default/files/2021 - 12/DEA%20Administrator%20Anne%20Milgram%20Remarks%20as%20Delivered- Dec%2016%202021.pdf (discussing CDC data on drug overdose deaths and criminal drug network activities). 39 Jerry H. Ratcliffe et al., The Philadelphia Predictive Policing Experiment, 17 J. EXPERIMENTAL CRIMINOLOGY 15, 21 (2021) (describing possible inputs for predictive policing model formerly known as HunchLab); see also Resourcerouter Frequently Asked Questions, SoundThinking, https://www.soundthinking.com/faqs/resourcerouter - faqs/ ( “We supplement data modeling with non- crime data . . . . Typical examples include seasonality, time of month, day of the week, time of day, holidays, upcoming events, weather, and locations of liquor establishments .”). 40 See Lum & Isaac, supra note 38, at 16 (describing “feedback loop” in predictive model trained on police records that overrepresent drug crimes in heavily patrolled areas). 41 Id. at 19. 42 Id. at 16. 48 demographic characteristics, for residents of that area even where rates of crime may be comparable to other neighborhoods. Person -based models may also be trained on data reflecting underlying disparities,43 which may adversely impact individuals who receive increased attention and law enforcement interactions."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_193",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nthat overrepresent drug crimes in heavily patrolled areas). 41 Id. at 19. 42 Id. at 16. 48 demographic characteristics, for residents of that area even where rates of crime may be comparable to other neighborhoods. Person -based models may also be trained on data reflecting underlying disparities,43 which may adversely impact individuals who receive increased attention and law enforcement interactions. In one person- based program, “officers are instructed to focus their attention on the highest point -value individuals … [who] are subjected to heightened surveillance, and, therefore, are more likely to be stopped, thus further increasing their point value.”44 This situation can create feedback loops in which “targeting of certain areas or certain races creates the impression of higher crime rates in those areas, which then justifies continued police presence there.” 45 Beyond the impact on residents and individuals, feedback loops can erode public trust in police by increasing police presence, and thus enforcement activities, in communities that are already distrustful of law enforcement. c. Privacy Individuals that a predictive policing tool assesses to be more likely to engage in or become a victim of crime may be subject to additional law enforcement scrutiny, raising concerns about privacy, surveillance, and harassment."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_194",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ncan erode public trust in police by increasing police presence, and thus enforcement activities, in communities that are already distrustful of law enforcement. c. Privacy Individuals that a predictive policing tool assesses to be more likely to engage in or become a victim of crime may be subject to additional law enforcement scrutiny, raising concerns about privacy, surveillance, and harassment. Even given stringent criteria for inclusion of an individual’s data in a predictive policing system, the absence of oversight and monitoring for adherence to these criteria can mean that some individuals experience law enforcement surveillance or interactions without substantiated links to criminal activity. Precedent exists for oversight concerns with criminal justice databases. 46 Developers of predictive policing models may also choose to augment police data by drawing from additional datasets.47 However, merging other datasets may also raise privacy concerns, such as revealing sensitive details of individuals or communities.48 43 See Andrew Guthrie Ferguson, Policing Predictive Policing , 94 W ASH. U. L. REV. 1109, 1148– 49 (2017) (“The result has been to justify disproportionate minority contacts and the collection of minority names in databases. These actions then feed a confirmation feedback loop that equates those currently in the system with those who need to be policed by the system."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_195",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nSee Andrew Guthrie Ferguson, Policing Predictive Policing , 94 W ASH. U. L. REV. 1109, 1148– 49 (2017) (“The result has been to justify disproportionate minority contacts and the collection of minority names in databases. These actions then feed a confirmation feedback loop that equates those currently in the system with those who need to be policed by the system. Essentially, high -crime areas or high -value suspects might only be considered ‘high’ because police already have data about those areas or people.”). 44 Sarah Brayne & Angèle Christin, Technologies of Crime Prediction: The Reception of Algorithms in Policing and Criminal Courts, Social Problems 1, 13 (2020) https://doi.org/10.1093/socpro/spaa004; see also Sarah Brayne, Big Data Surveillance: The Case of Policing, 977, 987 (2017), https://doi.org/10.1177/0003122417725865 (“An individual having a high po int value is predictive of future police contact and that police contact further increases the individual’s point value.”). 45 Ferguson, supra note 43 at 1153. 46 See, e.g., CAL. STA TE AUDITOR , THE CALGANG CRIMINAL INTELLIGENCE SYSTEM 1, 31– 32 (2016), https://www.auditor.ca.gov/pdfs/reports/2015 -130.pdf (finding California gang database’s “oversight structure does not ensure that user agencies collect and maintain criminal intelligence in a manner that does not invade individuals’ privacy rights,” and that some agencies lacked adequate support for including individuals in database)."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_196",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nat 1153. 46 See, e.g., CAL. STA TE AUDITOR , THE CALGANG CRIMINAL INTELLIGENCE SYSTEM 1, 31– 32 (2016), https://www.auditor.ca.gov/pdfs/reports/2015 -130.pdf (finding California gang database’s “oversight structure does not ensure that user agencies collect and maintain criminal intelligence in a manner that does not invade individuals’ privacy rights,” and that some agencies lacked adequate support for including individuals in database). 47 See Ratcliffe et al., supra note 3938 . 48 E.g. Arvind Narayanan & Vitaly Shmatikov , Robust De -anonymization of Large Sparse Datasets , https://ieeexplore.ieee.org/document/4531148 (connecting Netflix and IMDB data to learn potentially sensitive video- watching habits of individuals) . 49 d. Interpret ing and Explaining As models become more complex, they gain the ability to represent more intricate relationships and sophisticated patterns in the data.49 This increased flexibility, however, often comes with increased difficulty for humans to interpret and explain the internal workings of these complex models.50 In predictive policing, more complex models are likely to be marginally more accurate than simpler ones,51 especially when predicting rarer crimes. However, the diminishing marginal improvements that come with more sophisticated algorithms may not justify their use over simpler ones, given their higher cost, greater complexity, and decreased interpretability."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_197",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nto interpret and explain the internal workings of these complex models.50 In predictive policing, more complex models are likely to be marginally more accurate than simpler ones,51 especially when predicting rarer crimes. However, the diminishing marginal improvements that come with more sophisticated algorithms may not justify their use over simpler ones, given their higher cost, greater complexity, and decreased interpretability. A less complex predictive policing tool that is more interpretable may better align with law enforcement and community needs and values than a highly complex “black box” tool. An interpretable tool can allow for greater accountability and oversight by providing concrete explanations for a model’s predictions and may even increase transparency into the factors that influenced decisions. Recommendations Thoughtful deployment of predictive policing tools can not only mitigate risks but can also ensure that AI use for predictive policing offers accuracy and efficiency benefits for law enforcement. Entities that have deployed or are considering deploying predictive policing tools should consider the following recommendations. a. Assess Goals of the P redictive P olicing T ool with the Community When considering a predictive policing tool, a critical question is the particular community’s goals that have driven consideration of the tool."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_198",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\npolicing offers accuracy and efficiency benefits for law enforcement. Entities that have deployed or are considering deploying predictive policing tools should consider the following recommendations. a. Assess Goals of the P redictive P olicing T ool with the Community When considering a predictive policing tool, a critical question is the particular community’s goals that have driven consideration of the tool. After identifying objectives, a community should outline how it will measure the success of the tool or alternatives in addressing those goals. These initial steps should engage public agencies, relevant community- based organizations, and other stakeholders in the community, such that agencies can determine how to align their use of tools to community needs and expectations, address concerns and potential risks , and establish consensus for the implementation process. Failure to effectively engage with impacted communities can undermine public trust. Law enforcement agencies weighing the adoption of predictive policing tools should therefore engage with community members and their representatives (e.g. , county commissioners or city council members) regarding goals and measures of success. b."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_199",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nand expectations, address concerns and potential risks , and establish consensus for the implementation process. Failure to effectively engage with impacted communities can undermine public trust. Law enforcement agencies weighing the adoption of predictive policing tools should therefore engage with community members and their representatives (e.g. , county commissioners or city council members) regarding goals and measures of success. b. Assess the Need for a P redictive P olicing Tool and Possible A lternatives Law enforcement agencies should assess the likelihood a predictive policing tool will address the community’s goals, the shortcomings the tool might have, alternatives to the tool 49 See, e.g., PERRY ET AL ., supra note 1, at 36 (comparing “simple methods,” such as regression analyses, to “black box models,” which can model “extremely complicated relationships”). 50 Whereas simple models “are usually directly interpretable by a person,” more complex “black box models” are not. PERRY ET AL ., supra note 1, at 36. 51 See, e.g., PERRY ET AL ., supra note 1, at xix (“Although there is usually a correlation between the complexity of a model and its predictive power, increases in predictive power have tended to show diminishing returns.”). 50 (including non- AI alternatives), and ways the tool might address or exacerbate concerns."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_200",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nET AL ., supra note 1, at 36. 51 See, e.g., PERRY ET AL ., supra note 1, at xix (“Although there is usually a correlation between the complexity of a model and its predictive power, increases in predictive power have tended to show diminishing returns.”). 50 (including non- AI alternatives), and ways the tool might address or exacerbate concerns. Along with these considerations, law enforcement agencies should evaluate whether they have the resources, personnel, and technical expertise necessary for the proper use and monitoring of these types of systems in the short and long term. This assessment —and the full lifecycle of a predictive policing tool’s deployment —should include community engagement. Law enforcement agencies should seek to educate community members and their representatives on how a considered predictive policing tool works, the benefits of the tool, the short - and long- term costs of the tool, the risks associated with the tool (e.g., civil rights concerns), and plans for monitoring and mitigating risks. When consulting with stakeholders, law enforcement agencies should provide the public meaningful opportunities for participation by using plain language, considering language access needs, and communicating with those most likely to be negatively impacted by these tools. c."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_201",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nlong- term costs of the tool, the risks associated with the tool (e.g., civil rights concerns), and plans for monitoring and mitigating risks. When consulting with stakeholders, law enforcement agencies should provide the public meaningful opportunities for participation by using plain language, considering language access needs, and communicating with those most likely to be negatively impacted by these tools. c. Assess Which Data to Use to Train M odels and E nsure Data I s As Accurate As Possible Law enforcement agencies should carefully consider which data to include in a predictive policing model. To mitigate the risk of feedback loops, agencies should keep the model inputs focused on types of crime relevant to their goals. Additionally, because models should be continually updated with new data, agencies should consider filtering out data that reflect actions taken by police in response to previous model outputs in order to avoid feedback loops. Agencies should also ensure a central role for humans in choosing which data to use as inputs, deciding which metrics to use for evaluating accuracy, screening the model’s outputs with a crime analyst’s eye for contextual knowledge and historical factors, and determining which practices to implement in response to predictions."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_202",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nto previous model outputs in order to avoid feedback loops. Agencies should also ensure a central role for humans in choosing which data to use as inputs, deciding which metrics to use for evaluating accuracy, screening the model’s outputs with a crime analyst’s eye for contextual knowledge and historical factors, and determining which practices to implement in response to predictions. Although humans have the potential to introduce their own biases, they are also essential for ensuring that predictive policing tools are being used according to law and regulation, as well as relevant policies. By being transparent with the public about these choices, especially with respect to the selection of input data for predictive tools, agencies can ensure accountability and build public trust. Predictive models may have a veneer of neutrality that can be reinforced by automation bias. 52 To counteract this, user interfaces for predictive policing systems should include constraints, cues, notifications, and embedded content that reinforce appropriate use of the model, especially with regard to critically evaluating model outputs. Training users to think critically about the limits to algorithmic objectivity and error rates must be a top priority in any law enforcement organization using predictive models."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_203",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n52 To counteract this, user interfaces for predictive policing systems should include constraints, cues, notifications, and embedded content that reinforce appropriate use of the model, especially with regard to critically evaluating model outputs. Training users to think critically about the limits to algorithmic objectivity and error rates must be a top priority in any law enforcement organization using predictive models. 53 52 “Automation bias refers to undue deference to automated systems by human actors that disregard contradictory information from other sources or do not (thoroughly) search for additional information.” Saar Alon- Barkat & Madaline Busuioc, Human –AI Interactions in Public Sector Decision Making: “Automation Bias” and “Selective Adherence” to Algorithmic Advice , 33 J. PUB. ADMIN . RSCH. & THEORY 153, 155 (2023). 53 See ALEXANDER BABUTA & MARION OSWALD , ROYAL UNITED SERVS . INST. FOR DEF. & SEC. STUD., DATA ANALYTICS AND ALGORITHMIC BIAS IN POLICING 15 (2019), https://static.rusi.org/20190916_data_analytics_and_algorithmic_bias_in_policing_web_0.pdf (“Adequate training 51 Although elimination of all errors from a large dataset may be infeasible, law enforcement agencies have a responsibility to ensure that the data they collect on both incidents and individuals are as accurate as possible."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_204",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nOSWALD , ROYAL UNITED SERVS . INST. FOR DEF. & SEC. STUD., DATA ANALYTICS AND ALGORITHMIC BIAS IN POLICING 15 (2019), https://static.rusi.org/20190916_data_analytics_and_algorithmic_bias_in_policing_web_0.pdf (“Adequate training 51 Although elimination of all errors from a large dataset may be infeasible, law enforcement agencies have a responsibility to ensure that the data they collect on both incidents and individuals are as accurate as possible. Routine checks of police and other criminal justice data for accuracy and ongoing revisions to improve data quality can mitigate the risks associated with data errors for both the police and community members. To the extent feasible, organizations using predictive policing tools should est ablish channels for affected community members to determine what data is stored about them, learn about decisions made based on that data, and petition for omission or corrections of errors. d. Test, Measure, Validate, and Reevaluate, Including Independently and in a Real- world Context For validation purposes, agencies should use data collected before and after deployment. Pre-deployment data are recommended because they isolate the system’s ability to forecast without any interference from changes in response to the predictions."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_205",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nbased on that data, and petition for omission or corrections of errors. d. Test, Measure, Validate, and Reevaluate, Including Independently and in a Real- world Context For validation purposes, agencies should use data collected before and after deployment. Pre-deployment data are recommended because they isolate the system’s ability to forecast without any interference from changes in response to the predictions. Collecting post -deployment dat a is recommended because they might help in measuring the efficiency or accuracy of the model over time when responses are changing and potentially detecting, deterring, or preventing crimes in the forecasted areas.54 After validating the model, agencies should also conduct operational and field testing to better understand the impact of the model combined with interventions. Even a ccurate and well - validated models could produce unintended consequences when implemented in practice, so agencies should have mechanisms in place to identify the broad impact of their prediction- based interventions—including the possibility of bias and dis crimination —and make any appropriate changes based on continual evaluation."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_206",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nto better understand the impact of the model combined with interventions. Even a ccurate and well - validated models could produce unintended consequences when implemented in practice, so agencies should have mechanisms in place to identify the broad impact of their prediction- based interventions—including the possibility of bias and dis crimination —and make any appropriate changes based on continual evaluation. 55 The impact of a particular predictive policing approach on crime rates is a commonly applied metric, but other factors can yield a more complete picture of the impact, including: community -defined measures of success; citizen commendations or complaints; use of excessive or unwarranted force; traffic stops and field interviews; citations, fines, and fees; victim satisfaction surveys; citizen surveys about factors such as fear of crime and satisfaction with and trust in police; number of tips received; rates of victim and witness cooperation ; officer health, wellbeing, retention, and job satisfaction; and geographic residency of new applicants to the police force . 56 To identify disparate treatment or impacts, evaluations of models should include data focused on cognitive bias and fair decision- making would appear essential to ensure officers are able to consistently achieve the correct balance.”). 54 “Deployment of prediction boxes to the field and delivery of policing dosage to those boxes is expected to suppress some fraction of crime in those locations."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_207",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nidentify disparate treatment or impacts, evaluations of models should include data focused on cognitive bias and fair decision- making would appear essential to ensure officers are able to consistently achieve the correct balance.”). 54 “Deployment of prediction boxes to the field and delivery of policing dosage to those boxes is expected to suppress some fraction of crime in those locations. Predictive accuracy should therefore decline in response to directed patrol.” G.O. Mohler et al., Randomized Controlled Field Trials of Predictive Policing , 110 J. AM. STAT. ASS’N 1399, 1404 (2015). 55 See, e.g., NAT’L INST. STANDARDS & TECH., ARTIFICIAL INTELLIGENCE RISK MANAGEMENT FRAMEWORK (AI RMF 1.0), at 33 tbl.4 (2023), https://doi.org/10.6028/NIST.AI.100-1 . 56 Research exploring the accuracy of place- based predictive policing algorithms commonly relies on the Prediction Accuracy Index (PAI) or the Prediction Efficiency Index* (PEI*). See Spencer Chainey et al., The Utility of Hotspot Mapping for Predicting Spatial Patterns of Crime , 21 SEC. J. 4 (2008) (proposing PAI); Veronica M. White et al. , A Discussion of Current Crime Forecasting Indices and an Improvement to the Prediction Efficiency Index for 52 disaggregated by demographic factors such as race, national origin, age, gender, disability, and other characteristics. Testing and validation are necessary regardless of whether an agency develops a predictive policing tool in- house or acquires the tool from a third party."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_208",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\net al. , A Discussion of Current Crime Forecasting Indices and an Improvement to the Prediction Efficiency Index for 52 disaggregated by demographic factors such as race, national origin, age, gender, disability, and other characteristics. Testing and validation are necessary regardless of whether an agency develops a predictive policing tool in- house or acquires the tool from a third party. Part of testing and evaluation should include completing an impact assessment for the predictive policing tool before putting it into use. Agencies should adopt a mechanism for objective third- party auditing of models and source code to proactively address concerns about model accuracy, reliability, and potential for bias and discrimination. Agencies should routinely audit police databases to mitigate the costs of data errors for both users of the system and community members. Databases used in person- based predictive policing, for example, should be routinely audited to ensure that individuals meet the criteria for being included in the database. Models should be reevaluated periodically based on the policing patterns and crime rates that result from their use, ensuring the models are fair; equitable, including minimizing feedback loops; and aligned with public safety priorities. If seeking to procure a predictive policing tool from a third party, agencies should require regular evaluation and auditing as part of the vendor contract."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_209",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ndatabase. Models should be reevaluated periodically based on the policing patterns and crime rates that result from their use, ensuring the models are fair; equitable, including minimizing feedback loops; and aligned with public safety priorities. If seeking to procure a predictive policing tool from a third party, agencies should require regular evaluation and auditing as part of the vendor contract. Importantly, agencies should mitigate emerging risks to rights and safety, including by regularly updating the predictive policing tool to improve it and reduce its risks. Metrics used to assess accuracy in person -based predictive policing have much in common with those used in risk assessment, because person- based tools estimate, among other things, the likelihood of a person being involved in a crime. See chapter V for a detailed discussion of risk assessment. e. Broadly Consider C ommunity R esources to Address Root Causes of C rime How predictive policing tools are used matters. 57 In addition to (or in place of) a policing response, community- based interventions built around resources for public health and social services can help alleviate the burdens on officers and mitigate concerns about predictive models.58 f. Adopt P olicies Law enforcement agencies should adopt policies that address the use of the predictive policing system pre - and post- deployment."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_210",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n57 In addition to (or in place of) a policing response, community- based interventions built around resources for public health and social services can help alleviate the burdens on officers and mitigate concerns about predictive models.58 f. Adopt P olicies Law enforcement agencies should adopt policies that address the use of the predictive policing system pre - and post- deployment. Such policies should govern which predictive policing systems are approved for use, as well as how predictive models are selected, trained, implemented, Applications , 37 SEC. J. 47 (2024); see also Ned Levine, The “Hottest” Part of a Hotspot: Comments on “The Utility of Hotspot Mapping for Predicting Spatial Patterns of Crime” , 21 SEC. J. 295 (2008) (discussing Recapture Rate Index (RRI)); Veronica M. White & Joel Hunt, Measuring How Relatively “Good” a Hot -spot Map Is: A Summary of Current Metrics , 1 P ROCEEDINGS OF THE IISE ANNUAL CONFERENCE & EXPO 2022, at 97 (2022), available at https://www.ojp.gov/pdffiles1/nij/305365.pdf (evaluating PAI, RRI, PEI, and PEI*). 57 Cf. EXEC. OFF. OF THE PRESIDENT , BLUEPRINT FOR AN AI BILL OF RIGHTS 53–54 (Oct. 2022), https://www.whitehouse.gov/wp- content/uploads/2022/10/Blueprint -for-an-AI-Bill-of-Rights.pdf (describing “predictive policing” as an application of AI that may impact civil rights, civil liberties, or privacy). 58 ANDREW GUTHRIE FERGUSON , THE RISE OF BIG DATA POLICING : SURVEILLANCE , RACE, AND THE FUTURE OF LAW ENFORCEMENT 173–76 (2017)."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_211",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nCf. EXEC. OFF. OF THE PRESIDENT , BLUEPRINT FOR AN AI BILL OF RIGHTS 53–54 (Oct. 2022), https://www.whitehouse.gov/wp- content/uploads/2022/10/Blueprint -for-an-AI-Bill-of-Rights.pdf (describing “predictive policing” as an application of AI that may impact civil rights, civil liberties, or privacy). 58 ANDREW GUTHRIE FERGUSON , THE RISE OF BIG DATA POLICING : SURVEILLANCE , RACE, AND THE FUTURE OF LAW ENFORCEMENT 173–76 (2017). 53 interpreted, and evaluated. Each of these policies should consider the tradeoffs between public safety, community trust, and the potential harms of algorithmic error, human bias, automation bias, and system inequalities that may result in misclassification . For further discussion of governance measures, see the Conclu sion and Best Practices chapter . g. Ensure Adequate H uman T raining and Assessment Law enforcement organizations using predictive policing tools should require regular training on the operation and appropriate use of the specific tools. The training should be appropriate for the tools’ diverse users, and it should include modules to ensure users think critically about the limits to algorithmic objectivity, error rates, ways in which these tools are embedded in existing inequitable systems, and strategies to prevent and mitigate human biases and systemic inequities. Users of predictive policing models should receive training on how to interpret the model’s outputs."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_212",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nfor the tools’ diverse users, and it should include modules to ensure users think critically about the limits to algorithmic objectivity, error rates, ways in which these tools are embedded in existing inequitable systems, and strategies to prevent and mitigate human biases and systemic inequities. Users of predictive policing models should receive training on how to interpret the model’s outputs. The required training should also address how to determine what type of intervention, from police or other services, would be best to prevent or address the types of crime predicted in a given community, especially if predictions are driven by public health factors like substance abuse, homelessness, and mental health disorders. Law enforcement personnel should not be authorized to use predictive policing systems if their training is not current. 54 V. Risk Assessment Risk assessment instruments use quantitative analysis to estimate the likelihood that a certain outcome will occur in the criminal justice system, such as whether an individual will recidivat e or fail to appear for trial.1 These instruments are commonly based on statistical models.2 Agencies and courts may use the model output to inform decisions about individuals, including whether to require detention before trial, what sentence to impose, and what interventions to attempt."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_213",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ncertain outcome will occur in the criminal justice system, such as whether an individual will recidivat e or fail to appear for trial.1 These instruments are commonly based on statistical models.2 Agencies and courts may use the model output to inform decisions about individuals, including whether to require detention before trial, what sentence to impose, and what interventions to attempt. Risk assessment in criminal justice dates back nearly a century,3 and these types of tools are currently widely used.4 Based on the data available, it appears that e very state implements some form of risk assessment,5 with considerable local variation,6 and most states have a state law or court rule that addresses risk assessment.7 At the federal level, risk assessment instruments 1 See P’SHIP ON AI, REPORT ON ALGORITHMIC RISK ASSESSMENT TOOLS IN THE U.S. CRIMINAL JUSTICE SYSTEM 7 (2019), https://partnershiponai.org/paper/report -on-machine- learning -in-risk-assessment -tools -in-the-u-s- criminal - justice -system/ ( discussing definitions of risk assessment). 2 As noted in the introduction, this report follows the definition of “artificial intelligence” from OMB Memoranda M-24-10 and M -24-18, which does not depend on “the type of model” and includes “simple” models, such as regression models that use conventiona l statistics. 3 BERNARD E."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_214",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nlearning -in-risk-assessment -tools -in-the-u-s- criminal - justice -system/ ( discussing definitions of risk assessment). 2 As noted in the introduction, this report follows the definition of “artificial intelligence” from OMB Memoranda M-24-10 and M -24-18, which does not depend on “the type of model” and includes “simple” models, such as regression models that use conventiona l statistics. 3 BERNARD E. HARCOURT , AGAINST PREDICTION : PROFILING , POLICING , AND PUNISHING IN AN ACTUARIAL AGE 47- 76 (2013), https://academic.oup.com/chicago -scholarship -online/book/21282 . 4 See Risk Assessment Landscape , PUB. SAFETY RISK ASSESSMENT CLEARINGHOUSE , https://bja.ojp.gov/program/psrac/selection/risk -assessment -landscape (surveying uses of risk assessment nationwide); Risk Assessment Tool Database , BERKMAN KLEIN CTR., https://criminaljustice.tooltrack.org/ (compiling data from reports and jurisdictions about uses of risk assessment), How Many Jurisdictions Use Each Tool?, MAPPING PRETRIAL INJUSTICE , https://pretrialrisk.com/national- l andscape/how -many -jurisdictions -use-each- tool/ ( summarizing survey data about uses of risk assessment); Stanford Pretrial Risk Assessment Tools Factsheet Project , STANFORD L. SCH. POL’Y LAB, https://law.stanford.edu/pretrial- risk-assessment -tools -factsheet -project/ (collecting authoritative descriptions of common risk assessment instruments); N AT’L CTR."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_215",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nabout uses of risk assessment), How Many Jurisdictions Use Each Tool?, MAPPING PRETRIAL INJUSTICE , https://pretrialrisk.com/national- l andscape/how -many -jurisdictions -use-each- tool/ ( summarizing survey data about uses of risk assessment); Stanford Pretrial Risk Assessment Tools Factsheet Project , STANFORD L. SCH. POL’Y LAB, https://law.stanford.edu/pretrial- risk-assessment -tools -factsheet -project/ (collecting authoritative descriptions of common risk assessment instruments); N AT’L CTR. FOR STATE CTS., APPENDIX A: PROFILES OF ASSESSMENT INSTRUMENTS , https://www.ncsc.org/__data/assets/pdf_file/0014/27140/ran- appendix- a.pdf (same); Pretrial Release: Risk Assessment Tools, N AT’L CONF."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_216",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n( summarizing survey data about uses of risk assessment); Stanford Pretrial Risk Assessment Tools Factsheet Project , STANFORD L. SCH. POL’Y LAB, https://law.stanford.edu/pretrial- risk-assessment -tools -factsheet -project/ (collecting authoritative descriptions of common risk assessment instruments); N AT’L CTR. FOR STATE CTS., APPENDIX A: PROFILES OF ASSESSMENT INSTRUMENTS , https://www.ncsc.org/__data/assets/pdf_file/0014/27140/ran- appendix- a.pdf (same); Pretrial Release: Risk Assessment Tools, N AT’L CONF. OF STATE LEGISLATURES (June 30, 2022), https://www.ncsl.org/civil- an d-criminal- justice/pretrial- release- risk-assessment -tools ( surveying state laws and court rules that address the development and use of risk assessment instruments); 50- State Report on Public Safety Part 2, Strategy 2, Action Item 2, T HE COUNCIL OF STATE GOVERNMENTS , https://50statespublicsafety.us/part- 2/strategy -2/action -item-2/ (providing results of a 50- state survey on use of risk assessment in probation and parole); Cathy Hu et al., National Scan of Policy and Practice in Risk Assessment Policy Brief Number 2017 -01, THE RISK ASSESSMENT CLEARINGHOUSE (July 20, 2018, 3:13 PM), https://bja.ojp.gov/sites/g/files/xyckuh186/files/media/document/PB -Scan -of-Practice.pdf (survey of risk assessment practices, policies, procurement, and perceptions in 43 states)."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_217",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n-2/action -item-2/ (providing results of a 50- state survey on use of risk assessment in probation and parole); Cathy Hu et al., National Scan of Policy and Practice in Risk Assessment Policy Brief Number 2017 -01, THE RISK ASSESSMENT CLEARINGHOUSE (July 20, 2018, 3:13 PM), https://bja.ojp.gov/sites/g/files/xyckuh186/files/media/document/PB -Scan -of-Practice.pdf (survey of risk assessment practices, policies, procurement, and perceptions in 43 states). 5 50-State Report on Public Safety Part 2, Strategy 2, Action Item 2, T HE COUNCIL OF STATE GOVERNMENTS , https://50statespublicsafety.us/part- 2/strategy -2/action -item-2/ (providing results of a 50- state survey on use of risk assessment in probation and parole). 6 Risk Assessment Landscape , PUB. SAFETY RISK ASSESSMENT CLEARINGHOUSE , https://bja.ojp.gov/program/psrac/selection/risk -assessment -landscape (surveying uses of risk assessment nationwide). 7 NAT’L CONF. OF STATE LEGISLATURES (June 30, 2022), https://www.ncsl.org/civil- and-criminal- justice/pretrial- release- risk-assessment -tools ( surveying state laws and court rules that address the development and use of risk assessment instruments). 55 inform decision- making by courts, court services, and prisons. The Model Penal Code also encourages the use of risk assessment.8 This chapter begins with an overview describing how risk assessment is currently used in critical stages of the criminal justice system, as well as the typical design of these instruments."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_218",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\naddress the development and use of risk assessment instruments). 55 inform decision- making by courts, court services, and prisons. The Model Penal Code also encourages the use of risk assessment.8 This chapter begins with an overview describing how risk assessment is currently used in critical stages of the criminal justice system, as well as the typical design of these instruments. Next, the chapter describes the potential benefits of quantitative risk assessment in making criminal justice more effective, equitable, and efficient, followed by a discussion of risks including inaccuracy, biases, errors in data, inadequate validation, and insufficient consideration of alternatives. The chapter closes w ith a set of recommendations for the development and use of risk assessment instruments. Uses of Risk Assessment Risk assessment instruments inform decisions throughout the criminal justice system, including the following phases of prosecution and detention.9 For each phase, this chapter discuss es how risk assessment is used and provide examples of specific risk assessment tools currently in use. As discussed in greater detail below, risk assessment tools should be employed only after a thorough evaluation, including for predictive performance,10 potential bias,11 and suitability for the subject population, as well as the implementation of appropriate precautions. a."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_219",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\neach phase, this chapter discuss es how risk assessment is used and provide examples of specific risk assessment tools currently in use. As discussed in greater detail below, risk assessment tools should be employed only after a thorough evaluation, including for predictive performance,10 potential bias,11 and suitability for the subject population, as well as the implementation of appropriate precautions. a. Pretrial Release Pretrial service agencies and prosecutors make recommendations to judges and judicial officers who ultimately make decisions about the status of defendants before trial.12 A defendant may be released with no or minimal conditions, released subject to supervision and conditions, required to post bail to be released, or detained. Risk assessment can inform these decisions by assisting decision -makers in estimating the likelihood that a defendant will fail to appear in court, commit another offense before trial , or pose a risk to public safety . Examples used at the state and local levels include the Virginia Pretrial Risk Assessment Instrument (VPRAI) and VPRAI 8 Am. Law Inst., M ODEL PENAL CODE: SENTENCING § 6.03 reporter’s note F ( AM. L. INST., Proposed Final Draft 2017), available at https://robinainstitute.umn.edu/sites/robinainstitute.umn.edu/files/2022 - 02/mpcs_proposed_final_draft.pdf ; id . at § 6.09, cmt. E. 9 See Melissa Hamilton, Risk Assessment Tools in the Criminal Legal System – Theory and Practice: A Resource Guide , Nat’l Ass’n of Crim."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_220",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nVPRAI 8 Am. Law Inst., M ODEL PENAL CODE: SENTENCING § 6.03 reporter’s note F ( AM. L. INST., Proposed Final Draft 2017), available at https://robinainstitute.umn.edu/sites/robinainstitute.umn.edu/files/2022 - 02/mpcs_proposed_final_draft.pdf ; id . at § 6.09, cmt. E. 9 See Melissa Hamilton, Risk Assessment Tools in the Criminal Legal System – Theory and Practice: A Resource Guide , Nat’l Ass’n of Crim. Def. Laws. 16 fig. 1 (Nov. 2020) , https://www.nacdl.org/getattachment/a92d7c30- 32d4- 4b49 -9c57 -6c14ed0b9894/riskassessmentreportnovember182020.pdf ( noting a range of criminal justice system decision points where risk assessment instruments are used). 10 As discussed further below, there are a range of possible predictive performance metrics for risk assessment models, including precision and the false positive rate. 11 Similarly, as discussed further below, there are a range of possible bias metrics for risk assessment models, including calibration and predictive equality. See generally Alessandro Castelnovo et al., A Clarification of the Nuances in the Fairness Metrics Landscape , SCIENTIFIC REPORTS (2022); Simon Caton & Christian Haas, Fairness in Machine Learning: A Survey , ACM COMP. SURVEYS (2024)."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_221",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nrate. 11 Similarly, as discussed further below, there are a range of possible bias metrics for risk assessment models, including calibration and predictive equality. See generally Alessandro Castelnovo et al., A Clarification of the Nuances in the Fairness Metrics Landscape , SCIENTIFIC REPORTS (2022); Simon Caton & Christian Haas, Fairness in Machine Learning: A Survey , ACM COMP. SURVEYS (2024). 12 In the federal court system, federal laws establish a general presumption that a defendant should be released before trial unless the government establishes at a detention hearing that the defendant should be detained because they present a risk to the community or are unlikely to appear at subsequent proceedings. Many state court systems also have a presumption of release and allow for defendants to be released if they post cash bail. 56 Revised (VPRAI -R),13 Public Safety Assessment (PSA),14 Ohio Risk Assessment System Pretrial Assessment Tool (ORAS -PAT),15 and Correctional Offender Management Profiling for Alternative Sanctions Pretrial Release Risk (COMPAS PRRS -I and - II).16 In the federal system, U.S. Probation and Pretrial Services uses the Pretrial Risk Assessment (PTRA), an algorithmic tool developed by the Administrative Office of the U.S. Courts.17 b."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_222",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n(VPRAI -R),13 Public Safety Assessment (PSA),14 Ohio Risk Assessment System Pretrial Assessment Tool (ORAS -PAT),15 and Correctional Offender Management Profiling for Alternative Sanctions Pretrial Release Risk (COMPAS PRRS -I and - II).16 In the federal system, U.S. Probation and Pretrial Services uses the Pretrial Risk Assessment (PTRA), an algorithmic tool developed by the Administrative Office of the U.S. Courts.17 b. Sentencing Following a criminal conviction, a judge often has discretion to determine an appropriate sentence for the defendant, subject to applicable statutory ranges and sentencing guidelines.18 Risk assessment tools can support these decision- makers in estimating the likelihood that a defendant will recidivate, which is typically a factor in sentencing. Widely used risk assessments in sentencing include the Level of Service Revised (LSI -R) and L evel of Service Case Management Inventory (LS/CMI), 19 as well as the COMPAS General Recidivism Risk Scale (GRRS), Violent Recidivism Risk Scale (VRRS), and COMPAS -R Summative GRRS.20 Some jurisdictions use 13 See MARIE VANNOSTRAND & KENNETH J. ROSE, VA. DEP’T OF CRIM. JUST. SERVS ., PRETRIAL RISK ASSESSMENT IN VIRGINIA , VIRGINIA PRETRIAL RISK ASSESSMENT INSTRUMENT (2009) , https://www.dcjs.virginia.gov/sites/dcjs.virginia.gov/files/publications/corrections/virginia -pretrial- risk-assessment - report.pdf ; VA. DEP’T OF CRIM. JUST."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_223",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nas the COMPAS General Recidivism Risk Scale (GRRS), Violent Recidivism Risk Scale (VRRS), and COMPAS -R Summative GRRS.20 Some jurisdictions use 13 See MARIE VANNOSTRAND & KENNETH J. ROSE, VA. DEP’T OF CRIM. JUST. SERVS ., PRETRIAL RISK ASSESSMENT IN VIRGINIA , VIRGINIA PRETRIAL RISK ASSESSMENT INSTRUMENT (2009) , https://www.dcjs.virginia.gov/sites/dcjs.virginia.gov/files/publications/corrections/virginia -pretrial- risk-assessment - report.pdf ; VA. DEP’T OF CRIM. JUST. SERVS ., VIRGINIA PRETRIAL RISK ASSESSMENT INSTRUMENT - (VPRAI): INSTRUCTION MANUAL – VERSION 4.5 (2021), https://www.dcjs.virginia.gov/sites/dcjs.virginia.gov/files/publications/corrections/virginia -p retrial- risk-assessment - instrument -vprai_2.pdf ; KENNETH ROSE, STANFORD L. SCH. POL’Y LAB, RISK ASSESSMENT FACT SHEET : VIRGINIA PRETRIAL RISK ASSESSMENT INSTRUMENT (VPRAI) (2019), https://law.stanford.edu/wp - content/uploads/2019/06/VPRAI -Factsheet -FINAL -6-20.pdf . 14 See ADVANCING PRETRIAL POL’Y & RSCH, About the Public Safety Assessment , https://advancingpretrial.org/psa/about/ ; KRISTIN BECHTEL (ARNOLD VENTURES ), STANFORD L. SCH. POL’Y LAB, RISK ASSESSMENT FACT SHEET : PUBLIC SAFETY ASSESSMENT (PSA), https://law.stanford.edu/wp - content/uploads/2019/05/PSA -Sheet -CC-Final -5.10- CC-Upload.pdf. 15 Edward J. Latessa et al, The Creation and Validation of the Ohio Risk Assessment System (ORAS) , 74 Fed. Prob. J. 16 (2010), https://www.uscourts.gov/sites/default/files/74_1_2_0.pdf ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_224",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nAbout the Public Safety Assessment , https://advancingpretrial.org/psa/about/ ; KRISTIN BECHTEL (ARNOLD VENTURES ), STANFORD L. SCH. POL’Y LAB, RISK ASSESSMENT FACT SHEET : PUBLIC SAFETY ASSESSMENT (PSA), https://law.stanford.edu/wp - content/uploads/2019/05/PSA -Sheet -CC-Final -5.10- CC-Upload.pdf. 15 Edward J. Latessa et al, The Creation and Validation of the Ohio Risk Assessment System (ORAS) , 74 Fed. Prob. J. 16 (2010), https://www.uscourts.gov/sites/default/files/74_1_2_0.pdf . 16 EQUIVANT , PRACTITIONER ’S GUIDE TO COMPAS CORE (Apr. 2019) https://web.archive.org/web/20190520172536/http://www.equivant.com/wp- content/uploads/Practitioners -Guide -to- COMPAS -Core -040419.pdf . 17 Pretrial Risk Assessment , ADMIN . OFF. OF THE U.S. CTS., https://www.uscourts.gov/services -forms/probation- and- pretrial- services/supervision/pretrial- risk-assessment . 18 In several jurisdictions , a jury may determine the appropriate sentence. Research on how risk assessment interacts with human decision makers, discussed below, has focused on judges rather than juries. 19 Christopher T. Lowenkamp & Kristin Bechtel, The Predictive Validity of the LSI -R on a Sample of Offenders Drawn from the Records of the Iowa Department of Corrections Data Management System, 71 FED. PROB. J. 25 (2007) https://www.uscourts.gov/sites/default/files/71_3_4_0.pdf ; JAMES AUSTIN ET AL ., INST. ON CRIME , JUST. & CORR. AT GEO. WASH."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_225",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\non judges rather than juries. 19 Christopher T. Lowenkamp & Kristin Bechtel, The Predictive Validity of the LSI -R on a Sample of Offenders Drawn from the Records of the Iowa Department of Corrections Data Management System, 71 FED. PROB. J. 25 (2007) https://www.uscourts.gov/sites/default/files/71_3_4_0.pdf ; JAMES AUSTIN ET AL ., INST. ON CRIME , JUST. & CORR. AT GEO. WASH. UNIV., Reliability and Validity Study of the LSI–R Risk Assessment Instrument, Final Report submitted to the Pennsylvania Board of Probation and Parole (Jan. 9, 2003) https://www.ojp.gov/ncjrs/virtual- library/abstracts/reliability -and-validity -study -lsi-r-risk-assessment -instrument . 20 Eugenie Jackson & Christina Mendoza, Equivant/Northpointe, Setting the Record Straight: What the COMP AS Core Risk and Need Assessment Is and Is Not, H ARVARD DATA SCI. REV., Mar. 31, 2020 https://hdsr.mitpress.mit.edu/pub/hzwo7ax4/release/7 ; EQUIV ANT , PRACTITIONER ’S GUIDE TO COMPAS CORE (Apr. 2019) https://web.archive.org/web/20190520172536/http://www.equivant.com/wp- c ontent/uploads/Practitioners - Guide -to-COMPAS -Core -040419.pdf; Antonio Cordella & Francesco Gualdi, Algorithmic Formalization: Impacts on Administrative Processes, PUB. ADMIN . (Aug. 27, 2024), https://onlinelibrary.wiley.com/doi/10.1111/padm.13030 . 57 specialized instruments to evaluate the risk of recidivism in defendants convicted of sexual offenses.21 c."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_226",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nREV., Mar. 31, 2020 https://hdsr.mitpress.mit.edu/pub/hzwo7ax4/release/7 ; EQUIV ANT , PRACTITIONER ’S GUIDE TO COMPAS CORE (Apr. 2019) https://web.archive.org/web/20190520172536/http://www.equivant.com/wp- c ontent/uploads/Practitioners - Guide -to-COMPAS -Core -040419.pdf; Antonio Cordella & Francesco Gualdi, Algorithmic Formalization: Impacts on Administrative Processes, PUB. ADMIN . (Aug. 27, 2024), https://onlinelibrary.wiley.com/doi/10.1111/padm.13030 . 57 specialized instruments to evaluate the risk of recidivism in defendants convicted of sexual offenses.21 c. Prison Classification If a defendant is in custody or has a custodial sentence imposed, a court, jail, prison, or supporting agency must make decisions about detention. These decisions can include the type of facility, housing unit assignment, placement in a general or special population, and availability of programs, services, and work. Risk assessment instruments can inform these decisions by calling attention to predictors of potential violence and other misconduct while in custody. 22 The tools used for prison classification are predominantly designed to estimate the risk of recidivism after release,23 though some have been modified or evaluated for predicting prison misconduct.24 Tools 21 R. Karl Hanson et al., Assessing the Risk and Needs of Supervised Sexual Offenders: A Prospective Study Using STABLE- 2007, Static -99R, and Static -2002R , 42 C RIM. JUST. & BE HAV ., Dec."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_227",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nclassification are predominantly designed to estimate the risk of recidivism after release,23 though some have been modified or evaluated for predicting prison misconduct.24 Tools 21 R. Karl Hanson et al., Assessing the Risk and Needs of Supervised Sexual Offenders: A Prospective Study Using STABLE- 2007, Static -99R, and Static -2002R , 42 C RIM. JUST. & BE HAV ., Dec. 2015, at 1205, 1205, https://journals.sagepub.com/doi/full/10.1177/0093854815602094 (evaluating risk assessment tools applied to individuals convicted of sexual offenses). 22 See generally N AT’L INST. OF CORR., U.S. DEP’T JUST., OBJECTIVE PRISON CLASSIFICATION : A GUIDE FOR CORRECTIONAL AGENCIES (2nd ed. 2021), https://nicic.gov/resources/nic -library/all- library -items/objective -prison- classification -guide -correctional -agencies ; Richard A. Berk et al., A Randomized Experiment Testing Inmate Classification Systems , 2 C RIM. & PUB. POL’Y 215 (2003) (describing a randomized study to evaluate a prison classification system); Patricia L. Hardyman et al. , Internal Prison Classification Systems: Case Studies in Their Development and Implementation, NAT’L INST. OF CORR. (Jan. 2002), https://nicic.gov/resources/nic -lib rary/all- library -items/internal- prison -classification -systems -case-studies -their (describing the prison classifications systems in several states); Joe Russo, Michael J.D. Vermeer, Dulani Woods & Brian A."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_228",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\na randomized study to evaluate a prison classification system); Patricia L. Hardyman et al. , Internal Prison Classification Systems: Case Studies in Their Development and Implementation, NAT’L INST. OF CORR. (Jan. 2002), https://nicic.gov/resources/nic -lib rary/all- library -items/internal- prison -classification -systems -case-studies -their (describing the prison classifications systems in several states); Joe Russo, Michael J.D. Vermeer, Dulani Woods & Brian A. Jackson, Risk and Needs Assessments in Prisons: Identifying High- Priority Needs for Using Evidence -Based Practices , RAND (Sept. 9, 2020), https://www.rand.org/pubs/research_reports/RRA108- 5.html ; Daryl G. Kroner & Jeremy F. Mills, The Accuracy of Five Risk Appraisal Instruments in Predicting Institutional Misconduct and New Convictions , 28 CRIM. JUST. & BEHAV ., Aug. 2001, at 471, 471, https://journals.sagepub.com/doi/10.1177/009385480102800405 ; Thomas R. Kane, The Validity of Prison Classification: An Introduction to Practical Considerations and Research Issues , 32 CRIME & DELINQ ., July 1986, at 367, 367, https://journals.sagepub.com/doi/abs/10.1177/0011128786032003008 (describing methods for validating prison classification systems). 23James M."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_229",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nAppraisal Instruments in Predicting Institutional Misconduct and New Convictions , 28 CRIM. JUST. & BEHAV ., Aug. 2001, at 471, 471, https://journals.sagepub.com/doi/10.1177/009385480102800405 ; Thomas R. Kane, The Validity of Prison Classification: An Introduction to Practical Considerations and Research Issues , 32 CRIME & DELINQ ., July 1986, at 367, 367, https://journals.sagepub.com/doi/abs/10.1177/0011128786032003008 (describing methods for validating prison classification systems). 23James M. Byrne & Amy Dezember, The Research Director Perspective on the Design, Implementation, and Impact of Risk Assessment and Offender Classification Systems in USA Prisons: A National Survey , in HANDBOOK ON RISK AND NEED ASSESSMENT 48, 53 (Faye Taxman ed., 2016), https://www.taylorfrancis.com/chapters/edit/10.4324/9781315682327 -10/research -director -perspective- design- implementation -impact -risk-assessment -offender -classification -systems -usa-prisons -national- survey- james - byrneand- amy-dezember?context=ubx&refId=9495cf 84-b71e -455f-9547- 8e80237d7fa7 ( reporting results of a multistate survey on prison classification systems and finding that most responding states used a risk assessment tool designed to predict recidivism). 24 Edward Latessa et al. , Creation and Validation of the Ohio Risk Assessment System: Final Report , UNIV. OF CINCINNATI CTR. FOR CRIM. JUST. RSCH."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_230",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nsurvey- james - byrneand- amy-dezember?context=ubx&refId=9495cf 84-b71e -455f-9547- 8e80237d7fa7 ( reporting results of a multistate survey on prison classification systems and finding that most responding states used a risk assessment tool designed to predict recidivism). 24 Edward Latessa et al. , Creation and Validation of the Ohio Risk Assessment System: Final Report , UNIV. OF CINCINNATI CTR. FOR CRIM. JUST. RSCH. (July 2009), https://www.uc.edu/content/dam/uc/ccjr/docs/reports/project_reports/ORAS_Final_Report.pdf (describing the ORAS Prison Intake Tool, which is designed for prison intake use and validated as an estimate of post -release recidivism); Joshua S. Long, Appropriate Classification of Prisoners: Balancing Prison Safety with the Least Restrictive Placements of Ohio Inmates (Jun. 22, 2020) (Ph.D. dissertation, University of Cincinnati), https://cech.uc.edu/content/dam/refresh/cech -6 2/school -of-criminal- justice/research/2020/Joshua%20S.%20Long%206- 22-20.pdf ; Matthew Makarios & Edward J. Latessa, Developing a Risk and Needs Assessment Instrument for Prison Inmates: The Issue of Outcome , 40 CRIM. JUST. & BE HAV ., Dec."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_231",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nLong, Appropriate Classification of Prisoners: Balancing Prison Safety with the Least Restrictive Placements of Ohio Inmates (Jun. 22, 2020) (Ph.D. dissertation, University of Cincinnati), https://cech.uc.edu/content/dam/refresh/cech -6 2/school -of-criminal- justice/research/2020/Joshua%20S.%20Long%206- 22-20.pdf ; Matthew Makarios & Edward J. Latessa, Developing a Risk and Needs Assessment Instrument for Prison Inmates: The Issue of Outcome , 40 CRIM. JUST. & BE HAV ., Dec. 2013, at 1449, 1449, https://journals.sagepub.com/doi/full/10.1177/0093854813496240 (comparing risk assessment tools in the prison classification context, one designed to estimate misconduct in custody and the other designed to estimate post- release recidivism, and concluding that are significant differences and a “one size fits all” appr oach to risk assessment may undermine validity). 58 that have been specifically designed and validated for predicting prison misconduct are less common.25 In the federal system, the Federal Bureau of Prisons currently uses the Prisoner Assessment Tool Targeting Estimated Risk and Needs (PATTERN)26 to track dynamic changes in risk and the Standardized Prisoner Assessment for Reduction in Criminality (SPARC -13)27 to identify programmatic and treatment needs of inmates . d."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_232",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nbeen specifically designed and validated for predicting prison misconduct are less common.25 In the federal system, the Federal Bureau of Prisons currently uses the Prisoner Assessment Tool Targeting Estimated Risk and Needs (PATTERN)26 to track dynamic changes in risk and the Standardized Prisoner Assessment for Reduction in Criminality (SPARC -13)27 to identify programmatic and treatment needs of inmates . d. Probation, parole, and supervision Risk assessment tools are commonly used to inform decisions about the appropriate level of supervision for convicted persons who are not in custody, conditions for release and reentry plans from custody, and eligibility for earned release from custody. 28 Assessments that attempt to calculate likelihood of recidivism are common in these settings, too, such as LSI -R and COMPAS GRRS. In the federal system, the Federal Bureau of Prisons uses PATTERN to inform eligibility for earned time. 29 The Administrative Office of the U.S. Courts also developed the Post Conviction Risk Assessment (PCRA), which aims to predict general and violent recidivism and is used by federal probation officers."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_233",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ncommon in these settings, too, such as LSI -R and COMPAS GRRS. In the federal system, the Federal Bureau of Prisons uses PATTERN to inform eligibility for earned time. 29 The Administrative Office of the U.S. Courts also developed the Post Conviction Risk Assessment (PCRA), which aims to predict general and violent recidivism and is used by federal probation officers. 30 Risk Assessment Design There are, broadly, two types of risk assessment instruments: actuarial models, which quantitatively combine factors to estimate the likelihood that a risk will occur, and structured 25 E.g., Grant Duwe, The Development and Validation of a Classification System Predicting Severe and Frequent Prison Misconduct , 100 T HE PRISON J., Mar. 2020, at 173 https://journals.sagepub.com/doi/10.1177/0032885519894587 (describing the design and validation of a risk assessment tool for estimating the likelihood of misconduct in custody); Mark D. Cunningham et al. , An Actuarial Model for Assessment of Prison Violence Risk Among Maximum Security Inmates , 12 A SSESSMENT , Mar. 2005, at 40 https://journals.sagepub.com/doi/abs/10.1177/1073191104272815 (similar). 26 NAT’L INST. OF JUST., 2023 REVIEW AND REVALIDATION OF THE FIRST STEP ACT RISK ASSESSMENT TOOL (Aug. 2024), https://www.ojp.gov/pdffiles1/nij/309264.pdf ; Zachary Hamilton et al., Tailoring to a Mandate: The Development and Validation of the Prisoner Assessment Tool Targeting Estimated Risk and Needs (P ATTERN) , 39 JUST. Q., Apr."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_234",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n12 A SSESSMENT , Mar. 2005, at 40 https://journals.sagepub.com/doi/abs/10.1177/1073191104272815 (similar). 26 NAT’L INST. OF JUST., 2023 REVIEW AND REVALIDATION OF THE FIRST STEP ACT RISK ASSESSMENT TOOL (Aug. 2024), https://www.ojp.gov/pdffiles1/nij/309264.pdf ; Zachary Hamilton et al., Tailoring to a Mandate: The Development and Validation of the Prisoner Assessment Tool Targeting Estimated Risk and Needs (P ATTERN) , 39 JUST. Q., Apr. 2021, at 1129, 1129, https://www.tandfonline.com/doi/full/10.1080/07418825.2021.1906930 . 27 NAT’L INST. OF JUST., NCJ 309349, 2023 REVIEW AND VALIDATION OF THE FEDERAL BUREAU OF PRISONS NEEDS ASSESSMENT SYSTEM (Sept. 2024), https://www.ojp.gov/pdffiles1/nij/309349.pdf . 28 See, e.g., John Monahan & Jennifer L. Skeem, Risk Assessment in Criminal Sentencing , 12 A NN. REV. CRIM. PSYCH . 489, 494, 496 (2016) (describing risk assessments to shorten a sentence on the “back end”); Sheldon X. Zhang et al., An Analysis of Prisoner Reentry and Parole Risk Using COMP AS and Traditional Criminal History Measures , 6 Crime & Delinquency 167 (2014) (describing use of COMPAS in parole supervision). 29 See U.S. GOV’T ACCOUNTABILITY OFF., PUB. NO. GAO- 23-105139, BUREAU OF PRISONS SHOULD IMPROVE EFFORTS TO IMPLEMENT ITS RISK AND NEEDS ASSESSMENT SYSTEM , https://www.gao.gov/assets/gao -23-105139.pdf (describing how PATTERN is used for earned time eligibility). 30 Post Conviction Risk Assessment , ADMIN . OFF. OF THE U.S."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_235",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nCrime & Delinquency 167 (2014) (describing use of COMPAS in parole supervision). 29 See U.S. GOV’T ACCOUNTABILITY OFF., PUB. NO. GAO- 23-105139, BUREAU OF PRISONS SHOULD IMPROVE EFFORTS TO IMPLEMENT ITS RISK AND NEEDS ASSESSMENT SYSTEM , https://www.gao.gov/assets/gao -23-105139.pdf (describing how PATTERN is used for earned time eligibility). 30 Post Conviction Risk Assessment , ADMIN . OFF. OF THE U.S. CTS., https://www.uscourts.gov/services - forms/probation- and-pretrial- services/supervision/post -conviction- risk-assessment ; s ee also Seena Fazel et al., The Predictive Performance of Criminal Risk Assessment Tools Used at Sentencing: Systematic Review of Validation Studies , 81 J. CRIM. JUST., July –Aug. 2022 (analyzing sentencing and post -conviction tools). 59 judgments,31 which provide frameworks for applying experience and intuition.32 The simplest actuarial designs compute a sum of factors, without any weighting, to generate an overall risk score. More complex approaches use conventional statistical methods, typically linear or logistic regression. Recent models use advanced statistics and machine learning methods, such as boosted regression33 or gradient -boosted decision trees.34 Typically, the quantitative output of a model is converted into a category, such as low, moderate, or high risk, by applying predefined thresholds.35 The features that risk assessments take into consideration also vary significantly."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_236",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nconventional statistical methods, typically linear or logistic regression. Recent models use advanced statistics and machine learning methods, such as boosted regression33 or gradient -boosted decision trees.34 Typically, the quantitative output of a model is converted into a category, such as low, moderate, or high risk, by applying predefined thresholds.35 The features that risk assessments take into consideration also vary significantly. Some have over 100 distinct inputs, while others consider fewer than 10.36 The general long- term trend is toward fewer features that have a more readily understandable relationship with outcomes in the criminal justice system. 37 Early risk assessments tended to emphasize subjective characterizations of defendants, derived from professional interviews.38 Some early risk assessment tools also relied on impermissible factors, such as race.39 Modern risk assessment instruments tend to employ more objective factors that are more closely related to criminal justice outcomes. The factors may be fixed (e.g., criminal history) or changeable over time (e.g., time since last infraction or participatio n in drug treatment). 40 Some recent risk assessment tools also account for stages of the criminal justice system and periodic 31 Structured judgments are not a focus of this report, since they fall outside the definition of artificial intelligence in OMB Memoranda M- 24-10 and M -24-18."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_237",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nhistory) or changeable over time (e.g., time since last infraction or participatio n in drug treatment). 40 Some recent risk assessment tools also account for stages of the criminal justice system and periodic 31 Structured judgments are not a focus of this report, since they fall outside the definition of artificial intelligence in OMB Memoranda M- 24-10 and M -24-18. This chapter discusses them below as an important comparison for actuarial models, which can be AI within the OMB definition. 32 Sarah L. Desmarais & Jay P. Singh, Risk Assessment Instruments Validated and Implemented in Correctional Settings in the United States , THE COUNCIL OF STATE GOV’TS JUST. CTR. (Mar. 27, 2013), https://csgjusticecenter.org/wp -content/uploads/2020/02/Risk- Assessment -Instruments -Validated -and-Implemented - in-Correctional -Settings -in-the-United -States.pdf ( surveying the design and validation of risk assessment tools); Jennifer L. Skeem & John Monahan, Current Directions in Violence Risk Assessment , VA. PUB. L. & LEGAL THEORY RSCH. PAPER NO. 2011 -13 (Mar. 2011), https://gspp.berkeley.edu/assets/uploads/research/pdf/03 - 2011_Current_Directions_in_Violence_Risk_Assessment.pdf . 33 Zachary Hamilton et al., Tailoring to a Mandate: The Development and Validation of the Prisoner Assessment Tool Targeting Estimated Risk and Needs (P ATTERN) , 39 J UST. Q., Apr. 2021, at 1129, 1129, https://www.tandfonline.com/doi/full/10.1080/07418825.2021.1906930 ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_238",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nDirections in Violence Risk Assessment , VA. PUB. L. & LEGAL THEORY RSCH. PAPER NO. 2011 -13 (Mar. 2011), https://gspp.berkeley.edu/assets/uploads/research/pdf/03 - 2011_Current_Directions_in_Violence_Risk_Assessment.pdf . 33 Zachary Hamilton et al., Tailoring to a Mandate: The Development and Validation of the Prisoner Assessment Tool Targeting Estimated Risk and Needs (P ATTERN) , 39 J UST. Q., Apr. 2021, at 1129, 1129, https://www.tandfonline.com/doi/full/10.1080/07418825.2021.1906930 . 34 Jon Kleinberg et al., Human Decisions and Machine Predictions , 133 Q.J. ECON., Aug. 2017, at 237, 237, https://academic.oup.com/qje/article/133/1/237/4095198 . 35 The thresholds are typically set when developing, validating, or revalidating a risk assessment tool. The thresholds and their quantitative and qualitative meanings vary by risk assessment tool. 36 See the references accompanying the Uses of Risk Assessment section for factors that widely used risk assessment tools analyze. 37 Bernard E. Harcourt, Risk as a Proxy for Race: The Dangers of Risk Assessment , 27 F ED. SENT’G REP. 237 (2015), https://scholarship.law.columbia.edu/cgi/viewcontent.cgi?article=3568&context=faculty_scholarship (describing the long -term historical trend in risk assessment factors). 38 James Bonta & D.A. Andrews , Risk -Need -Responsivity Model for Offender Assessment and Rehabilitation, PUBLIC SAFETY CANADA (Jan."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_239",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nwidely used risk assessment tools analyze. 37 Bernard E. Harcourt, Risk as a Proxy for Race: The Dangers of Risk Assessment , 27 F ED. SENT’G REP. 237 (2015), https://scholarship.law.columbia.edu/cgi/viewcontent.cgi?article=3568&context=faculty_scholarship (describing the long -term historical trend in risk assessment factors). 38 James Bonta & D.A. Andrews , Risk -Need -Responsivity Model for Offender Assessment and Rehabilitation, PUBLIC SAFETY CANADA (Jan. 2007), https://www.publicsafety.gc.ca/cnt/rsrcs/pblctns/rsk -nd-rspnsvty/rsk- nd- rspnsvty- eng.pdf ; D.A. Andrews, James Bonta & J. Stephen Wormith, The Recent Past and Near Future of Risk and/or Need Assessment , 52 C RIME & DELINQ ., Jan. 2006, at 7, 7, https://journals.sagepub.com/doi/10.1177/0011128705281756 ; Desmarais & Singh supra note 32. 39 Early risk assessment instruments considered race as a factor. Modern models do not. See Bernard E. Harcourt, Risk as a Proxy for Race: The Dangers of Risk Assessment , 27 F ED. SENT’G REP. 237 (2015), https://scholarship.law.columbia.edu/cgi/viewcontent.cgi?article=3568&context=faculty_scholarship ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_240",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nAssessment , 52 C RIME & DELINQ ., Jan. 2006, at 7, 7, https://journals.sagepub.com/doi/10.1177/0011128705281756 ; Desmarais & Singh supra note 32. 39 Early risk assessment instruments considered race as a factor. Modern models do not. See Bernard E. Harcourt, Risk as a Proxy for Race: The Dangers of Risk Assessment , 27 F ED. SENT’G REP. 237 (2015), https://scholarship.law.columbia.edu/cgi/viewcontent.cgi?article=3568&context=faculty_scholarship . 40 These different categories of factors are sometimes delineated as “static” and “dynamic.” 60 reassessment and are designed to interact with treatment and supervision conditions that can affect risk calculations.41 Future risk assessment approaches could incorporate more frequent model validation and updates, as well as more frequent reassessments based on evolving factors.42 These changes could improve predictive performance and reduce biases. For example, researchers are currently exploring how to evaluate changes in risk based on real -time location and provide prompt support to individuals based on their unique risks and ne eds. 43 These types of ongoing assessments may create privacy risks for individuals, and future approaches may have to further account for both maximizing predictive performance and respecting privacy."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_241",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nbiases. For example, researchers are currently exploring how to evaluate changes in risk based on real -time location and provide prompt support to individuals based on their unique risks and ne eds. 43 These types of ongoing assessments may create privacy risks for individuals, and future approaches may have to further account for both maximizing predictive performance and respecting privacy. 44 Potential Benefits for a More Effective, Equitable, and Efficient Criminal Justice System The central promise of risk assessment is that empirical evaluation of the risk of future harmful behavior could be more accurate, transparent, and equitable than subjective human judgments alone. More accurate assessments of risk have the potential for significant benefits. They could enable better alignment between justice system functions including rehabilitation, deterrence, and incapacitation, and the prevention of future offenses. 45 Better predictions could also more accurately identify people who are unlikely to reoffend, channeling them toward lesser pretrial restrictions, lesser sentences, and less restrictive conditions of release."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_242",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nalone. More accurate assessments of risk have the potential for significant benefits. They could enable better alignment between justice system functions including rehabilitation, deterrence, and incapacitation, and the prevention of future offenses. 45 Better predictions could also more accurately identify people who are unlikely to reoffend, channeling them toward lesser pretrial restrictions, lesser sentences, and less restrictive conditions of release. 46 Efficiency in resource allocation is another possible upside of more accurate estimates of risk likelihood.47 Costlier aspects of criminal justice monitoring or detention could be better 41 The 2022 annual review and validation of PATTERN, for example, found that individuals in federal prison could and often did see their risk level change from first to last assessment, independent of simply getting older (which is associated with lower risk ). NAT’L INST. OF JUST., NCJ 305720, 2022 REVIEW AND REVALIDATION OF THE FIRST STEP ACT RISK ASSESSMENT TOOL 18, 35 (Mar. 2022), https://www.ojp.gov/pdffiles1/nij/305720.pdf . 42 See D. Michael Applegarth et al., Imperfect Tools: A Research Note on Developing, Applying, and Increasing Understanding of Criminal Justice Risk Assessments , 34 C RIM. JUST. POL’Y REV. 319, 323 (2023), https://journals.sagepub.com/doi/epub/10.1177/08874034231180505 (noting support of dynamic factors by focus group of winners of the National Institute of Justice’s Recidivism Forecasting Challenge)."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_243",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nTOOL 18, 35 (Mar. 2022), https://www.ojp.gov/pdffiles1/nij/305720.pdf . 42 See D. Michael Applegarth et al., Imperfect Tools: A Research Note on Developing, Applying, and Increasing Understanding of Criminal Justice Risk Assessments , 34 C RIM. JUST. POL’Y REV. 319, 323 (2023), https://journals.sagepub.com/doi/epub/10.1177/08874034231180505 (noting support of dynamic factors by focus group of winners of the National Institute of Justice’s Recidivism Forecasting Challenge). 43 The National Institute of Justice recently funded research to develop a real -time, cellphone -based intelligent tracking system to monitor people who are on community supervision with the goal of flagging potentially risky behavior and providing support to avert such actions. See M ARCUS ROGERS , NCJ 308693, AI ENABLED COMMUNITY SUPERVISION FOR CRIMINAL JUSTICE SERVICES 2–3 (2024) (Final Rep. to the Nat’l Inst. of Just., Award No. 2019 -75- CX-K001), https://www.ojp.gov/pdffiles1/nij/grants/308693.pdf . 44 See id. at 12 –13, 36. 45 See KLEINBERG ET AL ., supra note 33 at 237 ; Erin Collins, Punishing Risk , 107 G EO. L.J. 57, 72 -73 (2018), https://www.law.georgetown.edu/georgetown- law-journal/wp -content/uploads/sites/26/2018/12/Punishing- Risk- 2.pdf ; J ohn Monahan & Jennifer L. Skeem, Risk Assessment in Criminal Sentencing , 12 ANN. REV. CLINICAL PSYCH ., 489, 489, https://doi.org/10.1146/annurev- clinpsy -021815- 092945 . 46 See Sarah L."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_244",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nSee KLEINBERG ET AL ., supra note 33 at 237 ; Erin Collins, Punishing Risk , 107 G EO. L.J. 57, 72 -73 (2018), https://www.law.georgetown.edu/georgetown- law-journal/wp -content/uploads/sites/26/2018/12/Punishing- Risk- 2.pdf ; J ohn Monahan & Jennifer L. Skeem, Risk Assessment in Criminal Sentencing , 12 ANN. REV. CLINICAL PSYCH ., 489, 489, https://doi.org/10.1146/annurev- clinpsy -021815- 092945 . 46 See Sarah L. Desmarais, John Monahan & James Austin, The Empirical Case for Pretrial Risk Assessment Instruments , CRIM. J. & BE H AV . (2021). 47 Erin Collins, Punishing Risk , 107 G EO. L.J. 57, 76 -77 (2018), https://www.law.georgetown.edu/georgetown- law- journal/wp -content/uploads/sites/26/2018/12/Punishing- Risk-2.pdf .. 61 directed toward situations where there is greater predicted benefit.48 For a given level of public resources, it may be possible to obtain a greater level of public safety.49 Risk assessment instruments also have the potential to increase transparen cy of human judgments.50 A risk assessment tool could be made publicly accessible, along with its design documentation, validation studies, and guidance to practitioners.51 The data used for risk assessment could provide the basis for review of decisions —and correction , if necessary —by affected individuals and their counsel. A subjective decision- maker, by contrast, might not (intentionally or otherwise) fully explain the information that they considered and how they arrived at a decision."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_245",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nwith its design documentation, validation studies, and guidance to practitioners.51 The data used for risk assessment could provide the basis for review of decisions —and correction , if necessary —by affected individuals and their counsel. A subjective decision- maker, by contrast, might not (intentionally or otherwise) fully explain the information that they considered and how they arrived at a decision. Equity is another important motivation for using risk assessment tools. Models can be designed and validated to minimize disparities in predictive performance across demographic groups. 52 Models can also be designed and validated to ensure that individuals with similar salient characteristics, such as the crime charged and criminal history, receive similar estimates of risk likelihood. 53 When risk assessments are appropriately designed, validated, and used, actuarial models can be predictive of criminal justice outcomes and can outperform human judgments alone.54 48 There are, to be sure, other factors to consider in allocating criminal justice resources. Crime prevention is an important goal, but not the only goal. 49 KLEINBERG ET AL . supra note 33. 50 Alex Chohlas -Wood, Understanding Risk Assessment Instruments in Criminal Justice , BROOKINGS (June 19, 2020), https://www.brookings.edu/articles/understanding- risk-assessment -instruments -in-criminal- justice/ . 51 The Public Safety Assessment (PSA), for example, is available to the public."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_246",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nconsider in allocating criminal justice resources. Crime prevention is an important goal, but not the only goal. 49 KLEINBERG ET AL . supra note 33. 50 Alex Chohlas -Wood, Understanding Risk Assessment Instruments in Criminal Justice , BROOKINGS (June 19, 2020), https://www.brookings.edu/articles/understanding- risk-assessment -instruments -in-criminal- justice/ . 51 The Public Safety Assessment (PSA), for example, is available to the public. So are the PSA’s design documentation, validation studies, and guidance to practitioners. 52 This conception of equity is, in AI research and practice, often referred to as “group fairness.” See the design documentation and validation studies referenced in the first sec tion of this chapter for examples of how risk assessment tool developers address equity considerations. As discussed further below, there are differing possible equity metrics, and risk assessment tools may be considered equitable by some metrics and not by ot hers. The factors used for risk assessment can also be closely related to demographics (e.g., residential and income data can be related to race), adding further complexity to the challenge of measuring and mitigating biases. 53 In AI research and practice, this conception of equity is often referred to as “individual fairness.” As discussed further below, the use of “cut points” with risk assessment tools can introduce or exacerbate risks to individual fairness. See Jane R."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_247",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nand income data can be related to race), adding further complexity to the challenge of measuring and mitigating biases. 53 In AI research and practice, this conception of equity is often referred to as “individual fairness.” As discussed further below, the use of “cut points” with risk assessment tools can introduce or exacerbate risks to individual fairness. See Jane R. Bambauer, Tal Zarsky & Jonathan Mayer, When a Small Change Makes a Big Difference: Algorithmic Fairness Among Similar Individuals , 55 U.C. DAVIS L. REV. 2337 (2022). 54 SHAMENA ANWAR ET AL ., RAND CORP., RR-A3299- 1, WHAT HAPPENS WHEN JUDGES FOLLOW THE RECOMMENDATIONS OF PRETRIAL DETENTION RISK ASSESSMENT INSTRUMENTS MORE OFTEN ? 8 (2024) https://www.rand.org/pubs/research_reports/RRA3299- 1.html ; Desmarais et al., supra note 31; Jodi L. Viljoen et al., Are risk assessment tools more accurate than unstructured judgments in predicting violent, any, and sexual offending? A meta- analysis of direct comparison studies , B EHAV . SCI. & LAW (2024), https://onlinelibrary.wiley.com/doi/full/10.1002/bsl.2698 ; Zhiyuan Lin et al., The limits of human predictions of recidivism , 6 S CI. ADV. (2020), https://www.science.org/doi/10.1126/sciadv.aaz0652 ; R. Karl Hanson & Kelly E. Morton- Bourgon, The Accuracy of Recidivism Risk Assessments for Sexual Offenders: A Meta -Analysis , PUBLIC SAFETY AND EMERGENCY PREPAREDNESS CANADA (2007), https://publications.gc.ca/collections/Collection/PS3 -1- 2007 -1E.pdf ; D. A."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_248",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nSCI. & LAW (2024), https://onlinelibrary.wiley.com/doi/full/10.1002/bsl.2698 ; Zhiyuan Lin et al., The limits of human predictions of recidivism , 6 S CI. ADV. (2020), https://www.science.org/doi/10.1126/sciadv.aaz0652 ; R. Karl Hanson & Kelly E. Morton- Bourgon, The Accuracy of Recidivism Risk Assessments for Sexual Offenders: A Meta -Analysis , PUBLIC SAFETY AND EMERGENCY PREPAREDNESS CANADA (2007), https://publications.gc.ca/collections/Collection/PS3 -1- 2007 -1E.pdf ; D. A. Andrews et al., The Recent Past and Near Future of Risk and/or Need Assessment , 52 C RIME & DELINQ . 7 (2006), https://journals.sagepub.com/doi/10.1177/0011128705281756 ; D. Mossman, Assessing Predictions of Violence: Being Accurate about Accuracy , 62 J. CONSULT . CLIN. PSYCHOL . 783 (1994), https://pub med.ncbi.nlm.nih.gov/7962882/ ; Don M. Gottfredson, Effects of Judges’ Sentencing Decisions on Criminal Careers, National Institute of Justice: Research in Brief (November, 1999), 62 Modern models that are widely used have been evaluated for differing predictive performance by race or gender, with mixed results .55 As discussed further below, studies on the predictive performance and disparities of risk assessment tools have significant limitations, and results substantially differ by testing methods, prediction and bias metrics, populations of individuals studied, and translation from quantitative to qualitative findings."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_249",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nmodels that are widely used have been evaluated for differing predictive performance by race or gender, with mixed results .55 As discussed further below, studies on the predictive performance and disparities of risk assessment tools have significant limitations, and results substantially differ by testing methods, prediction and bias metrics, populations of individuals studied, and translation from quantitative to qualitative findings. It is possible that use of more advanced machine learning methods could meaningfully improve the performance and bias characteristics of risk assessment tools. 56 This area of research is nascent, however, and advanced models may be more difficult to understand and analyze. The Risks of Risk Assessment While there are potential benefits to risk assessment, those benefits may not be fully realized. Use of these tools can also potentially reinforce bias, inequality, and other problems in the criminal justice system. When considering implementation of a ris k assessment tool, careful analysis of possible downsides is important. Accuracy, which is a leading rationale for risk assessment in criminal justice, is also a leading concern. Applying standards widely used in scientific research, validation studies indicate that risk assessment models can better predict criminal justice outcomes than random chance, and possibly in some circumstances better than human judgment alone, but a risk materializing (or not) remains far from certain."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_250",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nAccuracy, which is a leading rationale for risk assessment in criminal justice, is also a leading concern. Applying standards widely used in scientific research, validation studies indicate that risk assessment models can better predict criminal justice outcomes than random chance, and possibly in some circumstances better than human judgment alone, but a risk materializing (or not) remains far from certain. 57 As an example, in one state’s recent comparative evaluation of several https://www.ojp.gov/pdffiles1/nij/178889.pdf ; see generally Michael J. White et al, The Meta -Analysis of Clinical Judgment Project: Fifty -Six Years of Accumulated Research on Clinical Versus Statistical Prediction, 34 T HE COUNSELING PSYCHOL . 341 (2006), https://journals.sagepub.com/doi/10.1177/0011000005285875 ; William M. Gove et al., Clinical Versus Mechanical Prediction: A Meta -Analysis , 12 P SYCHOL . ASSESS . 19 (2000), http://zaldlab.psy.vanderbilt.edu/resources/wmg00pa.pdf ; Robyn M. Dawes et al., Clinical Versus Actuarial Judgment , 243 SCIENCE 1668 (1989), https://meehl.umn.edu/sites/meehl.umn.edu/files/files/138cstixdawesfaustmeehl.pdf . 55 See the validation studies for risk assessment tools referenced in the first section of this chapter. There has been limited meta -analysis of relevant research. See Sarah L. Desmarais et al., Predictive Validity of Pretrial Risk Assessments: A Systematic Review of the Literature , 48 C RIM. JUST. & BE HAV ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_251",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n, 243 SCIENCE 1668 (1989), https://meehl.umn.edu/sites/meehl.umn.edu/files/files/138cstixdawesfaustmeehl.pdf . 55 See the validation studies for risk assessment tools referenced in the first section of this chapter. There has been limited meta -analysis of relevant research. See Sarah L. Desmarais et al., Predictive Validity of Pretrial Risk Assessments: A Systematic Review of the Literature , 48 C RIM. JUST. & BE HAV . 398 (2021) (surveying validation studies for pretrial risk assessment tools and noting in supplementary material the demographics in studies); Seena Fazel et al., The Predictive Performance of Criminal Risk Assessment Tools Used at Sentencing: Systematic Review of Validation Studies , 81 J. CRIM. JUST., July –Aug. 2022 (surveying validation studies for risk assessment tools used at sentencing and noting population demographics). There has also been limited research directly comparing risk assessment tools using similar populations and methods. See J UD. COUNCIL CAL., PRETRIAL RISK ASSESSMENT TOOL VALIDATION (2022), https://www.courts.ca.gov/documents/Pretrial- Pilot- Program -Risk-Assesment -Tool-Validation - 2022.pdf ( reporting results, including on race and gender disparities, from a coordinated multicounty validation study that examined several risk assessment tools)."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_252",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nsentencing and noting population demographics). There has also been limited research directly comparing risk assessment tools using similar populations and methods. See J UD. COUNCIL CAL., PRETRIAL RISK ASSESSMENT TOOL VALIDATION (2022), https://www.courts.ca.gov/documents/Pretrial- Pilot- Program -Risk-Assesment -Tool-Validation - 2022.pdf ( reporting results, including on race and gender disparities, from a coordinated multicounty validation study that examined several risk assessment tools). 56 Compare KLEINBERG ET AL ., supra note 33 at 259- 260 (finding that gradient -boosted decision trees substantially outperform logistic regression in predicting failure to appear) with Jongbin Jung et al., Simple Rules for Complex Decisions , April 2017, https://doi.org/10.48550/arXiv.1702.04690 (finding that simple rules can have equivalent performance to random forest models in predicting failure to appear). 57 JUD. COUNCIL CAL., PRETRIAL RISK ASSESSMENT TOOL VALIDATION (2022), https://www.courts.ca.gov/documents/Pretrial- Pilot- Program -Risk-Assesment -Tool-Validation -2022.pdf ; Sarah L. Desmarais et al., Performance of Recidivism Risk Assessment Instruments in U.S. Correctional Settings, in HANDBOOK OF RECIDIVISM RISK/NEEDS ASSESSMENT TOOLS 15 (J.P. Singh, D.G. Kroner, J.S. Wormith, S.L. Desmarais & Z."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_253",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nperformance to random forest models in predicting failure to appear). 57 JUD. COUNCIL CAL., PRETRIAL RISK ASSESSMENT TOOL VALIDATION (2022), https://www.courts.ca.gov/documents/Pretrial- Pilot- Program -Risk-Assesment -Tool-Validation -2022.pdf ; Sarah L. Desmarais et al., Performance of Recidivism Risk Assessment Instruments in U.S. Correctional Settings, in HANDBOOK OF RECIDIVISM RISK/NEEDS ASSESSMENT TOOLS 15 (J.P. Singh, D.G. Kroner, J.S. Wormith, S.L. Desmarais & Z. Hamilton eds., 2018), https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119184256.ch1 ; 63 pretrial risk assessment instruments, among individuals with the highest possible risk score, about a sixth to a quarter (depending on the tool) were subsequently arrested for a violent offense.58 As even this high arrest rate reflects , users of the tool should bear in mind that risk is not inevitability. Beyond the field of criminal justice, research has demonstrated that even with exceptionally high- quality and long- term data, and even with sophisticated machine learning models, accurately predicting life outcomes such as an eviction or job layoff can be beyond reach.59 Outcomes in the criminal justice system are similarly products of complex and interrelated individual, environmental, and societal factors."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_254",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ninevitability. Beyond the field of criminal justice, research has demonstrated that even with exceptionally high- quality and long- term data, and even with sophisticated machine learning models, accurately predicting life outcomes such as an eviction or job layoff can be beyond reach.59 Outcomes in the criminal justice system are similarly products of complex and interrelated individual, environmental, and societal factors. Perpetuation of bias and inequality is also a significant risk.60 Studies of risk assessment tools have, in some instances, found notable differences in predictive performance by race and gender.61 Moreover, a model that has similar predictive performance across groups by some metrics may have substantial differences by others. For example, a risk assessment tool that has comparable precision in predicting recidivism across demographic groups may have very different false positive rates across groups.62 Researchers have demonstrated that, under realistic assumptions, it can be mathematically impossible to achieve equality across multiple different bias DESMARAIS ET AL (2021) supra note 55 at 398; Seena Fazel et al., The predictive performance of criminal risk assessment tools used at sentencing: Systematic review of validation studies , 81 J. CRIM. JUST. (2022), https://pmc.ncbi.nlm.nih.gov/articles/PMC9755051/pdf/main.pdf ; Anne A. H."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_255",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ngroups.62 Researchers have demonstrated that, under realistic assumptions, it can be mathematically impossible to achieve equality across multiple different bias DESMARAIS ET AL (2021) supra note 55 at 398; Seena Fazel et al., The predictive performance of criminal risk assessment tools used at sentencing: Systematic review of validation studies , 81 J. CRIM. JUST. (2022), https://pmc.ncbi.nlm.nih.gov/articles/PMC9755051/pdf/main.pdf ; Anne A. H. de Hond et al., Interpreting area under the receiver operating characteristic curve, 4 T HE LANCET DIGITAL HEALTH 853 (2022), https://www.thelancet.com/journals/landig/article/PIIS2589 -7500(22)00188- 1/fulltext ; Seth J. Prins & Adam Reich, Criminogenic risk assessment: A meta -review and critical analysis , 23 P UNISH . & SOC’Y 578 (2021 ) https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9385164/ ; Sonja B. Starr, Evidence -Based Sentencing and the Scientific Rationalization of Discrimination , 66 Stan. L. Rev. 803, 842- 62 (2014). 58 JUD. COUNCIL CAL., PRETRIAL RISK ASSESSMENT TOOL VALIDATION (2022), https://www.courts.ca.gov/documents/Pretrial- Pilot- Program -Risk-Assesment -Tool-Validation -2022.pdf . 59 E.g., Matthew J. Salganik, Measuring the predictability of life outcomes with a scientific mass collaboration , 117 PROCS . NAT’L ACAD. SCIS. 8399 (2020), https://www.pnas.org/doi/10.1073/pnas.1915006117 . 60 This discussion focuses on race and gender disparities, which have been a primary focus of relevant research."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_256",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nCOUNCIL CAL., PRETRIAL RISK ASSESSMENT TOOL VALIDATION (2022), https://www.courts.ca.gov/documents/Pretrial- Pilot- Program -Risk-Assesment -Tool-Validation -2022.pdf . 59 E.g., Matthew J. Salganik, Measuring the predictability of life outcomes with a scientific mass collaboration , 117 PROCS . NAT’L ACAD. SCIS. 8399 (2020), https://www.pnas.org/doi/10.1073/pnas.1915006117 . 60 This discussion focuses on race and gender disparities, which have been a primary focus of relevant research. Other types of disparities may exist and have received limited study, such as on the basis of disability or language. For example, a risk assessment tool that uses employment as a risk factor without considering whether the person receives Social Security Disability Insu rance may result in discrimination on the basis of disability. There is also limited research on disparities across subgroups combining race and gender. 61 See JUD. COUNCIL CAL., PRETRIAL RISK ASSESSMENT TOOL VALIDATION (2022), https://www.courts.ca.gov/documents/Pretrial- Pilot- Program -Risk-Assesment -Tool-Validation -2022.pdf ; Desmarais et al (2021 ) supra note 55 at 398 ; Howard Henderson et al., Determining Racial Equity in Pretrial Risk Assessment, 86 F ED. PROB. 26 (2022), https://www.uscourts.gov/sites/default/files/86_3_5.pdf ; Matthew DeMichele et al., The Public Safety Assessment: A Re -Validation and Assessment of Predictive Utility and Differential Prediction by Race and Gender in Kentucky (Apr ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_257",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n-Tool-Validation -2022.pdf ; Desmarais et al (2021 ) supra note 55 at 398 ; Howard Henderson et al., Determining Racial Equity in Pretrial Risk Assessment, 86 F ED. PROB. 26 (2022), https://www.uscourts.gov/sites/default/files/86_3_5.pdf ; Matthew DeMichele et al., The Public Safety Assessment: A Re -Validation and Assessment of Predictive Utility and Differential Prediction by Race and Gender in Kentucky (Apr . 25, 2018), https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3168452 . 62 E.g., Julia Angwin et al., Machine Bias , ProPublica (May 23, 2016), https://www.propublica.org/article/machine - bias-risk-assessments -in-criminal- sentencing ( demonstrating these properties in an evaluation of the COMPAS risk assessment tool). 64 metrics like these.63 Navigating the subtle and complex tradeoffs across predictive performance and bias measures is a challenge inherent in risk assessment.64 Data is one potential source of bias for risk assessment models. Models are based on data from the criminal justice system, which can encode existing disparities. Consider, as an example, a risk assessment model that uses housing stability as an input and that outputs a score for risk of future arrest. Housing stability may depend on biases in the housing market, and arrests may be affected by biases in policing. The model may incorporate and perpetuate these biases, much like it incorporates other trends in data."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_258",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nConsider, as an example, a risk assessment model that uses housing stability as an input and that outputs a score for risk of future arrest. Housing stability may depend on biases in the housing market, and arrests may be affected by biases in policing. The model may incorporate and perpetuate these biases, much like it incorporates other trends in data. Some scholars question the extent to which risk assessment can mitigate disparities in the criminal justice system and society; risk assessment involves prediction based on past events, which may themselves reflect inequality. 65 Some scholars have further suggested that risk assessment may create circular processes, in which individuals or groups are affected by the criminal justice system, then flagged as higher risk, leading to further involvement in the system. 66 The process of designing, implementing, and validating risk assessment tools may also be affected by disparities. Risk assessment tools may perpetuate inequality when they are developed in a manner that does not incorporate, for example, the perspectives of individuals within affected communities .67 Tools may also be developed using data that is readily available, rather than alternative types of data that may be more predictive of criminal justice outcomes and less prone to encoding historical biases (e.g., using arrests rather than convictions).68 Data quality is another area of potential concern with risk assessment tools."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_259",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nexample, the perspectives of individuals within affected communities .67 Tools may also be developed using data that is readily available, rather than alternative types of data that may be more predictive of criminal justice outcomes and less prone to encoding historical biases (e.g., using arrests rather than convictions).68 Data quality is another area of potential concern with risk assessment tools. Discrepancies in how data is collected and categorized can result in misleading, incomplete, and inaccurate records that do not accurately reflect factors relevant to risk assess ment. 69 Some inputs to risk 63 Jon Kleinberg et al., Inherent Trade -Offs in the Fair Determination of Risk Scores , Nov. 2016, https://arxiv.org/abs/1609.05807 ; Alexandra Chouldechova, Fair Prediction with Disparate Impact: A Study of Bias in Recidivism Prediction Instruments , Feb. 2017, at 2, 4, https://arxiv.org/abs/1703.00056 ; Richard Berk et al., Fairness in Criminal Justice Risk Assessments: the State of the Art, 50 Sociol. Methods & Res. 3 (2018), https://journals.sagepub.com/doi/pdf/10.1177/0049124118782533. 64 See, e.g., Andrew Bell et al., The Possibility of Fairness: Revisiting the Impossibility Theorem in Practice (FaccT ’23: Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency, 2023), https://dl.acm.org/doi/abs/10.1145/3593013.3594007 . 65 See, e.g., Sandra G. Mayson, Bias In, Bias Out , 129 YALE L.J."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_260",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nthe State of the Art, 50 Sociol. Methods & Res. 3 (2018), https://journals.sagepub.com/doi/pdf/10.1177/0049124118782533. 64 See, e.g., Andrew Bell et al., The Possibility of Fairness: Revisiting the Impossibility Theorem in Practice (FaccT ’23: Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency, 2023), https://dl.acm.org/doi/abs/10.1145/3593013.3594007 . 65 See, e.g., Sandra G. Mayson, Bias In, Bias Out , 129 YALE L.J. 2122 (2019), https://www.yalelawjournal.org/article/bias -in-bias-out; Ben Green, The False Promise of Risk Assessments: Epistemic Reform and the Limits of Fairness , ACM FAT* (2020), https://dl.acm.org/doi/10.1145/3351095.3372869 . 66 See, e.g., Shawn D. Bushway, “Nothing Is More Opaque Than Absolute Transparency”: The Use of Prior History to Guide Sentencing, 2.1 H ARVARD DATA SCI. REV. (2020), https://hdsr.mitpress.mit.edu/pub/dudgcmk3/release/7 . 67 Ngozi Okidegbe, The Democratizing Potential of Algorithms? , 53 C ONN. L. REV. 739 (2022), https://scholarship.law.bu.edu/cgi/viewcontent.cgi?article=4138&context=faculty_scholarship . 68 Jessica M. Eaglin, Constructing Recidivism Risk , 67 E MORY L.J. 59, 101 -104 (2017), https://scholarlycommons.law.emory.edu/cgi/viewcontent.cgi?article=1046&context=elj . 69 See, e.g., Sarah Lageson, Criminally Bad Data: Inaccurate Criminal Records, Data Brokers, and Algorithmic Injustice , 2023 U. ILL. L. REV."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_261",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nhttps://hdsr.mitpress.mit.edu/pub/dudgcmk3/release/7 . 67 Ngozi Okidegbe, The Democratizing Potential of Algorithms? , 53 C ONN. L. REV. 739 (2022), https://scholarship.law.bu.edu/cgi/viewcontent.cgi?article=4138&context=faculty_scholarship . 68 Jessica M. Eaglin, Constructing Recidivism Risk , 67 E MORY L.J. 59, 101 -104 (2017), https://scholarlycommons.law.emory.edu/cgi/viewcontent.cgi?article=1046&context=elj . 69 See, e.g., Sarah Lageson, Criminally Bad Data: Inaccurate Criminal Records, Data Brokers, and Algorithmic Injustice , 2023 U. ILL. L. REV. 1771, 1775– 81, 1786 (describing sources of criminal record errors and the impact on automated decision -making). For example, inconsistent collection and coding of individuals’ race and ethnicity can complicate efforts to understand how justice outcomes for people of color differ from those of white individuals. See KELLY ROBERTS FREEMAN , CATHY HU & JESSE JANNETTA , RACIAL EQUITY AND CRIMINAL JUSTICE RISK ASSESSMENT , URBAN INST. 3-4 (2021) , https://www.urban.org/sites/default/files/publication/103864/racial- equity - and-criminal- justice -risk-assessment.pdf . 65 assessment models can be subjective, such as the quality of an individual’s relationship with their family, introducing possible inaccuracy and bias.70 There has been little evaluation about how consistent practitioners and individuals being assessed are in determining these inputs.71 Transparency is also a concern."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_262",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nRISK ASSESSMENT , URBAN INST. 3-4 (2021) , https://www.urban.org/sites/default/files/publication/103864/racial- equity - and-criminal- justice -risk-assessment.pdf . 65 assessment models can be subjective, such as the quality of an individual’s relationship with their family, introducing possible inaccuracy and bias.70 There has been little evaluation about how consistent practitioners and individuals being assessed are in determining these inputs.71 Transparency is also a concern. Individuals who are subject to a risk assessment tool (and their representatives) may not know that the tool was used or have sufficient information to understand how it works and how it performs. Affected individuals also m ay not be aware of the inputs provided to the tool or have an opportunity to correct mistakes. While some models are entirely open, providing free public access to design documentation, implementing materials, and validation studies, others are more restrictive. Commercial licensing requirements, nondisclosure agreements, and trade secret protections, for example, can inhibit evaluation and understanding. 72 The White House Blueprint for an AI Bill of Rights recommends that AI models used in sensitive domains, such as criminal justice, should provide “meaningful access to examine the system.” 73 Access to models is essential for enabling independent evaluation to quantify performance and identify issues."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_263",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nnondisclosure agreements, and trade secret protections, for example, can inhibit evaluation and understanding. 72 The White House Blueprint for an AI Bill of Rights recommends that AI models used in sensitive domains, such as criminal justice, should provide “meaningful access to examine the system.” 73 Access to models is essential for enabling independent evaluation to quantify performance and identify issues. The use of risk assessment models in contexts where they have not been properly validated is another source of concern. A model that is trained on one population, at one time, for one purpose may perform very differently on other populations, at later times, or when used for other purposes.74 There are significant differences in criminal trends and criminal law across jurisdictions, calling into question how well risk assessment models generalize. Risk assessment models are often used without any recent validation on the local population.75 It is a best practice 70 See Beth Karp, What Even Is a Criminal Attitude? – And Other Problems with Attitude and Associational Factors in Criminal Risk Assessment , 75 S TAN. L. REV. 1431 (2023), https://review.law.stanford.edu/wp - content/uploads/sites/3/2023/06/Karp- 75-Stan. -L.-Rev.-1431.pdf . 71 Sarah L. Desmarais et al., Performance of Recidivism Risk Assessment Instruments in U.S. Correctional Settings , in HANDBOOK OF RECIDIVISM RISK/NEEDS ASSESSMENT TOOLS (J.P. Singh, D.G. Kroner, J.S. Wormith, S.L. Desmarais & Z."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_264",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nAnd Other Problems with Attitude and Associational Factors in Criminal Risk Assessment , 75 S TAN. L. REV. 1431 (2023), https://review.law.stanford.edu/wp - content/uploads/sites/3/2023/06/Karp- 75-Stan. -L.-Rev.-1431.pdf . 71 Sarah L. Desmarais et al., Performance of Recidivism Risk Assessment Instruments in U.S. Correctional Settings , in HANDBOOK OF RECIDIVISM RISK/NEEDS ASSESSMENT TOOLS (J.P. Singh, D.G. Kroner, J.S. Wormith, S.L. Desmarais & Z. Hamilton eds., 2018), https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119184256.ch1 . 72 Hannah Bloch- Wehba, Access to Algorithms , 88 F ORDHAM L. REV. 1265 (2020), https://ir.lawnet.fordham.edu/cgi/viewcontent.cgi?article=5649&context=flr ; Rebecca Wexler, Life, Liberty, and Trade Secrets: Intellectual Property in the Criminal Justice System , 70 S TAN. L. REV. 1343 (2018), https://review.law.stanford.edu/wp -content/uploads/sites/3/2018/06/70- Stan. -L.-Rev.-1343.pdf ; Cynthia Rudin et al., The Age of Secrecy and Unfairness in Recidivism Prediction , 2.1 H ARV. DATA SCI. REV. (2020), https://hdsr.mitpress.mit.edu/pub/7z10o269/release/7 ; Cynthia Rudin et al., Broader Issues Surrounding Model Transparency in Criminal Justice Risk Scoring, 2.1 H ARV. DATA SCI. REV. (2020), https://hdsr.mitpress.mit.edu/pub/8jy98s9q/release/3 ; Greg Ridgeway, Transparency, Statistics, and Justice System Knowledge is Essential for Science of Risk Assessment , 2.1 H ARV. DATA SCI. REV."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_265",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nand Unfairness in Recidivism Prediction , 2.1 H ARV. DATA SCI. REV. (2020), https://hdsr.mitpress.mit.edu/pub/7z10o269/release/7 ; Cynthia Rudin et al., Broader Issues Surrounding Model Transparency in Criminal Justice Risk Scoring, 2.1 H ARV. DATA SCI. REV. (2020), https://hdsr.mitpress.mit.edu/pub/8jy98s9q/release/3 ; Greg Ridgeway, Transparency, Statistics, and Justice System Knowledge is Essential for Science of Risk Assessment , 2.1 H ARV. DATA SCI. REV. (2020), https://hdsr.mitpress.mit.edu/pub/vu6rc1yv/release/7 . 73EXEC. OFF. OF THE PRESIDENT , BLUEPRINT FOR AN AI BILL OF RIGHTS 51 (2022), https://www.whitehouse.gov/ostp/ai- bill-of-rights/ . 74 ALEXANDRA CHOULDECHOV A & KRISTIAN LUM, SAFETY & JUST. CHALLENGE , THE PRESENT AND FUTURE OF AI IN PRE-TRIAL RISK ASSESSMENT INSTRUMENTS 3, 5 (2020), https://safetyandjusticechallenge.org/resources/the -present - and-future -of-ai-in-pre-trial- risk-assessment -instruments/ ; Erika Montana et al., Cohort bias in predictive risk assessments of future criminal justice system involvement, 120 P ROCS . NAT’L ACAD. SCIS. (2023), https://www.pnas.org/doi/10.1073/pnas.2301990120 . 75 50-State Report on Public Safety Part 2, Strategy 2, Action Item 2, T HE COUNCIL OF STATE GOVERNMENTS , https://50statespublicsafety.us/part- 2/strategy -2/action -item-2/."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_266",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n5 (2020), https://safetyandjusticechallenge.org/resources/the -present - and-future -of-ai-in-pre-trial- risk-assessment -instruments/ ; Erika Montana et al., Cohort bias in predictive risk assessments of future criminal justice system involvement, 120 P ROCS . NAT’L ACAD. SCIS. (2023), https://www.pnas.org/doi/10.1073/pnas.2301990120 . 75 50-State Report on Public Safety Part 2, Strategy 2, Action Item 2, T HE COUNCIL OF STATE GOVERNMENTS , https://50statespublicsafety.us/part- 2/strategy -2/action -item-2/. 66 to build a predictive model on the most representative data available, or failing that, to evaluate a model on representative data to determine if it is suitable for use.76 There is limited research on the effects of risk assessment tools, both on the criminal justice systems and officials who use them and on the communities where they are implemented.77 More research is needed to understand how practitioners integrate risk assessment information into decision -making, including to examine the risks of automation and confirmation biases, why officials sometimes choose to override recommendations based on risk assessment, and how risk assessment affects the accuracy and disparities of decisions. 78 Similarly, more research is needed on how risk assessment can impact communities."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_267",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nMore research is needed to understand how practitioners integrate risk assessment information into decision -making, including to examine the risks of automation and confirmation biases, why officials sometimes choose to override recommendations based on risk assessment, and how risk assessment affects the accuracy and disparities of decisions. 78 Similarly, more research is needed on how risk assessment can impact communities. Studies of this type typically lack adequate controls to disentangle implementation of risk assessment from other trends, and the time horizon for studies may be too short to capture benefits and downsides. Converting model output into categories (e.g., “high risk”), rather than presenting probabilities and confidence intervals, may omit important information for decision- makers. 79 An individual may be just over or under the threshold for a risk category, for example. While risk categories may have value in helping to explain results and counter precision bias, omitting more detailed information can deprive decision- makers of essential context."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_268",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n(e.g., “high risk”), rather than presenting probabilities and confidence intervals, may omit important information for decision- makers. 79 An individual may be just over or under the threshold for a risk category, for example. While risk categories may have value in helping to explain results and counter precision bias, omitting more detailed information can deprive decision- makers of essential context. A final challenge is that evaluating risk is fundamentally different from determining the appropriate treatment for an individual from a range of possible treatments.80 Focusing on prediction of negative outcomes such as recidivism or failure to appear could divert resources from, and limit consideration of, interventions that may reduce the risk of those negative outcomes 76 For example, the Minnesota Department of Corrections compared a nationally available tool to a state -specific one and concluded that “there is a home -field advantage to risk assessment,” because the Minnesota tool outperformed an off -the-shelf tool. Grant Duwe, Mn. Dep’t of Corr., Evaluating Bias, Shrinkage and the Home -Field Advantage: Results from a Revalidation of the MnSTARR 2.0, at 29– 31 (2021). 77 Jodi L. Viljoen et al., Impact of Risk Assessment Instruments on Rates of Pretrial Detention, Postconviction Placements, and Release: A Systematic Review and Meta -Analysis , 43 L. HUM. BE HAV ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_269",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ntool. Grant Duwe, Mn. Dep’t of Corr., Evaluating Bias, Shrinkage and the Home -Field Advantage: Results from a Revalidation of the MnSTARR 2.0, at 29– 31 (2021). 77 Jodi L. Viljoen et al., Impact of Risk Assessment Instruments on Rates of Pretrial Detention, Postconviction Placements, and Release: A Systematic Review and Meta -Analysis , 43 L. HUM. BE HAV . 397 (2019), https://psycnet.apa.org/fulltext/2019- 46921- 001.pdf ; Megan Stevenson, Assessing Risk Assessment in Action , 103 MINN. L. REV. 303 (2018), https://scholarship.law.umn.edu/cgi/viewcontent.cgi?article=1057&context=mlr . Shamena Anwar et al ., RAND, RR-A3299- 1, WHAT HAPPENS WHEN JUDGES FOLLOW THE RECOMMENDATIONS OF PRETRIAL DETENTION RISK ASSESSMENT INSTRUMENTS MORE OFTEN ? 8 (2024), https://www.rand.org/pubs/research_reports/RRA3299- 1.html ; Matthew DeMichele et al., What Do Criminal Justice Professionals Think About Risk Assessment at Pretrial ?, 83 F ED. PROB. 32 (2019). https://www.uscourts.gov/sites/default/files/83_1_5_0.pdf ; Sarah Riley, Overriding (In)justice: Pretrial Risk Assessment Administration on the Frontlines , FaccT ’24: Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency, 2024), https://facctconference.org/static/papers24/facct24 -35.pdf ; Brandon Garrett & John Monahan, Judging Risk , 108 C AL. L. REV. 439 (2020). https://www.californialawreview.org/print/judging -risk ; Megan T. Stevenson & Jennifer L."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_270",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nF ED. PROB. 32 (2019). https://www.uscourts.gov/sites/default/files/83_1_5_0.pdf ; Sarah Riley, Overriding (In)justice: Pretrial Risk Assessment Administration on the Frontlines , FaccT ’24: Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency, 2024), https://facctconference.org/static/papers24/facct24 -35.pdf ; Brandon Garrett & John Monahan, Judging Risk , 108 C AL. L. REV. 439 (2020). https://www.californialawreview.org/print/judging -risk ; Megan T. Stevenson & Jennifer L. Doleac, Algorithmic Risk Assessment in the Hands of Humans , AM. ECON. J.: ECON. POL’Y. (Nov. 2024), https://www.aeaweb.org/articles?id=10.1257/pol.20220620 . 79 Melissa Hamilton, Risk Assessment Tools in the Criminal Legal System – Theory and Practice: A Resource Guide, NAT’L ASS’N OF CRIM. DEF. LAWS. 44-48 (Nov. 2020), https://www.nacdl.org/getattachment/a92d7c30- 32d4- 4b49- 9c57- 6c14ed0b9894/riskassessmentreportnovember182020.pdf ; Starr (2014), supra note 57. 80 Chelsea Barabas et al., Interventions over Predictions: Reframing the Ethical Debate for Actuarial Risk Assessment (Conference on Fairness, Accountability, and Transparency, Proceedings of Machine Learning Research, 2018), https://proceedings.mlr.press/v81/barabas18a/barabas18a.pdf ; Erin Collins, Punishing Risk , 107 G EO. L.J. 57 (2018), https://www.law.georgetown.edu/georgetown- la w-journal/wp -content/uploads/sites/26/2018/12/Punishing- Risk-2.pdf ; Starr (2014), supra note 57."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_271",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n9c57- 6c14ed0b9894/riskassessmentreportnovember182020.pdf ; Starr (2014), supra note 57. 80 Chelsea Barabas et al., Interventions over Predictions: Reframing the Ethical Debate for Actuarial Risk Assessment (Conference on Fairness, Accountability, and Transparency, Proceedings of Machine Learning Research, 2018), https://proceedings.mlr.press/v81/barabas18a/barabas18a.pdf ; Erin Collins, Punishing Risk , 107 G EO. L.J. 57 (2018), https://www.law.georgetown.edu/georgetown- la w-journal/wp -content/uploads/sites/26/2018/12/Punishing- Risk-2.pdf ; Starr (2014), supra note 57. 67 and otherwise improve individual rehabilitation and public safety. For example, emphasizing criminal justice risks may deemphasize interventions outside the criminal justice system, such as substance abuse treatment or job training, that could have positive effects. Recommendations a. Risk Assessment Tool Design, Implementation, and Validation Before moving forward with a risk assessment tool, it is important to document objectives, performance and bias criteria, expected benefits and risks, and alternatives to using the tool. Risk assessment tools should only be used if the expected benefits clearly outweigh the risks, substantiated by adequate evidence. In some circumstances, it may be preferable to use trained professionals and structured judgments rather than an actuarial risk assessment model."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_272",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nit is important to document objectives, performance and bias criteria, expected benefits and risks, and alternatives to using the tool. Risk assessment tools should only be used if the expected benefits clearly outweigh the risks, substantiated by adequate evidence. In some circumstances, it may be preferable to use trained professionals and structured judgments rather than an actuarial risk assessment model. Throughout the process of deciding whether and how to use risk assessment, engagement with affected communities and stakeholders is essential. Their perspectives are vital for setting goals, identifying possible issues, and integrating mitigation strategies. Because r isk assessment tools are built and validated on data , a critical early step is careful evaluati on of the quality of available data, identifying gaps, inconsistencies, or biases that could affect risk assessment. Agencies should consider setting policies and procedures in place to collect, label, and store data efficiently and accurately, ensuring the integrity, completeness, and provenance of the data. Transparency about available data is a valuable part of maximizing the quality of the data used, as stakeholders may be well -positioned to identify opportunities and shortcomings with that data. If a tool involves risk factors within an individual’s control, transparency can also enable affected individuals to better understand how to reduce their risk score."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_273",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nand provenance of the data. Transparency about available data is a valuable part of maximizing the quality of the data used, as stakeholders may be well -positioned to identify opportunities and shortcomings with that data. If a tool involves risk factors within an individual’s control, transparency can also enable affected individuals to better understand how to reduce their risk score. If data under consideration for a risk assessment tool includes information covered by antidiscrimination law (e.g., race, gender, disability, or age), or foreseeable proxies for those protected characteristics (e.g., ZIP code as a proxy for race), designe rs and implementers should be especially cautious and ensure legal compliance. They should also bear in mind that large criminal justice databases are almost certain to contain errors. Criminal justice data may also reflect inconsistencies in recordkeeping and enforcement. Developers of risk assessment tools should account for these issues, trying to quantify them and build tools that are robust against errors and inconsistencies. At the same time, if there are types of data available that can serve a similar purpose in risk assessment, they should carefully consider tradeoffs. Relying on charges filed or convictions rather than arrests may reduce the possibility of bias, for example, by accounting for disparities in policing and involving additional compone nts of the criminal justice system."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_274",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nand inconsistencies. At the same time, if there are types of data available that can serve a similar purpose in risk assessment, they should carefully consider tradeoffs. Relying on charges filed or convictions rather than arrests may reduce the possibility of bias, for example, by accounting for disparities in policing and involving additional compone nts of the criminal justice system. Developers of r isk assessment tool s should also be mindful of t he value of a fit between the data they are utilizing and the jurisdiction in which the tool will be used. The data used for the output of the risk assessment tool should also closely resemble the decision that the tool will support. For example, a tool for predicting misconduct in custody would ideally by built with data about misconduct in custody, rather than data about recidivism after release. Also, w here there is sufficient data in a jurisdiction, it is preferable to build a model specific to that jurisdiction rather than rely on a model built with data that may not be representative. And i f a risk assessment tool 68 uses data from multiple jurisdictions, the tool should account for possible differences in data definitions across jurisdictions. Risk assessment tools should also be evaluated in a real -world context before deployment."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_275",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nbuild a model specific to that jurisdiction rather than rely on a model built with data that may not be representative. And i f a risk assessment tool 68 uses data from multiple jurisdictions, the tool should account for possible differences in data definitions across jurisdictions. Risk assessment tools should also be evaluated in a real -world context before deployment. First, this evaluation should include performance in predicting real -world outcomes, on the specific population whose risk is being assessed, as well as measurement of predictive performance across demographic groups, to identify possible biases. There should also be a baseline included in the evaluation, such as predictions made by a human or a previous model, to comparatively assess a tool’s performance. Second, depl oyment of new risk assessment tools should be phased, facilitating observation and mitigation of risks. This approach also provides data for comparatively assessing the community impacts of using risk assessment tool. Third, t he design, implementation, and validation of a risk assessment tool should be reviewed by an evaluator who is independent of the tool’s developer. Finally, if significant risks are identified before deployment, mitigations for those risks should be designed, implemented, and validated before the deployment continues. b."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_276",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ndata for comparatively assessing the community impacts of using risk assessment tool. Third, t he design, implementation, and validation of a risk assessment tool should be reviewed by an evaluator who is independent of the tool’s developer. Finally, if significant risks are identified before deployment, mitigations for those risks should be designed, implemented, and validated before the deployment continues. b. Continuous Monitoring and Human Oversight Continuous monitoring of risk assessment tools is essential for ensuring they continue to meet objectives and rapidly identifying emerging issues. These tools should be continuously monitored to identify possible changes in predictive performance, biases, or data. This monitoring should be automated, to the extent possible, to allow quick responses to changes. Tools should also be periodically revalidated, to ensure that trends in criminal justice and changes in laws, policies, and practices have not undermined performance. Similarly, tools should be retrained or update d on a periodic basis, to account for changing context. This process should consider prior feedback and outcomes, which may suggest ways of improving the tool’s design. Risk assessment tools should be paired with policies and procedures, and ideally automated monitoring, to ensure the accuracy of input data. They should not displace human decision- making in the criminal justice system."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_277",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nd on a periodic basis, to account for changing context. This process should consider prior feedback and outcomes, which may suggest ways of improving the tool’s design. Risk assessment tools should be paired with policies and procedures, and ideally automated monitoring, to ensure the accuracy of input data. They should not displace human decision- making in the criminal justice system. They should be accompanied by guidance and training for decision- makers about the tool and its limitations. Individuals affected by a risk assessment tool should receive notice and explanation and should have an opportunity to respond. When a decision -maker in the criminal justice system uses a risk assessment tool, to the extent possible, the individual being assessed (and their representatives) should receive notice of the tool and explanation of how it is being used. Where feasible, an individual should be able to seek correction of errors in any input data or submit additional relevant context. c. Training and Education Individuals who use risk assessments in criminal justice should be trained on how to interpret a tool’s scores, as well as the limits of prediction. With respect to limits, training curricula should pay special attention to the potential for bias and creat ing or perpetuating disparities."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_278",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nerrors in any input data or submit additional relevant context. c. Training and Education Individuals who use risk assessments in criminal justice should be trained on how to interpret a tool’s scores, as well as the limits of prediction. With respect to limits, training curricula should pay special attention to the potential for bias and creat ing or perpetuating disparities. Users of a risk assessment tool, including judges, prosecutors, defense attorneys, pretrial or probation officers, correctional staff, community supervision staff, and others, should be 69 informed about how the tool works and its limitations. Training programs and other educational offerings should evolve with changes in research and the tool. d. Policies Agencies should issue guidance to risk assessment users on appropriate and prohibited uses of the risk assessment tool. Agencies should also issue guidance to risk assessment users on when decisions from the risk assessment tool may require additional huma n oversight and intervention— for example, when there is high uncertainty in a risk assessment tool’s predictions, or when a decision has particularly high impact. Agencies should provide public notice and documentation on the use of the system, as well as information on its design (including input data) and the testing conducted to mitigate risks of the system."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_279",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nadditional huma n oversight and intervention— for example, when there is high uncertainty in a risk assessment tool’s predictions, or when a decision has particularly high impact. Agencies should provide public notice and documentation on the use of the system, as well as information on its design (including input data) and the testing conducted to mitigate risks of the system. Agencies should ensure that there is meaningful access to the risk assessment tool, such that researchers and stakeholders can conduct their own evaluations. Agencies should only use risk assessment tools where the prediction model can be made transparent to the public. Agencies should not use risk assessment tools where this core functionality is obscured by trade secret protections or other barriers. Agencies should not use tools with prediction thresholds that cannot be evaluated and changed by agency policymakers. Agencies should set a model’s prediction thresholds according to a methodology for achieving specific objectives, and agencies should provide decision- makers with individualized context about a risk assessment beyond a categorization. e. Research Future research should examine risk assessment tools to better understand predictive performance, biases, how they compare to alternatives, and how they affect decision- makers and communities. 70 VI. Conclusion & Best Practices The preceding chapters offer insight into uses of AI within the criminal justice system."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_280",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ndecision- makers with individualized context about a risk assessment beyond a categorization. e. Research Future research should examine risk assessment tools to better understand predictive performance, biases, how they compare to alternatives, and how they affect decision- makers and communities. 70 VI. Conclusion & Best Practices The preceding chapters offer insight into uses of AI within the criminal justice system. These uses potentially offer important benefits to the institutions and individuals in the criminal justice system—including judges, pretrial and probation officers, prosecutors, law enforcement officers, forensic professionals, criminal defendants, and defense attor neys—and to the broader public. The preceding chapters also discuss significant risks as well as important policy and technological considerations that users should understand and mitigate. Each chapter underscores that responsible use of AI is critical, especially in the criminal justice context, where the deployment of this technology is quickly evolving and where public safety and individual rights are on the line. Each chapter also recommends practices to mitigate risks and preserve privacy, civil liberties, and civil rights when using AI in the criminal justice context. Central to all these recommendations is AI governance."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_281",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nis critical, especially in the criminal justice context, where the deployment of this technology is quickly evolving and where public safety and individual rights are on the line. Each chapter also recommends practices to mitigate risks and preserve privacy, civil liberties, and civil rights when using AI in the criminal justice context. Central to all these recommendations is AI governance. As a general matter, governance “provides a framework for decision- making by establishing standards and procedures and clarifying roles and responsibilities.” 1 As applied to AI, governance includes the broad range of decisions surrounding the technology’s development, use, and safeguards. Further, in the context of the criminal justice system, AI governance must be adaptable to account for change, but it must also be grounded in enduring values. Indeed, AI governance in this space must account for civil rights and civil liberties just as much as technical considerations such as data quality and data security. Governance is central to the Department of Justice’s r esponsible use of AI, and this report emphasizes the importance of AI governance at the diverse law enforcement agencies and other criminal justice institutions using AI or contemplating its use. AI governance will take different shapes, depending on the size, scope, mission, and resources of each actor or institution operating within the criminal justice system."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_282",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nthe Department of Justice’s r esponsible use of AI, and this report emphasizes the importance of AI governance at the diverse law enforcement agencies and other criminal justice institutions using AI or contemplating its use. AI governance will take different shapes, depending on the size, scope, mission, and resources of each actor or institution operating within the criminal justice system. As with other forms of governance, smaller or resource -constrained criminal justice ac tors—including those at the state, local, and municipal level —may not be in a position to fully implement each recommendation exactly as written in this report. However, a key takeaway is that AI presents a new set of considerations that actors and institutions in the criminal justice system should take into account in adapting their overall governance structures. The recommendations included below, and detailed in each of the preceding chapters, draw from the work of a community of scholars across the United States and abroad, as well as the work of our colleagues elsewhere in the Federal Government on publications such as: • The White House Office of Science and Technology Policy’s “The Blueprint for an AI Bill of Rights: Making Automated Systems Work for the American People” 2; 1 Governance, Digital.gov, https://digital.gov/topics/governance/ . 2 EXEC. OFF. OF THE PRESIDENT , BLUEPRINT FOR AN AI BILL OF RIGHTS 5 (Oct."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_283",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nof our colleagues elsewhere in the Federal Government on publications such as: • The White House Office of Science and Technology Policy’s “The Blueprint for an AI Bill of Rights: Making Automated Systems Work for the American People” 2; 1 Governance, Digital.gov, https://digital.gov/topics/governance/ . 2 EXEC. OFF. OF THE PRESIDENT , BLUEPRINT FOR AN AI BILL OF RIGHTS 5 (Oct. 2022), https://www.whitehouse.gov/wp- content/uploads/2022/10/Blueprint -for-an-AI-Bill-of-Rights.pdf ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_284",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nthe Federal Government on publications such as: • The White House Office of Science and Technology Policy’s “The Blueprint for an AI Bill of Rights: Making Automated Systems Work for the American People” 2; 1 Governance, Digital.gov, https://digital.gov/topics/governance/ . 2 EXEC. OFF. OF THE PRESIDENT , BLUEPRINT FOR AN AI BILL OF RIGHTS 5 (Oct. 2022), https://www.whitehouse.gov/wp- content/uploads/2022/10/Blueprint -for-an-AI-Bill-of-Rights.pdf . 71 • NIST’s “Artificial Intelligence Risk Management Framework,”3 and Special Publication 1270, “Towards a Standard for Identifying and Managing Bias in Artificial Intelligence”4; • OMB’s Memorandum M -24-10, “Advancing Governance, Innovation, and Risk Management for Agency Use of Artificial Intelligence,”5 and Memorandum M-24-18, “Advancing the Responsible Acquisition of Artificial Intelligence in Government”6; • “National Security Memorandum on Advancing the United States’ Leadership in Artificial Intelligence ; Harnessing Artificial Intelligence to Fulfill National Security Objectives; and Fostering the Safety, Security, and Trustworthiness of Artificial Intelligence ” 7 and the associated “Framework to Advance AI Governance and Risk Management in National Security .”8 The recommendations in this chapter are also goals that the Department of Justice is working toward for its own uses of AI, as described in the Department’s “Compliance Plan for OMB Memorandum M- 24-10.”9 Foundations for AI Governance To establish a durable and comprehensive AI governance program, criminal justice agencies should identify the problem to solve and the reasons why the use of AI is preferable to alternatives; establish clear organizational and reporting structures to provide oversight, monitoring, and evaluation; hire, train, and retain a workforce with adequate resources to devise, enact, and enforce policies; build, operate, and routinely monitor the AI systems; regularly evaluate the performance of systems for accuracy and any unintended biases or disparities; and mitigate their associated risks."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_285",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nof AI is preferable to alternatives; establish clear organizational and reporting structures to provide oversight, monitoring, and evaluation; hire, train, and retain a workforce with adequate resources to devise, enact, and enforce policies; build, operate, and routinely monitor the AI systems; regularly evaluate the performance of systems for accuracy and any unintended biases or disparities; and mitigate their associated risks. 3 NAT’L INST. STANDARDS & TECH., ARTIFICIAL INTELLIGENCE RISK MANAGEMENT FRAMEWORK : GENERATIVE ARTIFICIAL INTELLIGENCE PROFILE (July 2024), available at https://doi.org/10.6028/NIST.AI.600-1 . 4 Reva Schwartz et al., N AT. INST. STANDARDS & TECH. SPECIAL PUBL’N 1270, TOWARDS A STANDARD FOR IDENTIFYING AND MANAGING BIAS IN ARTIFICIAL INTELLIGENCE (2022), https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.1270.pdf . 5 MEMORANDUM FROM SHALANDA D. YOUNG , DIR., OFF. MGMT. & BUDGET , EXEC. OFF. OF THE PRESIDENT , TO HEADS OF EXEC. DEP'TS & AGENCIES , (Mar. 28, 2024), available at https://www.whitehouse.gov/wp- content/uploads/2024/03/M -24-10-Advancing- Governance -Innovation- and-Risk-Management -for-Agency -Use-of- Artificial- Intelligence.pdf . 6 MEMORANDUM FROM SHALANDA D. YOUNG , DIR., OFF. MGMT. & BUDGET , EXEC. OFF. OF THE PRESIDENT , TO HEADS OF EXEC. DEP'TS & AGENCIES , (Sep. 24, 2024), available at https://www.whitehouse.gov/wp- content/uploads/2024/10/M -24-18-AI-Acquisition -Memorandum.pdf ."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_286",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nHEADS OF EXEC. DEP'TS & AGENCIES , (Mar. 28, 2024), available at https://www.whitehouse.gov/wp- content/uploads/2024/03/M -24-10-Advancing- Governance -Innovation- and-Risk-Management -for-Agency -Use-of- Artificial- Intelligence.pdf . 6 MEMORANDUM FROM SHALANDA D. YOUNG , DIR., OFF. MGMT. & BUDGET , EXEC. OFF. OF THE PRESIDENT , TO HEADS OF EXEC. DEP'TS & AGENCIES , (Sep. 24, 2024), available at https://www.whitehouse.gov/wp- content/uploads/2024/10/M -24-18-AI-Acquisition -Memorandum.pdf . 7 MEMORANDUM ON ADVANCING THE UNITED STATES ’ LEADERSHIP IN ARTIFICIAL INTELLIGENCE ; HARNESSING ARTIFICIAL INTELLIGENCE TO FULFILL NATIONAL SECURITY OBJECTIVES ; AND FOSTERING THE SAFETY , SECURITY , AND TRUSTWORTHINESS OF ARTIFICIAL INTELLIGENCE (Oct. 24, 2024), available at https://www.govinfo.gov/app/details/DCPD -202400945 . 8 FRAMEWORK TO ADVANCE AI GOVERNANCE AND RISK MANAGEMENT IN NATIONAL SECURITY (OCT. 24, 2024) , available at https://ai.gov/wp -content/uploads/2024/10/NSM -Framework -to-Advance -AI-Governance -and-Risk- Management -in-National- Security.pdf . 9 U.S. DEP’T OF JUST., COMPLIANCE PLAN FOR OMB MEMORANDUM M-24-10 (Oct. 2024), available at https://www.justice.gov/media/1373026/dl . 72 a."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_287",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nAND TRUSTWORTHINESS OF ARTIFICIAL INTELLIGENCE (Oct. 24, 2024), available at https://www.govinfo.gov/app/details/DCPD -202400945 . 8 FRAMEWORK TO ADVANCE AI GOVERNANCE AND RISK MANAGEMENT IN NATIONAL SECURITY (OCT. 24, 2024) , available at https://ai.gov/wp -content/uploads/2024/10/NSM -Framework -to-Advance -AI-Governance -and-Risk- Management -in-National- Security.pdf . 9 U.S. DEP’T OF JUST., COMPLIANCE PLAN FOR OMB MEMORANDUM M-24-10 (Oct. 2024), available at https://www.justice.gov/media/1373026/dl . 72 a. Conduct a Needs and Alternatives Assessment Criminal justice agencies should know what problem or function they are trying to solve or address and how both AI and non- AI alternatives might present a solution.10 For example , judges, pretrial and probation officers, prosecutors, law enforcements officers, and defense attorneys may be seeking to more accurately calculate the likelihood that an individual will have a particular outcome in the criminal justice system. That calculation can in turn help judges make transparent, non- discriminatory, and equitable decisions. Similarly, agencies seek to drive law enforcement efficiencies and best direct limited resources. Agencies could consider risk assessment tools as compared to subjective assessments, or predictive policing tools as compared to traditional resource allocation measures. b."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_288",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nwill have a particular outcome in the criminal justice system. That calculation can in turn help judges make transparent, non- discriminatory, and equitable decisions. Similarly, agencies seek to drive law enforcement efficiencies and best direct limited resources. Agencies could consider risk assessment tools as compared to subjective assessments, or predictive policing tools as compared to traditional resource allocation measures. b. Establish a Clear Organizational Structure Criminal justice agencies, like other institutions working within the criminal justice system, vary in size, scope, resources, and mission. Regardless of institutional size, however, a tiered human -centered structure that assigns to individuals distinct operational, decision -making, and oversight responsibilities commensurate with their function, training, and experience will be key to maintaining an effective AI governance program. For example, at the Department of Justice, the Attorney General has designa ted a Chief AI Officer (CAIO) and an Emerging Technology Board (ETB), as required in OMB M -24-10. The CAIO has primary responsibility for coordination of the Department’s use of AI, efforts to promote AI innovation, and management of risks from the use of AI. The CAIO coordinates with components across DOJ and reports to the Deputy Attorney General. The ETB serves as the Department’s AI Governance Board. c."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_289",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nTechnology Board (ETB), as required in OMB M -24-10. The CAIO has primary responsibility for coordination of the Department’s use of AI, efforts to promote AI innovation, and management of risks from the use of AI. The CAIO coordinates with components across DOJ and reports to the Deputy Attorney General. The ETB serves as the Department’s AI Governance Board. c. Catalog Uses of A I Agencies should catalog existing and new uses of AI and facilitate organization- wide visibility into these uses. Awareness of the AI uses occurring within the agency is the foundation for other governance steps. As feasible, agencies should also aim for greater transparency by making their use cases public. For example , the Department of Justice’s AI governance process begins with identifying existing, new, and planned uses of AI across the Department. Components will report AI use cases, per the Advancing American AI Act and OMB M -24-10, and the Department will also revie w procurement, privacy governance, and IT gove rnance records to ensure comprehensiveness. d. Hire, Train, and Retain AI Workforce Agencies interested in using AI should hire, train, and retain a workforce that understands the technical aspects, operational considerations, and tradeoffs associated with the use of AI (and remains knowledgeable as AI rapidly evolves)."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_290",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n-24-10, and the Department will also revie w procurement, privacy governance, and IT gove rnance records to ensure comprehensiveness. d. Hire, Train, and Retain AI Workforce Agencies interested in using AI should hire, train, and retain a workforce that understands the technical aspects, operational considerations, and tradeoffs associated with the use of AI (and remains knowledgeable as AI rapidly evolves). An adequately trai ned workforce should be able to understand, among other things, the source and limitations of the data on which a system is trained, the potential sources of any discrimination and bias, how these sources can affect outcomes in the 10 For institutions already using AI, this might take the form of an inventory that addresses the functionality of the tool (what does it do?), alternative tools (are there other options to achieve that result?), and a justification for using the tool that a ccounts for risks and mitigation strategies (why was the tool chosen among the existing alternatives?). 73 criminal justice system, the steps necessary to mitigate bias and discrimination, and means of implementing effective monitoring and auditing of AI systems. Pre-Deployment Measures Prior to deploying AI systems, law enforcement agencies and other agencies involved in criminal justice should also undertake the following measures. e."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_291",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nrisks and mitigation strategies (why was the tool chosen among the existing alternatives?). 73 criminal justice system, the steps necessary to mitigate bias and discrimination, and means of implementing effective monitoring and auditing of AI systems. Pre-Deployment Measures Prior to deploying AI systems, law enforcement agencies and other agencies involved in criminal justice should also undertake the following measures. e. Implement Policies and Procedures Use of AI in the criminal justice system must be governed by robust human- centered policies and procedures that describe the permitted and prohibited uses of the AI system, the data used to train the system, the metrics and processes used to validate or evaluate the accuracy of the output, the frequency of monitoring, and the risks of using a particular AI system. The use of AI in the criminal justice system must also comply with the Constitution; statutes; rules of evidence, discovery, and procedure; discovery obligations ; and ethical commitments . These policies and procedures should be developed by agencies in collaboration with relevant stakeholders and should anticipate and incorporate civil rights and civil liberties concerns. In addition, these policies should be regularly re -evaluated to ensure accuracy and consistency with current technology, best practices, and legal requirements."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_292",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nrules of evidence, discovery, and procedure; discovery obligations ; and ethical commitments . These policies and procedures should be developed by agencies in collaboration with relevant stakeholders and should anticipate and incorporate civil rights and civil liberties concerns. In addition, these policies should be regularly re -evaluated to ensure accuracy and consistency with current technology, best practices, and legal requirements. Keeping “Humans in the Loop:” Individuals and institutions operating in the criminal justice system that use AI systems must ensure that human judgment drives the system’s design, implementation, and use. Users should be mindful that AI cannot displace human decision-making (and, indeed, doing so would be counter to established laws, norms, and principles designating different roles to, for instance, judges, officers, and prosecutors), and AI system outputs should be reviewed and verified by a human being. Courts, agencies, and decision- makers should create decision -making processes and guidelines for the use of AI to ensure a human reviews any outputs for accuracy. For high -impact decisions (such as cause for arrest or length of a sentence), the output of an AI system should not be the sole basis for a decision."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_293",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nverified by a human being. Courts, agencies, and decision- makers should create decision -making processes and guidelines for the use of AI to ensure a human reviews any outputs for accuracy. For high -impact decisions (such as cause for arrest or length of a sentence), the output of an AI system should not be the sole basis for a decision. For example, Department of Justice decisions regarding investigative steps, detention, prosecution, and evaluation or analysis of forensic evidence may take into account AI outputs to assist in colle ction and analysis of information, but trained professionals make the decisions. Community Outreach and Public Notice : Consistent with applicable law and government guidance, and to the extent feasible, criminal justice entities should actively engage the public and relevant stakeholders regarding the intended use of potentially rights -or-safety -impacting AI technologies. 11 Disclosures should not include sensitive operational and law enforcement information but should generally include a plain language description of the system; the data used to train the system (e.g., driver license photos in the case of a facial recognition AI system); who 11 OMB Memorandum M -24-10 offers useful guidance to agencies assessing whether AI may be rights -impacting or safety -impacting."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_294",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nnot include sensitive operational and law enforcement information but should generally include a plain language description of the system; the data used to train the system (e.g., driver license photos in the case of a facial recognition AI system); who 11 OMB Memorandum M -24-10 offers useful guidance to agencies assessing whether AI may be rights -impacting or safety -impacting. In particular, M -24-10 defines these terms (note that rights -impacting AI includes AI that, among other factors, may have a signifi cant effect on civil rights, civil liberties, or privacy) and specifies AI uses presumed to be rights - or safety -impacting. An agency’s engagement with the community and stakeholders may identify additional, potentially community -specific factors to consid er in assessing the possible impact of an AI technology. 74 will have access to the system; the circumstances for the system’s deployment; and governance mechanisms in place, such as whether the system will have an opt -out mechanism once deployed. Disclosure and engagement regarding the general purpose of an AI sys tem might be feasible and useful even if disclosing details of capabilities and implementation is infeasible. Engagement can help build trust and ensure public support for adopted technologies."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_295",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nthe system’s deployment; and governance mechanisms in place, such as whether the system will have an opt -out mechanism once deployed. Disclosure and engagement regarding the general purpose of an AI sys tem might be feasible and useful even if disclosing details of capabilities and implementation is infeasible. Engagement can help build trust and ensure public support for adopted technologies. Defining and Categorizing Risk : Criminal justice entities using AI should define and measure AI risks to rights and safety; categorize AI uses based on those risks; adopt commensurately greater safeguards for uses with rights - and safety -impacting risks; and determine their risk tolera nce as an organization. The potential impact of AI uses varies dramatically, and the rigor of governance processes to manage risk may vary accordingly. Regular Updates : Policies and procedures will inevitably require updates and should contemplate the circumstances that may warrant revisions. Agencies may consider, for instance, reviewing their AI governance policies on a yearly basis to account for technological and le gal developments in this area. Agencies should consult with their legal counsel as needed to make appropriate revisions to reflect intervening legal decisions or changes in the applicable rules or statutes in the civil or criminal context. f."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_296",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nwarrant revisions. Agencies may consider, for instance, reviewing their AI governance policies on a yearly basis to account for technological and le gal developments in this area. Agencies should consult with their legal counsel as needed to make appropriate revisions to reflect intervening legal decisions or changes in the applicable rules or statutes in the civil or criminal context. f. Identify and Analyze Training Data Quality and Sources Prior to deploying any AI system, individuals and institutions operating in the criminal justice system should closely track and identify the quality and sources of the data on which the AI system was trained and assess the relevance of the data the system was trained on to their particular use and jurisdiction. This is a crucial consideration for all AI systems bu t may be particularly relevant to institutions intending to contract AI systems designed, administered, or maintained by third- party vendors who may use proprietary training data sets or may otherwise be unwilling to disclose such information to their clients. To that end, criminal justice actors should obtain legal advice and involve procurement professionals to understand and negotiate contracts that allow those actors to examine the training data and address other important civil rights, civil liberties, or privacy concerns. g. Test Systems Under Deployment Conditions Criminal justice entities should conduct rigorous pre -deployment testing of any AI or automated systems."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_297",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nTo that end, criminal justice actors should obtain legal advice and involve procurement professionals to understand and negotiate contracts that allow those actors to examine the training data and address other important civil rights, civil liberties, or privacy concerns. g. Test Systems Under Deployment Conditions Criminal justice entities should conduct rigorous pre -deployment testing of any AI or automated systems. To the extent possible, such testing should be performed by independent third parties following domain- specific best practices and under conditions tha t mirror actual end -to- end deployment conditions. This testing must account for and seek to reflect the complex operational and societal contexts in which these systems are used. Testing a system in isolation may not accurately or fully reflect the system’ s impact. Agencies should also use pilots and limited releases in advance of full deployment to identify and mitigate against potential risks. The performance of the AI system should be evaluated against the performance of the status quo—such as technologi cal tools or human processes that AI will be replacing or supplementing—and alternatives, and performance factors should include testing for bias, discrimination, and disparities. To instill public confidence, agencies may also consider facilitating external testing as feasible. 75 h."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_298",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nagainst potential risks. The performance of the AI system should be evaluated against the performance of the status quo—such as technologi cal tools or human processes that AI will be replacing or supplementing—and alternatives, and performance factors should include testing for bias, discrimination, and disparities. To instill public confidence, agencies may also consider facilitating external testing as feasible. 75 h. Evaluate Risks and Implement Risk Mitigation Strategies After testing, criminal justice agencies should identify rights - or safety -impacting use cases and possible mitigation measures. Mitigation measures should include reconsidering use of rights - or safety -impacting use cases for which risks cannot be effectively mitigated. The decision not to proceed with a use case must be a feasible option. i. Create Technology- Specific Policies Some AI use cases, such as facial recognition, create unique or significant considerations that may justify dedicated policies. Agencies should consider whether specific policies are appropriate for particular use cases. Post-Deployment Measures After deploying AI systems, criminal justice agencies should also undertake the following measures. j. Monitor the AI System Following deployment, entities should conduct regular audits and monitoring of their uses of AI."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_299",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\nsuch as facial recognition, create unique or significant considerations that may justify dedicated policies. Agencies should consider whether specific policies are appropriate for particular use cases. Post-Deployment Measures After deploying AI systems, criminal justice agencies should also undertake the following measures. j. Monitor the AI System Following deployment, entities should conduct regular audits and monitoring of their uses of AI. Entities should adopt a mechanism for objective, independent auditing of models and source code to proactively address concerns about model accuracy, reliability, outdated training or test data, and potential for bias and discrimination. k. Evaluate New Uses Agencies should also consider whether and how their use of the AI system might have evolved over time, or how the context in which the system was deployed may have changed. If agencies identify new uses or new data sources that were not considered or evaluated pre- deployment, or if the context changes substantially, those agencies should implement pre - deployment strategies to the new uses and new data and evaluate whether those new uses and new data present new risks to the rights or safety of individuals, whether the new use is appropriate in light of those risks, and any mitigation strategies to be executed. l."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_300",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ndeployment, or if the context changes substantially, those agencies should implement pre - deployment strategies to the new uses and new data and evaluate whether those new uses and new data present new risks to the rights or safety of individuals, whether the new use is appropriate in light of those risks, and any mitigation strategies to be executed. l. Continue Engaging with the Public Post- deployment, agencies should continue to actively consult the public, and in particular, communities they judge will be most likely to be affected by the implementation of AI in the criminal justice system. Community engagement should be proactive, and feedback should be solicited on a regular, ongoing basis. Entities should establish channels for affected community members to seek recourse and alternatives to AI systems where practicable. While this report considers many critical uses of AI in the criminal justice system as specified by EO 14110, existing and possible uses extend well beyond these cases. Use cases associated with future and emerging AI technologies —such as generative AI —might also have a transformative impact on the criminal justice system. Establishing robust AI governance programs 76 at criminal justice agencies can position those agencies to address risks of these use cases and better capture their promise."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_301",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\n14110, existing and possible uses extend well beyond these cases. Use cases associated with future and emerging AI technologies —such as generative AI —might also have a transformative impact on the criminal justice system. Establishing robust AI governance programs 76 at criminal justice agencies can position those agencies to address risks of these use cases and better capture their promise. 77 Legal Disclaimer This report is intended to support the development of policies and practices that protect civil rights, civil liberties, privacy, and equity, and that promote democratic values in the building, deployment, and governance of automated systems. It reflects a nd describes academic studies, policy proposals, and advocacy positions that might not be adopted or endorsed by the U.S. government. This report is non- binding and does not constitute U.S. government policy. It does not supersede, modify, or direct an interpretation of any existing statute, regulation, policy, or international instrument. It does not constitute binding guidance for the public or federal agencies and therefore does not require compliance with the principles described herein. It also is not determinative of what the U.S. government’s position will be in any international negotiation."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_302",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ngovernment policy. It does not supersede, modify, or direct an interpretation of any existing statute, regulation, policy, or international instrument. It does not constitute binding guidance for the public or federal agencies and therefore does not require compliance with the principles described herein. It also is not determinative of what the U.S. government’s position will be in any international negotiation. The Department’s inclusion of recommendations does not indicate a determination that adoption of those recommendations would necessarily satisfy requirements set forth in existing statutes, regulations, policies, or international instruments, or the requirements of the federal agencies that enforce them. Recommendations are not intended to, and do not, prohibit or limit any lawful activity of a government agency, including law enforcement, national security, or intelligence activities. The appropriate application of the recommendations set forth in this report depends significantly on the context in which automated systems are being utilized. In some circumstances, application of these recommendations in whole or in part may not be appropriate given the intended use of automated systems to achieve government agency missions. Future sector -specific guidance will likely be necessary and important for guiding the use of automated systems in certain settings."
  },
  {
    "id": "AI_EO_Report_20241203_-_final_chunk_303",
    "text": "Source: 19 AI EO Report (2024.12.03) - final.pdf\n\ndepends significantly on the context in which automated systems are being utilized. In some circumstances, application of these recommendations in whole or in part may not be appropriate given the intended use of automated systems to achieve government agency missions. Future sector -specific guidance will likely be necessary and important for guiding the use of automated systems in certain settings. This report recognizes that law enforcement activities require a balancing of equities, for example, between the protection of sensitive law enforcement information and public access to information; as such, public access to information may not be appropri ate, or may need to be adjusted to protect sources, methods, and other law enforcement equities. In all circumstances, federal departments and agencies remain subject to judicial and congressional oversight, as well as oversight by private and public civil liberties and privacy- focused organizations, as well as existing laws, policies , and safeguards that govern automated systems. This report is not intended to, and does not, create any legal right, benefit, or defense, substantive or procedural, enforceable at law or in equity by any party against the United States, its departments, agencies, or entities, its officers, employees, or agents, or any other person, nor does it constitute a waiver of sovereign immunity."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_0",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nEXECUTIVE OFFICE OF THE PRESIDENT OFFlCEOFMANAGEMENTANDBUDGET WASHINGTON , D.C. 20503 THE DIRECTOR April 3, 2025 M-25-21 MEMORANDUM FOR THE HEADS OF EXECUTIVE DEPARTMENTS AND AGENCIES FROM: R~ssell T. Vought \\\\ 1 \\ A Director \\J \\..\\l~ SUBJECT: Accelerating Federal Use of AI through Innovation , Governance, and Public Trust OVERVIEW On January 23, 2025, President Trump signed Executive Order (E.O.) 14179, Removing Barriers to American Leadership in Artificial Intelligence, to advance the United States' global AI dominance and to promote responsible AI innovation. Now more than ever, agencies 1 are empowered to drive AI innovation and seize the opportunity to apply the best of American AI. Through this memorandum, agencies are directed to provide improved services to the public, while maintaining strong safeguards for civil rights, civil liberties, and privacy. This memorandum provides guidance to agencies on ways to promote human flourishing , economic competitiveness and national security. Agencies must follow the detailed implementation instructions and requirements included in the Appendix. This memorandum rescinds and replaces Office of Management and Budget (0MB) Memorandum M-24-10, Advancing Governance, Innovation, and Risk Management for Agency Use ofArtificial Intelligence. SCOPE This memorandum is directed to the heads of all Executive Branch departments and agencies, including independent regulatory agencies."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_1",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\ncompetitiveness and national security. Agencies must follow the detailed implementation instructions and requirements included in the Appendix. This memorandum rescinds and replaces Office of Management and Budget (0MB) Memorandum M-24-10, Advancing Governance, Innovation, and Risk Management for Agency Use ofArtificial Intelligence. SCOPE This memorandum is directed to the heads of all Executive Branch departments and agencies, including independent regulatory agencies. 2 GUIDANCE ON FEDERAL USE OF AI The United States is at the forefront of AI development, and agencies must adopt a forward-leaning and pro-innovation approach that takes advantage of this technology to help shape the future of government operations. Agencies are encouraged to harness solutions that bring the best value to taxpayers, increase quality of public services, and enhance government efficiency. Through this memorandum , agencies will be charged to lessen the burden of bureaucratic restrictions and to build effective policies and processes for the timely deployment 1 The term \"agency\" has the meaning provided in 44 U.S.C. § 3502(1). 2 The term \"independent regulatory agency\" is defined in 44 U.S.C. § 3502(5). of AI. Agencies are directed to accelerate the Federal use of AI by focusing on three key priorities: innovation, governance, and public trust.3 Consistent with these goals, agencies must undertake the requirements described in the Appendix."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_2",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nterm \"agency\" has the meaning provided in 44 U.S.C. § 3502(1). 2 The term \"independent regulatory agency\" is defined in 44 U.S.C. § 3502(5). of AI. Agencies are directed to accelerate the Federal use of AI by focusing on three key priorities: innovation, governance, and public trust.3 Consistent with these goals, agencies must undertake the requirements described in the Appendix. This includes the following: Agencies must remove barriers to innovation and provide the best value for the taxpayer. Agencies must lean forward on adopting effective, mission-enabling AI to benefit the American people. To best achieve this, agencies must remove unnecessary and bureaucratic requirements that inhibit innovation and responsible adoption. Agencies must develop public AI strategies that elevate AI adoption and innovation as a priority, while increasing transparency to the American public, civil society, and industry. Agencies must maximize the value of existing investments to ensure speedy deployment and to protect taxpayer dollars from duplicative spending, including sharing resources within an agency and across government. Agencies must also reuse resources that enable AI adoption, such as agency data, models, code, and assessments of AI performance. When choosing to pursue an AI acquisition, agencies should invest in the American AI marketplace and maximize the use of AI products and services that are developed and produced in the United States."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_3",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nresources within an agency and across government. Agencies must also reuse resources that enable AI adoption, such as agency data, models, code, and assessments of AI performance. When choosing to pursue an AI acquisition, agencies should invest in the American AI marketplace and maximize the use of AI products and services that are developed and produced in the United States. To lead these innovation priorities, agencies are encouraged to develop and retain AI and AI-enabling talent who have the technical experience to scale and govern AI to improve mission outcomes. Agencies must empower AI leaders to accelerate responsible AI adoption. Agencies must cut down on bureaucratic bottlenecks and redefine AI governance as an enabler of effective and safe innovation. As a step towards accelerating responsible adoption, agencies must establish clear expectations for their workforce on appropriate AI use­ particularly when an agency is using AI to support consequential decision-making. Agency policies must enable agency heads to delegate responsibilities and accountability for risk acceptance to appropriate officials throughout the agency, ensuring that swift action is possible with sufficient guardrails in place. Agencies must identify a Chief AI Officer to champion their agency's AI goals by advising on how to make these improvements, and agencies must allocate appropriate resources and responsibilities to effect the changes in this memorandum."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_4",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\ndelegate responsibilities and accountability for risk acceptance to appropriate officials throughout the agency, ensuring that swift action is possible with sufficient guardrails in place. Agencies must identify a Chief AI Officer to champion their agency's AI goals by advising on how to make these improvements, and agencies must allocate appropriate resources and responsibilities to effect the changes in this memorandum. To support these efforts, 0MB will convene and chair an interagency council to maximize agency efficiencies by coordinating the development and use of AI in their programs and operations. Agencies must also be accountable to the taxpayer and must continue with all relevant reporting requirements, including updating their annual AI use case inventory, compliance plans, and reporting as requested by 0MB. Agencies must ensure their use of AI works for the American people. Every day, the Federal Government takes action and makes decisions that have consequential impacts on the public. If AI is used to perform such action, agencies must deploy 3 The requirements in this section are consistent with the following laws and policies: AI in Government Act of 2020, Advancing American AI Act, E.O. 13960, and E.O. 14179. 2 trustworthy AI, ensuring that rapid AI innovation is not achieved at the expense of the American people or any violations of their trust."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_5",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nto perform such action, agencies must deploy 3 The requirements in this section are consistent with the following laws and policies: AI in Government Act of 2020, Advancing American AI Act, E.O. 13960, and E.O. 14179. 2 trustworthy AI, ensuring that rapid AI innovation is not achieved at the expense of the American people or any violations of their trust. As such, agencies are directed to implement minimum risk management practices for AI that could have significant impacts when deployed (\"high-impact AI\"), as outlined in the Appendix, and to prioritize the use of AI that is safe, secure, and resilient. When the high-impact AI is not performing at an appropriate level, agencies must have a plan to discontinue its use until actions are taken to achieve compliance with this memorandum. If proper risk mitigation is not possible, agencies must cease the use of the AI. In an effort to reduce redundancy and unnecessary burden, agencies are reminded that risk management practices for AI should be proportionate to the anticipated risk from its intended use. These protections will ensure that agencies are serving the American public. 3 Appendix: M-25-21 Implementation Guidance for Agencies 1."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_6",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nmitigation is not possible, agencies must cease the use of the AI. In an effort to reduce redundancy and unnecessary burden, agencies are reminded that risk management practices for AI should be proportionate to the anticipated risk from its intended use. These protections will ensure that agencies are serving the American public. 3 Appendix: M-25-21 Implementation Guidance for Agencies 1. SCOPE This memorandum provides guidance to agencies on how to innovate and promote the responsible adoption, use, and continued development of AI, while ensuring appropriate safeguards are in place to protect privacy, civil rights, and civil liberties, and to mitigate any unlawful discrimination, consistent with the AI in Government Act.4 This memorandum does not address general issues related to Federal information and information systems. This memorandum does not supersede, and should be considered in concert with, other more general Federal policies. Agencies must continue to comply with applicable law and 0MB policies in other domains relevant to AI, and must continue to coordinate compliance across the agency with all appropriate officials. All agency officials retain their existing authorities and responsibilities established in other laws and policies. a. Covered Agencies. Except as specifically noted, this memorandum applies to all agencies defined in 44 U.S.C. § 3502(1)."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_7",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\ncomply with applicable law and 0MB policies in other domains relevant to AI, and must continue to coordinate compliance across the agency with all appropriate officials. All agency officials retain their existing authorities and responsibilities established in other laws and policies. a. Covered Agencies. Except as specifically noted, this memorandum applies to all agencies defined in 44 U.S.C. § 3502(1). 5 As noted in the relevant sections, some requirements in this memorandum apply only to Chief Financial Officers Act (CFO Act) agencies as identified in 31 U.S.C. § 901(b), and other requirements do not apply to elements of the Intelligence Community, as defined in 50 U.S.C. § 3003. b. Covered AI. This memorandum provides requirements and recommendations that apply to new and existing AI that is developed, used, or acquired by or on behalf of covered agencies. This memorandum does not, by contrast, govern agencies': 4 Consistent with provisions of the AI in Government Act of2020, which required the issuance of this memorandum, and the Advancing American AI Act, this memorandum sets forth multiple independent requirements and recommendations for agencies, and 0MB intends that these requirements and recommendations be treated as severable. For example, the memorandum's provisions regarding the integrating of AI governance in Section 3 are capable of operating independently, and serve an independent purpose, from the required risk management practices set forth in Section 4."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_8",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nAI Act, this memorandum sets forth multiple independent requirements and recommendations for agencies, and 0MB intends that these requirements and recommendations be treated as severable. For example, the memorandum's provisions regarding the integrating of AI governance in Section 3 are capable of operating independently, and serve an independent purpose, from the required risk management practices set forth in Section 4. Likewise, each of Section 4's individual risk management practices serve an independent purpose and can function independently from the other risk management practices. Accordingly, while this memorandum governs only agencies' own use of AI and does not create rights or obligations for the public, in the event that a court were to stay or enjoin application of a particular provision of this memorandum, or its application to a particular factual circumstance, 0MB would intend that the remainder of the memorandum remain operative."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_9",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\npractices. Accordingly, while this memorandum governs only agencies' own use of AI and does not create rights or obligations for the public, in the event that a court were to stay or enjoin application of a particular provision of this memorandum, or its application to a particular factual circumstance, 0MB would intend that the remainder of the memorandum remain operative. 5The term \"agency,\" as used in both the AI in Government Act of 2020 and the Advancing American AI Act, is defined as \"any executive department, military department, Government corporation, Government controlled corporation, or other establishment in the executive branch of the Government (including the Executive Office of the President), or any independent regulatory agency,\" but does not include the Government Accountability Office; the Federal Election Commission; the governments of the District of Columbia and of the territories and possessions of the United States, and their various subdivisions; or Government-owned contractor-operated facilities, including laboratories engaged in national defense research and production activities. 44 U.S.C. § 3502(1); see AI in Government Act of2020 § 102(2) (defining \"agency\" by reference to§ 3502); Advancing American AI Act§ 7223(1) (same). As a result, independent regulatory agencies as defined in 44 U.S.C. § 3502(5), which were not included in the definitions of\"agency\" in Executive Order 13960, are covered by this memorandum. 4 1."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_10",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nresearch and production activities. 44 U.S.C. § 3502(1); see AI in Government Act of2020 § 102(2) (defining \"agency\" by reference to§ 3502); Advancing American AI Act§ 7223(1) (same). As a result, independent regulatory agencies as defined in 44 U.S.C. § 3502(5), which were not included in the definitions of\"agency\" in Executive Order 13960, are covered by this memorandum. 4 1. regulatory actions designed to prescribe law or policy regarding non-agency uses of AI; 6 11. assessments of particular AI applications because the AI provider is the target or potential target of a regulatory enforcement , law enforcement, or national security action; 7 111. development of metrics, methods, and standards to test and measure AI, where such metrics, methods, and standards result in use by the general public or the government as a whole; or 1v. use of AI to carry out basic research or applied research, except where the purpose of such research is to develop particular AI applications for agency use. The requirements and recommendations of this memorandum apply to system functionality that implements or is reliant on AI, rather than to the entirety of an information system that incorporates AI. As noted in the relevant sections, some requirements in this memorandum apply only in specific circumstances in which agencies use AI that is deemed high-impact. c. Applicability to National Security Systems."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_11",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nrequirements and recommendations of this memorandum apply to system functionality that implements or is reliant on AI, rather than to the entirety of an information system that incorporates AI. As noted in the relevant sections, some requirements in this memorandum apply only in specific circumstances in which agencies use AI that is deemed high-impact. c. Applicability to National Security Systems. This memorandum does not cover AI when it is being used as a component of a National Security System. 8 2. DRIVING AI INNOVATION The Federal Government has demonstrated that AI can improve public services, increase mission effectiveness, and reduce costs to the American people. Agencies have a responsibility to identify and remove barriers to further responsible AI adoption and application, where practicable , while providing meaningful public transparency into the Federal Government's use of AI. Agencies should focus on improving mission effectiveness through the use of AI by building upon their existing capabilities to drive responsible AI innovation, strengthen their AI and AI-enabling talent, and improve their ability to develop and procure AI. a. Developing Agency AI Strategies Within 180 days ofthe issuance of this memorandum, each CFO Act agency must develop an AI Strategy for identifying and removing barriers to their responsible use of AI and for achieving enterprise-wide improvements in the maturity of their applications."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_12",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\ninnovation, strengthen their AI and AI-enabling talent, and improve their ability to develop and procure AI. a. Developing Agency AI Strategies Within 180 days ofthe issuance of this memorandum, each CFO Act agency must develop an AI Strategy for identifying and removing barriers to their responsible use of AI and for achieving enterprise-wide improvements in the maturity of their applications. Agencies must use the AI Strategies template, to be provided by 0MB, and make their AI Strategies publicly 6 For guidance on regulatory and non-regulatory approaches to AI applications developed and deployed outside of the Federal government and best practices to reduce barriers to the development and adoption of AI technologies , agencies should consult 0MB Memorandum M-21-06, Guidance for Regulation ofArtificial Intelligence Applications (Nov. 17, 2020), https://trumpwhitehouse.archives.gov /wp-content/uploads /2020/11/M-2 l-06.pdf. 7 AI is not in scope when it is the target or potential target of such an action, but it is in scope when the AI is used to carry out an enforcement action. For example, when evaluating an AI tool to determine whether it violates the law, the AI would not be in scope; if an agency was using that same AI tool to assess a different target, then the AI would be in scope. 8 AI innovation and risk for National Security Systems must be managed appropriately, but these systems are governed through other policy."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_13",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nevaluating an AI tool to determine whether it violates the law, the AI would not be in scope; if an agency was using that same AI tool to assess a different target, then the AI would be in scope. 8 AI innovation and risk for National Security Systems must be managed appropriately, but these systems are governed through other policy. Agencies should reference existing guidelines in place, such as the Department of Defense's (DoD) Responsible Artificial Intelligence Strategy and Implementation Pathway and the Office of the Director of National Intelligence's Principles ofArtificial Intelligence Ethics for the Intelligence Community, as well as policies governing specific high-risk national security applications of AI, such as DoD Directive 3000.09, Autonomy in Weapon Systems, https://ogc.osd.mil/Portals /99/autonomy in weapon systems dodd 3000 09.pdf. 5 available on the agency's website. To ensure accountability to the taxpayer, strategies should be understandable, accessible to the public, and transparent about how their investments in AI innovation benefit the American people. Agencies should assess their AI maturity goals and accelerate and scale AI adoption, by appropriately resourcing areas such as data governance, information technology (IT), infrastructure, quality data assets, integration and interoperability, accessibility, privacy, confidentiality, and security."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_14",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nto the taxpayer, strategies should be understandable, accessible to the public, and transparent about how their investments in AI innovation benefit the American people. Agencies should assess their AI maturity goals and accelerate and scale AI adoption, by appropriately resourcing areas such as data governance, information technology (IT), infrastructure, quality data assets, integration and interoperability, accessibility, privacy, confidentiality, and security. Agencies must strive to utilize and scale existing tools, processes, and resources for AI governance whenever possible to avoid the creation of additional bureaucracy, and invest in technical solutions to make compliance more efficient. Agency AI Strategies must be consistent with this memorandum and include: 1. current and planned AI use cases that are most impactful to an agency's mission, operations, or service delivery;9 11. an assessment of the agency's current state of AI maturity and a plan to achieve the agency's AI maturity goals, by addressing, at a minimum, plans or processes to: A. develop AI-enabling infrastructure 10 across the AI lifecycle including development, testing, deployment, continuous monitoring; 11 B. ensure access to quality data12 for AI and data traceability; 13 C. develop enterprise capacity for AI innovation; D. provide AI tools and capacity to support the agency's AI research and development (R&D) efforts; E."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_15",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\naddressing, at a minimum, plans or processes to: A. develop AI-enabling infrastructure 10 across the AI lifecycle including development, testing, deployment, continuous monitoring; 11 B. ensure access to quality data12 for AI and data traceability; 13 C. develop enterprise capacity for AI innovation; D. provide AI tools and capacity to support the agency's AI research and development (R&D) efforts; E. develop the necessary operations, governance, and infrastructure to manage risks from the use of AI, including risks related to information security and privacy; F. recruit, hire, train, retain, and empower an AI-ready workforce and achieve AI literacy for non-practitioners involved in AI; and G. identify, track, and facilitate future AI investment or procurement. 9 Consistent with sections 7225(d) and 7228 of the Advancing American AI Act, this requirement applies to CFO Act agencies except for the Department of Defense, and does not apply to elements of the Intelligence Community, as defined in 50 U.S.C. § 3003(4). Information that would be protected from release ifrequested under 5 U.S.C. § 552 need not be included in the strategy. 10 Agencies should ensure that their AI projects have access to adequate IT infrastructure, including high­ performance computing infrastructure specialized for AI training and inference, where necessary."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_16",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nto elements of the Intelligence Community, as defined in 50 U.S.C. § 3003(4). Information that would be protected from release ifrequested under 5 U.S.C. § 552 need not be included in the strategy. 10 Agencies should ensure that their AI projects have access to adequate IT infrastructure, including high­ performance computing infrastructure specialized for AI training and inference, where necessary. Agencies should also ensure adequate access for AI developers to the software tools, open-source libraries, and deployment and monitoring capabilities necessary to rapidly develop, test, and maintain AI applications. 11 Agencies should update, as necessary, processes for information system authorization and continuous monitoring to better address the needs ofAI applications. 12 Agencies should develop adequate infrastructure and capacity to sufficiently share, curate, and govern agency data for use in training, testing, and operating AI. This includes an agency's capacity to maximize appropriate access to and sharing of both internally held data and agency data managed by third parties. Agencies should also explore the possible utility of and legal authorities supporting the use of publicly available information, and encourage its use where appropriate and consistent with the data practices outlined in this memorandum. 13 In this context, traceability refers to an agency's ability to track and internally audit datasets used for AI, and where relevant, key metadata."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_17",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nthird parties. Agencies should also explore the possible utility of and legal authorities supporting the use of publicly available information, and encourage its use where appropriate and consistent with the data practices outlined in this memorandum. 13 In this context, traceability refers to an agency's ability to track and internally audit datasets used for AI, and where relevant, key metadata. A significant enabler of traceability is clear documentation that is meaningful or understandable to individual users and reflects the process for model-driven development. 6 b. Sharing of Agency Data and AI Assets Agencies can save taxpayer dollars by actively engaging in quality data governance and management and the reuse of data and AI assets. Chief AI Officers (CAIOs), as described in Section 3(a)(i), and Chief Data Officers (CDOs) are encouraged to coordinate internally and across the Federal Government on criteria for data interoperability and standardization of data formats as a means of increased AI adoption. Agencies should identify and share commonly used packages or functions that have the greatest potential for reuse by other agencies or by the public. 1. Encouraging Reuse of AI Code and Models. Agencies must proactively share across the Federal Government their custom-developed code-including models and model weights-whether agency developed or procured, for AI applications in active use, except in the circumstances described in paragraphs A through D below."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_18",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nor functions that have the greatest potential for reuse by other agencies or by the public. 1. Encouraging Reuse of AI Code and Models. Agencies must proactively share across the Federal Government their custom-developed code-including models and model weights-whether agency developed or procured, for AI applications in active use, except in the circumstances described in paragraphs A through D below. Agencies must also prioritize sharing AI code, models, and data government-wide , consistent with the Open, Public, Electronic and Necessary (OPEN) Government Data Act. 14 Agencies, where practicable, must also release and maintain AI code as open source software in a public repository 15 unless the: A. sharing of the code is restricted by law or regulation , including patent or intellectual property law, the Export Asset Regulations, the International Traffic in Arms Regulations, or Federal laws and regulations governing classified information; B. sharing of the code would create an identifiable risk to national security, confidentiality of Government information, individual privacy, or the rights or safety ofthe public; C. agency is prevented from doing so by a contractual obligation; or D. sharing of the code would create an identifiable risk to agency mission, programs , or operations, or to the stability, security, or integrity of an agency's systems or personnel. 11. Sharing and Releasing AI Data Assets."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_19",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nGovernment information, individual privacy, or the rights or safety ofthe public; C. agency is prevented from doing so by a contractual obligation; or D. sharing of the code would create an identifiable risk to agency mission, programs , or operations, or to the stability, security, or integrity of an agency's systems or personnel. 11. Sharing and Releasing AI Data Assets. Data used to develop and test AI may constitute a \"data asset\" within the meaning of 44 U.S.C. § 3502(17) . Agencies must include them in their comprehensive data inventories if required by the OPEN Government Data Act and 0MB Memorandum M-25-05, Phase 2 Implementation ofthe Foundations for Evidence- 14 Title II of the Foundations for Evidence-Based Policymaking Act of 2018, Pub. L. No. 115-435, https://www.congress.gov /l l5/statute/STATUTE-132 /STATUTE-l 32-Pg5529.pdf. 15 For guidance and best practices related to sharing code and releasing it as open source, agencies should consult 0MB Memorandum M-16-21 , Federal Source Code Policy: Achieving Efficiency, Transparency , and Innovation through Reusable and Open Source Software (Aug. 8, 2016), https://www.whitehouse.gov /wp­ content/uploads /legacy drupal files/omb/memoranda/2016 /m 16 21.pdf."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_20",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nPub. L. No. 115-435, https://www.congress.gov /l l5/statute/STATUTE-132 /STATUTE-l 32-Pg5529.pdf. 15 For guidance and best practices related to sharing code and releasing it as open source, agencies should consult 0MB Memorandum M-16-21 , Federal Source Code Policy: Achieving Efficiency, Transparency , and Innovation through Reusable and Open Source Software (Aug. 8, 2016), https://www.whitehouse.gov /wp­ content/uploads /legacy drupal files/omb/memoranda/2016 /m 16 21.pdf. Agencies are additionally encouraged to draw upon existing collaboration methods to facilitate the sharing and release of code and models, the General Services Administration's AI Community of Practice, and https://www.code .gov, as well as other publicly available code repositories. 7 Based Policymaking Act of2018: Open Government Data Access and Management Guidance. 16 111. Unintended Disclosure of Data from AI Models. Consistent with Section 2( d)(i), agencies should assess the risks associated with AI models, as they may reveal sensitive details of the data used to develop them. 17 c. Leveraging American AI and Innovation Executive Order 14179 recognizes the importance of American AI development to promote human :flourishing, economic competitiveness, and national security. Consistent with applicable law, it is the policy of the United States to buy American and to maximize the use of AI products and services that are developed and produced in the United States."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_21",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\n17 c. Leveraging American AI and Innovation Executive Order 14179 recognizes the importance of American AI development to promote human :flourishing, economic competitiveness, and national security. Consistent with applicable law, it is the policy of the United States to buy American and to maximize the use of AI products and services that are developed and produced in the United States. 0MB Memorandum M-25-22, Driving Efficient Acquisition ofArtificial Intelligence in Government, covers the importance of American AI in federal procurement. d. Effective Federal Procurement of AI This section provides agencies with recommendations for the responsible procurement of AI capabilities to facilitate compliance with the minimum risk management practices for high­ impact AI use cases detailed in Section 4. Consistent with Section 7224(d) ofthe Advancing American AI Act and Executive Order 14179, 0MB will issue revised guidance to ensure that Federal contracts for the acquisition of an AI product or service align with the recommendations of this memorandum. 1. Maximizing the Value of Data for AI. In contracts for AI products and services, agencies should treat relevant data, or improvements to that data-such as cleaning and labeling­ as a critical asset for their AI maturity."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_22",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nrevised guidance to ensure that Federal contracts for the acquisition of an AI product or service align with the recommendations of this memorandum. 1. Maximizing the Value of Data for AI. In contracts for AI products and services, agencies should treat relevant data, or improvements to that data-such as cleaning and labeling­ as a critical asset for their AI maturity. Agencies should take steps to ensure that their contracts retain sufficient rights to Federal Government data and retain any improvements to that data, including the continued design, development, testing, and operation of AI. Additionally, agencies should consider contractual terms that prevent vendor lock-in and also protect Federal information used by vendors in the development and operation of AI products and services for the Federal Government. Contract terms should protect such data from unauthorized disclosure or use, and from being used to train or improve the functionality of the vendor's commercial offerings without express permission from the agency. 11. Performance Improvement. Agencies, where practicable, are encouraged to better track and evaluate performance of their procured AI by: 16 Where such data is already publicly available, agencies are not required to duplicate it, but should maintain and share the provenance of such data and how others can access it."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_23",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nthe vendor's commercial offerings without express permission from the agency. 11. Performance Improvement. Agencies, where practicable, are encouraged to better track and evaluate performance of their procured AI by: 16 Where such data is already publicly available, agencies are not required to duplicate it, but should maintain and share the provenance of such data and how others can access it. For guidance on the sharing and release of data assets, see 0MB Memorandum M-25-05, Phase 2 Implementation ofthe Foundations for Evidence-Based Policymaking Act o/2018: Open Government Data Access and Management Guidance (Jan. 15, 2025), https :/ /www.whitehouse.gov/wp-content/up loads/2025/01 /M-25-05- Phase-2-Implementation-of-the-Foundations­ for-Evidence- Based-Policymaking-Act-of-2018-Open-Government- Data-Access-and- Management-Guidance. pdf. 17 The risks of unintended disclosure differ by model, and agencies should also not assume that an AI model poses the same privacy and confidentiality risks as the data used to develop it. 8 A. documenting known capabilities and limitations of the AI and any guidelines on how the system is intended to be used; B. documenting provenance of the data used to train, fine-tune, or operate the AI; C. conducting ongoing testing and validation on AI model performance; the effectiveness of vendor AI offerings; and associated risk management measures, including by testing in real-world conditions; D."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_24",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\ncapabilities and limitations of the AI and any guidelines on how the system is intended to be used; B. documenting provenance of the data used to train, fine-tune, or operate the AI; C. conducting ongoing testing and validation on AI model performance; the effectiveness of vendor AI offerings; and associated risk management measures, including by testing in real-world conditions; D. assessing for overfitting to known test data, ensuring that AI developers or vendors are not directly relying on the test data to train their AI systems; 18 E. considering contractual terms that prioritize the continuous improvement, performance monitoring, and evaluation of effectiveness of procured AI; and F. requiring sufficient post-award monitoring and evaluation of effectiveness ofthe AI, where appropriate in the context of the product or service acquired. 111. Promoting Competition in Federal Procurement of AI. Agencies should adopt procurement practices that encourage competition to sustain a robust Federal AI marketplace, such as by preferencing interoperable AI products and services. e. Enabling an AI-Ready Federal Workforce Training the Federal workforce about AI improves efficiency and increases AI adoption. The Federal workforce has a responsibility to develop and maintain, at a minimum, foundational knowledge of how to use AI responsibly in performing their official duties."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_25",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nto sustain a robust Federal AI marketplace, such as by preferencing interoperable AI products and services. e. Enabling an AI-Ready Federal Workforce Training the Federal workforce about AI improves efficiency and increases AI adoption. The Federal workforce has a responsibility to develop and maintain, at a minimum, foundational knowledge of how to use AI responsibly in performing their official duties. Agencies are strongly encouraged to prioritize recruiting, developing, and retaining technical talent in AI roles. The benefits include increasing enterprise capacity for responsible AI innovation, providing the Federal workforce pathways to AI up-skilling, and assisting employees in applying AI to their work. Agencies should take action by: 1. Leveraging AI Trainings and Resources to Upskill Existing Staff. Agencies should leverage AI training programs and resources, such as the annual training made available government-wide by 0MB and GSA, 19 to strengthen the technical skills of staff in AI and AI-enabling roles. Agencies should develop additional technical training or resources as needed to increase practical, hands-on expertise with AI technologies. 11. Promoting AI Talent. Agencies should focus recruitment efforts on individuals that have demonstrated operational experience in designing, deploying, and scaling AI systems in high-impact environments. 111. Ensuring Accountability."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_26",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\n19 to strengthen the technical skills of staff in AI and AI-enabling roles. Agencies should develop additional technical training or resources as needed to increase practical, hands-on expertise with AI technologies. 11. Promoting AI Talent. Agencies should focus recruitment efforts on individuals that have demonstrated operational experience in designing, deploying, and scaling AI systems in high-impact environments. 111. Ensuring Accountability. Agencies, in coordination with relevant agency officials, should identify and track, as appropriate, existing and emerging needs related to AI talent and expertise across the agency to ensure technical talent and resources are allocated properly and aligned with mission needs. 18 For instance, using validation data to train a model could lead the model to learn spurious correlations that make the model appear accurate in tests but degrade the real-world performance of the AI system. 19 See the AI Training Act, Pub. L. No. 117-207, https://www.congress.gov/l l 7/plaws/publ207/PLA W­ l l 7publ207 .pdf. 9 3. IMPROVING AI GOVERNANCE Effective AI governance is key to accelerated innovation as it empowers professionals at all levels to align processes, establish clear policies, and foster accountability while reducing unnecessary barriers to AI adoption."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_27",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nreal-world performance of the AI system. 19 See the AI Training Act, Pub. L. No. 117-207, https://www.congress.gov/l l 7/plaws/publ207/PLA W­ l l 7publ207 .pdf. 9 3. IMPROVING AI GOVERNANCE Effective AI governance is key to accelerated innovation as it empowers professionals at all levels to align processes, establish clear policies, and foster accountability while reducing unnecessary barriers to AI adoption. To that end, agencies must identify key officials to lead agency AI adoption and promote the sharing of best practices, empowering the entire Federal workforce to leverage AI in fulfilling their mission. Consistent with these goals, agencies must undertake the following: a. Agency Governance Roles and Bodies Consistent with agency policies, the Federal workforce is encouraged to embrace AI adoption at all levels of the Federal Government and to use AI for innovation and increased efficiency. To support this adoption and use, senior agency leaders must effectively distribute responsibilities and accountability, collaborating with agency officials in AI and AI-enabling roles. In support of these objectives and consistent with Executive Order 13960 and Executive Order 14179, agency heads are responsible for establishing the following: 1. Chief AI Officers. Within 60 days of the issuance of this memorandum, the head of each agency must retain or designate a Chief AI Officer (CAIO)."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_28",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\naccountability, collaborating with agency officials in AI and AI-enabling roles. In support of these objectives and consistent with Executive Order 13960 and Executive Order 14179, agency heads are responsible for establishing the following: 1. Chief AI Officers. Within 60 days of the issuance of this memorandum, the head of each agency must retain or designate a Chief AI Officer (CAIO). CAI Os will promote AI innovation, adoption, and governance, in coordination with appropriate agency officials. Agency heads may choose to designate an existing official, such as a Chief Information Officer, Chief Data Officer, Chief Technology Officer, or similar official with relevant or complementary authorities and responsibilities, provided that individual has significant expertise in AI. For CFO Act agencies, the CAIO must hold a position at the Senior Executive Service, Scientific and Professional, or Senior Leader level, or equivalent. For other agencies, the CAIO must be at or above Grade 14 of the General Schedule (GS), or the equivalent for agencies that do not use the GS classification system. CAIOs must have the necessary authority to perform the responsibilities in this section and must be positioned highly enough to engage regularly with other agency leadership, to include the Deputy Secretary or equivalent. Agencies must notify 0MB within 30 days when the designated CAIO changes or the position is vacant. CAI Os, in coordination with appropriate agency officials, must: A."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_29",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nCAIOs must have the necessary authority to perform the responsibilities in this section and must be positioned highly enough to engage regularly with other agency leadership, to include the Deputy Secretary or equivalent. Agencies must notify 0MB within 30 days when the designated CAIO changes or the position is vacant. CAI Os, in coordination with appropriate agency officials, must: A. promote agency-wide responsible AI innovation and adoption in accordance with this memorandum through a governance and oversight process; B. coordinate with other responsible agency officials to ensure that the agency's use of AI complies with applicable law and govemmentwide guidance; C. serve as the senior advisor on AI to the head of the agency and within their agency's executive decision-making forums; D. represent their agency in and collaborate with coordination bodies related to their agency's AI activities, including external forums such as AI-related councils, standard-setting bodies, relevant governance boards, or international bodies; E. maintain the agency's AI Use Case Inventory; 20 F. ensure processes are in place for the agency's high-impact AI use, consistent with Section 4 of this memorandum, by: 1. establishing a process for determining and documenting AI use cases as high­ impact; 2. establishing processes to measure, monitor, and evaluate the ongoing performance and effectiveness of the agency's high-impact AI applications; 3."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_30",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nagency's AI Use Case Inventory; 20 F. ensure processes are in place for the agency's high-impact AI use, consistent with Section 4 of this memorandum, by: 1. establishing a process for determining and documenting AI use cases as high­ impact; 2. establishing processes to measure, monitor, and evaluate the ongoing performance and effectiveness of the agency's high-impact AI applications; 3. overseeing agency compliance with requirements to manage risks from the use of AI, including those established in this memorandum and in relevant law and policy; 4. establishing a process for an independent review of high-impact use cases before risk acceptance, consistent with Section 4; 5. centrally tracking high-impact use cases and use case determinations; G. advise on the transformation of the agency's workforce into an AI-ready workforce; H. ensure that custom-developed AI code and the data used to develop and test AI are appropriately inventoried, shared, and released in agency code and data repositories, in coordination with their agency's relevant officials; I. provide guidance on AI investments to the agency head and agency CFO related to resourcing requirements necessary to implement this memorandum; and J. support agency efforts to track AI spending. 11. Agency AI Governance Board. Within 90 days of the issuance of this memorandum, each CFO Act agency must convene its relevant agency officials to coordinate and govern issues related to the use of AI within the Executive Branch."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_31",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nand agency CFO related to resourcing requirements necessary to implement this memorandum; and J. support agency efforts to track AI spending. 11. Agency AI Governance Board. Within 90 days of the issuance of this memorandum, each CFO Act agency must convene its relevant agency officials to coordinate and govern issues related to the use of AI within the Executive Branch. Agencies are permitted to rely on existing governance bodies to fulfill this requirement. Agencies are responsible for ensuring that agency AI governance boards: A. include a chair, at the Deputy Secretary level or equivalent, and a vice-chair who is the agency CAIO. Working through this Board, CAIOs will support their respective Deputy Secretaries in coordinating agency AI activities; B. include appropriate representation from key stakeholder offices or components, including those responsible for addressing IT, cybersecurity, data, budget, statistics, legal counsel, privacy, civil rights, and civil liberties. When relevant, AI governance boards must include representatives from the following disciplines: agency management, human capital, procurement, customer experience, program evaluation, and officials responsible for implementing AI within an agency's program office(s); and C. consult external experts, as needed and appropriate , to broaden the perspective of the designated governance board and to integrate sector-specific expertise, including recommendations on innovative agency AI use cases."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_32",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nboards must include representatives from the following disciplines: agency management, human capital, procurement, customer experience, program evaluation, and officials responsible for implementing AI within an agency's program office(s); and C. consult external experts, as needed and appropriate , to broaden the perspective of the designated governance board and to integrate sector-specific expertise, including recommendations on innovative agency AI use cases. 20 As required by Pub. L. No. 117-263, div. G, title LXXII, subtitle B, § 7225 (codified at 40 U.S.C. 11301 note), https://www.congress .gov/l l 7/plaws/publ263/PLAW-l l 7publ263.pdf. 11 b. Agency Governance Responsibilities Agencies must enable responsible AI governance and ensure innovative and appropriate use of AI agency-wide. Agency heads must: 1. Empower Agency AI Leaders. Agencies must enable trained and accountable agency officials at the lowest appropriate level21 to identify, assess, mitigate, and accept risk for AI use cases.22 11. Develop Compliance Plans."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_33",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nl 7/plaws/publ263/PLAW-l l 7publ263.pdf. 11 b. Agency Governance Responsibilities Agencies must enable responsible AI governance and ensure innovative and appropriate use of AI agency-wide. Agency heads must: 1. Empower Agency AI Leaders. Agencies must enable trained and accountable agency officials at the lowest appropriate level21 to identify, assess, mitigate, and accept risk for AI use cases.22 11. Develop Compliance Plans. Consistent with Section 104( c) and ( d) of the AI in Government Act of 2020, within 180 days of the issuance of this memorandum or any update to this memorandum, and every two years thereafter until 2036, each agency must submit to 0MB and post publicly on the agency's website either a plan to achieve consistency with this memorandum, or a written determination that the agency does not use and does not anticipate using covered AL Agencies must also include plans to update any existing internal AI principles and guidelines to ensure consistency with this memorandum.23 0MB will provide templates for these compliance plans. m. Update Agency Policies."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_34",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nagency's website either a plan to achieve consistency with this memorandum, or a written determination that the agency does not use and does not anticipate using covered AL Agencies must also include plans to update any existing internal AI principles and guidelines to ensure consistency with this memorandum.23 0MB will provide templates for these compliance plans. m. Update Agency Policies. Within 270 days of the issuance of this memorandum, agencies must revisit and update where necessary their internal policies on IT infrastructure ( e.g., software tools, use of open source software, libraries, and code for AI development, software deployment and platform modernization), data (e.g., data inventory; making quality data available for use by AI; lawful access to agency data, third-party data, and publicly available data, where appropriate; representativeness), cybersecurity (e.g., information system authorizations, continuous monitoring, continuous authorizations for Al), and privacy to align with this memorandum, Executive Order 14179, Executive Order 13960, and with applicable law. Agency policies should aim to advance using models that are built with less data, require less compute, and are inherently more explainable, where possible. 1v. Develop Generative AI Policy."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_35",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nwhere appropriate; representativeness), cybersecurity (e.g., information system authorizations, continuous monitoring, continuous authorizations for Al), and privacy to align with this memorandum, Executive Order 14179, Executive Order 13960, and with applicable law. Agency policies should aim to advance using models that are built with less data, require less compute, and are inherently more explainable, where possible. 1v. Develop Generative AI Policy. Within 270 days ofthe issuance of this memorandum, agencies should develop a policy that sets the terms for acceptable use of generative AI for their missions and establishes adequate safeguards and oversight mechanisms that allow generative AI to be used in the agency without posing undue risk. v. Update AI Use Case Inventories. Each agency (except for the Department of Defense and the Intelligence Community) must inventory its AI use cases at least annually, submit the inventory to 0MB, and post a public version on the agency's website. Agencies are encouraged to update the public versions of their inventories on an ongoing basis to reflect 21 Agencies are encouraged to assign these responsibilities to agency officials who are accountable for the misS:ion outcome of the AI use case. 22 The process for reviewing and accepting risk for AI use cases is separate from, and does not supersede, the authorization process for information systems, consistent with 0MB Circular No."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_36",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\ninventories on an ongoing basis to reflect 21 Agencies are encouraged to assign these responsibilities to agency officials who are accountable for the misS:ion outcome of the AI use case. 22 The process for reviewing and accepting risk for AI use cases is separate from, and does not supersede, the authorization process for information systems, consistent with 0MB Circular No. A-130, Managing Information as a Strategic Resource, https:/ /bidenwhitehouse.archives .gov/wp- content/uploads /legacy drupal files/omb/circulars/ A 130/a 130revised.pdf. 23 Given the importance of context-specific guidance on AI, agencies are encouraged to continue implementing their agency's AI principles and guidelines, so long as they do not conflict with this memorandum. 12 their current use of AI. 0MB will issue detailed instructions to agencies regarding the inventory and its scope. c. Federal Governance Roles and Bodies Breaking barriers to AI adoption and ensuring the government is maximizing efficiency requires coordination. The primary interagency body to lead this coordination will be the Chief AI Officer Council. 1. Chief AI Officer Council."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_37",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nmemorandum. 12 their current use of AI. 0MB will issue detailed instructions to agencies regarding the inventory and its scope. c. Federal Governance Roles and Bodies Breaking barriers to AI adoption and ensuring the government is maximizing efficiency requires coordination. The primary interagency body to lead this coordination will be the Chief AI Officer Council. 1. Chief AI Officer Council. Within 90 days of the issuance of this memorandum, the Director of 0MB, or designated senior official within 0MB, shall convene and chair an interagency council to coordinate the development and use of AI in agencies' programs and operations, other than the use of AI in national security systems, and to advance the implementation of the AI Principles established by Section 6 of Executive Order 13960. The Chief AI Officer Council shall: A. include as members the Chief AI Officers of CFO Act agencies, as well as representatives of the White House Office of Science and Technology Policy, the Office of the Director ofNational Intelligence, and other agencies as identified by the Chair; B. coordinate the development and use of AI across agencies' programs and operations, including enabling compliance with implementation of this memorandum and all other applicable authorities; C. develop and promote shared templates, formats, technical resources, and exemplary uses of agency AI adoption and implementation; and D."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_38",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nOffice of the Director ofNational Intelligence, and other agencies as identified by the Chair; B. coordinate the development and use of AI across agencies' programs and operations, including enabling compliance with implementation of this memorandum and all other applicable authorities; C. develop and promote shared templates, formats, technical resources, and exemplary uses of agency AI adoption and implementation; and D. sunset five years after the issuance of this memorandum, unless otherwise authorized by the 0MB Director. 4. FOSTERING PUBLIC TRUST IN FEDERAL USE OF AI Agencies must continue to develop AI that serves the public by, for example, increasing the accessibility of government services, increasing government efficiency, enhancing national security, and growing American economic competitiveness in a way that benefits people across the United States. Agencies must ensure their AI use is trustworthy, secure, and accountable, in accordance with Executive Order 13960. In the pursuit of agency-wide AI adoption and use, the Federal workforce at varying levels will participate in AI or AI-enabling roles, with accountable officials assuming risk.24 As part of this effort, AI risk management policies must be written to both ensure the minimum number of requirements necessary to enable the trustworthy and responsible use of AI and also ensure those requirements are understandable and implementable."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_39",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nadoption and use, the Federal workforce at varying levels will participate in AI or AI-enabling roles, with accountable officials assuming risk.24 As part of this effort, AI risk management policies must be written to both ensure the minimum number of requirements necessary to enable the trustworthy and responsible use of AI and also ensure those requirements are understandable and implementable. Agencies are required to implement minimum risk management practices, detailed in Section 4(b) of this memorandum, to manage risks from high-impact AI use cases. However, Sections 4(a) through (b) of this memorandum do not apply to elements ofthe Intelligence 24 Agencies are encouraged to assign these responsibilities to agency officials who are accountable for the mission outcome of the AI use case. 13 Community .25 Consistent with these goals, agencies must undertake the following, in addition to following 0MB standards and requirements governing information dissemination, where applicable.26 a. Determining High-Impact AI This section introduces requirements that are only applicable to \"high-impact\" agency uses of AI. As further defined in Section 5 of this memorandum, AI is considered high-impact when its output serves as a principal basis for decisions or actions that have a legal, material, binding, or significant effect on rights or safety."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_40",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\ninformation dissemination, where applicable.26 a. Determining High-Impact AI This section introduces requirements that are only applicable to \"high-impact\" agency uses of AI. As further defined in Section 5 of this memorandum, AI is considered high-impact when its output serves as a principal basis for decisions or actions that have a legal, material, binding, or significant effect on rights or safety. As part of conducting internal reviews of high­ impact use, agencies should evaluate the AI' s specific output and its potential risks when assessing the applicability of the high-impact definition. 27 A high-impact determination is possible whether there is or is not human oversight for the decision or action. 28 Section 6 provides agencies with categories of AI use cases that are automatically presumed to be high-impact. For AI use cases in these categories, an appropriate agency official must submit written documentation to notify the CAIO when making a determination that a particular AI use case does not actually meet the definition of high-impact. CAI Os are responsible for providing such determinations to 0MB upon request. Agencies are also encouraged to identify additional context-specific risks that are associated with their use of such AI and address them as appropriate. CAIOs may revisit any determinations made within their agency to conclude that an AI use case is considered \"high-impact\" and must be subject to the minimum risk management practices at any time."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_41",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\ndeterminations to 0MB upon request. Agencies are also encouraged to identify additional context-specific risks that are associated with their use of such AI and address them as appropriate. CAIOs may revisit any determinations made within their agency to conclude that an AI use case is considered \"high-impact\" and must be subject to the minimum risk management practices at any time. The practices in this section represent an initial baseline for managing risk from the implementation of high-impact AI use cases.29 Agencies are also encouraged to continue developing their own agency-specific practices, as appropriate and consistent with this memorandum and the principles in Executive Orders 13960 and 14179. Where possible, agencies should streamline approvals for intended use cases that are closely related in their deployment context and have substantially similar risk profiles. In implementing AI risk management for high-impact AI use cases, agencies and their CAIOs are responsible for the following: 1. Implementing Risk Management Practices and Termination of Non-Compliant AI."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_42",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nprinciples in Executive Orders 13960 and 14179. Where possible, agencies should streamline approvals for intended use cases that are closely related in their deployment context and have substantially similar risk profiles. In implementing AI risk management for high-impact AI use cases, agencies and their CAIOs are responsible for the following: 1. Implementing Risk Management Practices and Termination of Non-Compliant AI. Within 365 days of the issuance of this memorandum, agencies must document implementation of the minimum practices in Section 4(b) of this memorandum for high­ impact uses of AI and be prepared to report them to 0MB, as part of periodic accountability reviews, the annual AI use case inventory, or upon request as determined 25 Although elements of the Intelligence Community are not required to implement these practices, they are encouraged to do so. 26 See 0MB Memorandum M-19-15, Improving Implementation ofthe Information Quality Act, https://trumpwhitehouse .archives.gov/wp-content/uploads /20 l 9/04/M-19-15.pdf. 27 AI may be integrated in decision or activity pipelines in high-impact categories without meeting the defmition of high-impact because the Al's output does not actually \"serve as a principal basis for\" the relevant type of agency action or decision, as described in this memorandum's definition of \"high-impact Al.\" See Section 5. 28 Additional details are provided in Section 6 to assist with risk determinations for high-impact Al."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_43",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nactivity pipelines in high-impact categories without meeting the defmition of high-impact because the Al's output does not actually \"serve as a principal basis for\" the relevant type of agency action or decision, as described in this memorandum's definition of \"high-impact Al.\" See Section 5. 28 Additional details are provided in Section 6 to assist with risk determinations for high-impact Al. 29 For AI systems, agencies must continue to follow applicable authorization to operate requirements from 0MB Circular No. A-130, Managing Information as a Strategic Resource. 14 by 0MB. If a particular high-impact use case is not compliant with the minimum practices then the agency must safely discontinue use of the AI functionality. Pilot programs for a proposed AI use case are exempt from the minimum risk management practices, provided that: A. the program is of limited scale and duration; B. the agency CAIO has certified that the pilot may go forward, and that certification is tracked centrally; C. when possible, individuals who may interact with the AI have the ability to opt into and out of participating in the pilot, with sufficient notice to make an informed decision; and D. minimum risk management practices are applied where practicable. 11. Authorizing Waivers from Minimum Practices for High-Impact AI."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_44",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\npilot may go forward, and that certification is tracked centrally; C. when possible, individuals who may interact with the AI have the ability to opt into and out of participating in the pilot, with sufficient notice to make an informed decision; and D. minimum risk management practices are applied where practicable. 11. Authorizing Waivers from Minimum Practices for High-Impact AI. In coordination with other relevant officials, an agency CAIO may waive one or more of the requirements in this section for a specific covered AI application or component after making a written determination, based upon a system-specific and context-specific risk assessment, that fulfilling the requirement would increase risks to safety or rights overall or would create an unacceptable impediment to critical agency operations. An agency CAIO, in coordination with other relevant officials, must certify the ongoing validity of each waiver on an annual basis, and may also revoke a previously issued waiver at any time. The CAIO's responsibility under this paragraph shall not be delegated down to other officials. 111. Tracking Waivers from Minimum Practices for High-Impact AI."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_45",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nimpediment to critical agency operations. An agency CAIO, in coordination with other relevant officials, must certify the ongoing validity of each waiver on an annual basis, and may also revoke a previously issued waiver at any time. The CAIO's responsibility under this paragraph shall not be delegated down to other officials. 111. Tracking Waivers from Minimum Practices for High-Impact AI. In addition to the certification and publication requirements in Section 4(a)(ii) and Section 4(a)(iv) of this memorandum, CAIOs must centrally track waivers, reassess them if there are significant changes to the conditions or context in which the AI is used, and within 30 days of granting or revoking any waiver, report to 0MB on the scope, justification, and evidence supporting that action. 1v. Publicly Reporting Determinations and Waivers. To the extent consistent with law and governmentwide policy, each agency must publicly release a summary describing each individual determination and waiver, as well its justification. 0MB will issue detailed instructions for these summaries. Alternatively, agencies must publicly indicate, if the agency has no active determinations or waivers. b. Implementing Minimum Risk Management Practices for High-Impact AI Agencies must implement the following minimum risk management practices for high­ impact AI use cases: 1. Conduct Pre-Deployment Testing."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_46",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\ndescribing each individual determination and waiver, as well its justification. 0MB will issue detailed instructions for these summaries. Alternatively, agencies must publicly indicate, if the agency has no active determinations or waivers. b. Implementing Minimum Risk Management Practices for High-Impact AI Agencies must implement the following minimum risk management practices for high­ impact AI use cases: 1. Conduct Pre-Deployment Testing. Agencies must develop pre-deployment testing and prepare risk mitigation plans that reflect expected real-world outcomes and identify expected benefits to the AI use. In conducting pre-deployment testing, if an agency does not have access to the underlying AI source code, models, or data, the agency must use 15 alternative test methodologies, such as querying the AI service and observing the outputs or providing evaluation data to the vendor and obtaining results. 11. Complete AI Impact Assessment. Agencies must complete an AI impact assessment before deploying any high-impact AI use case. These assessments must be updated periodically and throughout the AI' s lifecycle, as appropriate, using target variables that anticipate real-world outcomes. The AI impact assessments must be documented and address or include, at a minimum: A."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_47",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nthe vendor and obtaining results. 11. Complete AI Impact Assessment. Agencies must complete an AI impact assessment before deploying any high-impact AI use case. These assessments must be updated periodically and throughout the AI' s lifecycle, as appropriate, using target variables that anticipate real-world outcomes. The AI impact assessments must be documented and address or include, at a minimum: A. the intended purpose for the AI and its expected benefit, supported by specific metrics or qualitative analysis, assessing impact inclusive of but not limited to costs, customer experience, or expected positive outcomes of AI use, as compared to existing agency processes; B. the quality and appropriateness ofthe relevant data and model capability, supported by a summary of the data used in the AI' s design, development, training, testing, and operation and its fitness for the AI' s intended purpose; describe the data collection, and preparation process; and indicate whether the data is to be publicly disclosed as an open government data asset. When applicable, this summary must describe information included in the data about classes protected by Federal nondiscrimination laws; C. the potential impacts ofusing AI, supported by documentation on potential impacts on the privacy, civil rights, and civil liberties of the public, and of using or not using AI."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_48",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\ndata is to be publicly disclosed as an open government data asset. When applicable, this summary must describe information included in the data about classes protected by Federal nondiscrimination laws; C. the potential impacts ofusing AI, supported by documentation on potential impacts on the privacy, civil rights, and civil liberties of the public, and of using or not using AI. The assessment should reference privacy impact assessments, CAIO-approved minimum risk management practice waivers or other materials, if relevant, and also describe any planned mitigation measures for anticipated negative impacts, such as unlawful discrimination; 30 D. reassessment scheduling andprocedures, supported by schedules for periodic reassessments as well as reassessment requirements following significant modifications to an underlying AI system, in addition to the specific requirements and processes for such testing; E. related costs analysis, supported by a summary of direct costs associated and expected savings, if any; F. results ofindependent review, supported by an independent reviewer within the agency who has not been involved in the development. The independent reviewer of the impact assessment shall identify any potential concerns or gaps. Any comments provided by the independent reviewer must be included in the impact assessment documentation and shared with the individual accepting the risk for the AI use case when that determination is made; and 30 Pub. L. No."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_49",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nwho has not been involved in the development. The independent reviewer of the impact assessment shall identify any potential concerns or gaps. Any comments provided by the independent reviewer must be included in the impact assessment documentation and shared with the individual accepting the risk for the AI use case when that determination is made; and 30 Pub. L. No. 107-347, § 208 and 0MB Memorandum M-03-22, 0MB Guidance for Implementing the Privacy Provisions ofthe £-Government Act of2002, https://bidenwhitehouse.archives.gov /wp- content/uploads /legacy drupal files/omb/memoranda/2003 /m03 22.pdf. 16 G. risk acceptance, supported by a signature from the individual accepting the risk. 111. Conduct Ongoing Monitoring for Performance and Potential Adverse Impacts. Agencies must conduct testing and periodic human review of AI use cases, where feasible, to identify any adverse impacts to the performance and security of AI functionality, including those that may violate laws governing privacy, civil rights, or civil liberties. Ongoing monitoring must be designed to detect unforeseen circumstances, changes to an AI system after deployment, or changes to the context of use or associated data. Agencies must implement appropriate mitigations and ensure proper system and use documentation; and where possible, develop processes enabling traceability and transparency in this evaluation. 1v. Ensure Adequate Human Training and Assessment."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_50",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nor civil liberties. Ongoing monitoring must be designed to detect unforeseen circumstances, changes to an AI system after deployment, or changes to the context of use or associated data. Agencies must implement appropriate mitigations and ensure proper system and use documentation; and where possible, develop processes enabling traceability and transparency in this evaluation. 1v. Ensure Adequate Human Training and Assessment. Agencies must ensure there is sufficient and periodic training, assessment, and oversight for operators of AI to interpret and act on the AI' s output and manage associated risks. Training should be conducted on a periodic basis, as determined by the agency, and should be specific to the AI system or service being operated and how it is being used. v. Provide Additional Human Oversight, Intervention, and Accountability. Agencies must ensure human oversight, intervention, and accountability suitable for high-impact use cases. When practicable and consistent with existing agency practices, agencies must ensure that the AI functionality has an appropriate fail-safe that minimizes the risk of significant harm. 31 v1. Offer Consistent Remedies or Appeals. Agencies must ensure that individuals affected by AI-enabled decisions have access to a timely human review and a chance to appeal any negative impacts, when appropriate."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_51",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\ncases. When practicable and consistent with existing agency practices, agencies must ensure that the AI functionality has an appropriate fail-safe that minimizes the risk of significant harm. 31 v1. Offer Consistent Remedies or Appeals. Agencies must ensure that individuals affected by AI-enabled decisions have access to a timely human review and a chance to appeal any negative impacts, when appropriate. If an agency already has an appeals or human review process in place, such as appeals of adverse actions, it may extend or adapt that process to cover decisions made with AI, consistent with applicable law. Any remedy process should be designed to avoid placing unnecessary burdens on the individual and should follow established guidance for minimizing administrative burdens. v11. Consult and Incorporate Feedback from End Users and the Public. Agencies must provide an option for end users and the public to submit feedback on the use case, where appropriate, in the design, development, and use ofthe AI and use such feedback to inform agency decision-making regarding the AI (refer to Section 8 of this memorandum). 31 For example, an AI-enabled safety mechanism may require an immediate and automated action to prevent a harm from occurring. It would not be practicable in this case to require human intervention to approve the activation of the safety mechanism. However, agencies must still determine the appropriate oversight and accountability processes for such a use of AI. 17 5."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_52",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nmemorandum). 31 For example, an AI-enabled safety mechanism may require an immediate and automated action to prevent a harm from occurring. It would not be practicable in this case to require human intervention to approve the activation of the safety mechanism. However, agencies must still determine the appropriate oversight and accountability processes for such a use of AI. 17 5. DEFINITIONS The below definitions apply for the purposes of this memorandum. Agency: The term \"agency\" has the meaning provided in 44 U.S.C. § 3502(1). Artificial Intelligence (AI): The term \"artificial intelligence \" has the meaning provided in Section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019.32 For the purposes of this memorandum, the following technical context should guide interpretation of the definition above: 1. This definition of AI encompasses, but is not limited to, the AI technical subfields of machine learning (including deep learning as well as supervised, unsupervised , and semi­ supervised approaches), reinforcement learning, transfer learning, and generative AI. 2. This definition of AI does not include robotic process automation or other systems whose behavior is defined only by human-defined rules or that learn solely by repeating an observed practice exactly as it was conducted. 3."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_53",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nof machine learning (including deep learning as well as supervised, unsupervised , and semi­ supervised approaches), reinforcement learning, transfer learning, and generative AI. 2. This definition of AI does not include robotic process automation or other systems whose behavior is defined only by human-defined rules or that learn solely by repeating an observed practice exactly as it was conducted. 3. For this definition, no system should be considered too simple to qualify as covered AI due to a lack of technical complexity (e.g., the smaller number of parameters in a model, the type of model, or the amount of data used for training purposes). 4. This definition includes systems that are fully autonomous, partially autonomous, and not autonomous , and it includes systems that operate both with and without human oversight. AI and AI-Enabling Roles: The term \"AI and AI-enabling roles\" refers to positions whose major duties include contributions that are important for successful and responsible AI outcomes."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_54",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nof data used for training purposes). 4. This definition includes systems that are fully autonomous, partially autonomous, and not autonomous , and it includes systems that operate both with and without human oversight. AI and AI-Enabling Roles: The term \"AI and AI-enabling roles\" refers to positions whose major duties include contributions that are important for successful and responsible AI outcomes. AI and AI-Enabling Roles include both technical and non-technical roles, such as data scientists, software engineers, data engineers, data governance specialists, privacy officials, statisticians , machine learning engineers, applied scientists , designers, economists , operations researchers, product managers, policy analysts, program managers, behavioral and social scientists, customer experience strategists, human resource specialists, contracting officials, managers, and attorneys. AI Maturity: The term \"AI maturity\" refers to a Federal Government organization's capacity to successfully and responsibly adopt AI into their operations and decision-making across the organization, manage its risks, and comply with relevant Federal law, regulation, and policy on AI. AI Model: The term \"AI model\" means a component of an information system that implements AI technology and uses computational, statistical, or machine-learning techniques to produce outputs from a given set of inputs."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_55",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nsuccessfully and responsibly adopt AI into their operations and decision-making across the organization, manage its risks, and comply with relevant Federal law, regulation, and policy on AI. AI Model: The term \"AI model\" means a component of an information system that implements AI technology and uses computational, statistical, or machine-learning techniques to produce outputs from a given set of inputs. AI System: The term \"AI system\" has the definition provided in Section 7223 of the Advancing American AI Act, which states that \"[t]he term 'artificial intelligence system'- (A) means any 32 Pub. L. No. 115-232, § 238(g), https://www.govinfo.gov /content/pkg!PLAW-l l5publ232 /pdf/PLA W­ l 15publ232.pdf."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_56",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nand uses computational, statistical, or machine-learning techniques to produce outputs from a given set of inputs. AI System: The term \"AI system\" has the definition provided in Section 7223 of the Advancing American AI Act, which states that \"[t]he term 'artificial intelligence system'- (A) means any 32 Pub. L. No. 115-232, § 238(g), https://www.govinfo.gov /content/pkg!PLAW-l l5publ232 /pdf/PLA W­ l 15publ232.pdf. 18 data system, software, application, tool, or utility that operates in whole or in part using dynamic or static machine learning algorithms or other forms of artificial intelligence, whether- (i) the data system, software, application, tool, or utility is established primarily for the purpose of researching, developing, or implementing artificial intelligence technology; or (ii) artificial intelligence capability is integrated into another system or agency business process, operational activity, or technology system; and (B) does not include any common commercial product within which artificial intelligence is embedded, such as a word processor or map navigation system.\" Applied Research: The term \"applied research\" refers to original investigation undertaken in order to acquire new knowledge to determine the means by which a specific practical aim or objective may be met."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_57",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nactivity, or technology system; and (B) does not include any common commercial product within which artificial intelligence is embedded, such as a word processor or map navigation system.\" Applied Research: The term \"applied research\" refers to original investigation undertaken in order to acquire new knowledge to determine the means by which a specific practical aim or objective may be met. Basic Research: The term \"basic research\" refers to experimental or theoretical work undertaken primarily to acquire new knowledge of the underlying foundations of phenomena and observable facts without a specific application towards processes or products in mind. Custom-Developed Code: The term \"custom-developed code\" has the meaning provided in Appendix A of 0MB Memorandum M-16-21. Customer Experience: The term \"customer experience\" means the public's perceptions of, and overall satisfaction with, the interactions with an agency, product, or service. Data Asset: The term \"data asset\" has the meaning provided in 44 U.S.C § 3502. Federal Information: The term \"Federal information\" has the meaning provided in 0MB Circular A-130. High-Impact AI: AI with an output that serves as a principal basis for decisions or actions with legal, material, binding, or significant effect on: 1. an individual or entity's civil rights, civil liberties, or privacy; or 2. an individual or entity's access to education, housing, insurance, credit, employment, and other programs; 3."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_58",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nhas the meaning provided in 0MB Circular A-130. High-Impact AI: AI with an output that serves as a principal basis for decisions or actions with legal, material, binding, or significant effect on: 1. an individual or entity's civil rights, civil liberties, or privacy; or 2. an individual or entity's access to education, housing, insurance, credit, employment, and other programs; 3. an individual or entity's access to critical government resources or services; 4. human health and safety; 5. critical infrastructure or public safety; or 6. strategic assets or resources, including high-value property and information marked as sensitive or classified by the Federal Government. Information Technology: The term \"information technology\" has the definition given in 40 U.S.C. § 11101(6). Model Weight: The term \"model weight\" means a numerical parameter within an AI model that helps determine the model's outputs in response to inputs. 19 National Security System: The term \"National Security System\" has the meaning provided in 44 U.S.C. § 3552(b)(6). Open Government Data Asset: The term \"open government data asset\" has the meaning provided in 44 U.S.C § 3502. Open Source Software: The term \"open source software\" has the meaning provided in Appendix A ofOMB Memorandum M-16-21."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_59",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\noutputs in response to inputs. 19 National Security System: The term \"National Security System\" has the meaning provided in 44 U.S.C. § 3552(b)(6). Open Government Data Asset: The term \"open government data asset\" has the meaning provided in 44 U.S.C § 3502. Open Source Software: The term \"open source software\" has the meaning provided in Appendix A ofOMB Memorandum M-16-21. Significant Modification: The term \"significant modification\" refers to an update to an AI application or to the conditions or context in which it is used, such as through changing its functionality, underlying structure, or performance, that meaningfully alters the Al's impact, rendering prior evaluations, training, or documentation misleading to users, overseers, or individuals affected by the system. This includes significantly changing the context, scope, or intended purpose in which the AI is used. 20 6. PURPOSES FOR WHICH AI IS PRESUMED TO BE HIGH-IMPACT The following is a list of categories for which the use or expected use of AI that serves as a principal basis for an agency decision or action is presumed to be high-impact. However, the following is not an exhaustive list of potentially high-impact AI use cases and agencies should base any final decisions for whether an AI use case is high-impact on the definition provided in Section 6. a."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_60",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nuse or expected use of AI that serves as a principal basis for an agency decision or action is presumed to be high-impact. However, the following is not an exhaustive list of potentially high-impact AI use cases and agencies should base any final decisions for whether an AI use case is high-impact on the definition provided in Section 6. a. Safety-critical functions of critical infrastructure or government facilities, emergency services, fire and life safety systems within structures, food safety mechanisms, or traffic control systems and other systems controlling physical transit; b. Physical movements of robots, robotic appendages, vehicles or craft (whether land, sea, air, or underground), or industrial equipment that have the potential to cause significant injury to humans; c. Use of kinetic or non-kinetic measures for attack or active defense in real world circumstances that could cause significant injury to humans; d. Transport, safety, design, development, or use of hazardous chemicals or biological agents; e. Design, construction, or testing of equipment, systems, or public infrastructure that would pose a significant risk to safety if they failed; f. In healthcare contexts, the medically relevant functions of medical devices; patient diagnosis, risk assessment, or treatment; the allocation ofcare in the context of public insurance; or the control of health-insurance costs and underwriting; g. Control of access to, or the security of, government facilities; h."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_61",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nor public infrastructure that would pose a significant risk to safety if they failed; f. In healthcare contexts, the medically relevant functions of medical devices; patient diagnosis, risk assessment, or treatment; the allocation ofcare in the context of public insurance; or the control of health-insurance costs and underwriting; g. Control of access to, or the security of, government facilities; h. Adjudication or enforcement of sanctions, trade restrictions, or other controls on exports, investments, or shipping; 1. The blocking, removal, hiding, or limitation of the reach of protected speech; J. In law enforcement contexts, production of risk assessments about individuals; identification of criminal suspects; forecast of crime; tracking of non-governmental vehicles over time in public spaces; application of biometric identification (e.g., iris, facial, fingerprint, or gait matching); facial reconstruction based on genetic information; social media monitoring; application of digital forensic techniques; use of cyber intrusions; physical location-monitoring or tracking of individuals; detection of weapons or violent activity; or determinations related to recidivism, sentencing, parole, supervised release, probation, bail, pretrial release, or pretrial detention; k. Preparation or adjudication of risk assessments related to foreign nationals seeking temporary or permanent access to the U.S."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_62",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\ninformation; social media monitoring; application of digital forensic techniques; use of cyber intrusions; physical location-monitoring or tracking of individuals; detection of weapons or violent activity; or determinations related to recidivism, sentencing, parole, supervised release, probation, bail, pretrial release, or pretrial detention; k. Preparation or adjudication of risk assessments related to foreign nationals seeking temporary or permanent access to the U.S. or its territories including related to immigration, asylum, detention, or travel approval status; 1. Use of biometric identification for one-to-many identification in publicly accessible spaces; m. Ability to apply for, or adjudication of, requests for critical federal services, processes, and benefits to include loans and access to public housing; determination of continued eligibility for ongoing benefits; the control of access-through biometrics or other means ( e.g., signature matching)-to IT systems for accessing services for benefits; detection of fraudulent use or attempted use of government services; adjudication of penalties in the context of government benefits; 21 n. Determination of the terms or conditions of Federal employment, including pre­ employment screening, reasonable accommodation, pay or promotion, performance management, hiring or termination, or recommending disciplinary action; reassignment ofworkers to new tasks or teams; or o."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_63",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nservices for benefits; detection of fraudulent use or attempted use of government services; adjudication of penalties in the context of government benefits; 21 n. Determination of the terms or conditions of Federal employment, including pre­ employment screening, reasonable accommodation, pay or promotion, performance management, hiring or termination, or recommending disciplinary action; reassignment ofworkers to new tasks or teams; or o. Provision of language translation ( e.g., foreign translation and audiovisual translation) when responses are legally binding or for an interaction that directly informs an agency decision or action. 22 7. METHODS OF UNDERSTANDING AI RISK MANAGEMENT Below are ways in which risks may arise from the use of AI. The term \"risks from the use of AI\" refers to risks related to efficacy, safety, fairness, transparency, accountability, appropriateness, or lawfulness of a decision or action resulting from the use of AI to inform, influence, decide, or execute that decision or action. This includes such risks regardless of whether: 1. the AI merely informs the decision or action, partially automates it, or fully automates it; 2. there is or is not human oversight for the decision or action; 3. it is or is not readily apparent that a decision or action took place, such as when an AI application performs a background task or silently declines to take an action; or 4."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_64",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nmerely informs the decision or action, partially automates it, or fully automates it; 2. there is or is not human oversight for the decision or action; 3. it is or is not readily apparent that a decision or action took place, such as when an AI application performs a background task or silently declines to take an action; or 4. the humans involved in making the decision or action or that are affected by it are or are not aware ofhow or to what extent the AI influenced or automated the decision or action. The following factors can create, contribute to, or exacerbate risks from the use of AI: 1. AI outputs that are inaccurate or misleading; 2. AI outputs that are unreliable, ineffective, or not robust; 3. AI outputs that discriminate on the basis of a protected characteristic; 4. AI outputs that contribute to actions or decisions resulting in harmful or unsafe outcomes, including AI outputs that lower the barrier for people to take intentional and harmful actions; 5. AI being used for tasks to which it is poorly suited or being inappropriately repurposed in a context for which it was not intended; 6. AI being used in a context in which affected people have a reasonable expectation that a human is or should be primarily responsible for a decision or action; and 7. the adversarial evasion or manipulation of AI, as in the case of an entity purposefully inducing AI to misclassify an input."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_65",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\na context for which it was not intended; 6. AI being used in a context in which affected people have a reasonable expectation that a human is or should be primarily responsible for a decision or action; and 7. the adversarial evasion or manipulation of AI, as in the case of an entity purposefully inducing AI to misclassify an input. This definition applies to risks specifically arising from using AI and that affect the outcomes of decisions or actions. It does not include all risks associated with AI, such as risks related to the privacy, security, and confidentiality of the data used to train AI or used as inputs to AI models. 23 8. Public Consultation and Feedback To carry out public consultations and feedback processes, agencies are recommended to take appropriate steps to solicit public input, which could include: 33 1. direct usability testing, such as observing users interacting with the system; 2. general solicitations of comments from the public, such as a request for information in the Federal Register or a \"Tell Us About Your Experience\" sheet with an open-ended space for responses; 3. post-transaction customer feedback collections; 34 4. public hearings or meetings; and 5. any other transparent process that seeks public input, comments, or feedback from the affected groups in a meaningful, accessible, and effective manner."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_66",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\npublic, such as a request for information in the Federal Register or a \"Tell Us About Your Experience\" sheet with an open-ended space for responses; 3. post-transaction customer feedback collections; 34 4. public hearings or meetings; and 5. any other transparent process that seeks public input, comments, or feedback from the affected groups in a meaningful, accessible, and effective manner. 33 Agencies are encouraged to engage with 0MB on whether they are required to submit information collection requests for 0MB clearance under the Paperwork Reduction Act (44 U.S.C. § 3507), https://uscode.house.gov /view.xhtml?reg=44 +U.S.C.+%EF%BF%BD+3507&f=treesort&fg =true&num =20&hl=tru e&edition=prelim&granuleid=USC-prelim-title44-section3507 , for the purposes of these consultations and feedback processes. 34 Information on post-transaction customer feedback surveys can be found in 0MB Circular A-11, Section 280 - Managing Customer Experience and Improving Service Delivery, https://www.performance.gov /cx/assets/files/2019 all %20280.pdf. 24 Consolidated Table of Actions Each Agency Retain or designate a Chief AI Officer. 3(a)(i) Each CFO Convene relevant agency officials to coordinate 3( a)(ii) Act Agency and govern issues tied to the use of AI within the Federal Government through an agency AI Governance Board. 0MB Convene a Chief AI Officer Council, led by the 3(C)(i) Director of 0MB, or designated senior official."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_67",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nActions Each Agency Retain or designate a Chief AI Officer. 3(a)(i) Each CFO Convene relevant agency officials to coordinate 3( a)(ii) Act Agency and govern issues tied to the use of AI within the Federal Government through an agency AI Governance Board. 0MB Convene a Chief AI Officer Council, led by the 3(C)(i) Director of 0MB, or designated senior official. Each CFO Develop and release publicly an agency strategy 2(a) Act Agency for removing barriers to the use of AI and advancing agency AI maturity. Each Agency Submit to 0MB and release publicly an agency 3(b )(ii) compliance plan to achieve consistency with this memorandum, or a written determination that the agency does not use and does not anticipate using covered AI. Each Agency Update internal policies on IT infrastructure, 3(b)(iii) data, cybersecurity, and privacy. Each Agency Develop a Generative AI policy. 3(b)(iv) Each Agency * Implement the minimum risk management 4(a)(i) practices for high-impact uses of AI. Each Agency * Report directly to 0MB any determinations and 4(a)(iii) waivers that are granted or revoked. Each Agency * Publicly report determinations and waivers for 4(a)(iv) AI use cases. Each Publicly release an AI use case inventory 3(b)(v) Agency** consistent with 0MB instructions. 60 days 90 days 90 days 180 days 180 days, and every two years until 2036 270 days 270 days 365 days Annually and 30- days after significant modifications 365 days Annually * Excluding elements of the Intelligence Community."
  },
  {
    "id": "M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust_chunk_68",
    "text": "Source: 2 M-25-21-Accelerating-Federal-Use-of-AI-through-Innovation-Governance-and-Public-Trust.pdf\n\nand waivers for 4(a)(iv) AI use cases. Each Publicly release an AI use case inventory 3(b)(v) Agency** consistent with 0MB instructions. 60 days 90 days 90 days 180 days 180 days, and every two years until 2036 270 days 270 days 365 days Annually and 30- days after significant modifications 365 days Annually * Excluding elements of the Intelligence Community. ** Excluding elements of the Intelligence Community. The Department of Defense is exempt from the requirement to inventory individual use cases. 25"
  },
  {
    "id": "5_Ways_OCIO_Supports_Responsible_Artificial_Intelligence___US_Department_of_Labor_Blog_chunk_0",
    "text": "Source: 20 5 Ways OCIO Supports Responsible Artificial Intelligence _ U.S. Department of Labor Blog.pdf\n\nU.S. DEPARTMENT OF LABOR BLOG MENU 5 Ways OCIO Supports Responsible Artificial Intelligence Filed inData and Techn ology,Techn ology•By: Louis Charlier•January 19, 2024 Artificial intelligence is finding its way into more aspects of everyday life, including the way we work. This administration wants to make sure government is leading the way with President Biden’s October 2023 executive order calling for the “Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence.” It sets a whole-of-government strategy to manage the risks and harness the benefits of AI, including protecting Americans’ privacy, supporting workers, and ensuring responsible and effective government use. Under the executive order, the Labor Department is developing principles and best practices for employers and AI developers, and a report on the abilities of agencies to support workers displaced by AI, among other deliverables. Our Office of the Chief Information Officer is also responding to the executive order by coordinating the development and use of AI in our agency’s programs and operations. How is OCIO responding? We recognize AI has the power to both revolutionize the workplace and pose potential challenges. Our goal is to make sure AI in government technology helps – rather than harms – America’s workers and creates efficiency and value for our department staff who serve the public."
  },
  {
    "id": "5_Ways_OCIO_Supports_Responsible_Artificial_Intelligence___US_Department_of_Labor_Blog_chunk_1",
    "text": "Source: 20 5 Ways OCIO Supports Responsible Artificial Intelligence _ U.S. Department of Labor Blog.pdf\n\nand use of AI in our agency’s programs and operations. How is OCIO responding? We recognize AI has the power to both revolutionize the workplace and pose potential challenges. Our goal is to make sure AI in government technology helps – rather than harms – America’s workers and creates efficiency and value for our department staff who serve the public. As chief AI officer at the department, I am leading this work and collaboration with our federal agency partners. Here are five ways the department’s AI strategies align with the executive order: 1. Transparency An official website of the United States governmentHere's how you know 13/08/2025, 21:14 5 Ways OCIO Supports Responsible Artiﬁcial Intelligence | U.S. Department of Labor Blog https://blog.dol.gov/2024/01/19/5-ways-ocio-supports-responsible-artiﬁcial-intelligence 1/5 EO standard: Requiring developers of the most powerful AI systems to share their safety test results and other critical information with the U.S. government. OCIO action: Publishing the department’s AI use case inventory. We want to be transparent with the public about how we are deploying emerging technology. 2. Trust EO standard: Developing standards, tools and tests to help ensure that AI systems are safe, secure, and trustworthy. OCIO action: Partnering with a presidential fellow to create an AI Center of Excellence. We have a review process to make sure our AI products are responsible, ethical and reduce bias."
  },
  {
    "id": "5_Ways_OCIO_Supports_Responsible_Artificial_Intelligence___US_Department_of_Labor_Blog_chunk_2",
    "text": "Source: 20 5 Ways OCIO Supports Responsible Artificial Intelligence _ U.S. Department of Labor Blog.pdf\n\nthe public about how we are deploying emerging technology. 2. Trust EO standard: Developing standards, tools and tests to help ensure that AI systems are safe, secure, and trustworthy. OCIO action: Partnering with a presidential fellow to create an AI Center of Excellence. We have a review process to make sure our AI products are responsible, ethical and reduce bias. Each of our AI solutions are built to address only the issue they were created to solve. 3. Cybersecurity EO standard: Establishing an advanced cybersecurity program to develop AI tools to find and fix vulnerabilities in critical software. OCIO action: Investing to enhance cyber strength and fortify our digital infrastructure. We deploy AI and machine learning to predict, detect and prioritize cyber risks to our data and respond accordingly. 4. Privacy EO standard: Developing guidelines for federal agencies to evaluate the effectiveness of privacy-preserving techniques. OCIO action: Forming an AI advisory board. We adhere to the AI Guide for Government for responsible AI frameworks that prevent infringement on privacy or other human rights. 5. Workforce EO standard: Rapidly hiring more AI professionals. OCIO response: Taking part in a governmentwide hiring surge for AI experts. We joined a similar hiring effort in 2020 for customer experience designers. For information on opportunities, check out available IT jobs at OCIO. Where do we go in 2024?"
  },
  {
    "id": "5_Ways_OCIO_Supports_Responsible_Artificial_Intelligence___US_Department_of_Labor_Blog_chunk_3",
    "text": "Source: 20 5 Ways OCIO Supports Responsible Artificial Intelligence _ U.S. Department of Labor Blog.pdf\n\nframeworks that prevent infringement on privacy or other human rights. 5. Workforce EO standard: Rapidly hiring more AI professionals. OCIO response: Taking part in a governmentwide hiring surge for AI experts. We joined a similar hiring effort in 2020 for customer experience designers. For information on opportunities, check out available IT jobs at OCIO. Where do we go in 2024? OCIO will continue to work with our agency partners to develop, implement and maintain trustworthy AI technology to enhance productivity and better serve the public. Louis Charlier is the chief AI officer and the deputy chief information officer at the U.S. Department of Labor. Follow OCIO on LinkedIn. Tags:Office of the Chief Information Officer (OCIO), Artificial Intelligence (AI), information technology (IT), emerging technology (innovation) SHARE THIS: Black History and Labor History – Test Your KnowledgeBlack History and Labor History – Test Your Knowledge 13/08/2025, 21:14 5 Ways OCIO Supports Responsible Artiﬁcial Intelligence | U.S. Department of Labor Blog https://blog.dol.gov/2024/01/19/5-ways-ocio-supports-responsible-artiﬁcial-intelligence 2/5 RELATED POSTS MOR E FROM AUTHOR Scroll to top Making Artificial Intelligence Work for Workers A New Investment to Enhance Cyber Strength A Year of Innovation Supporting America’s Workers Making the Grade in IT Modernization Stay Connected! Sign up to receive Department of Labor updates."
  },
  {
    "id": "5_Ways_OCIO_Supports_Responsible_Artificial_Intelligence___US_Department_of_Labor_Blog_chunk_4",
    "text": "Source: 20 5 Ways OCIO Supports Responsible Artificial Intelligence _ U.S. Department of Labor Blog.pdf\n\n5 Ways OCIO Supports Responsible Artiﬁcial Intelligence | U.S. Department of Labor Blog https://blog.dol.gov/2024/01/19/5-ways-ocio-supports-responsible-artiﬁcial-intelligence 2/5 RELATED POSTS MOR E FROM AUTHOR Scroll to top Making Artificial Intelligence Work for Workers A New Investment to Enhance Cyber Strength A Year of Innovation Supporting America’s Workers Making the Grade in IT Modernization Stay Connected! Sign up to receive Department of Labor updates. Email Address SUBSCRIBE Agencies Forms Guidance Search FAQ About DOL News Contact Us FEDERAL GOVERNMENT White House Benefits.gov Coronavirus Resources Disaster Recovery Assistance13/08/2025, 21:14 5 Ways OCIO Supports Responsible Artiﬁcial Intelligence | U.S. Department of Labor Blog https://blog.dol.gov/2024/01/19/5-ways-ocio-supports-responsible-artiﬁcial-intelligence 3/5 DisasterAssistance.gov USA.gov Notification of EEO Violations No Fear Act Data U.S. Office of Special Counsel LABOR DEPARTMENT About DOL Guidance Search Español Office of Inspector General Subscribe to the DOL Newsletter Read the DOL Newsletter Emergency Accountability Status Link A to Z Index ABOUT THE SITE Freedom of Information Act Disclaimers Plug-Ins Used on DOL.gov Accessibility Statement U.S. DEP ARTMENT OF LABOR 200 Constitution Ave NW Washington, DC 20210 1-866-4-USA-DOL 1-866-487-2365 www.dol.gov Connect With DOL13/08/2025, 21:14 5 Ways OCIO Supports Responsible Artiﬁcial Intelligence | U.S."
  },
  {
    "id": "5_Ways_OCIO_Supports_Responsible_Artificial_Intelligence___US_Department_of_Labor_Blog_chunk_5",
    "text": "Source: 20 5 Ways OCIO Supports Responsible Artificial Intelligence _ U.S. Department of Labor Blog.pdf\n\nGeneral Subscribe to the DOL Newsletter Read the DOL Newsletter Emergency Accountability Status Link A to Z Index ABOUT THE SITE Freedom of Information Act Disclaimers Plug-Ins Used on DOL.gov Accessibility Statement U.S. DEP ARTMENT OF LABOR 200 Constitution Ave NW Washington, DC 20210 1-866-4-USA-DOL 1-866-487-2365 www.dol.gov Connect With DOL13/08/2025, 21:14 5 Ways OCIO Supports Responsible Artiﬁcial Intelligence | U.S. Department of Labor Blog https://blog.dol.gov/2024/01/19/5-ways-ocio-supports-responsible-artiﬁcial-intelligence 4/5 Site Map Important W ebsite Notices Privacy & Security Statement13/08/2025, 21:14 5 Ways OCIO Supports Responsible Artiﬁcial Intelligence | U.S. Department of Labor Blog https://blog.dol.gov/2024/01/19/5-ways-ocio-supports-responsible-artiﬁcial-intelligence 5/5"
  },
  {
    "id": "Removing_Barriers_to_American_Leadership_in_Artificial_Intelligence_The_White_House_chunk_0",
    "text": "Source: 3 Removing Barriers to American Leadership in Artificial Intelligence – The White House.pdf\n\nPRESIDENTIAL ACTIONS REMOVING BARRIERS TO AMERICAN LEADERSHIP IN ARTIFICIAL INTELLIGENCE The White House January 23, 2025 By the authority vested in me as President by the Constitution and the laws of the United States of America, it is hereby ordered as follows: Section 1. Purpose. The United States has long been at the forefront of artificial intelligence (AI) innovation, driven by the strength of our free markets, world-class research institutions, and entrepreneurial spirit. To maintain this leadership, we must develop AI systems that are free from ideological bias or engineered social agendas. W ith the right Government policies, we can solidify our position as the global leader in AI and secure a brighter future for all Americans. This order revokes certain existing AI policies and directives that act as barriers to American AI innovation, clearing a path for the United States to act decisively to retain global leadership in artificial intelligence. Sec. 2. Policy. It is the policy of the United States to sustain and enhance America’s global AI dominance in order to promote human flourishing, economic competitiveness, and national security. Sec. 3. Definition. For the purposes of this order, “artificial intelligence” or “AI” has the meaning set forth in 15 U.S.C. 9401(3). Sec. 4. Developing an Artificial Intelligence Action Plan."
  },
  {
    "id": "Removing_Barriers_to_American_Leadership_in_Artificial_Intelligence_The_White_House_chunk_1",
    "text": "Source: 3 Removing Barriers to American Leadership in Artificial Intelligence – The White House.pdf\n\nSec. 2. Policy. It is the policy of the United States to sustain and enhance America’s global AI dominance in order to promote human flourishing, economic competitiveness, and national security. Sec. 3. Definition. For the purposes of this order, “artificial intelligence” or “AI” has the meaning set forth in 15 U.S.C. 9401(3). Sec. 4. Developing an Artificial Intelligence Action Plan. (a) W ithin 180 days of this order, the Assistant to the President for Science and Technology (APST), the SpecialTheWHITE HOUSE13/08/2025, 21:12 Removing Barriers to American Leadership in Artiﬁcial Intelligence – The White House https://www.whitehouse.gov/presidential-actions/2025/01/removing-barriers-to-american-leadership-in-artiﬁcial-intelligence/ 1/4 Advisor for AI and Crypto, and the Assistant to the President for National Security Affairs (APNSA), in coordination with the Assistant to the President for Economic Policy, the Assistant to the President for Domestic Policy, the Director of the Office of Management and Budget (OMB Director), and the heads of such executive departments and agencies (agencies) as the APST and APNSA deem relevant, shall develop and submit to the President an action plan to achieve the policy set forth in section 2 of this order. Sec. 5. Implementation of Order Revocation."
  },
  {
    "id": "Removing_Barriers_to_American_Leadership_in_Artificial_Intelligence_The_White_House_chunk_2",
    "text": "Source: 3 Removing Barriers to American Leadership in Artificial Intelligence – The White House.pdf\n\nPresident for Domestic Policy, the Director of the Office of Management and Budget (OMB Director), and the heads of such executive departments and agencies (agencies) as the APST and APNSA deem relevant, shall develop and submit to the President an action plan to achieve the policy set forth in section 2 of this order. Sec. 5. Implementation of Order Revocation. (a) The APST, the Special Advisor for AI and Crypto, and the APNSA shall immediately review, in coordination with the heads of all agencies as they deem relevant, all policies, directives, regulations, orders, and other actions taken pursuant to the revoked Executive Order 14110 of October 30, 2023 (Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence). The APST, the Special Advisor for AI and Crypto, and the APNSA shall, in coordination with the heads of relevant agencies, identify any actions taken pursuant to Executive Order 14110 that are or may be inconsistent with, or present obstacles to, the policy set forth in section 2 of this order. For any such agency actions identified, the heads of agencies shall, as appropriate and consistent with applicable law, suspend, revise, or rescind such actions, or propose suspending, revising, or rescinding such actions."
  },
  {
    "id": "Removing_Barriers_to_American_Leadership_in_Artificial_Intelligence_The_White_House_chunk_3",
    "text": "Source: 3 Removing Barriers to American Leadership in Artificial Intelligence – The White House.pdf\n\nactions taken pursuant to Executive Order 14110 that are or may be inconsistent with, or present obstacles to, the policy set forth in section 2 of this order. For any such agency actions identified, the heads of agencies shall, as appropriate and consistent with applicable law, suspend, revise, or rescind such actions, or propose suspending, revising, or rescinding such actions. If in any case such suspension, revision, or rescission cannot be finalized immediately, the APST and the heads of agencies shall promptly take steps to provide all available exemptions authorized by any such orders, rules, regulations, guidelines, or policies, as appropriate and consistent with applicable law, until such action can be finalized. (b) W ithin 60 days of this order, the OMB Director, in coordination with the APST, shall revise OMB Memoranda M-24-10 and M-24-18 as necessary to make them consistent with the policy set forth in section 2 of this order. Sec. 6. General Provisions. (a) Nothing in this order shall be construed to impair or otherwise affect: (i) the authority granted by law to an executive department or agency, or the head thereof; or (ii) the functions of the Director of the Office of Management and Budget relating to budgetary, administrative, or legislative proposals. (b) This order shall be implemented consistent with applicable law and subject to the availability of appropriations."
  },
  {
    "id": "Removing_Barriers_to_American_Leadership_in_Artificial_Intelligence_The_White_House_chunk_4",
    "text": "Source: 3 Removing Barriers to American Leadership in Artificial Intelligence – The White House.pdf\n\nconstrued to impair or otherwise affect: (i) the authority granted by law to an executive department or agency, or the head thereof; or (ii) the functions of the Director of the Office of Management and Budget relating to budgetary, administrative, or legislative proposals. (b) This order shall be implemented consistent with applicable law and subject to the availability of appropriations. (c) This order is not intended to, and does not, create any right or benefit, substantive13/08/2025, 21:12 Removing Barriers to American Leadership in Artiﬁcial Intelligence – The White House https://www.whitehouse.gov/presidential-actions/2025/01/removing-barriers-to-american-leadership-in-artiﬁcial-intelligence/ 2/4 or procedural, enforceable at law or in equity by any party against the United States, its departments, agencies, or entities, its officers, employees, or agents, or any other person. THE W HITE HOUSE, January 23, 2025."
  },
  {
    "id": "Removing_Barriers_to_American_Leadership_in_Artificial_Intelligence_The_White_House_chunk_5",
    "text": "Source: 3 Removing Barriers to American Leadership in Artificial Intelligence – The White House.pdf\n\nand does not, create any right or benefit, substantive13/08/2025, 21:12 Removing Barriers to American Leadership in Artiﬁcial Intelligence – The White House https://www.whitehouse.gov/presidential-actions/2025/01/removing-barriers-to-american-leadership-in-artiﬁcial-intelligence/ 2/4 or procedural, enforceable at law or in equity by any party against the United States, its departments, agencies, or entities, its officers, employees, or agents, or any other person. THE W HITE HOUSE, January 23, 2025. NEWS ADMINISTRATION ISSUES CONTACT EOP VISIT GALLERY VIDEO LIBRARY AMERICA 250 FOUNDING FATHERS Subscribe to The White House newsletter Your em ail SIG N U P Text POTUS to 45470 to receive updates13/08/2025, 21:12 Removing Barriers to American Leadership in Artiﬁcial Intelligence – The White House https://www.whitehouse.gov/presidential-actions/2025/01/removing-barriers-to-american-leadership-in-artiﬁcial-intelligence/ 3/4 THE WHITE HOUSE 1600 Pennsylvania Ave NW Washington, DC 20500 WH.GOV Copyright Privacy13/08/2025, 21:12 Removing Barriers to American Leadership in Artiﬁcial Intelligence – The White House https://www.whitehouse.gov/presidential-actions/2025/01/removing-barriers-to-american-leadership-in-artiﬁcial-intelligence/ 4/4"
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_0",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nUnited States Department of Agriculture Fiscal Year 2025–2026 AI Strategy BMessage from the Secretary of Agriculture ............................................................................................................ i Message from the USDA Chief Data and AI Officer ............................................................................................. ii Introduction ........................................................................................................................................................................... 1 Vision Statement ................................................................................................................................................................ 2 Vision, Goals, and Objectives ......................................................................................................................................... 3 Go al 1: AI Governance and Leadership ................................................................................................................ 4 Go al 2: Workforce Readiness for AI ..................................................................................................................... 5 Go al 3: AI Infrastructure and Toolset .................................................................................................................."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_1",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nAI Strategy BMessage from the Secretary of Agriculture ............................................................................................................ i Message from the USDA Chief Data and AI Officer ............................................................................................. ii Introduction ........................................................................................................................................................................... 1 Vision Statement ................................................................................................................................................................ 2 Vision, Goals, and Objectives ......................................................................................................................................... 3 Go al 1: AI Governance and Leadership ................................................................................................................ 4 Go al 2: Workforce Readiness for AI ..................................................................................................................... 5 Go al 3: AI Infrastructure and Toolset .................................................................................................................. 7 Go al 4: Data Readiness and Access ....................................................................................................................."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_2",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\ni Message from the USDA Chief Data and AI Officer ............................................................................................. ii Introduction ........................................................................................................................................................................... 1 Vision Statement ................................................................................................................................................................ 2 Vision, Goals, and Objectives ......................................................................................................................................... 3 Go al 1: AI Governance and Leadership ................................................................................................................ 4 Go al 2: Workforce Readiness for AI ..................................................................................................................... 5 Go al 3: AI Infrastructure and Toolset .................................................................................................................. 7 Go al 4: Data Readiness and Access ..................................................................................................................... 9 Go al 5: Ethical, Equitable, and Responsible Use of AI ................................................................................."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_3",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nIntroduction ........................................................................................................................................................................... 1 Vision Statement ................................................................................................................................................................ 2 Vision, Goals, and Objectives ......................................................................................................................................... 3 Go al 1: AI Governance and Leadership ................................................................................................................ 4 Go al 2: Workforce Readiness for AI ..................................................................................................................... 5 Go al 3: AI Infrastructure and Toolset .................................................................................................................. 7 Go al 4: Data Readiness and Access ..................................................................................................................... 9 Go al 5: Ethical, Equitable, and Responsible Use of AI ................................................................................. 11 Conclusion ..........................................................................................................................................................................."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_4",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nVision Statement ................................................................................................................................................................ 2 Vision, Goals, and Objectives ......................................................................................................................................... 3 Go al 1: AI Governance and Leadership ................................................................................................................ 4 Go al 2: Workforce Readiness for AI ..................................................................................................................... 5 Go al 3: AI Infrastructure and Toolset .................................................................................................................. 7 Go al 4: Data Readiness and Access ..................................................................................................................... 9 Go al 5: Ethical, Equitable, and Responsible Use of AI ................................................................................. 11 Conclusion ........................................................................................................................................................................... 13 Acknowledgments ..........................................................................................................................................................."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_5",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\n2 Vision, Goals, and Objectives ......................................................................................................................................... 3 Go al 1: AI Governance and Leadership ................................................................................................................ 4 Go al 2: Workforce Readiness for AI ..................................................................................................................... 5 Go al 3: AI Infrastructure and Toolset .................................................................................................................. 7 Go al 4: Data Readiness and Access ..................................................................................................................... 9 Go al 5: Ethical, Equitable, and Responsible Use of AI ................................................................................. 11 Conclusion ........................................................................................................................................................................... 13 Acknowledgments ........................................................................................................................................................... 14 Contact Information and Accessibility ...................................................................................................................."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_6",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\n3 Go al 1: AI Governance and Leadership ................................................................................................................ 4 Go al 2: Workforce Readiness for AI ..................................................................................................................... 5 Go al 3: AI Infrastructure and Toolset .................................................................................................................. 7 Go al 4: Data Readiness and Access ..................................................................................................................... 9 Go al 5: Ethical, Equitable, and Responsible Use of AI ................................................................................. 11 Conclusion ........................................................................................................................................................................... 13 Acknowledgments ........................................................................................................................................................... 14 Contact Information and Accessibility .................................................................................................................... 15 Appendix .............................................................................................................................................................................. 16Contents ii“The U.S."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_7",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nand Leadership ................................................................................................................ 4 Go al 2: Workforce Readiness for AI ..................................................................................................................... 5 Go al 3: AI Infrastructure and Toolset .................................................................................................................. 7 Go al 4: Data Readiness and Access ..................................................................................................................... 9 Go al 5: Ethical, Equitable, and Responsible Use of AI ................................................................................. 11 Conclusion ........................................................................................................................................................................... 13 Acknowledgments ........................................................................................................................................................... 14 Contact Information and Accessibility .................................................................................................................... 15 Appendix .............................................................................................................................................................................. 16Contents ii“The U.S. Department of Agriculture and the agriculture sector in the United States have long embraced technology and the opportunities it can provide to produce more with less, helping us feed, fuel, and clothe a growing global population."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_8",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nand Responsible Use of AI ................................................................................. 11 Conclusion ........................................................................................................................................................................... 13 Acknowledgments ........................................................................................................................................................... 14 Contact Information and Accessibility .................................................................................................................... 15 Appendix .............................................................................................................................................................................. 16Contents ii“The U.S. Department of Agriculture and the agriculture sector in the United States have long embraced technology and the opportunities it can provide to produce more with less, helping us feed, fuel, and clothe a growing global population. From biotechnology to precision agriculture, these advancements allow our farmers, ranchers, and producers to remain the standard for high-quality, safe, and nutritious food. At the Department, we simultaneously use new technologies to find ways to be more efficient in our work for the American people, be they farmers, consumers, or residents of rural communities. That is why I am proud to announce the U.S."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_9",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nagriculture, these advancements allow our farmers, ranchers, and producers to remain the standard for high-quality, safe, and nutritious food. At the Department, we simultaneously use new technologies to find ways to be more efficient in our work for the American people, be they farmers, consumers, or residents of rural communities. That is why I am proud to announce the U.S. Department of Agriculture’s first comprehensive strategy for integrating artificial intelligence (AI) to advance our mission of ensuring the health, safety, and prosperity of American agriculture. This document, guided by President Biden’s leadership, and the Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence, will build the foundation for USDA to meaningfully enhance our artificial intelligence capabilities, infrastructure, and workforce. At the heart of our strategy is a commitment to transparency, ethics, and accountability. We recognize the transformative potential of AI, but most importantly, we also understand the importance of using it responsibly. Therefore, our AI Strategy for Fiscal Years 2025 – 2026 reflects a thoughtful, responsible, transparent, and accountable approach to harnessing cutting-edge technologies that support data-informed decision-making, improve our efficiency, and enhance our ability to serve the American people."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_10",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nethics, and accountability. We recognize the transformative potential of AI, but most importantly, we also understand the importance of using it responsibly. Therefore, our AI Strategy for Fiscal Years 2025 – 2026 reflects a thoughtful, responsible, transparent, and accountable approach to harnessing cutting-edge technologies that support data-informed decision-making, improve our efficiency, and enhance our ability to serve the American people. While USDA has responsibly used AI for some time, institutionalizing this work and charting a path forward on how we use it well is an exciting new chapter for USDA. I am confident that our responsible and purposeful use of AI will strengthen the future of American agriculture for generations to come.” Thomas J. Vilsack Secretary U.S. Department of Agriculture iiii“Our progress in advanced analytics and data- informed decision-making over the past decade demonstrates the importance of this inaugural AI Strategy, which will establish the technological and cultural infrastructure to responsibly use AI, increase employee satisfaction, and expand the impact of our mission delivery. This Strategy underpins and builds on USDA’s strategic goals as well as data, information technology (IT), and workforce strategies to ensure that our data, technology, workforce, and governance structures support responsible and effective AI use."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_11",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nAI Strategy, which will establish the technological and cultural infrastructure to responsibly use AI, increase employee satisfaction, and expand the impact of our mission delivery. This Strategy underpins and builds on USDA’s strategic goals as well as data, information technology (IT), and workforce strategies to ensure that our data, technology, workforce, and governance structures support responsible and effective AI use. USDA further commits to designing and deploying AI strategically and in ways that respect privacy, safeguard data, and minimize biases so that all stakeholders can benefit from the opportunities that AI can provide. This document could not have been created without the collaboration and invaluable inputs received from stakeholders representing every USDA Mission Area and key departmental functions including, but not limited to: data, program delivery, procurement, human resources, diversity and inclusion, cybersecurity, privacy, IT, human rights, finance, and strategic planning. Together, we have built a vision for AI at USDA that lays the foundation to explore and enhance our potential over the next two years and onwards.” Christopher Alvares Chief Data & AI Officer U.S. Department of Agriculture The U.S. Department of Agriculture (USDA) works to provide economic opportunity through innovation to help rural America thrive, to promote agricultural production to feed the nation and the world, and to preserve America’s natural resources."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_12",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nfoundation to explore and enhance our potential over the next two years and onwards.” Christopher Alvares Chief Data & AI Officer U.S. Department of Agriculture The U.S. Department of Agriculture (USDA) works to provide economic opportunity through innovation to help rural America thrive, to promote agricultural production to feed the nation and the world, and to preserve America’s natural resources. These missions and our back-end operations will all benefit from AI-driven efficiencies and insights. Our use of AI will be underpinned by the necessary infrastructure, data readiness, governance, and workforce preparedness, and most importantly measures to ensure the ethical, equitable, and responsible use of AI. At USDA, AI will have an outsized impact by: Introduction Creating operational efficiencies by using AI and generative AI (GenAI) to streamline repetitive tasks and enhance our front-line workforce’s ability to save time and focus on mission- related priorities. In particular, GenAI can streamline activities such as drafting summaries, reports, and communication materials to improve efficiency and knowledge sharing. AI will not replace our workforce, rather it will enhance and augment our workforce."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_13",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nby using AI and generative AI (GenAI) to streamline repetitive tasks and enhance our front-line workforce’s ability to save time and focus on mission- related priorities. In particular, GenAI can streamline activities such as drafting summaries, reports, and communication materials to improve efficiency and knowledge sharing. AI will not replace our workforce, rather it will enhance and augment our workforce. Leveraging our vast amounts of geospatial data and computer vision capabilities to help us explore automating the analysis of satellite, drone, and ground-level imagery to monitor crop health, forest health, predict the spread of wildfire, and assess damage from natural disasters. It can also enhance real-time surveillance to improve land use planning and assess biosecurity threats. Expanding the use of predictive analytics such as intelligent automation and machine learning to enhance agricultural production, improve food safety, increase sustainability, predict changes in crop yields, increase understanding of animal disease outbreaks, and more proactively allocate resources to mitigate the impacts of droughts, floods, or pest outbreaks. Driving data-informed agricultural policy and research, such as processing large datasets, creating actionable insights for policymaking, forecasting market trends, improving pest management, and enabling better decisions that benefit farmers and consumers alike."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_14",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nincrease sustainability, predict changes in crop yields, increase understanding of animal disease outbreaks, and more proactively allocate resources to mitigate the impacts of droughts, floods, or pest outbreaks. Driving data-informed agricultural policy and research, such as processing large datasets, creating actionable insights for policymaking, forecasting market trends, improving pest management, and enabling better decisions that benefit farmers and consumers alike. Forging stronger relationships with academia and expanding our already-strong presence at agricultural schools and universities across the country can both improve how we do business and can help us recruit the future AI workforce. Exploring AI in a semi-federated model will help us elevate expertise from across our USDA Mission Areas, offices, and programs to make USDA-wide policies stronger, and also identify when flexibility is needed for trailblazers to have room to explore and innovate within the parameters of this Strategy.This FY25–26 USDA AI Strategy is a product of consultation with hundreds of programmatic, operational, and executive stakeholders across Mission Areas and Staff Offices. Our Strategy incorporates a broad definition of AI, inclusive of advanced analytics and generative AI, and seeks to support USDA’s existing culture of innovation and data-informed decision-making by strategically integrating AI into our federated operating environment."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_15",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nStrategy.This FY25–26 USDA AI Strategy is a product of consultation with hundreds of programmatic, operational, and executive stakeholders across Mission Areas and Staff Offices. Our Strategy incorporates a broad definition of AI, inclusive of advanced analytics and generative AI, and seeks to support USDA’s existing culture of innovation and data-informed decision-making by strategically integrating AI into our federated operating environment. The goals and objectives in this document address the findings of our current state assessment and provide a clear path to responsible and effective AI adoption. In this way, the Strategy also builds on several objectives in the FY24– 26 USDA Data Strategy related to artificial intelligence, machine learning, and automated systems (for more on USDA’s definition of AI, reference “Key Definitions” in the Appendix). 1 USDA will build workforce readiness, governance, and technological infrastructure required to safely integrate AI into our mission and business delivery and more effectively distribute benefits and services internally and across the nation. Over the next two years, USDA aims to be a leader in the federal space in growing and supporting our data and AI workforce. We understand that increasing our AI maturity is a large undertaking that will not be possible without supporting top talent, engaging our employees, and using AI as a tool to allow our people to free up their time to focus on the mission."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_16",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nto be a leader in the federal space in growing and supporting our data and AI workforce. We understand that increasing our AI maturity is a large undertaking that will not be possible without supporting top talent, engaging our employees, and using AI as a tool to allow our people to free up their time to focus on the mission. USDA will empower its practitioners to use AI and GenAI effectively and safely, recognizing the power of these tools to enable our practitioners and not replace them. USDA is embarking on a two-year journey of learning and growth that will position us to make the most out of AI advancements and opportunities in the years to come. Collaboration across USDA will be the main driver to achieve our vision. We understand that AI encompasses a vast range of capabilities, and we cannot approach AI in a silo. The Chief AI Officer (CAIO) will consult closely with many communities, including but not limited to: data, IT, human resources, finance, procurement, legal, civil rights, inclusion and diversity, labor unions, agencies and programs, and more. These diverse perspectives will not only help us achieve the goals set out in this document, but they will also help ensure that our actions collectively work to the benefit of USDA’s beneficiaries and stakeholders. Similarly, external partnerships will also play a critical part in our journey."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_17",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nlegal, civil rights, inclusion and diversity, labor unions, agencies and programs, and more. These diverse perspectives will not only help us achieve the goals set out in this document, but they will also help ensure that our actions collectively work to the benefit of USDA’s beneficiaries and stakeholders. Similarly, external partnerships will also play a critical part in our journey. We will continue to work with the National Institute of Standards and Technology (NIST) to adapt frameworks; with academia to help us pressure test innovative ideas and build a pipeline of talent; and with federal, state, local, tribal, territorial government and international partners to share ideas and best practices. Together, USDA and our stakeholders will implement scalable AI systems that enhance decision-making, automate routine processes, and improve mission outcomes. USDA will leverage AI to reshape how we meet our goals and improve our operations through targeted use cases and the effective deployment of cutting-edge solutions.Vision Statement 2 FY2025 –2026 AI Strategy: Vision, Goals, and Objectives Goals and objectives USDA’s AI leadership will empower employees and provide a robust, flexible, and transparent governance framework that fosters innovation, encourages collaboration, and promotes responsible, safe, and value-added use of AI."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_18",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nmeet our goals and improve our operations through targeted use cases and the effective deployment of cutting-edge solutions.Vision Statement 2 FY2025 –2026 AI Strategy: Vision, Goals, and Objectives Goals and objectives USDA’s AI leadership will empower employees and provide a robust, flexible, and transparent governance framework that fosters innovation, encourages collaboration, and promotes responsible, safe, and value-added use of AI. OBJECTIVES : 1.1: Mature USDA’s AI governance and leadership structures, empo wer Mission Area ACAIOs, and clearly define AI policies, roles, and r esponsibilities across the enterprise. 1.2: De termine the appropriate level of oversight for AI use cases and t ools across their entire lifecycle while encouraging experimentation. 1.3: Collaborate with governmental, academic, and private sector p artners to ensure the best AI outcomes.USDA will strategically develop, recruit, and retain a diverse workforce with AI skills and competencies that effectively anticipate and meet current and future program needs. OBJECTIVES: 2.1: Foster a culture of innovation where human expertise remains c entral to the design, implementation, and continuous improvement o f AI technologies. 2.2: Expand our ability to recruit, empower, and retain AI-skilled pr actitioners by developing an AI talent management framework. 2.3: Promote AI learning opportunities for all employees at all skill levels."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_19",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\ncurrent and future program needs. OBJECTIVES: 2.1: Foster a culture of innovation where human expertise remains c entral to the design, implementation, and continuous improvement o f AI technologies. 2.2: Expand our ability to recruit, empower, and retain AI-skilled pr actitioners by developing an AI talent management framework. 2.3: Promote AI learning opportunities for all employees at all skill levels. 2.4: Integrate federal and department-wide AI priorities into USDA w orkforce planning efforts. USDA will adopt and adapt AI policies and risk-based frameworks that protect human rights, health, and safety and mitigate risks through transparency, accountability, and inclusivity. OBJECTIVES: 5.1: Ensure proper risk frameworks and human oversight are in place across the AI lifecycle to evaluate and mitigate potential bias and undesirable outcomes. 5.2: Monitor industry developments and vendors’ use of AI to prevent improper use and ensure federal and departmental policy compliance. 5.3: Partner with stakeholders to create feedback loops, leverage cutting-edge tools, and continually improve our use of AI.USDA will promote and develop secure and scalable infrastructure and tools that encourage trustworthy, high-impact, and innovative AI use. OBJECTIVES : 3.1: E xpand a common infrastructure and toolset, including the USDA AI L ab, to enable mission-focused and high-impact AI use cases."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_20",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\n5.3: Partner with stakeholders to create feedback loops, leverage cutting-edge tools, and continually improve our use of AI.USDA will promote and develop secure and scalable infrastructure and tools that encourage trustworthy, high-impact, and innovative AI use. OBJECTIVES : 3.1: E xpand a common infrastructure and toolset, including the USDA AI L ab, to enable mission-focused and high-impact AI use cases. 3.2: Establish robust AI infrastructure standards that promote responsible, s afe, innovative, and secure use of AI. 3.3: Prioritize investments in infrastructure, tools, prototypes, and AI so lutions that have the executive support, funding, and resources needed t o be successful across their lifecycle.USDA will ensure data readiness and access for AI by providing clear guidance on data stewardship, supporting timely and effective data usage, and building confidence in AI outputs. OBJECTIVES: 4.1: Invest in data management practices to support AI readiness, unlock e xperimentation, and provide confidence in AI outcomes. 4.2: Make our data more accessible to promote in-house AI exploration whi le maintaining robust data protections."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_21",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nand access for AI by providing clear guidance on data stewardship, supporting timely and effective data usage, and building confidence in AI outputs. OBJECTIVES: 4.1: Invest in data management practices to support AI readiness, unlock e xperimentation, and provide confidence in AI outcomes. 4.2: Make our data more accessible to promote in-house AI exploration whi le maintaining robust data protections. 4.3: Prio ritize data rights, quality, and accessibility throughout the pr ocurement lifecycle for AI capabilities.vision USDA will build workforce readiness, governance, and technological infrastructure required to safely integrate AI into our mission and business delivery and more effectively distribute benefits and services internally and across the nation. 1. AI Governance and Leadership 2. Workforce Readiness for AI 5. Ethical, Equitable, and Responsible Use of AI 3. AI Infrastructure and Toolset 4. Data Readiness and Access 3 USDA’s AI leadership will empower employees and provide a robust, flexible, and transparent governance framework that fosters innovation, encourages collaboration, and promotes responsible, safe, and value-added use of AI. Goal 1: AI Governance and Leadership Over the next two years, USDA’s empowered AI leaders and governance bodies will oversee our progress towards the AI vision mapped in this Strategy."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_22",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\n3 USDA’s AI leadership will empower employees and provide a robust, flexible, and transparent governance framework that fosters innovation, encourages collaboration, and promotes responsible, safe, and value-added use of AI. Goal 1: AI Governance and Leadership Over the next two years, USDA’s empowered AI leaders and governance bodies will oversee our progress towards the AI vision mapped in this Strategy. They will lay the foundation for USDA’s long-term use of AI to gain operational and mission delivery enhancements and spearhead collaborative partnerships to achieve this vision. USDA’s AI work aligns to our existing strategies such as the USDA Strategic Plan , USDA Data Strategy , USDA Science and Research Strategy , USDA IT Strategic Plan , IT Workforce Strategic Plan , and Digital First policy from OMB . USDA has already made significant headway in building a resilient, responsive, and strong foundation for AI governance, including appointing a Chief AI Officer (CAIO), establishing the USDA AI Council, and launching the USDA Generative AI Review Board (GAIRB). Continuing to formalize and mature USDA’s AI leadership and governance structures will support the development and deployment of effective and responsible AI use. Led by the CAIO, USDA will coordinate efforts to mature governance processes across all levels of the Department that keep pace with the evolving technology landscape."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_23",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nAI Council, and launching the USDA Generative AI Review Board (GAIRB). Continuing to formalize and mature USDA’s AI leadership and governance structures will support the development and deployment of effective and responsible AI use. Led by the CAIO, USDA will coordinate efforts to mature governance processes across all levels of the Department that keep pace with the evolving technology landscape. The CAIO and designated AI leaders at each Mission Area will share best practices, deliver guidance, and stand up appropriate governance structures to evaluate and support current and future use of AI at USDA. AI governance standards and policies will help USDA’s workforce effectively utilize AI by clarifying expectations for AI development and deployment while enabling exploration. Our risk-based approach to AI governance will seek to balance innovation and risk mitigation, encouraging high-impact use cases and supporting compliant AI adoption. USDA will also define how leadership structures, roles, and responsibilities will cascade across the organization. AI leadership will focus on setting clear priorities, reducing redundancy in oversight structures, customizing oversight frameworks to meet the needs of their programs, and enabling implementation of AI at the Mission Area level."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_24",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nand risk mitigation, encouraging high-impact use cases and supporting compliant AI adoption. USDA will also define how leadership structures, roles, and responsibilities will cascade across the organization. AI leadership will focus on setting clear priorities, reducing redundancy in oversight structures, customizing oversight frameworks to meet the needs of their programs, and enabling implementation of AI at the Mission Area level. 4Key FY24 Accomplishments Appointed the USDA Chief AI Officer (CAIO) Established the USDA AI Council Established the USDA Generative AI Review Board (GAIRB) Evaluated and approved over a dozen Generative AI proof of concept proposalsPublished Interim Generative AI Guidance USDA’s AI leadership will empower employees and provide a robust, flexible, and transparent governance framework that fosters innovation, encourages collaboration, and promotes responsible, safe, and value-added use of AI. OBJECTIVE 1.1 Mature USDA’s AI governance and leadership structures, empower Mission Area ACAIOs, and clearly define AI policies, roles, and responsibilities across the enterprise. Key Actions: • S trengthen the pillars of our AI governance and leadership structure at the Department level: the Chief AI Officer (CAIO), the USDA AI Council, the Gener ative AI Review Board, and the USDA Chief Data Officer Council."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_25",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nAI governance and leadership structures, empower Mission Area ACAIOs, and clearly define AI policies, roles, and responsibilities across the enterprise. Key Actions: • S trengthen the pillars of our AI governance and leadership structure at the Department level: the Chief AI Officer (CAIO), the USDA AI Council, the Gener ative AI Review Board, and the USDA Chief Data Officer Council. • C ascade AI governance to the Mission Area, Staff Office, Agency, and Program levels in a way that complements unique program-specific r equirements and processes, whether that is a responsibility added to an e xisting oversight structure or a newly created oversight body. • E stablish the Assistant Chief AI Officer (ACAIO) role at the Mission Area level. • Upda te internal USDA guidance for artificial intelligence, evolve the interim g uidance on generative AI, and establish clear decision-making processes f or AI projects throughout their lifecycle. Updated guidance will encourage e xperimentation and innovation with the appropriate levels of oversight.OBJECTIVE 1.2 Determine the appropriate level of oversight for AI use cases and tools across their entire lifecycle while encouraging experimentation. Key Actions: • Depl oy a clear, risk-based evaluation framework to assess, prioritize, and tr ack AI use cases to support Department operations, strategic priorities, and mis sion delivery, in alignment with existing USDA strategies."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_26",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nthe appropriate levels of oversight.OBJECTIVE 1.2 Determine the appropriate level of oversight for AI use cases and tools across their entire lifecycle while encouraging experimentation. Key Actions: • Depl oy a clear, risk-based evaluation framework to assess, prioritize, and tr ack AI use cases to support Department operations, strategic priorities, and mis sion delivery, in alignment with existing USDA strategies. • E valuate and adopt government-wide best practices and industry standards t o meet our needs. Our framework will define which types of AI use cases need to be reviewed by which governance bodies, what evaluation is required f or off-the-shelf tools to be deployed, and what safeguards are needed for the ongoing use of AI, in alignment with Goal 5 of the AI Strategy. • T rack all applicable AI use cases in the publicly available USDA AI Inventory and develop a common approach for tracking internal R&D AI use cases to m aintain transparency and commitment to our priorities. • De velop standard requirements language to be added to every contract for the purchase of AI tools and capabilities to ensure that vendor use of AI al igns with USDA’s policies around the ethical, equitable, and responsible use o f AI, in alignment with Goal 5 of this Strategy. Goal 1: AI Governance and Leadership OBJECTIVE 1.3 Collaborate with governmental, academic, and private sector partners to ensure the best AI outcomes."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_27",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nfor the purchase of AI tools and capabilities to ensure that vendor use of AI al igns with USDA’s policies around the ethical, equitable, and responsible use o f AI, in alignment with Goal 5 of this Strategy. Goal 1: AI Governance and Leadership OBJECTIVE 1.3 Collaborate with governmental, academic, and private sector partners to ensure the best AI outcomes. Key Actions: • E xpand on our already strong and diverse partnerships with universities, no n-profits, and the private sector to leverage their expertise and knowledge and hel p us deploy the most impactful use of AI. • C ontinue to partner across federal, state, local, tribal, territorial, and i nternational governments to share lessons learned, explore fit-for-federal t echnologies, and identify policies and frameworks to promote the r esponsible use of AI. • Pr ovide clear guidance on the appropriate use of third-party AI as well as r equirements for secure handling of USDA data in partner environments to miti gate risk in a shared AI operating space. 5AI Spotlight – USDA AI Council USDA built out the USDA AI Council with broad-based membership, chaired by the Deputy Secretary, with the CAIO as Vice-Chair, and members representing every USDA Mission Area, Information Technology, Civil Rights, Diversity and Inclusion, Budget and Program Analysis, Customer Experience, Security, Technology, Finance, and Administration, pictured above."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_28",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nrisk in a shared AI operating space. 5AI Spotlight – USDA AI Council USDA built out the USDA AI Council with broad-based membership, chaired by the Deputy Secretary, with the CAIO as Vice-Chair, and members representing every USDA Mission Area, Information Technology, Civil Rights, Diversity and Inclusion, Budget and Program Analysis, Customer Experience, Security, Technology, Finance, and Administration, pictured above. The USDA AI Council’s diverse members will set the direction for USDA’s AI journey.USDA AI Council Administration, Customer Experience, FinanceUSDA Leadership: Deputy Secretary, Office of Budget and Program Analysis AI Leadership: Chief AI Officer, Senior Advisor on AI Mission Area Under SecretariesCivil Rights, Diversity & InclusionInformation Security, Technology USDA will strategically develop, recruit, and retain a diverse workforce with AI skills and competencies that effectively anticipate and meet current and future program needs. USDA’s primary commitment related to artificial intelligence is to remain a government leader in empowering our workforce to use AI and to keep humans in the loop of AI development, management, and use."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_29",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nSecurity, Technology USDA will strategically develop, recruit, and retain a diverse workforce with AI skills and competencies that effectively anticipate and meet current and future program needs. USDA’s primary commitment related to artificial intelligence is to remain a government leader in empowering our workforce to use AI and to keep humans in the loop of AI development, management, and use. We will prioritize investments in our AI and AI-enabling workforce aligned to the findings from (1) our department-wide AI Current State Assessment, (2) a joint CAIO, OHRM, and USDA Digital Service AI Training Needs Assessment, and (3) the FY24 Data & AI Workforce and Training Plans submitted by every USDA Mission Area and Staff Office. Our assessments identified ongoing and planned efforts related to hiring, retention, and upskilling as well as key workforce opportunities and risks associated with AI. We also identified key opportunities for cross-USDA collaboration and areas where offices need leadership support."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_30",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nAssessment, and (3) the FY24 Data & AI Workforce and Training Plans submitted by every USDA Mission Area and Staff Office. Our assessments identified ongoing and planned efforts related to hiring, retention, and upskilling as well as key workforce opportunities and risks associated with AI. We also identified key opportunities for cross-USDA collaboration and areas where offices need leadership support. Key findings and needs uncovered during the assessment and therefore prioritized in this Strategy include: offering foundational AI literacy to all USDA practitioners; expanding targeted training opportunities to upskill practitioners in research and other technical roles; creating professional development opportunities such as details and rotations for employees to gain on-the-job experience; continuing to build on the success of the USDA AI Center of Excellence (CoE) to share best practices; and clarifying policies and guidance so that all practitioners understand expectations and requirements around the use of AI."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_31",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nto upskill practitioners in research and other technical roles; creating professional development opportunities such as details and rotations for employees to gain on-the-job experience; continuing to build on the success of the USDA AI Center of Excellence (CoE) to share best practices; and clarifying policies and guidance so that all practitioners understand expectations and requirements around the use of AI. USDA has already made significant progress in promoting upskilling and shared training resources for our data workforce through initiatives like the USDA Data Science Training Program (DSTP), and we plan to build on this strong foundation to support both AI practitioners and stakeholders.Goal 2: Workforce Readiness for AI Key FY24 Accomplishments Hosted early career talent supporting key data & AI initiatives, including USDA Digital Corps and Pathways interns Issued guidance to leverage the OPM AI and AI-enabling Direct Hire Authority Delivered Responsible AI training Expanded the USDA-wide Data Science Training Program (DSTP) to over 150 practitioners and added AI topicsDesignated an AI Talent Lead within the Office of Human Resources Management (OHRM) Sponsored university data and AI hackathons Issued policy and procedural guidance on shared certificates within USDA to expedite AI hiringPartnered with Women in Data for their annual Datathon Built AI expertise in the Agricultural Research Service (ARS) through postdoctoral fellowship and graduate student internship programs as well as AI training opportunities for ARS researchers 6 7Goal 2: Workforce Readiness for AI USDA will strategically develop, recruit, and retain a diverse workforce with AI skills and competencies that effectively anticipate and meet current and future program needs."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_32",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nannual Datathon Built AI expertise in the Agricultural Research Service (ARS) through postdoctoral fellowship and graduate student internship programs as well as AI training opportunities for ARS researchers 6 7Goal 2: Workforce Readiness for AI USDA will strategically develop, recruit, and retain a diverse workforce with AI skills and competencies that effectively anticipate and meet current and future program needs. OBJECTIVE 2.1 Foster a culture of innovation where human expertise remains central to the design, implementation, and continuous improvement of AI technologies. Key Actions: • C ontinue to invest in the USDA AI Center of Excellence (CoE) to: encourage the sharing of training plans and curriculums, resources, use cases, and be st practices across the Department; gain broad-based feedback on pr oposed future trainings, policies, and priorities; and equip our practitioners t o serve as the “human in the loop” as we build and oversee the use of AI. • H ost public-facing competitions, such as hackathons, to crowd-source so lutions to USDA’s biggest challenges, along with post-competition debrie fs for internal and external audiences. • I dentify additional academic partnerships to engage with students, including via course capstones and hackathons.OBJECTIVE 2.2 Expand our ability to recruit, empower, and retain AI-skilled practitioners by developing an AI talent management framework."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_33",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\n• H ost public-facing competitions, such as hackathons, to crowd-source so lutions to USDA’s biggest challenges, along with post-competition debrie fs for internal and external audiences. • I dentify additional academic partnerships to engage with students, including via course capstones and hackathons.OBJECTIVE 2.2 Expand our ability to recruit, empower, and retain AI-skilled practitioners by developing an AI talent management framework. Key Actions: • De velop position management standards for AI and AI-enabling roles to s treamline hiring and increase the effectiveness of hiring strategies. USDA wi ll build upon recent successes, including rapid hiring of highly skilled pr actitioners, leveraging Direct Hire Authority for critical data and AI-related r oles, and using shared certificates which allow collaboration between hiring m anagers across USDA agencies. • C ontinue to focus on early career and internship programs to recruit AI talent, including expanding our participation in the General Services Administration (GSA) US Digital Corps fellowship program and continuing t o partner with the USDA Digital Service and the Office of Partnerships and P ublic Engagement (OPPE) to use Pathways, Virtual Student Federal S ervice, and other opportunities to bring early career talent to USDA. • Pr ovide more opportunities for existing USDA practitioners to learn and gr ow, including via rotational details."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_34",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nDigital Corps fellowship program and continuing t o partner with the USDA Digital Service and the Office of Partnerships and P ublic Engagement (OPPE) to use Pathways, Virtual Student Federal S ervice, and other opportunities to bring early career talent to USDA. • Pr ovide more opportunities for existing USDA practitioners to learn and gr ow, including via rotational details. We will build on the existing partnership be tween the CAIO, CTO, and Mission Areas to identify rotational detail o pportunities to increase employees’ familiarity with IT services ar chitectures, responsible AI, security, and data readiness for common AI appl ications across the Department. • De velop a mechanism to identify and track AI expertise across the Dep artment and identify and implement retention initiatives to harmonize AI ski lls with program needs.OBJECTIVE 2.3 Promote AI learning opportunities for all employees at all skill levels. Key Actions: • E xpand AI training offerings and promote learning opportunities, regardless o f skill level. The CAIO will pilot and deploy AI-related trainings for USDA empl oyees, from foundational AI literary training for the entire workforce, t o research and category-specific AI training opportunities for leadership, AI pr actitioners, and other groups critical to the AI lifecycle."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_35",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nlevels. Key Actions: • E xpand AI training offerings and promote learning opportunities, regardless o f skill level. The CAIO will pilot and deploy AI-related trainings for USDA empl oyees, from foundational AI literary training for the entire workforce, t o research and category-specific AI training opportunities for leadership, AI pr actitioners, and other groups critical to the AI lifecycle. • M ature the USDA Data Science Training Program (DSTP) to include more AI-r elated training and prepare the workforce for real-world data and AI pr ojects typically seen at USDA. AI Spotlight – Hackathons In FY24, USDA successfully sponsored hackathons with various academic institutions and internally at USDA to crowdsource solutions for pressing problems, promote skill-building for practitioners, and build a strong pipeline of eager talent. The CAIO sponsored internal hackathons at events such as the USDA Innovation Symposium to develop and upskill internal talent and focus on USDA-wide initiatives. The CAIO also sponsored external hackathons with academic institutions including Colorado State University, South Carolina State University, and Hack Midwest. The AI CoE ran several cross-agency pilots as a learning experience, and the National Agriculture Statistics Service (NASS) held several Machine Learning hackathons."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_36",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nsuch as the USDA Innovation Symposium to develop and upskill internal talent and focus on USDA-wide initiatives. The CAIO also sponsored external hackathons with academic institutions including Colorado State University, South Carolina State University, and Hack Midwest. The AI CoE ran several cross-agency pilots as a learning experience, and the National Agriculture Statistics Service (NASS) held several Machine Learning hackathons. In FY25–26, USDA plans to expand our presence and partnerships and will continue hosting hackathons and rapid prototyping events to attract bright talent to the mission as well as provide our own workforce the opportunity to work with cutting edge technology, sharpen their skills, and develop innovative solutions. OBJECTIVE 2.4 Integrate federal and department-wide AI priorities into USDA workforce planning efforts. Key Actions: • C ontinue to strengthen the partnership between the USDA CAIO, USDA Chie f Human Capital Officer, and USDA Digital Service . • Al ign with applicable policies and regulations, including Federal and US DA-wide hiring guidance and priorities on recruiting, retaining, and u pskilling AI talent. To help lead these efforts in collaboration with the CAIO, US DA designated an AI Talent Lead within the Office of Human Resources M anagement (OHRM) who will designate talent leads at each USDA Mission Ar ea to coordinate AI talent efforts."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_37",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nregulations, including Federal and US DA-wide hiring guidance and priorities on recruiting, retaining, and u pskilling AI talent. To help lead these efforts in collaboration with the CAIO, US DA designated an AI Talent Lead within the Office of Human Resources M anagement (OHRM) who will designate talent leads at each USDA Mission Ar ea to coordinate AI talent efforts. • C onsult with our employees to understand the potential impact of AI on our w ork and develop pathways to AI occupations. • De fine and refine AI and AI-enabling roles and positions as well as establish me trics and KPIs to track progress in hiring, upskilling, and retaining our AI w orkforce across USDA. USDA will promote and develop secure and scalable infrastructure and tools that encourage trustworthy, high-impact, and innovative AI use. Key FY24 Accomplishments Launched the USDA Innovation Hub and AI Lab Developed the Generative AI Innovation Adoption Pipeline Framework Invested in infrastructure and training to accelerate adoption of AI methods on SCINet’s supercomputers used by ARS and Forest Service scientistsCompleted FY24 Data & Analytics Modernization Plans across every Mission Area 8Goal 3: AI Infrastructure and Toolset USDA commits to establishing or adopting cost-effective, accessible, and flexible standards for AI infrastructure and tools."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_38",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nthe Generative AI Innovation Adoption Pipeline Framework Invested in infrastructure and training to accelerate adoption of AI methods on SCINet’s supercomputers used by ARS and Forest Service scientistsCompleted FY24 Data & Analytics Modernization Plans across every Mission Area 8Goal 3: AI Infrastructure and Toolset USDA commits to establishing or adopting cost-effective, accessible, and flexible standards for AI infrastructure and tools. We will strategically invest in infrastructure and tools that support testing and experimentation, as well as encourage the sharing of code and models to promote AI use cases beneficial to both USDA operations and mission delivery. In FY24, USDA already began to map infrastructure needs to support data and AI via the USDA Data & Analytics Modernization Plans. These plans were completed by every USDA Mission Area and by Staff Offices to understand major upcoming infrastructure investments, identify opportunities to collaborate and share costs, and help prioritize shared USDA-wide investments. Investment in shared AI infrastructure and tools will allow for AI practitioners across USDA to work and experiment in sandboxes as well as share code and best practices without the creation of expensive and duplicative architecture. USDA will continue to assess AI infrastructure needs and set standards for procuring and using AI tools that align with federal risk-based frameworks."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_39",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\ninvestments. Investment in shared AI infrastructure and tools will allow for AI practitioners across USDA to work and experiment in sandboxes as well as share code and best practices without the creation of expensive and duplicative architecture. USDA will continue to assess AI infrastructure needs and set standards for procuring and using AI tools that align with federal risk-based frameworks. In line with these standards, we will set clear requirements for sustainable AI infrastructure that is trustworthy, secure, accessible, and scalable to meet USDA’s federated needs and in alignment with unique Mission Area requirements. USDA understands that investing in infrastructure is a long-term goal that requires long- term planning to operate and maintain what we build; USDA will continue to evaluate and assess the budget landscape to ensure that our infrastructure priorities are sustainable, offer a return on investment, and are feasible within the existing funding climate. 9USDA will promote and develop secure and scalable infrastructure and tools that encourage trustworthy, high-impact, and innovative AI use. OBJECTIVE 3.1 Expand a common infrastructure and toolset, including the USDA AI Lab, to enable mission-focused and high-impact AI use cases."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_40",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nensure that our infrastructure priorities are sustainable, offer a return on investment, and are feasible within the existing funding climate. 9USDA will promote and develop secure and scalable infrastructure and tools that encourage trustworthy, high-impact, and innovative AI use. OBJECTIVE 3.1 Expand a common infrastructure and toolset, including the USDA AI Lab, to enable mission-focused and high-impact AI use cases. Key Actions: • Impl ement a semi-federated AI infrastructure where all Mission Areas and S taff Offices will have access to centralized, high-value tools and en vironments to test and innovate, while also identifying where flexibility is needed for customized tools so that trailblazers have room to explore and i nnovate within the parameters of this Strategy. USDA encompasses pr ograms with a wide range of missions, so we will also encourage flexibility f or Mission Areas to take advantage of economies of scale using USDA-wide t ools as well as to customize tools that meet their needs. • Depl oy a hub-and-spoke model to promote code sharing, pilot program de velopment, and support research and development, with the USDA AI L ab as the “hub” and with Mission Area Innovation Incubators as the “spokes”. The USDA AI Lab will provide a rapid-prototyping environment to accelerate de veloping and testing AI solutions tailored to USDA’s needs."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_41",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\ntheir needs. • Depl oy a hub-and-spoke model to promote code sharing, pilot program de velopment, and support research and development, with the USDA AI L ab as the “hub” and with Mission Area Innovation Incubators as the “spokes”. The USDA AI Lab will provide a rapid-prototyping environment to accelerate de veloping and testing AI solutions tailored to USDA’s needs. • E nhance the Enterprise Data Analytics Platform & Toolset (EDAPT) to serve a s the foundation for enterprise AI work by providing more access to curated da ta and common data and AI tools. • De velop an AI infrastructure and toolset vision that maps current and pl anned needs and provides a roadmap for AI toolset adoption across USDA. • E ncourage the use of GenAI tools and solutions in a safe and r esponsible way to promote experimentation with guardrails and oversight in place. OBJECTIVE 3.2 Establish robust AI infrastructure standards that promote responsible, safe, innovative, and secure use of AI. Key Actions: • Review NIST and other standards and risk-based frameworks to set USDA s tandards for AI use and tool requirements. • Pr ovide guidance on recommended and approved AI and GenAI tools that ac commodates a spectrum of Mission Area and Staff Office readiness and needs for AI adoption, ranging from building their own tools to implementing c ommercial off-the-shelf solutions. • M aintain an inventory of platforms and tools being used for AI so that i nvestments are not duplicated across the organization."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_42",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\non recommended and approved AI and GenAI tools that ac commodates a spectrum of Mission Area and Staff Office readiness and needs for AI adoption, ranging from building their own tools to implementing c ommercial off-the-shelf solutions. • M aintain an inventory of platforms and tools being used for AI so that i nvestments are not duplicated across the organization. • E xpand on USDA’s Generative AI Innovation Adoption Pipeline framework to enc ourage risk-based experimentation prior to deployment. • E xpand our existing cloud “policy-as-code” actions to assist in managing i nfrastructure in a federated environment. OBJECTIVE 3.3 Prioritize investments in infrastructure, tools, prototypes, and AI solutions that have the executive support, funding, and resources needed to be successful across their lifecycle. Key Actions: • Prio ritize investments that provide the best value to USDA in the long- t erm, whether they are via procurement or built in-house. Infrastructure mus t be rightsized with the necessary performance and computing power, with continuous assessment to ensure we plan for sustainable growth. • A ssess options and encourage shared investments and partnerships across US DA to bring down the total cost of ownership. • Is sue requirements for sustainable AI investments that include developing l ong-term operations and maintenance (O&M) and training plans."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_43",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nbe rightsized with the necessary performance and computing power, with continuous assessment to ensure we plan for sustainable growth. • A ssess options and encourage shared investments and partnerships across US DA to bring down the total cost of ownership. • Is sue requirements for sustainable AI investments that include developing l ong-term operations and maintenance (O&M) and training plans. The review o f AI tools and vendor support contracts will include ensuring compliance with USDA and federal risk-based frameworks and standards as well as an a ssessment for shadow AI (see Objective 5.2 for more information). Approved AI and GenAI tools will be included in an inventory that Mission Areas and S taff Offices can quickly adopt, avoiding bureaucracy and re-approvals. AI Spotlight – USDA AI Lab In 2024, USDA launched the USDA AI Lab, a common cloud environment to collaborate, share code and infrastructure, and exchange lessons learned in a safe and secure manner. The USDA AI Lab, serviced by the USDA Digital Infrastructure Services Center (DISC), is a partnership between the CAIO and the CTO. When fully matured, the AI Lab will augment our ability to test and implement innovative technologies as well as enhance our risk tolerance and risk management processes for AI."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_44",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nexchange lessons learned in a safe and secure manner. The USDA AI Lab, serviced by the USDA Digital Infrastructure Services Center (DISC), is a partnership between the CAIO and the CTO. When fully matured, the AI Lab will augment our ability to test and implement innovative technologies as well as enhance our risk tolerance and risk management processes for AI. While the AI Lab is in its early stages, early successes have shown that an incubation environment rapidly accelerates AI adoption while also reducing risks.Goal 3: AI Infrastructure and Toolset USDA will ensure data readiness and access for AI by providing clear guidance on data stewardship, supporting timely and effective data usage, and building confidence in AI outputs. Data readiness is the foundation for AI readiness. To close data readiness gaps and effectively leverage AI, we will align with the data quality commitments outlined in the USDA Data Strategy for FY2024–FY2026 and push forward on meeting the requirements of the Foundations for Evidence-Based Policymaking Act of 2018 (“Evidence Act”) . USDA will continue to develop our USDA Data Catalog and improve our data quality and data classification methods and standards. To identify Data Catalog priorities, Mission Areas and Staff Offices recently completed Metadata Management Plans and Data Quality & Measurement Management Plans in support of the USDA Data Strategy ."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_45",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nFoundations for Evidence-Based Policymaking Act of 2018 (“Evidence Act”) . USDA will continue to develop our USDA Data Catalog and improve our data quality and data classification methods and standards. To identify Data Catalog priorities, Mission Areas and Staff Offices recently completed Metadata Management Plans and Data Quality & Measurement Management Plans in support of the USDA Data Strategy . These plans included specific actions that Mission Areas are taking to establish data readiness for AI and map minimum standards with program-specific requirements for data collection, usage, sharing, and security. As we prepare our data for AI, USDA will align on data sharing and access agreements while also properly protecting USDA data. Data sharing will support our goals to innovate and increase cooperation among AI practitioners. To facilitate data sharing, we will clarify and transparently share our data access processes that protect sensitive data, especially personally identifiable information (PII), and the privacy of the public and our partners."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_46",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nwill align on data sharing and access agreements while also properly protecting USDA data. Data sharing will support our goals to innovate and increase cooperation among AI practitioners. To facilitate data sharing, we will clarify and transparently share our data access processes that protect sensitive data, especially personally identifiable information (PII), and the privacy of the public and our partners. We will continue to identify where we need to integrate evolving data quality and access standards into our contracts with vendors and external partners to specify and outline processes for data validation and improvement.Goal 4: Data Readiness and Access Key FY24 Accomplishments Publish ed the USDA Data Strategy for FY2024 –FY2026 Expanded the USDA Data CatalogThe guidance in this document will apply to every stage of the AI lifecycle – from development to staging to production environments – and the right access and quality checks must be in place across these different stages for us to have confidence in the outputs of AI. Overall, we believe that improving our data readiness and access processes will help us leverage AI to support our mission and increase trust with our stakeholders and customers."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_47",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\ndevelopment to staging to production environments – and the right access and quality checks must be in place across these different stages for us to have confidence in the outputs of AI. Overall, we believe that improving our data readiness and access processes will help us leverage AI to support our mission and increase trust with our stakeholders and customers. Completed the USDA Metadata Management Plan Completed the USDA Data Quality & Measurement Management Plan 10 11USDA will ensure data readiness and access for AI by providing clear guidance on data stewardship, supporting timely and effective data usage, and building confidence in AI outputs. OBJECTIVE 4.1 Invest in data management practices to support AI readiness, unlock experimentation, and provide confidence in AI outcomes. Key Actions: • E nsure our data is properly documented with robust logging of metadata and AI use cases in the USDA Data Catalog, our Departmental source of truth f or metadata. • De velop guidelines and criteria for data classification related to AI use cases. • E stablish metrics that help us identify anomalies and trends in the data to a ssess the relevance and fitness of data for ongoing AI projects. • C apture selected priority data lineage in our Data Catalog to promote data qual ity and transparency regarding data sources, transformations, usage, and controlled inference and derivation across AI systems and models. • E xplore the use of AI and GenAI to improve internal data management."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_48",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nto a ssess the relevance and fitness of data for ongoing AI projects. • C apture selected priority data lineage in our Data Catalog to promote data qual ity and transparency regarding data sources, transformations, usage, and controlled inference and derivation across AI systems and models. • E xplore the use of AI and GenAI to improve internal data management. • E xplore the use of third-party datasets to augment AI use cases. OBJECTIVE 4.2 Make our data more accessible to promote in-house AI exploration while maintaining robust data protections. Key Actions: • C ontinue to build the partnership between the CAIO, the Chief Information S ecurity Officer (CISO), and the Chief Privacy Officer. • S tandardize and make transparent USDA’s data sharing and access pr ocesses, in alignment with the priorities detailed in Objective 4.2 in the US DA FY24 –26 Data Strategy. • M aintain data protection standards, secure PII, and prevent USDA data from l eaking into public AI models. OBJECTIVE 4.3 Prioritize data rights, quality, and accessibility throughout the procurement lifecycle for AI capabilities. Key Actions: • R equire all contracts and vendor partnerships to adhere to USDA data ac cess, privacy, and usage policies. • S tandardize required contract language and templates that define g overnment data ownership, access rights, and usage parameters."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_49",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\neaking into public AI models. OBJECTIVE 4.3 Prioritize data rights, quality, and accessibility throughout the procurement lifecycle for AI capabilities. Key Actions: • R equire all contracts and vendor partnerships to adhere to USDA data ac cess, privacy, and usage policies. • S tandardize required contract language and templates that define g overnment data ownership, access rights, and usage parameters. • W ork with vendors to proactively disclose when their products or services uti lize generative AI, including future plans for software updates to include g enerative AI components. • C ollect lessons learned from contract outcomes to refine USDA’s required l anguage and share best practices across the AI and contracting communities a t USDA. Goal 4: Data Readiness and Access AI Spotlight – USDA Data Strategy Responsible AI is nearly impossible to deliver without a strong data program. As such, USDA’s AI journey is intertwined with its data journey. In October 2023, USDA released its second Data Strategy, covering Fiscal Years 2024 through 2026 and building on the success of the previous data strategy. With the increase in importance related to responsible and ethical deployment and use of AI, the successful execution of the USDA Data Strategy is important now more than ever. USDA will adopt and adapt AI policies and risk-based frameworks that protect human rights, health, and safety and mitigate risks through transparency, accountability, and inclusivity."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_50",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nsuccess of the previous data strategy. With the increase in importance related to responsible and ethical deployment and use of AI, the successful execution of the USDA Data Strategy is important now more than ever. USDA will adopt and adapt AI policies and risk-based frameworks that protect human rights, health, and safety and mitigate risks through transparency, accountability, and inclusivity. Key FY24 Accomplishments Served on the Federal CAIO Council working groups Set up an AI Red Team resource to assist with Generative AI deployments Adopted the MITRE AI Maturity ModelCarried out market research for ethical AI training aimed at the Generative AI Review Board and USDA leadershipUSDA is committed to the ethical, equitable, and responsible development and adoption of AI, meaning we will mitigate bias, ensure legal compliance, promote transparency, understand environmental impacts, protect data privacy, build public trust, and provide societal benefits with our AI use. Specifically, we will integrate risk management controls into AI development and adoption to minimize potential bias at each stage of the AI lifecycle. We will adapt the AI Risk Management Framework proposed by the National Institute of Standards and Technology (NIST) to meet USDA-specific needs and ensure our oversight matches the varying level of potential risks based on program or type of data. We will periodically reassess this framework to make sure we respond to the evolving technology landscape."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_51",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nof the AI lifecycle. We will adapt the AI Risk Management Framework proposed by the National Institute of Standards and Technology (NIST) to meet USDA-specific needs and ensure our oversight matches the varying level of potential risks based on program or type of data. We will periodically reassess this framework to make sure we respond to the evolving technology landscape. Additionally, we will continue to ensure compliance with federal AI Inventory requirements and identify whether any use cases are rights-impacting, safety-impacting, or both. We will promote training and best practices for the practitioners who will serve as our “humans in the loop.” We will also work with partners to provide consistent opportunities for feedback and input across the AI lifecycle, including meeting statutory requirements for state, local, tribal, and territorial (SLTT) use of artificial intelligence for public benefit administration. In addition to upskilling our federal staff and responding to feedback from our partners, we will refine and continuously update procurement guidance to ensure vendors comply with USDA’s requirements for ethics, integrity, and bias protections, especially for higher-risk AI applications like GenAI.As we scale our AI capabilities, we will simultaneously scale our risk frameworks, governance, and training to evolve with changing needs, preserve public trust in our AI use, and meet USDA’s civil rights and environmental sustainability commitments."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_52",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\ncontinuously update procurement guidance to ensure vendors comply with USDA’s requirements for ethics, integrity, and bias protections, especially for higher-risk AI applications like GenAI.As we scale our AI capabilities, we will simultaneously scale our risk frameworks, governance, and training to evolve with changing needs, preserve public trust in our AI use, and meet USDA’s civil rights and environmental sustainability commitments. Published the Framework for State, Local, Tribal, and Territorial Use of Artificial Intelligence for Public Benefit Administration Supported five USDA National Institute of Food and Agriculture (NIFA) agriculture AI Institutes to advance knowledge of trustworthy AI, invest in rural economies, expand and diversify the AI workforce, and grow human-AI collaboration via multi-stakeholder partnerships 12Goal 5: Ethical, Equitable, and Responsible Use of AI 13USDA will adopt and adapt AI policies and risk-based frameworks that protect human rights, health, and safety and mitigate risks through transparency, accountability, and inclusivity. OBJECTIVE 5.1 Ensure proper risk frameworks and human oversight are in place across the AI lifecycle to evaluate and mitigate potential bias and undesirable outcomes."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_53",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\npartnerships 12Goal 5: Ethical, Equitable, and Responsible Use of AI 13USDA will adopt and adapt AI policies and risk-based frameworks that protect human rights, health, and safety and mitigate risks through transparency, accountability, and inclusivity. OBJECTIVE 5.1 Ensure proper risk frameworks and human oversight are in place across the AI lifecycle to evaluate and mitigate potential bias and undesirable outcomes. Key Actions: • In tegrate the NIST AI Risk Management Framework into Departmental and Mis sion Area governance processes and tailor this Framework to our unique AI needs in consultation with diverse perspectives, with the understanding th at the Framework will be updated as technology and needs evolve. • Pr ovide guidance and training to staff on how to use a risk-based approach i n determining whether AI use cases meet USDA’s minimum risk management pr actices, with special consideration given to mitigating bias in models that m ay affect underserved communities. • C ollaborate with Federal agencies and SLTT stakeholders to encourage the appropriate use of AI in public benefit administration.OBJECTIVE 5.2 Monitor industry developments and vendors’ use of AI to prevent improper use and ensure federal and departmental policy compliance. Key Actions: • W ork with vendors to protect USDA data, especially PII, and proactively add ress any impacts related to ethics, integrity, and bias."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_54",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nagencies and SLTT stakeholders to encourage the appropriate use of AI in public benefit administration.OBJECTIVE 5.2 Monitor industry developments and vendors’ use of AI to prevent improper use and ensure federal and departmental policy compliance. Key Actions: • W ork with vendors to protect USDA data, especially PII, and proactively add ress any impacts related to ethics, integrity, and bias. • W ork with procurement and IT staff to incorporate standardized contract l anguage in service and supply contracts to uphold USDA AI policies. • Cr eate a process to review Generative AI in commercial software and c ontinue to update our processes and policies as needed. • E ducate contracting officers on industry developments in AI to assist with ho listic AI contract reviews and actions. • E ncourage vendors to adopt minimum standard feature sets from NIST and US DA. OBJECTIVE 5.3 Partner with stakeholders to create feedback loops, leverage cutting-edge tools, and continually improve our use of AI. Key Actions: • De velop feedback mechanisms to continuously refine our AI products with i nput from our internal and external stakeholders, including the public. • P artner with our Customer Experience community to ensure a “customer-first mi ndset” when identifying bias and inaccuracies in AI models throughout the AI l ifecycle."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_55",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\ntools, and continually improve our use of AI. Key Actions: • De velop feedback mechanisms to continuously refine our AI products with i nput from our internal and external stakeholders, including the public. • P artner with our Customer Experience community to ensure a “customer-first mi ndset” when identifying bias and inaccuracies in AI models throughout the AI l ifecycle. • E xplore the use of “bias bounties” where users hunt for errors or bias in our mo dels and report issues, thus incentivizing the inclusive and collaborative i mprovement of our AI models. • E xpand our network of internal testers to crowdsource red team reviews and i mprove our capacity for continuous testing and development. • P artner with the USDA cybersecurity community to leverage their cutting- ed ge tools and concepts for feedback and automated testing in the AI space. Goal 5: Ethical, Equitable, and Responsible Use of AI AI Spotlight – AI Use Case Inventory USDA has a long track record of developing, using, and transparently tracking AI to support our research, operations, and mission-delivery agendas. Last year, USDA included 40+ active use cases in our AI Inventory ranging from the Animal and Plant Health Inspection Service’s predictive modeling of invasive pest species to the Natural Resources Conservation Service’s water supply forecasting to the Office of the Chief Information Officer’s intelligent routing of service requests, and many more."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_56",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nto support our research, operations, and mission-delivery agendas. Last year, USDA included 40+ active use cases in our AI Inventory ranging from the Animal and Plant Health Inspection Service’s predictive modeling of invasive pest species to the Natural Resources Conservation Service’s water supply forecasting to the Office of the Chief Information Officer’s intelligent routing of service requests, and many more. The AI Center of Excellence (CoE), with active members across USDA, built out and maintains an internal site that links to the Inventory, provides USDA-specific guidance and definitions from relevant policies and pertinent executive orders, answers FAQs, and even launched an interactive internal dashboard to help users quickly identify and track AI use. 1414Our inaugural AI Strategy sets a vision to take advantage of AI opportunities and leverage the vast potential of AI to support USDA’s continued delivery of high-quality benefits and services to the American public. We are committed to AI-enabling investments because we see AI as a technology that can radically expand our mission delivery by improving both our back-end operations and customer experience."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_57",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nStrategy sets a vision to take advantage of AI opportunities and leverage the vast potential of AI to support USDA’s continued delivery of high-quality benefits and services to the American public. We are committed to AI-enabling investments because we see AI as a technology that can radically expand our mission delivery by improving both our back-end operations and customer experience. We see a future where AI continues to augment our existing analytics capabilities to optimize resource allocation, drive process improvements, and streamline data management across our programs; a future where employees can save time in repetitive tasks to focus on higher-order priorities; a future where we can more accurately predict and proactively respond to environmental and agricultural trends like disease outbreaks and wildfires. In short, we see a future where AI augments our ability to steward the resources and serve the people of this nation. While practitioners across USDA have successfully used traditional AI capabilities for many years, we are now entering an age of GenAI that requires new investment in our human and technological capacity. In response to these technological advances, our Strategy aims to provide a common vision that our AI practitioners and stakeholders can use to navigate the rapidly evolving technological landscape while safely and responsibly delivering our mission."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_58",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\ntraditional AI capabilities for many years, we are now entering an age of GenAI that requires new investment in our human and technological capacity. In response to these technological advances, our Strategy aims to provide a common vision that our AI practitioners and stakeholders can use to navigate the rapidly evolving technological landscape while safely and responsibly delivering our mission. In the coming months, we will translate the goals and objectives in this Strategy into an implementation roadmap that builds upon our recent successes. We look forward to transparently sharing our progress throughout this journey. Specifically, the USDA Chief AI Officer will work with Mission Areas to cascade this strategy down across the organization in the form of either Mission Area AI strategies or implementation roadmaps. USDA will continue empowering our AI governance structures and naming Assistant Chief AI Officers across Mission Areas and Staff Offices to lead the implementation of this strategy and initiate program-specific efforts to meet their unique needs. We will focus our efforts on ensuring practitioners have access to the governance structures, training resources, and tools they need, and have the necessary support to responsibly plan, deploy, and oversee AI use cases while mitigating bias."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_59",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nOfficers across Mission Areas and Staff Offices to lead the implementation of this strategy and initiate program-specific efforts to meet their unique needs. We will focus our efforts on ensuring practitioners have access to the governance structures, training resources, and tools they need, and have the necessary support to responsibly plan, deploy, and oversee AI use cases while mitigating bias. Specifically, we will work with the National Institute of Standards and Technology (NIST) and other federal agencies to identify best practices in responsible AI, adapt to evolving technologies and frameworks, and continue to protect our workforce and stakeholders from potential bias. To do so, we will leverage our AI Lab to test potential innovations and inform policy and procedures. We will build red teams, engage with our partners and the public to collect continuous feedback, and follow risk-based frameworks to ensure AI use cases are fit for purpose."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_60",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nand frameworks, and continue to protect our workforce and stakeholders from potential bias. To do so, we will leverage our AI Lab to test potential innovations and inform policy and procedures. We will build red teams, engage with our partners and the public to collect continuous feedback, and follow risk-based frameworks to ensure AI use cases are fit for purpose. The collaborative nature of our Strategy development and implementation plan will help us to develop a comprehensive foundation for AI at USDA, inclusive of traditional AI, advanced analytics, machine learning, and generative AI, supportive of both AI practitioners and consumers.Conclusion 15Acknowledgments This document could not have been created without the invaluable contributions and inputs from over 200 stakeholders representing every Mission Area and Departmental Administration / Staff Office, as well as unwavering support from USDA’s leadership. We would like to especially thank our 57 AI Strategy Taskforce members who worked tirelessly over the last several months to build consensus and help shape the vision for this strategy and who will play instrumental roles in ensuring its success over the next two years."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_61",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nand Departmental Administration / Staff Office, as well as unwavering support from USDA’s leadership. We would like to especially thank our 57 AI Strategy Taskforce members who worked tirelessly over the last several months to build consensus and help shape the vision for this strategy and who will play instrumental roles in ensuring its success over the next two years. CHRIS TOPHER (CHRIS) AL VARES US DA Chief Data & AI Of ficer F ATIMA TE RRY Dep uty Director, US DA Digital Service ARIANNE G ALLAGHER- WE LCHER Di rector, USDA Digital Service DONALD B ITNER III Chief Technology Of ficer JUS TIN R ONCA Food Safety and Inspection S ervice (FSIS) ACDO CHRIS R OTTLER F ood, Nutrition, and Consumer S ervices (FNCS) ACDO C YNTHIA (C YNDY) PARR R esearch, Education, and E conomics (REE) ACDO ELANGO THILL AI F arm Production and C onservation (FPAC) ACDO R AMONA C AREY N atural Resources and Environment (NRE) ACDO ORLANDO (RICH) B ACA M arketing and Regulatory Pr ograms (MRP) ACDO J ACOB (JAKE) JO UBERT Office of Human Resources M anagement (OHRM) Senior Advisor JAMES (JIM) B ARHAM R ural Development (RD ) ACDO FRE DY DIA Z US DA Deputy Chief Da ta OfficerAbby Hansen • Adrian Wright • Alan Clayborne • Amy Ngo • Ann Stapleton • Anthony Andreassi • Anthony Davis Arianne Gallagher-Welcher • Breton Wilbun • Brian Mohr • Camille Haylock • Carl Mayes • Chelsey Rogers • Chris Corder Chris Quatrano • Chris Rottler • Christopher Aston • Cynthia Parr • Dallas Selle • Daniel Coleman • David Biggins Don Bitner • Ed Messerlie • Elango Thillai • Elisabeth Grinspoon • Fatima Terry • George Lovelace • Haris Balcinovic Jacob Joubert • Jarvis Haney • Jay Sutaye • Jennifer Zwicke • Jessica Massey • Jessica Washebek • Jim Hipple Jim Shrader Karl Leckrone • Kate Kase • Katrina Tripp • Katya Noykhovich • Kayla Roach • Linda Spangler • Lisa Hastings Mandie Lee • Melissa Clough • Michelle Moore • Michelle Santiago • Nick Pallotta • Orlando Baca • Pam McGovern Pat Curry • Ramona Carey • Rick Toothman • Robert Eaton • Sarah Clore • Sarah Tomlinson • Sean May • Shaun Rolph Stephanie Blaine • Tawana Gaskins • Taylor Nelson • Zahid Chaudhryai taskforce M eMbers USDA is an equal opportunity provider, employer, and lender."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_62",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nMichelle Moore • Michelle Santiago • Nick Pallotta • Orlando Baca • Pam McGovern Pat Curry • Ramona Carey • Rick Toothman • Robert Eaton • Sarah Clore • Sarah Tomlinson • Sean May • Shaun Rolph Stephanie Blaine • Tawana Gaskins • Taylor Nelson • Zahid Chaudhryai taskforce M eMbers USDA is an equal opportunity provider, employer, and lender. | Is sued November 2024 16For more information or questions regarding this plan, please contact: askusda@usda.gov Additional copies of this Strategic Plan can be downloaded from USDA’s Web site at: www.usda.gov /ai Persons with disabilities who require alternative means of communication for program information (e.g., Braille, large print, audiotape, American Sign Language, etc.) should contact the responsible Agency or USDA’s TARGET Center at (202) 720-2600 (voice and TTY) or contact USDA through the Federal Relay Service at (800) 877-8339 .Contact Information and Accessibility Term Definition Source 17Appendix Artificial intelligence A machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations, or decisions influencing real or virtual environments."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_63",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nLanguage, etc.) should contact the responsible Agency or USDA’s TARGET Center at (202) 720-2600 (voice and TTY) or contact USDA through the Federal Relay Service at (800) 877-8339 .Contact Information and Accessibility Term Definition Source 17Appendix Artificial intelligence A machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use machine- and human-based inputs to perceive real and virtual environments; abstract such perceptions into models through analysis in an automated manner; and use model inference to formulate options for information or action.See definitions in both the Executive Order 14110 and in OMB M–24–10 AI and AI-enabling roles Individuals with positions and major duties whose contributions are important for successful and responsible AI outcomes."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_64",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\ninputs to perceive real and virtual environments; abstract such perceptions into models through analysis in an automated manner; and use model inference to formulate options for information or action.See definitions in both the Executive Order 14110 and in OMB M–24–10 AI and AI-enabling roles Individuals with positions and major duties whose contributions are important for successful and responsible AI outcomes. AI and AI-Enabling Roles include both technical and non-technical roles, such as data scientists, software engineers, data engineers, data governance specialists, statisticians, machine learning engineers, applied scientists, designers, economists, operations researchers, product managers, policy analysts, program managers, behavioral and social scientists, customer experience strategists, human resource specialists, contracting officials, managers, and attorneys.OMB M–24–10 AI model A component of an information system that implements AI technology and uses computational, statistical, or machine-learning techniques to produce outputs from a given set of inputs.Executive Order 14110 , Section 3 Data Science Training ProgramA 9-month program providing USDA staff an environment to learn data science skills."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_65",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nexperience strategists, human resource specialists, contracting officials, managers, and attorneys.OMB M–24–10 AI model A component of an information system that implements AI technology and uses computational, statistical, or machine-learning techniques to produce outputs from a given set of inputs.Executive Order 14110 , Section 3 Data Science Training ProgramA 9-month program providing USDA staff an environment to learn data science skills. The program offers curated learning tracks in an e-learning platform, monthly USDA exercises and review sessions, guest lectures and workshops, facilitator support through office hours, one-on-one help, and mentorship, and a capstone project.USDA definition Generative AI The class of AI models that emulate the structure and characteristics of input data in order to generate derived synthetic content. This can include images, videos, audio, text, and other digital content.OMB M–24–10 Infrastructure The hardware, software, and network resources involved in information technology operations. This serves as the technological foundation of our computing, networking, and digital operations. Infrastructure includes but is not limited to servers (on premise and cloud), databases (including transactional), and devices.USDA definition Platform The software-based environments sitting on the technological infrastructure that facilitate the development, deployment, and management of data systems, applications, tools, and services."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_66",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nresources involved in information technology operations. This serves as the technological foundation of our computing, networking, and digital operations. Infrastructure includes but is not limited to servers (on premise and cloud), databases (including transactional), and devices.USDA definition Platform The software-based environments sitting on the technological infrastructure that facilitate the development, deployment, and management of data systems, applications, tools, and services. Platform includes analytical components, transactional entities, tools, libraries, application programming interfaces, and Extract, Transform, Load tools.USDA definition Responsible AI AI that: a. Has the potential to help solve urgent challenges while making our world more prosperous, productive, innovative, and secure. b. Mitigates societal harms such as fraud, discrimination, bias, and disinformation; displace and disempower workers; stifle competition; and pose risks to national security.Executive Order 14110, Section 11. De finitions of Key Terms 18Appendix Our consultative approach placed a heavy emphasis on considering the benefits and risks AI in its current and future state of use at USDA. Our internal assessment highlighted significant interest in AI for operational and programmatic applications and indicated some current use of AI. Departmental and Mission Area stakeholders prioritized a clear, shared governance framework and a common AI training curriculum."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_67",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nconsultative approach placed a heavy emphasis on considering the benefits and risks AI in its current and future state of use at USDA. Our internal assessment highlighted significant interest in AI for operational and programmatic applications and indicated some current use of AI. Departmental and Mission Area stakeholders prioritized a clear, shared governance framework and a common AI training curriculum. AI is one of many tools in USDA’s toolbox to generate insights and operational efficiencies. While there is significant interest in AI and its potential to improve mission delivery, stakeholders also highlighted the need to first understand tool options and infrastructure needs, recruit and retain AI-skilled staff, and address data quality concerns. The FY25 –26 USDA AI Strategy builds on these priorities and will inform governance and risk management practices, support innovation and use case research and development, expand transparency and enable us to meet federal requirements more easily and facilitate collaboration and resource sharing with internal and external partners.Since being appointed, the USDA Chief AI Officer (CAIO) engaged with fellow CAIOs through the Federal CAIO Council and shared challenges, successes, and best practices around AI, construction of an AI strategy, as well as CAIO priorities and advice. In development of this Strategy, hundreds of AI stakeholders across USDA assisted efforts through several methods of consultation and conversation."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_68",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nexternal partners.Since being appointed, the USDA Chief AI Officer (CAIO) engaged with fellow CAIOs through the Federal CAIO Council and shared challenges, successes, and best practices around AI, construction of an AI strategy, as well as CAIO priorities and advice. In development of this Strategy, hundreds of AI stakeholders across USDA assisted efforts through several methods of consultation and conversation. Their inputs helped to ground USDA’s vision and goals and shape achievable objectives and actions that will ground and support our current and future AI capabilities. To arrive at the goals, objectives, and action in this Strategy, our process involved:2. AI S trategy Methodology & Overview of USDA’s AI Maturity Assessment Engaging in a benchmarking assessment to review peer Agencies’ AI strategies. Reviewing and aligning with recent Executive Orders, OMB M–24 –10, the USDA Strategic Plan, and internal plans and strategies to refine this Strategy’s goals and objectives. Conducting a current state maturity assessment, which gathered 110 responses from AI stakeholders to a survey aligned with the MITRE AI Maturity Model .Hosting current state assessment and future state visioning workshops with 13 Departmental Administration and Staff Offices, every USDA Mission Area, USDA’s AI Center of Excellence, USDA’s Cloud Working Group, etc., representing over 210 USDA stakeholders."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_69",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nand objectives. Conducting a current state maturity assessment, which gathered 110 responses from AI stakeholders to a survey aligned with the MITRE AI Maturity Model .Hosting current state assessment and future state visioning workshops with 13 Departmental Administration and Staff Offices, every USDA Mission Area, USDA’s AI Center of Excellence, USDA’s Cloud Working Group, etc., representing over 210 USDA stakeholders. Convening a taskforce of 57 key AI stakeholders representing USDA Mission Areas and expertise spanning data, IT, procurement, legal, civil rights, human resources, etc. to draft and review goals and objectives.1. 2. 3.4. 5. 19 Appendix 3."
  },
  {
    "id": "United_States_Department_of_Agriculture_Fiscal_Year_20252026_AI_Strategy_chunk_70",
    "text": "Source: 4 United States Department of Agriculture Fiscal Year 2025–2026 AI Strategy.pdf\n\nAdministration and Staff Offices, every USDA Mission Area, USDA’s AI Center of Excellence, USDA’s Cloud Working Group, etc., representing over 210 USDA stakeholders. Convening a taskforce of 57 key AI stakeholders representing USDA Mission Areas and expertise spanning data, IT, procurement, legal, civil rights, human resources, etc. to draft and review goals and objectives.1. 2. 3.4. 5. 19 Appendix 3. R eferences ▶Executive Order 14110 (Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence) ▶Office of Management and Budget M–24–10 (Advancing Governance, Innovation, and Risk Management for Agency Use of Artificial Intelligence) ▶Foundations for Evidence-Based Policymaking Act of 2018 (“Evidence Act”) ▶Office of Management and Budget M–23–22 (Delivering a Digital- First Public Experience) ▶Government-wide Hiring Authorities for Advancing Federal Government Use of Artificial Intelligence (AI)Relevant Federal Guidance ▶FY24–26 USDA Data Strategy ▶ FY22–26 USDA Strategic Plan ▶FY23–26 USDA Science and Research Strategy ▶FY22–26 USDA IT Strategic Plan ▶FY23–26 USDA IT Workforce Strategic Plan ▶ USDA AI Inventory ▶FNS Framework for State, Local, Tribal, and Territorial Use of Artificial Intelligence for Public Benefit AdministrationRelevant USDA Strategies and Resources ▶National Institute of Standards and Technology (NIST) AI Risk Management Framework ▶MITRE AI Maturity Model ▶General Services Administration (GSA) US Digital Corps ▶ USDA Pathways Program ▶ Virtual Student Federal Service ▶Women In Data – 2023 DatathonRelevant Federal Guidance 19"
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_0",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nNIST AI 100-1 Artificial Intelligence Risk Management Framework (AI RMF 1.0) NIST AI 100-1 Artificial Intelligence Risk Management Framework (AI RMF 1.0) This publication is available free of charge from: https://doi.org/10.6028/NIST.AI.100-1 January 2023 U.S. Department of Commerce Gina M. Raimondo, Secretary National Institute of Standards and Technology Laurie E. Locascio, NIST Director and Under Secretary of Commerce for Standards and Technology Certain commercial entities, equipment, or materials may be identified in this document in order to describe an experimental procedure or concept adequately. Such identification is not intended to imply recommenda- tion or endorsement by the National Institute of Standards and Technology, nor is it intended to imply that the entities, materials, or equipment are necessarily the best available for the purpose. This publication is available free of charge from: https://doi.org/10.6028/NIST.AI.100-1 Update Schedule and Versions The Artificial Intelligence Risk Management Framework (AI RMF) is intended to be a living document. NIST will review the content and usefulness of the Framework regularly to determine if an update is appro- priate; a review with formal input from the AI community is expected to take place no later than 2028. The Framework will employ a two-number versioning system to track and identify major and minor changes."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_1",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nis intended to be a living document. NIST will review the content and usefulness of the Framework regularly to determine if an update is appro- priate; a review with formal input from the AI community is expected to take place no later than 2028. The Framework will employ a two-number versioning system to track and identify major and minor changes. The first number will represent the generation of the AI RMF and its companion documents (e.g., 1.0) and will change only with major revisions. Minor revisions will be tracked using “.n” after the generation number (e.g., 1.1). All changes will be tracked using a Version Control Table which identifies the history, including version number, date of change, and description of change. NIST plans to update the AI RMF Playbook frequently. Comments on the AI RMF Playbook may be sent via email to AIframework@nist.gov at any time and will be reviewed and integrated on a semi-annual basis."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_2",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\n1.1). All changes will be tracked using a Version Control Table which identifies the history, including version number, date of change, and description of change. NIST plans to update the AI RMF Playbook frequently. Comments on the AI RMF Playbook may be sent via email to AIframework@nist.gov at any time and will be reviewed and integrated on a semi-annual basis. Table of Contents Executive Summary 1 Part 1: Foundational Information 4 1 Framing Risk 4 1.1 Understanding and Addressing Risks, Impacts, and Harms 4 1.2 Challenges for AI Risk Management 5 1.2.1 Risk Measurement 5 1.2.2 Risk Tolerance 7 1.2.3 Risk Prioritization 7 1.2.4 Organizational Integration and Management of Risk 8 2 Audience 9 3 AI Risks and Trustworthiness 12 3.1 Valid and Reliable 13 3.2 Safe 14 3.3 Secure and Resilient 15 3.4 Accountable and Transparent 15 3.5 Explainable and Interpretable 16 3.6 Privacy-Enhanced 17 3.7 Fair – with Harmful Bias Managed 17 4 Effectiveness of the AI RMF 19 Part 2: Core and Profiles 20 5 AI RMF Core 20 5.1 Govern 21 5.2 Map 24 5.3 Measure 28 5.4 Manage 31 6 AI RMF Profiles 33 Appendix A: Descriptions of AI Actor Tasks from Figures 2 and 3 35 Appendix B: How AI Risks Differ from Traditional Software Risks 38 Appendix C: AI Risk Management and Human-AI Interaction 40 Appendix D: Attributes of the AI RMF 42 List of Tables Table 1 Categories and subcategories for the GOVERN function. 22 Table 2 Categories and subcategories for the MAP function."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_3",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nof AI Actor Tasks from Figures 2 and 3 35 Appendix B: How AI Risks Differ from Traditional Software Risks 38 Appendix C: AI Risk Management and Human-AI Interaction 40 Appendix D: Attributes of the AI RMF 42 List of Tables Table 1 Categories and subcategories for the GOVERN function. 22 Table 2 Categories and subcategories for the MAP function. 26 Table 3 Categories and subcategories for the MEASURE function. 29 Table 4 Categories and subcategories for the MANAGE function. 32 i NIST AI 100-1 AI RMF 1.0 List of Figures Fig. 1 Examples of potential harms related to AI systems. Trustworthy AI systems and their responsible use can mitigate negative risks and contribute to bene- fits for people, organizations, and ecosystems. 5 Fig. 2 Lifecycle and Key Dimensions of an AI System. Modified from OECD (2022) OECD Framework for the Classification of AI systems — OECD Digital Economy Papers. The two inner circles show AI systems’ key di- mensions and the outer circle shows AI lifecycle stages. Ideally, risk man- agement efforts start with the Plan and Design function in the application context and are performed throughout the AI system lifecycle. See Figure 3 for representative AI actors. 10 Fig. 3 AI actors across AI lifecycle stages. See Appendix A for detailed descrip- tions of AI actor tasks, including details about testing, evaluation, verifica- tion, and validation tasks."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_4",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nrisk man- agement efforts start with the Plan and Design function in the application context and are performed throughout the AI system lifecycle. See Figure 3 for representative AI actors. 10 Fig. 3 AI actors across AI lifecycle stages. See Appendix A for detailed descrip- tions of AI actor tasks, including details about testing, evaluation, verifica- tion, and validation tasks. Note that AI actors in the AI Model dimension (Figure 2) are separated as a best practice, with those building and using the models separated from those verifying and validating the models. 11 Fig. 4 Characteristics of trustworthy AI systems. Valid & Reliable is a necessary condition of trustworthiness and is shown as the base for other trustworthi- ness characteristics. Accountable & Transparent is shown as a vertical box because it relates to all other characteristics. 12 Fig. 5 Functions organize AI risk management activities at their highest level to govern, map, measure, and manage AI risks. Governance is designed to be a cross-cutting function to inform and be infused throughout the other three functions. 20 Page ii NIST AI 100-1 AI RMF 1.0 Executive Summary Artificial intelligence (AI) technologies have significant potential to transform society and people’s lives – from commerce and health to transportation and cybersecurity to the envi- ronment and our planet. AI technologies can drive inclusive economic growth and support scientific advancements that improve the conditions of our world."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_5",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nthree functions. 20 Page ii NIST AI 100-1 AI RMF 1.0 Executive Summary Artificial intelligence (AI) technologies have significant potential to transform society and people’s lives – from commerce and health to transportation and cybersecurity to the envi- ronment and our planet. AI technologies can drive inclusive economic growth and support scientific advancements that improve the conditions of our world. AI technologies, how- ever, also pose risks that can negatively impact individuals, groups, organizations, commu- nities, society, the environment, and the planet. Like risks for other types of technology, AI risks can emerge in a variety of ways and can be characterized as long- or short-term, high- or low-probability, systemic or localized, and high- or low-impact. The AI RMF refers to an AI system as an engineered or machine-based system that can, for a given set of objectives, generate outputs such as predictions, recommenda- tions, or decisions influencing real or virtual environments. AI systems are designed to operate with varying levels of autonomy (Adapted from: OECD Recommendation on AI:2019; ISO/IEC22989:2022). While there are myriad standards and best practices to help organizations mitigate the risks of traditional software or information-based systems, the risks posed by AI systems are in many ways unique (See Appendix B)."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_6",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\ntions, or decisions influencing real or virtual environments. AI systems are designed to operate with varying levels of autonomy (Adapted from: OECD Recommendation on AI:2019; ISO/IEC22989:2022). While there are myriad standards and best practices to help organizations mitigate the risks of traditional software or information-based systems, the risks posed by AI systems are in many ways unique (See Appendix B). AI systems, for example, may be trained on data that can change over time, sometimes significantly and unexpectedly, affecting system function- ality and trustworthiness in ways that are hard to understand. AI systems and the contexts in which they are deployed are frequently complex, making it difficult to detect and respond to failures when they occur. AI systems are inherently socio-technical in nature, meaning they are influenced by societal dynamics and human behavior. AI risks – and benefits – can emerge from the interplay of technical aspects combined with societal factors related to how a system is used, its interactions with other AI systems, who operates it, and the social context in which it is deployed. These risks make AI a uniquely challenging technology to deploy and utilize both for orga- nizations and within society. Without proper controls, AI systems can amplify, perpetuate, or exacerbate inequitable or undesirable outcomes for individuals and communities. With proper controls, AI systems can mitigate and manage inequitable outcomes."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_7",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nwho operates it, and the social context in which it is deployed. These risks make AI a uniquely challenging technology to deploy and utilize both for orga- nizations and within society. Without proper controls, AI systems can amplify, perpetuate, or exacerbate inequitable or undesirable outcomes for individuals and communities. With proper controls, AI systems can mitigate and manage inequitable outcomes. AI risk management is a key component of responsible development and use of AI sys- tems. Responsible AI practices can help align the decisions about AI system design, de- velopment, and uses with intended aim and values. Core concepts in responsible AI em- phasize human centricity, social responsibility, and sustainability. AI risk management can drive responsible uses and practices by prompting organizations and their internal teams who design, develop, and deploy AI to think more critically about context and potential or unexpected negative and positive impacts. Understanding and managing the risks of AI systems will help to enhance trustworthiness, and in turn, cultivate public trust. Page 1 NIST AI 100-1 AI RMF 1.0 Social responsibility can refer to the organization’s responsibility “for the impacts of its decisions and activities on society and the environment through transparent and ethical behavior” ( ISO26000:2010)."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_8",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nunexpected negative and positive impacts. Understanding and managing the risks of AI systems will help to enhance trustworthiness, and in turn, cultivate public trust. Page 1 NIST AI 100-1 AI RMF 1.0 Social responsibility can refer to the organization’s responsibility “for the impacts of its decisions and activities on society and the environment through transparent and ethical behavior” ( ISO26000:2010). Sustainability refers to the “state of the global system, including environmental, social, and economic aspects, in which the needs of the present are met without compromising the ability of future generations to meet their own needs” ( ISO/IEC TR 24368:2022). Responsible AI is meant to result in technology that is also equitable and accountable. The expectation is that organizational practices are carried out in accord with “ professional responsibility ,” defined by ISOas an approach that “aims to ensure that professionals who design, develop, or deploy AI systems and applications or AI-based products or systems, recognize their unique position to exert influence on people, society, and the future of AI” ( ISO/IEC TR 24368:2022). As directed by the National Artificial Intelligence Initiative Act of 2020 (P.L. 116-283), the goal of the AI RMF is to offer a resource to the organizations designing, developing, deploying, or using AI systems to help manage the many risks of AI and promote trustwor- thy and responsible development and use of AI systems."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_9",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nof AI” ( ISO/IEC TR 24368:2022). As directed by the National Artificial Intelligence Initiative Act of 2020 (P.L. 116-283), the goal of the AI RMF is to offer a resource to the organizations designing, developing, deploying, or using AI systems to help manage the many risks of AI and promote trustwor- thy and responsible development and use of AI systems. The Framework is intended to be voluntary , rights-preserving, non-sector-specific, and use-case agnostic, providing flexibil- ity to organizations of all sizes and in all sectors and throughout society to implement the approaches in the Framework. The Framework is designed to equip organizations and individuals – referred to here as AI actors – with approaches that increase the trustworthiness of AI systems, and to help foster the responsible design, development, deployment, and use of AI systems over time. AI actors are defined by the Organisation for Economic Co-operation and Development (OECD) as “those who play an active role in the AI system lifecycle, including organiza- tions and individuals that deploy or operate AI” [OECD (2019) Artificial Intelligence in Society—OECD iLibrary] (See Appendix A). The AI RMF is intended to be practical, to adapt to the AI landscape as AI technologies continue to develop, and to be operationalized by organizations in varying degrees and capacities so society can benefit from AI while also being protected from its potential harms."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_10",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nthat deploy or operate AI” [OECD (2019) Artificial Intelligence in Society—OECD iLibrary] (See Appendix A). The AI RMF is intended to be practical, to adapt to the AI landscape as AI technologies continue to develop, and to be operationalized by organizations in varying degrees and capacities so society can benefit from AI while also being protected from its potential harms. The Framework and supporting resources will be updated, expanded, and improved based on evolving technology, the standards landscape around the world, and AI community ex- perience and feedback. NIST will continue to align the AI RMF and related guidance with applicable international standards, guidelines, and practices. As the AI RMF is put into use, additional lessons will be learned to inform future updates and additional resources. The Framework is divided into two parts. Part 1 discusses how organizations can frame the risks related to AI and describes the intended audience. Next, AI risks and trustworthi- ness are analyzed, outlining the characteristics of trustworthy AI systems, which include Page 2 NIST AI 100-1 AI RMF 1.0 valid and reliable, safe, secure and resilient, accountable and transparent, explainable and interpretable, privacy enhanced, and fair with their harmful biases managed. Part 2 comprises the “Core” of the Framework. It describes four specific functions to help organizations address the risks of AI systems in practice."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_11",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nof trustworthy AI systems, which include Page 2 NIST AI 100-1 AI RMF 1.0 valid and reliable, safe, secure and resilient, accountable and transparent, explainable and interpretable, privacy enhanced, and fair with their harmful biases managed. Part 2 comprises the “Core” of the Framework. It describes four specific functions to help organizations address the risks of AI systems in practice. These functions – GOVERN , MAP ,MEASURE , and MANAGE – are broken down further into categories and subcate- gories. While GOVERN applies to all stages of organizations’ AI risk management pro- cesses and procedures, the MAP ,MEASURE , and MANAGE functions can be applied in AI system-specific contexts and at specific stages of the AI lifecycle. Additional resources related to the Framework are included in the AI RMF Playbook, which is available via the NIST AI RMF website: https://www.nist.gov/itl/ai-risk-management-framework. Development of the AI RMF by NIST in collaboration with the private and public sec- tors is directed and consistent with its broader AI efforts called for by the National AI Initiative Act of 2020, the National Security Commission on Artificial Intelligence recom- mendations, and the Plan for Federal Engagement in Developing Technical Standards and Related Tools."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_12",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nRMF website: https://www.nist.gov/itl/ai-risk-management-framework. Development of the AI RMF by NIST in collaboration with the private and public sec- tors is directed and consistent with its broader AI efforts called for by the National AI Initiative Act of 2020, the National Security Commission on Artificial Intelligence recom- mendations, and the Plan for Federal Engagement in Developing Technical Standards and Related Tools. Engagement with the AI community during this Framework’s development – via responses to a formal Request for Information, three widely attended workshops, public comments on a concept paper and two drafts of the Framework, discussions at mul- tiple public forums, and many small group meetings – has informed development of the AI RMF 1.0 as well as AI research and development and evaluation conducted by NIST and others. Priority research and additional guidance that will enhance this Framework will be captured in an associated AI Risk Management Framework Roadmap to which NIST and the broader community can contribute. Page 3 NIST AI 100-1 AI RMF 1.0 Part 1: Foundational Information 1. Framing Risk AI risk management offers a path to minimize potential negative impacts of AI systems, such as threats to civil liberties and rights, while also providing opportunities to maximize positive impacts. Addressing, documenting, and managing AI risks and potential negative impacts effectively can lead to more trustworthy AI systems."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_13",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nAI 100-1 AI RMF 1.0 Part 1: Foundational Information 1. Framing Risk AI risk management offers a path to minimize potential negative impacts of AI systems, such as threats to civil liberties and rights, while also providing opportunities to maximize positive impacts. Addressing, documenting, and managing AI risks and potential negative impacts effectively can lead to more trustworthy AI systems. 1.1 Understanding and Addressing Risks, Impacts, and Harms In the context of the AI RMF, riskrefers to the composite measure of an event’s probability of occurring and the magnitude or degree of the consequences of the corresponding event. The impacts, or consequences, of AI systems can be positive, negative, or both and can result in opportunities or threats (Adapted from: ISO31000:2018). When considering the negative impact of a potential event, risk is a function of 1) the negative impact, or magni- tude of harm, that would arise if the circumstance or event occurs and 2) the likelihood of occurrence (Adapted from: OMB Circular A-130:2016). Negative impact or harm can be experienced by individuals, groups, communities, organizations, society, the environment, and the planet. “Risk management refers to coordinated activities to direct and control an organiza- tion with regard to risk” (Source: ISO31000:2018)."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_14",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\ntude of harm, that would arise if the circumstance or event occurs and 2) the likelihood of occurrence (Adapted from: OMB Circular A-130:2016). Negative impact or harm can be experienced by individuals, groups, communities, organizations, society, the environment, and the planet. “Risk management refers to coordinated activities to direct and control an organiza- tion with regard to risk” (Source: ISO31000:2018). While risk management processes generally address negative impacts, this Framework of- fers approaches to minimize anticipated negative impacts of AI systems andidentify op- portunities to maximize positive impacts. Effectively managing the risk of potential harms could lead to more trustworthy AI systems and unleash potential benefits to people (individ- uals, communities, and society), organizations, and systems/ecosystems. Risk management can enable AI developers and users to understand impacts and account for the inherent lim- itations and uncertainties in their models and systems, which in turn can improve overall system performance and trustworthiness and the likelihood that AI technologies will be used in ways that are beneficial. The AI RMF is designed to address new risks as they emerge. This flexibility is particularly important where impacts are not easily foreseeable and applications are evolving. While some AI risks and benefits are well-known, it can be challenging to assess negative impacts and the degree of harms."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_15",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nlikelihood that AI technologies will be used in ways that are beneficial. The AI RMF is designed to address new risks as they emerge. This flexibility is particularly important where impacts are not easily foreseeable and applications are evolving. While some AI risks and benefits are well-known, it can be challenging to assess negative impacts and the degree of harms. Figure 1 provides examples of potential harms that can be related to AI systems. AI risk management efforts should consider that humans may assume that AI systems work – and work well – in allsettings. For example, whether correct or not, AI systems are often perceived as being more objective than humans or as offering greater capabilities than general software. Page 4 NIST AI 100-1 AI RMF 1.0 Fig. 1. Examples of potential harms related to AI systems. Trustworthy AI systems and their responsible use can mitigate negative risks and contribute to benefits for people, organizations, and ecosystems. 1.2 Challenges for AI Risk Management Several challenges are described below. They should be taken into account when managing risks in pursuit of AI trustworthiness. 1.2.1 Risk Measurement AI risks or failures that are not well-defined or adequately understood are difficult to mea- sure quantitatively or qualitatively. The inability to appropriately measure AI risks does not imply that an AI system necessarily poses either a high or low risk."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_16",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\ndescribed below. They should be taken into account when managing risks in pursuit of AI trustworthiness. 1.2.1 Risk Measurement AI risks or failures that are not well-defined or adequately understood are difficult to mea- sure quantitatively or qualitatively. The inability to appropriately measure AI risks does not imply that an AI system necessarily poses either a high or low risk. Some risk measurement challenges include: Risks related to third-party software, hardware, and data: Third-party data or systems can accelerate research and development and facilitate technology transition. They also may complicate risk measurement. Risk can emerge both from third-party data, software or hardware itself and how it is used. Risk metrics or methodologies used by the organization developing the AI system may not align with the risk metrics or methodologies uses by the organization deploying or operating the system. Also, the organization developing the AI system may not be transparent about the risk metrics or methodologies it used. Risk measurement and management can be complicated by how customers use or integrate third- party data or systems into AI products or services, particularly without sufficient internal governance structures and technical safeguards. Regardless, all parties and AI actors should manage risk in the AI systems they develop, deploy, or use as standalone or integrated components."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_17",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nmetrics or methodologies it used. Risk measurement and management can be complicated by how customers use or integrate third- party data or systems into AI products or services, particularly without sufficient internal governance structures and technical safeguards. Regardless, all parties and AI actors should manage risk in the AI systems they develop, deploy, or use as standalone or integrated components. Tracking emergent risks: Organizations’ risk management efforts will be enhanced by identifying and tracking emergent risks and considering techniques for measuring them. Page 5 NIST AI 100-1 AI RMF 1.0 AI system impact assessment approaches can help AI actors understand potential impacts or harms within specific contexts. Availability of reliable metrics: The current lack of consensus on robust and verifiable measurement methods for risk and trustworthiness, and applicability to different AI use cases, is an AI risk measurement challenge. Potential pitfalls when seeking to measure negative risk or harms include the reality that development of metrics is often an institu- tional endeavor and may inadvertently reflect factors unrelated to the underlying impact. In addition, measurement approaches can be oversimplified, gamed, lack critical nuance, be- come relied upon in unexpected ways, or fail to account for differences in affected groups and contexts."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_18",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nwhen seeking to measure negative risk or harms include the reality that development of metrics is often an institu- tional endeavor and may inadvertently reflect factors unrelated to the underlying impact. In addition, measurement approaches can be oversimplified, gamed, lack critical nuance, be- come relied upon in unexpected ways, or fail to account for differences in affected groups and contexts. Approaches for measuring impacts on a population work best if they recognize that contexts matter, that harms may affect varied groups or sub-groups differently, and that communities or other sub-groups who may be harmed are not always direct users of a system. Risk at different stages of the AI lifecycle: Measuring risk at an earlier stage in the AI lifecycle may yield different results than measuring risk at a later stage; some risks may be latent at a given point in time and may increase as AI systems adapt and evolve. Fur- thermore, different AI actors across the AI lifecycle can have different risk perspectives. For example, an AI developer who makes AI software available, such as pre-trained mod- els, can have a different risk perspective than an AI actor who is responsible for deploying that pre-trained model in a specific use case. Such deployers may not recognize that their particular uses could entail risks which differ from those perceived by the initial developer."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_19",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nperspectives. For example, an AI developer who makes AI software available, such as pre-trained mod- els, can have a different risk perspective than an AI actor who is responsible for deploying that pre-trained model in a specific use case. Such deployers may not recognize that their particular uses could entail risks which differ from those perceived by the initial developer. All involved AI actors share responsibilities for designing, developing, and deploying a trustworthy AI system that is fit for purpose. Risk in real-world settings: While measuring AI risks in a laboratory or a controlled environment may yield important insights pre-deployment, these measurements may differ from risks that emerge in operational, real-world settings. Inscrutability: Inscrutable AI systems can complicate risk measurement. Inscrutability can be a result of the opaque nature of AI systems (limited explainability or interpretabil- ity), lack of transparency or documentation in AI system development or deployment, or inherent uncertainties in AI systems. Human baseline: Risk management of AI systems that are intended to augment or replace human activity, for example decision making, requires some form of baseline metrics for comparison. This is difficult to systematize since AI systems carry out different tasks – and perform tasks differently – than humans."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_20",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nin AI system development or deployment, or inherent uncertainties in AI systems. Human baseline: Risk management of AI systems that are intended to augment or replace human activity, for example decision making, requires some form of baseline metrics for comparison. This is difficult to systematize since AI systems carry out different tasks – and perform tasks differently – than humans. Page 6 NIST AI 100-1 AI RMF 1.0 1.2.2 Risk Tolerance While the AI RMF can be used to prioritize risk, it does not prescribe risk tolerance. Risk tolerance refers to the organization’s or AI actor’s (see Appendix A) readiness to bear the risk in order to achieve its objectives. Risk tolerance can be influenced by legal or regula- tory requirements (Adapted from: ISO GUIDE 73). Risk tolerance and the level of risk that is acceptable to organizations or society are highly contextual and application and use-case specific. Risk tolerances can be influenced by policies and norms established by AI sys- tem owners, organizations, industries, communities, or policy makers. Risk tolerances are likely to change over time as AI systems, policies, and norms evolve. Different organiza- tions may have varied risk tolerances due to their particular organizational priorities and resource considerations. Emerging knowledge and methods to better inform harm/cost-benefit tradeoffs will con- tinue to be developed and debated by businesses, governments, academia, and civil society."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_21",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\ncommunities, or policy makers. Risk tolerances are likely to change over time as AI systems, policies, and norms evolve. Different organiza- tions may have varied risk tolerances due to their particular organizational priorities and resource considerations. Emerging knowledge and methods to better inform harm/cost-benefit tradeoffs will con- tinue to be developed and debated by businesses, governments, academia, and civil society. To the extent that challenges for specifying AI risk tolerances remain unresolved, there may be contexts where a risk management framework is not yet readily applicable for mitigating negative AI risks. The Framework is intended to be flexible and to augment existing risk practices which should align with applicable laws, regulations, and norms. Organizations should follow existing regulations and guidelines for risk criteria, tolerance, and response established by organizational, domain, discipline, sector, or professional requirements. Some sectors or industries may have established definitions of harm or established documentation, reporting, and disclosure requirements. Within sectors, risk management may depend on existing guidelines for specific applications and use case settings. Where established guidelines do not exist, organizations should define reasonable risk tolerance. Once tolerance is defined, this AI RMF can be used to manage risks and to document risk management processes."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_22",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nmay have established definitions of harm or established documentation, reporting, and disclosure requirements. Within sectors, risk management may depend on existing guidelines for specific applications and use case settings. Where established guidelines do not exist, organizations should define reasonable risk tolerance. Once tolerance is defined, this AI RMF can be used to manage risks and to document risk management processes. 1.2.3 Risk Prioritization Attempting to eliminate negative risk entirely can be counterproductive in practice because not all incidents and failures can be eliminated. Unrealistic expectations about risk may lead organizations to allocate resources in a manner that makes risk triage inefficient or impractical or wastes scarce resources. A risk management culture can help organizations recognize that not all AI risks are the same, and resources can be allocated purposefully. Actionable risk management efforts lay out clear guidelines for assessing trustworthiness of each AI system an organization develops or deploys. Policies and resources should be prioritized based on the assessed risk level and potential impact of an AI system. The extent to which an AI system may be customized or tailored to the specific context of use by the AI deployer can be a contributing factor."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_23",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nclear guidelines for assessing trustworthiness of each AI system an organization develops or deploys. Policies and resources should be prioritized based on the assessed risk level and potential impact of an AI system. The extent to which an AI system may be customized or tailored to the specific context of use by the AI deployer can be a contributing factor. Page 7 NIST AI 100-1 AI RMF 1.0 When applying the AI RMF, risks which the organization determines to be highest for the AI systems within a given context of use call for the most urgent prioritization and most thorough risk management process. In cases where an AI system presents unacceptable negative risk levels – such as where significant negative impacts are imminent, severe harms are actually occurring, or catastrophic risks are present – development and deployment should cease in a safe manner until risks can be sufficiently managed. If an AI system’s development, deployment, and use cases are found to be low-risk in a specific context, that may suggest potentially lower prioritization. Risk prioritization may differ between AI systems that are designed or deployed to directly interact with humans as compared to AI systems that are not. Higher initial prioritization may be called for in settings where the AI system is trained on large datasets comprised of sensitive or protected data such as personally identifiable information, or where the outputs of the AI systems have direct or indirect impact on humans."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_24",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\ndesigned or deployed to directly interact with humans as compared to AI systems that are not. Higher initial prioritization may be called for in settings where the AI system is trained on large datasets comprised of sensitive or protected data such as personally identifiable information, or where the outputs of the AI systems have direct or indirect impact on humans. AI systems designed to interact only with computational systems and trained on non-sensitive datasets (for example, data collected from the physical environment) may call for lower initial prioritization. Nonethe- less, regularly assessing and prioritizing risk based on context remains important because non-human-facing AI systems can have downstream safety or social implications. Residual risk – defined as risk remaining after risk treatment (Source: ISO GUIDE 73) – directly impacts end users or affected individuals and communities. Documenting residual risks will call for the system provider to fully consider the risks of deploying the AI product and will inform end users about potential negative impacts of interacting with the system. 1.2.4 Organizational Integration and Management of Risk AI risks should not be considered in isolation. Different AI actors have different responsi- bilities and awareness depending on their roles in the lifecycle. For example, organizations developing an AI system often will not have information about how the system may be used."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_25",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nusers about potential negative impacts of interacting with the system. 1.2.4 Organizational Integration and Management of Risk AI risks should not be considered in isolation. Different AI actors have different responsi- bilities and awareness depending on their roles in the lifecycle. For example, organizations developing an AI system often will not have information about how the system may be used. AI risk management should be integrated and incorporated into broader enterprise risk management strategies and processes. Treating AI risks along with other critical risks, such as cybersecurity and privacy, will yield a more integrated outcome and organizational efficiencies. The AI RMF may be utilized along with related guidance and frameworks for managing AI system risks or broader enterprise risks. Some risks related to AI systems are common across other types of software development and deployment. Examples of overlapping risks include: privacy concerns related to the use of underlying data to train AI systems; the en- ergy and environmental implications associated with resource-heavy computing demands; security concerns related to the confidentiality, integrity, and availability of the system and its training and output data; and general security of the underlying software and hardware for AI systems."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_26",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\ndeployment. Examples of overlapping risks include: privacy concerns related to the use of underlying data to train AI systems; the en- ergy and environmental implications associated with resource-heavy computing demands; security concerns related to the confidentiality, integrity, and availability of the system and its training and output data; and general security of the underlying software and hardware for AI systems. Page 8 NIST AI 100-1 AI RMF 1.0 Organizations need to establish and maintain the appropriate accountability mechanisms, roles and responsibilities, culture, and incentive structures for risk management to be ef- fective. Use of the AI RMF alone will not lead to these changes or provide the appropriate incentives. Effective risk management is realized through organizational commitment at senior levels and may require cultural change within an organization or industry. In addi- tion, small to medium-sized organizations managing AI risks or implementing the AI RMF may face different challenges than large organizations, depending on their capabilities and resources. 2. Audience Identifying and managing AI risks and potential impacts – both positive and negative – re- quires a broad set of perspectives and actors across the AI lifecycle. Ideally, AI actors will represent a diversity of experience, expertise, and backgrounds and comprise demograph- ically and disciplinarily diverse teams."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_27",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\ndifferent challenges than large organizations, depending on their capabilities and resources. 2. Audience Identifying and managing AI risks and potential impacts – both positive and negative – re- quires a broad set of perspectives and actors across the AI lifecycle. Ideally, AI actors will represent a diversity of experience, expertise, and backgrounds and comprise demograph- ically and disciplinarily diverse teams. The AI RMF is intended to be used by AI actors across the AI lifecycle and dimensions. The OECD has developed a framework for classifying AI lifecycle activities according to five key socio-technical dimensions, each with properties relevant for AI policy and gover- nance, including risk management [OECD (2022) OECD Framework for the Classification of AI systems — OECD Digital Economy Papers]. Figure 2 shows these dimensions, slightly modified by NIST for purposes of this framework. The NIST modification high- lights the importance of test, evaluation, verification, and validation (TEVV) processes throughout an AI lifecycle and generalizes the operational context of an AI system. AI dimensions displayed in Figure 2 are the Application Context, Data and Input, AI Model, and Task and Output. AI actors involved in these dimensions who perform or manage the design, development, deployment, evaluation, and use of AI systems and drive AI risk management efforts are the primary AI RMF audience."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_28",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nand generalizes the operational context of an AI system. AI dimensions displayed in Figure 2 are the Application Context, Data and Input, AI Model, and Task and Output. AI actors involved in these dimensions who perform or manage the design, development, deployment, evaluation, and use of AI systems and drive AI risk management efforts are the primary AI RMF audience. Representative AI actors across the lifecycle dimensions are listed in Figure 3 and described in detail in Appendix A. Within the AI RMF, all AI actors work together to manage risks and achieve the goals of trustworthy and responsible AI. AI actors with TEVV-specific expertise are integrated throughout the AI lifecycle and are especially likely to benefit from the Framework. Performed regularly, TEVV tasks can provide insights relative to technical, societal, legal, and ethical standards or norms, and can assist with anticipating impacts and assessing and tracking emergent risks. As a regular process within an AI lifecycle, TEVV allows for both mid-course remediation and post-hoc risk management. The People & Planet dimension at the center of Figure 2 represents human rights and the broader well-being of society and the planet. The AI actors in this dimension comprise a separate AI RMF audience who informs the primary audience. These AI actors may in- clude trade associations, standards developing organizations, researchers, advocacy groups, Page 9 NIST AI 100-1 AI RMF 1.0 Fig. 2."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_29",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\ndimension at the center of Figure 2 represents human rights and the broader well-being of society and the planet. The AI actors in this dimension comprise a separate AI RMF audience who informs the primary audience. These AI actors may in- clude trade associations, standards developing organizations, researchers, advocacy groups, Page 9 NIST AI 100-1 AI RMF 1.0 Fig. 2. Lifecycle and Key Dimensions of an AI System. Modified from OECD (2022) OECD Framework for the Classification of AI systems — OECD Digital Economy Papers. The two inner circles show AI systems’ key dimensions and the outer circle shows AI lifecycle stages. Ideally, risk management efforts start with the Plan and Design function in the application context and are performed throughout the AI system lifecycle. See Figure 3 for representative AI actors. environmental groups, civil society organizations, end users, and potentially impacted in- dividuals and communities. These actors can: • assist in providing context and understanding potential and actual impacts; • be a source of formal or quasi-formal norms and guidance for AI risk management; • designate boundaries for AI operation (technical, societal, legal, and ethical); and • promote discussion of the tradeoffs needed to balance societal values and priorities related to civil liberties and rights, equity, the environment and the planet, and the economy."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_30",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nunderstanding potential and actual impacts; • be a source of formal or quasi-formal norms and guidance for AI risk management; • designate boundaries for AI operation (technical, societal, legal, and ethical); and • promote discussion of the tradeoffs needed to balance societal values and priorities related to civil liberties and rights, equity, the environment and the planet, and the economy. Successful risk management depends upon a sense of collective responsibility among AI actors shown in Figure 3. The AI RMF functions, described in Section 5, require diverse perspectives, disciplines, professions, and experiences. Diverse teams contribute to more open sharing of ideas and assumptions about the purposes and functions of technology – making these implicit aspects more explicit. This broader collective perspective creates opportunities for surfacing problems and identifying existing and emergent risks. Page 10 NIST AI 100-1 AI RMF 1.0 Fig. 3. AI actors across AI lifecycle stages. See Appendix A for detailed descriptions of AI actor tasks, including details about testing, evaluation, verification, and validation tasks. Note that AI actors in the AI Model dimension (Figure 2) are separated as a best practice, with those building and using the models separated from those verifying and validating the models. Page 11 NIST AI 100-1 AI RMF 1.0 3."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_31",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nSee Appendix A for detailed descriptions of AI actor tasks, including details about testing, evaluation, verification, and validation tasks. Note that AI actors in the AI Model dimension (Figure 2) are separated as a best practice, with those building and using the models separated from those verifying and validating the models. Page 11 NIST AI 100-1 AI RMF 1.0 3. AI Risks and Trustworthiness For AI systems to be trustworthy, they often need to be responsive to a multiplicity of cri- teria that are of value to interested parties. Approaches which enhance AI trustworthiness can reduce negative AI risks. This Framework articulates the following characteristics of trustworthy AI and offers guidance for addressing them. Characteristics of trustworthy AI systems include: valid and reliable, safe, secure and resilient, accountable and trans- parent, explainable and interpretable, privacy-enhanced, and fair with harmful bias managed. Creating trustworthy AI requires balancing each of these characteristics based on the AI system’s context of use. While all characteristics are socio-technical system at- tributes, accountability and transparency also relate to the processes and activities internal to an AI system and its external setting. Neglecting these characteristics can increase the probability and magnitude of negative consequences. Fig. 4. Characteristics of trustworthy AI systems."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_32",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nrequires balancing each of these characteristics based on the AI system’s context of use. While all characteristics are socio-technical system at- tributes, accountability and transparency also relate to the processes and activities internal to an AI system and its external setting. Neglecting these characteristics can increase the probability and magnitude of negative consequences. Fig. 4. Characteristics of trustworthy AI systems. Valid & Reliable is a necessary condition of trustworthiness and is shown as the base for other trustworthiness characteristics. Accountable & Transparent is shown as a vertical box because it relates to all other characteristics. Trustworthiness characteristics (shown in Figure 4) are inextricably tied to social and orga- nizational behavior, the datasets used by AI systems, selection of AI models and algorithms and the decisions made by those who build them, and the interactions with the humans who provide insight from and oversight of such systems. Human judgment should be employed when deciding on the specific metrics related to AI trustworthiness characteristics and the precise threshold values for those metrics. Addressing AI trustworthiness characteristics individually will not ensure AI system trust- worthiness; tradeoffs are usually involved, rarely do all characteristics apply in every set- ting, and some will be more or less important in any given situation."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_33",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\njudgment should be employed when deciding on the specific metrics related to AI trustworthiness characteristics and the precise threshold values for those metrics. Addressing AI trustworthiness characteristics individually will not ensure AI system trust- worthiness; tradeoffs are usually involved, rarely do all characteristics apply in every set- ting, and some will be more or less important in any given situation. Ultimately, trustwor- thiness is a social concept that ranges across a spectrum and is only as strong as its weakest characteristics. When managing AI risks, organizations can face difficult decisions in balancing these char- acteristics. For example, in certain scenarios tradeoffs may emerge between optimizing for interpretability and achieving privacy. In other cases, organizations might face a tradeoff between predictive accuracy and interpretability. Or, under certain conditions such as data sparsity, privacy-enhancing techniques can result in a loss in accuracy, affecting decisions Page 12 NIST AI 100-1 AI RMF 1.0 about fairness and other values in certain domains. Dealing with tradeoffs requires tak- ing into account the decision-making context. These analyses can highlight the existence and extent of tradeoffs between different measures, but they do not answer questions about how to navigate the tradeoff. Those depend on the values at play in the relevant context and should be resolved in a manner that is both transparent and appropriately justifiable."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_34",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nwith tradeoffs requires tak- ing into account the decision-making context. These analyses can highlight the existence and extent of tradeoffs between different measures, but they do not answer questions about how to navigate the tradeoff. Those depend on the values at play in the relevant context and should be resolved in a manner that is both transparent and appropriately justifiable. There are multiple approaches for enhancing contextual awareness in the AI lifecycle. For example, subject matter experts can assist in the evaluation of TEVV findings and work with product and deployment teams to align TEVV parameters to requirements and de- ployment conditions. When properly resourced, increasing the breadth and diversity of input from interested parties and relevant AI actors throughout the AI lifecycle can en- hance opportunities for informing contextually sensitive evaluations, and for identifying AI system benefits and positive impacts. These practices can increase the likelihood that risks arising in social contexts are managed appropriately. Understanding and treatment of trustworthiness characteristics depends on an AI actor’s particular role within the AI lifecycle. For any given AI system, an AI designer or developer may have a different perception of the characteristics than the deployer. Trustworthiness characteristics explained in this document influence each other."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_35",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\ncan increase the likelihood that risks arising in social contexts are managed appropriately. Understanding and treatment of trustworthiness characteristics depends on an AI actor’s particular role within the AI lifecycle. For any given AI system, an AI designer or developer may have a different perception of the characteristics than the deployer. Trustworthiness characteristics explained in this document influence each other. Highly secure but unfair systems, accurate but opaque and uninterpretable systems, and inaccurate but secure, privacy-enhanced, and transparent systems are all unde- sirable. A comprehensive approach to risk management calls for balancing tradeoffs among the trustworthiness characteristics. It is the joint responsibility of all AI ac- tors to determine whether AI technology is an appropriate or necessary tool for a given context or purpose, and how to use it responsibly. The decision to commission or deploy an AI system should be based on a contextual assessment of trustworthi- ness characteristics and the relative risks, impacts, costs, and benefits, and informed by a broad set of interested parties. 3.1 Valid and Reliable Validation is the “confirmation, through the provision of objective evidence, that the re- quirements for a specific intended use or application have been fulfilled” (Source: ISO 9000:2015)."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_36",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nsystem should be based on a contextual assessment of trustworthi- ness characteristics and the relative risks, impacts, costs, and benefits, and informed by a broad set of interested parties. 3.1 Valid and Reliable Validation is the “confirmation, through the provision of objective evidence, that the re- quirements for a specific intended use or application have been fulfilled” (Source: ISO 9000:2015). Deployment of AI systems which are inaccurate, unreliable, or poorly gener- alized to data and settings beyond their training creates and increases negative AI risks and reduces trustworthiness. Reliability is defined in the same standard as the “ability of an item to perform as required, without failure, for a given time interval, under given conditions” (Source: ISO/IEC TS 5723:2022). Reliability is a goal for overall correctness of AI system operation under the conditions of expected use and over a given period of time, including the entire lifetime of the system. Page 13 NIST AI 100-1 AI RMF 1.0 Accuracy and robustness contribute to the validity and trustworthiness of AI systems, and can be in tension with one another in AI systems."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_37",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\na goal for overall correctness of AI system operation under the conditions of expected use and over a given period of time, including the entire lifetime of the system. Page 13 NIST AI 100-1 AI RMF 1.0 Accuracy and robustness contribute to the validity and trustworthiness of AI systems, and can be in tension with one another in AI systems. Accuracy is defined by ISO/IEC TS 5723:2022 as “closeness of results of observations, computations, or estimates to the true values or the values accepted as being true.” Mea- sures of accuracy should consider computational-centric measures (e.g., false positive and false negative rates), human-AI teaming, and demonstrate external validity (generalizable beyond the training conditions). Accuracy measurements should always be paired with clearly defined and realistic test sets – that are representative of conditions of expected use – and details about test methodology; these should be included in associated documen- tation. Accuracy measurements may include disaggregation of results for different data segments. Robustness orgeneralizability is defined as the “ability of a system to maintain its level of performance under a variety of circumstances” (Source: ISO/IEC TS 5723:2022). Ro- bustness is a goal for appropriate system functionality in a broad set of conditions and circumstances, including uses of AI systems not initially anticipated."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_38",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nmeasurements may include disaggregation of results for different data segments. Robustness orgeneralizability is defined as the “ability of a system to maintain its level of performance under a variety of circumstances” (Source: ISO/IEC TS 5723:2022). Ro- bustness is a goal for appropriate system functionality in a broad set of conditions and circumstances, including uses of AI systems not initially anticipated. Robustness requires not only that the system perform exactly as it does under expected uses, but also that it should perform in ways that minimize potential harms to people if it is operating in an unexpected setting. Validity and reliability for deployed AI systems are often assessed by ongoing testing or monitoring that confirms a system is performing as intended. Measurement of validity, accuracy, robustness, and reliability contribute to trustworthiness and should take into con- sideration that certain types of failures can cause greater harm. AI risk management efforts should prioritize the minimization of potential negative impacts, and may need to include human intervention in cases where the AI system cannot detect or correct errors. 3.2 Safe AI systems should “not under defined conditions, lead to a state in which human life, health, property, or the environment is endangered” (Source: ISO/IEC TS 5723:2022)."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_39",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\ngreater harm. AI risk management efforts should prioritize the minimization of potential negative impacts, and may need to include human intervention in cases where the AI system cannot detect or correct errors. 3.2 Safe AI systems should “not under defined conditions, lead to a state in which human life, health, property, or the environment is endangered” (Source: ISO/IEC TS 5723:2022). Safe operation of AI systems is improved through: • responsible design, development, and deployment practices; • clear information to deployers on responsible use of the system; • responsible decision-making by deployers and end users; and • explanations and documentation of risks based on empirical evidence of incidents. Different types of safety risks may require tailored AI risk management approaches based on context and the severity of potential risks presented. Safety risks that pose a potential risk of serious injury or death call for the most urgent prioritization and most thorough risk management process. Page 14 NIST AI 100-1 AI RMF 1.0 Employing safety considerations during the lifecycle and starting as early as possible with planning and design can prevent failures or conditions that can render a system dangerous. Other practical approaches for AI safety often relate to rigorous simulation and in-domain testing, real-time monitoring, and the ability to shut down, modify, or have human inter- vention into systems that deviate from intended or expected functionality."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_40",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nthe lifecycle and starting as early as possible with planning and design can prevent failures or conditions that can render a system dangerous. Other practical approaches for AI safety often relate to rigorous simulation and in-domain testing, real-time monitoring, and the ability to shut down, modify, or have human inter- vention into systems that deviate from intended or expected functionality. AI safety risk management approaches should take cues from efforts and guidelines for safety in fields such as transportation and healthcare, and align with existing sector- or application-specific guidelines or standards. 3.3 Secure and Resilient AI systems, as well as the ecosystems in which they are deployed, may be said to be re- silient if they can withstand unexpected adverse events or unexpected changes in their envi- ronment or use – or if they can maintain their functions and structure in the face of internal and external change and degrade safely and gracefully when this is necessary (Adapted from: ISO/IEC TS 5723:2022). Common security concerns relate to adversarial examples, data poisoning, and the exfiltration of models, training data, or other intellectual property through AI system endpoints. AI systems that can maintain confidentiality, integrity, and availability through protection mechanisms that prevent unauthorized access and use may be said to be secure ."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_41",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nand gracefully when this is necessary (Adapted from: ISO/IEC TS 5723:2022). Common security concerns relate to adversarial examples, data poisoning, and the exfiltration of models, training data, or other intellectual property through AI system endpoints. AI systems that can maintain confidentiality, integrity, and availability through protection mechanisms that prevent unauthorized access and use may be said to be secure . Guidelines in the NIST Cybersecurity Framework and Risk Manage- ment Framework are among those which are applicable here. Security and resilience are related but distinct characteristics. While resilience is the abil- ity to return to normal function after an unexpected adverse event, security includes re- silience but also encompasses protocols to avoid, protect against, respond to, or recover from attacks. Resilience relates to robustness and goes beyond the provenance of the data to encompass unexpected or adversarial use (or abuse or misuse) of the model or data. 3.4 Accountable and Transparent Trustworthy AI depends upon accountability. Accountability presupposes transparency. Transparency reflects the extent to which information about an AI system and its outputs is available to individuals interacting with such a system – regardless of whether they are even aware that they are doing so."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_42",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nor adversarial use (or abuse or misuse) of the model or data. 3.4 Accountable and Transparent Trustworthy AI depends upon accountability. Accountability presupposes transparency. Transparency reflects the extent to which information about an AI system and its outputs is available to individuals interacting with such a system – regardless of whether they are even aware that they are doing so. Meaningful transparency provides access to appropriate levels of information based on the stage of the AI lifecycle and tailored to the role or knowledge of AI actors or individuals interacting with or using the AI system. By promoting higher levels of understanding, transparency increases confidence in the AI system. This characteristic’s scope spans from design decisions and training data to model train- ing, the structure of the model, its intended use cases, and how and when deployment, post-deployment, or end user decisions were made and by whom. Transparency is often necessary for actionable redress related to AI system outputs that are incorrect or otherwise lead to negative impacts. Transparency should consider human-AI interaction: for exam- Page 15 NIST AI 100-1 AI RMF 1.0 ple, how a human operator or user is notified when a potential or actual adverse outcome caused by an AI system is detected. A transparent system is not necessarily an accurate, privacy-enhanced, secure, or fair system."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_43",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nthat are incorrect or otherwise lead to negative impacts. Transparency should consider human-AI interaction: for exam- Page 15 NIST AI 100-1 AI RMF 1.0 ple, how a human operator or user is notified when a potential or actual adverse outcome caused by an AI system is detected. A transparent system is not necessarily an accurate, privacy-enhanced, secure, or fair system. However, it is difficult to determine whether an opaque system possesses such characteristics, and to do so over time as complex systems evolve. The role of AI actors should be considered when seeking accountability for the outcomes of AI systems. The relationship between risk and accountability associated with AI and tech- nological systems more broadly differs across cultural, legal, sectoral, and societal contexts. When consequences are severe, such as when life and liberty are at stake, AI developers and deployers should consider proportionally and proactively adjusting their transparency and accountability practices. Maintaining organizational practices and governing structures for harm reduction, like risk management, can help lead to more accountable systems. Measures to enhance transparency and accountability should also consider the impact of these efforts on the implementing entity, including the level of necessary resources and the need to safeguard proprietary information."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_44",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nconsider proportionally and proactively adjusting their transparency and accountability practices. Maintaining organizational practices and governing structures for harm reduction, like risk management, can help lead to more accountable systems. Measures to enhance transparency and accountability should also consider the impact of these efforts on the implementing entity, including the level of necessary resources and the need to safeguard proprietary information. Maintaining the provenance of training data and supporting attribution of the AI system’s decisions to subsets of training data can assist with both transparency and accountability. Training data may also be subject to copyright and should follow applicable intellectual property rights laws. As transparency tools for AI systems and related documentation continue to evolve, devel- opers of AI systems are encouraged to test different types of transparency tools in cooper- ation with AI deployers to ensure that AI systems are used as intended. 3.5 Explainable and Interpretable Explainability refers to a representation of the mechanisms underlying AI systems’ oper- ation, whereas interpretability refers to the meaning of AI systems’ output in the context of their designed functional purposes."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_45",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nsystems are encouraged to test different types of transparency tools in cooper- ation with AI deployers to ensure that AI systems are used as intended. 3.5 Explainable and Interpretable Explainability refers to a representation of the mechanisms underlying AI systems’ oper- ation, whereas interpretability refers to the meaning of AI systems’ output in the context of their designed functional purposes. Together, explainability and interpretability assist those operating or overseeing an AI system, as well as users of an AI system, to gain deeper insights into the functionality and trustworthiness of the system, including its out- puts. The underlying assumption is that perceptions of negative risk stem from a lack of ability to make sense of, or contextualize, system output appropriately. Explainable and interpretable AI systems offer information that will help end users understand the purposes and potential impact of an AI system. Risk from lack of explainability may be managed by describing how AI systems function, with descriptions tailored to individual differences such as the user’s role, knowledge, and skill level. Explainable systems can be debugged and monitored more easily, and they lend themselves to more thorough documentation, audit, and governance. Page 16 NIST AI 100-1 AI RMF 1.0 Risks to interpretability often can be addressed by communicating a description of why an AI system made a particular prediction or recommendation."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_46",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\ndifferences such as the user’s role, knowledge, and skill level. Explainable systems can be debugged and monitored more easily, and they lend themselves to more thorough documentation, audit, and governance. Page 16 NIST AI 100-1 AI RMF 1.0 Risks to interpretability often can be addressed by communicating a description of why an AI system made a particular prediction or recommendation. (See “Four Principles of Explainable Artificial Intelligence” and “Psychological Foundations of Explainability and Interpretability in Artificial Intelligence” found here.) Transparency, explainability, and interpretability are distinct characteristics that support each other. Transparency can answer the question of “what happened” in the system. Ex- plainability can answer the question of “how” a decision was made in the system. Inter- pretability can answer the question of “why” a decision was made by the system and its meaning or context to the user. 3.6 Privacy-Enhanced Privacy refers generally to the norms and practices that help to safeguard human autonomy, identity, and dignity. These norms and practices typically address freedom from intrusion, limiting observation, or individuals’ agency to consent to disclosure or control of facets of their identities (e.g., body, data, reputation)."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_47",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nmade by the system and its meaning or context to the user. 3.6 Privacy-Enhanced Privacy refers generally to the norms and practices that help to safeguard human autonomy, identity, and dignity. These norms and practices typically address freedom from intrusion, limiting observation, or individuals’ agency to consent to disclosure or control of facets of their identities (e.g., body, data, reputation). (See The NIST Privacy Framework: A Tool for Improving Privacy through Enterprise Risk Management.) Privacy values such as anonymity, confidentiality, and control generally should guide choices for AI system design, development, and deployment. Privacy-related risks may influence security, bias, and transparency and come with tradeoffs with these other characteristics. Like safety and security, specific technical features of an AI system may promote or reduce privacy. AI systems can also present new risks to privacy by allowing inference to identify individuals or previously private information about individuals. Privacy-enhancing technologies (“PETs”) for AI, as well as data minimizing methods such as de-identification and aggregation for certain model outputs, can support design for privacy-enhanced AI systems. Under certain conditions such as data sparsity, privacy- enhancing techniques can result in a loss in accuracy, affecting decisions about fairness and other values in certain domains."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_48",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nor previously private information about individuals. Privacy-enhancing technologies (“PETs”) for AI, as well as data minimizing methods such as de-identification and aggregation for certain model outputs, can support design for privacy-enhanced AI systems. Under certain conditions such as data sparsity, privacy- enhancing techniques can result in a loss in accuracy, affecting decisions about fairness and other values in certain domains. 3.7 Fair – with Harmful Bias Managed Fairness in AI includes concerns for equality and equity by addressing issues such as harm- ful bias and discrimination. Standards of fairness can be complex and difficult to define be- cause perceptions of fairness differ among cultures and may shift depending on application. Organizations’ risk management efforts will be enhanced by recognizing and considering these differences. Systems in which harmful biases are mitigated are not necessarily fair. For example, systems in which predictions are somewhat balanced across demographic groups may still be inaccessible to individuals with disabilities or affected by the digital divide or may exacerbate existing disparities or systemic biases. Page 17 NIST AI 100-1 AI RMF 1.0 Bias is broader than demographic balance and data representativeness. NIST has identified three major categories of AI bias to be considered and managed: systemic, computational and statistical, and human-cognitive."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_49",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\ngroups may still be inaccessible to individuals with disabilities or affected by the digital divide or may exacerbate existing disparities or systemic biases. Page 17 NIST AI 100-1 AI RMF 1.0 Bias is broader than demographic balance and data representativeness. NIST has identified three major categories of AI bias to be considered and managed: systemic, computational and statistical, and human-cognitive. Each of these can occur in the absence of prejudice, partiality, or discriminatory intent. Systemic bias can be present in AI datasets, the orga- nizational norms, practices, and processes across the AI lifecycle, and the broader society that uses AI systems. Computational and statistical biases can be present in AI datasets and algorithmic processes, and often stem from systematic errors due to non-representative samples. Human-cognitive biases relate to how an individual or group perceives AI sys- tem information to make a decision or fill in missing information, or how humans think about purposes and functions of an AI system. Human-cognitive biases are omnipresent in decision-making processes across the AI lifecycle and system use, including the design, implementation, operation, and maintenance of AI. Bias exists in many forms and can become ingrained in the automated systems that help make decisions about our lives."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_50",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nor fill in missing information, or how humans think about purposes and functions of an AI system. Human-cognitive biases are omnipresent in decision-making processes across the AI lifecycle and system use, including the design, implementation, operation, and maintenance of AI. Bias exists in many forms and can become ingrained in the automated systems that help make decisions about our lives. While bias is not always a negative phenomenon, AI sys- tems can potentially increase the speed and scale of biases and perpetuate and amplify harms to individuals, groups, communities, organizations, and society. Bias is tightly asso- ciated with the concepts of transparency as well as fairness in society. (For more informa- tion about bias, including the three categories, see NIST Special Publication 1270, Towards a Standard for Identifying and Managing Bias in Artificial Intelligence.) Page 18 NIST AI 100-1 AI RMF 1.0 4. Effectiveness of the AI RMF Evaluations of AI RMF effectiveness – including ways to measure bottom-line improve- ments in the trustworthiness of AI systems – will be part of future NIST activities, in conjunction with the AI community. Organizations and other users of the Framework are encouraged to periodically evaluate whether the AI RMF has improved their ability to manage AI risks, including but not lim- ited to their policies, processes, practices, implementation plans, indicators, measurements, and expected outcomes."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_51",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nthe trustworthiness of AI systems – will be part of future NIST activities, in conjunction with the AI community. Organizations and other users of the Framework are encouraged to periodically evaluate whether the AI RMF has improved their ability to manage AI risks, including but not lim- ited to their policies, processes, practices, implementation plans, indicators, measurements, and expected outcomes. NIST intends to work collaboratively with others to develop met- rics, methodologies, and goals for evaluating the AI RMF’s effectiveness, and to broadly share results and supporting information."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_52",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nto periodically evaluate whether the AI RMF has improved their ability to manage AI risks, including but not lim- ited to their policies, processes, practices, implementation plans, indicators, measurements, and expected outcomes. NIST intends to work collaboratively with others to develop met- rics, methodologies, and goals for evaluating the AI RMF’s effectiveness, and to broadly share results and supporting information. Framework users are expected to benefit from: • enhanced processes for governing, mapping, measuring, and managing AI risk, and clearly documenting outcomes; • improved awareness of the relationships and tradeoffs among trustworthiness char- acteristics, socio-technical approaches, and AI risks; • explicit processes for making go/no-go system commissioning and deployment deci- sions; • established policies, processes, practices, and procedures for improving organiza- tional accountability efforts related to AI system risks; • enhanced organizational culture which prioritizes the identification and management of AI system risks and potential impacts to individuals, communities, organizations, and society; • better information sharing within and across organizations about risks, decision- making processes, responsibilities, common pitfalls, TEVV practices, and approaches for continuous improvement; • greater contextual knowledge for increased awareness of downstream risks; • strengthened engagement with interested parties and relevant AI actors; and • augmented capacity for TEVV of AI systems and associated risks."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_53",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nindividuals, communities, organizations, and society; • better information sharing within and across organizations about risks, decision- making processes, responsibilities, common pitfalls, TEVV practices, and approaches for continuous improvement; • greater contextual knowledge for increased awareness of downstream risks; • strengthened engagement with interested parties and relevant AI actors; and • augmented capacity for TEVV of AI systems and associated risks. Page 19 NIST AI 100-1 AI RMF 1.0 Part 2: Core and Profiles 5. AI RMF Core The AI RMF Core provides outcomes and actions that enable dialogue, understanding, and activities to manage AI risks and responsibly develop trustworthy AI systems. As illus- trated in Figure 5, the Core is composed of four functions: GOVERN ,MAP ,MEASURE , and MANAGE . Each of these high-level functions is broken down into categories and sub- categories. Categories and subcategories are subdivided into specific actions and outcomes. Actions do not constitute a checklist, nor are they necessarily an ordered set of steps. Fig. 5. Functions organize AI risk management activities at their highest level to govern, map, measure, and manage AI risks. Governance is designed to be a cross-cutting function to inform and be infused throughout the other three functions. Risk management should be continuous, timely, and performed throughout the AI system lifecycle dimensions."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_54",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nare they necessarily an ordered set of steps. Fig. 5. Functions organize AI risk management activities at their highest level to govern, map, measure, and manage AI risks. Governance is designed to be a cross-cutting function to inform and be infused throughout the other three functions. Risk management should be continuous, timely, and performed throughout the AI system lifecycle dimensions. AI RMF Core functions should be carried out in a way that reflects diverse and multidisciplinary perspectives, potentially including the views of AI actors out- side the organization. Having a diverse team contributes to more open sharing of ideas and assumptions about purposes and functions of the technology being designed, developed, Page 20 NIST AI 100-1 AI RMF 1.0 deployed, or evaluated – which can create opportunities to surface problems and identify existing and emergent risks. An online companion resource to the AI RMF, the NIST AI RMF Playbook, is available to help organizations navigate the AI RMF and achieve its outcomes through suggested tactical actions they can apply within their own contexts. Like the AI RMF, the Playbook is voluntary and organizations can utilize the suggestions according to their needs and interests. Playbook users can create tailored guidance selected from suggested material for their own use and contribute their suggestions for sharing with the broader community."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_55",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nRMF and achieve its outcomes through suggested tactical actions they can apply within their own contexts. Like the AI RMF, the Playbook is voluntary and organizations can utilize the suggestions according to their needs and interests. Playbook users can create tailored guidance selected from suggested material for their own use and contribute their suggestions for sharing with the broader community. Along with the AI RMF, the Playbook is part of the NIST Trustworthy and Responsible AI Resource Center. Framework users may apply these functions as best suits their needs for managing AI risks based on their resources and capabilities. Some organizations may choose to select from among the categories and subcategories; others may choose and have the capacity to apply all categories and subcategories. Assuming a governance struc- ture is in place, functions may be performed in any order across the AI lifecycle as deemed to add value by a user of the framework. After instituting the outcomes in GOVERN , most users of the AI RMF would start with the MAP function and con- tinue to MEASURE orMANAGE . However users integrate the functions, the process should be iterative, with cross-referencing between functions as necessary. Simi- larly, there are categories and subcategories with elements that apply to multiple functions, or that logically should take place before certain subcategory decisions."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_56",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\n, most users of the AI RMF would start with the MAP function and con- tinue to MEASURE orMANAGE . However users integrate the functions, the process should be iterative, with cross-referencing between functions as necessary. Simi- larly, there are categories and subcategories with elements that apply to multiple functions, or that logically should take place before certain subcategory decisions. 5.1 Govern The GOVERN function: • cultivates and implements a culture of risk management within organizations design- ing, developing, deploying, evaluating, or acquiring AI systems; • outlines processes, documents, and organizational schemes that anticipate, identify, and manage the risks a system can pose, including to users and others across society – and procedures to achieve those outcomes; • incorporates processes to assess potential impacts; • provides a structure by which AI risk management functions can align with organi- zational principles, policies, and strategic priorities; • connects technical aspects of AI system design and development to organizational values and principles, and enables organizational practices and competencies for the individuals involved in acquiring, training, deploying, and monitoring such systems; and • addresses full product lifecycle and associated processes, including legal and other issues concerning use of third-party software or hardware systems and data."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_57",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nand strategic priorities; • connects technical aspects of AI system design and development to organizational values and principles, and enables organizational practices and competencies for the individuals involved in acquiring, training, deploying, and monitoring such systems; and • addresses full product lifecycle and associated processes, including legal and other issues concerning use of third-party software or hardware systems and data. Page 21 NIST AI 100-1 AI RMF 1.0 GOVERN is a cross-cutting function that is infused throughout AI risk management and enables the other functions of the process. Aspects of GOVERN , especially those related to compliance or evaluation, should be integrated into each of the other functions. Attention to governance is a continual and intrinsic requirement for effective AI risk management over an AI system’s lifespan and the organization’s hierarchy. Strong governance can drive and enhance internal practices and norms to facilitate orga- nizational risk culture. Governing authorities can determine the overarching policies that direct an organization’s mission, goals, values, culture, and risk tolerance. Senior leader- ship sets the tone for risk management within an organization, and with it, organizational culture. Management aligns the technical aspects of AI risk management to policies and operations. Documentation can enhance transparency, improve human review processes, and bolster accountability in AI system teams."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_58",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\ndetermine the overarching policies that direct an organization’s mission, goals, values, culture, and risk tolerance. Senior leader- ship sets the tone for risk management within an organization, and with it, organizational culture. Management aligns the technical aspects of AI risk management to policies and operations. Documentation can enhance transparency, improve human review processes, and bolster accountability in AI system teams. After putting in place the structures, systems, processes, and teams described in the GOV- ERN function, organizations should benefit from a purpose-driven culture focused on risk understanding and management. It is incumbent on Framework users to continue to ex- ecute the GOVERN function as knowledge, cultures, and needs or expectations from AI actors evolve over time. Practices related to governing AI risks are described in the NIST AI RMF Playbook. Table 1 lists the GOVERN function’s categories and subcategories. Table 1: Categories and subcategories for the GOVERN function. GOVERN 1: Policies, processes, procedures, and practices across the organization related to the mapping, measuring, and managing of AI risks are in place, transparent, and implemented effectively.GOVERN 1.1: Legal and regulatory requirements involving AI are understood, managed, and documented. GOVERN 1.2: The characteristics of trustworthy AI are inte- grated into organizational policies, processes, procedures, and practices."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_59",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nfor the GOVERN function. GOVERN 1: Policies, processes, procedures, and practices across the organization related to the mapping, measuring, and managing of AI risks are in place, transparent, and implemented effectively.GOVERN 1.1: Legal and regulatory requirements involving AI are understood, managed, and documented. GOVERN 1.2: The characteristics of trustworthy AI are inte- grated into organizational policies, processes, procedures, and practices. GOVERN 1.3: Processes, procedures, and practices are in place to determine the needed level of risk management activities based on the organization’s risk tolerance. GOVERN 1.4:The risk management process and its outcomes are established through transparent policies, procedures, and other controls based on organizational risk priorities.Categories Subcategories Continued on next page Page 22 NIST AI 100-1 AI RMF 1.0 Table 1: Categories and subcategories for the GOVERN function. (Continued) GOVERN 1.5: Ongoing monitoring and periodic review of the risk management process and its outcomes are planned and or- ganizational roles and responsibilities clearly defined, including determining the frequency of periodic review. GOVERN 1.6: Mechanisms are in place to inventory AI systems and are resourced according to organizational risk priorities."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_60",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nTable 1: Categories and subcategories for the GOVERN function. (Continued) GOVERN 1.5: Ongoing monitoring and periodic review of the risk management process and its outcomes are planned and or- ganizational roles and responsibilities clearly defined, including determining the frequency of periodic review. GOVERN 1.6: Mechanisms are in place to inventory AI systems and are resourced according to organizational risk priorities. GOVERN 1.7: Processes and procedures are in place for decom- missioning and phasing out AI systems safely and in a man- ner that does not increase risks or decrease the organization’s trustworthiness. GOVERN 2: Accountability structures are in place so that the appropriate teams and individuals are empowered, responsible, and trained for mapping, measuring, and managing AI risks.GOVERN 2.1: Roles and responsibilities and lines of communi- cation related to mapping, measuring, and managing AI risks are documented and are clear to individuals and teams throughout the organization. GOVERN 2.2: The organization’s personnel and partners receive AI risk management training to enable them to perform their du- ties and responsibilities consistent with related policies, proce- dures, and agreements. GOVERN 2.3: Executive leadership of the organization takes re- sponsibility for decisions about risks associated with AI system development and deployment."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_61",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nare clear to individuals and teams throughout the organization. GOVERN 2.2: The organization’s personnel and partners receive AI risk management training to enable them to perform their du- ties and responsibilities consistent with related policies, proce- dures, and agreements. GOVERN 2.3: Executive leadership of the organization takes re- sponsibility for decisions about risks associated with AI system development and deployment. GOVERN 3: Workforce diversity, equity, inclusion, and accessibility processes are prioritized in the mapping, measuring, and managing of AI risks throughout the lifecycle.GOVERN 3.1: Decision-making related to mapping, measuring, and managing AI risks throughout the lifecycle is informed by a diverse team (e.g., diversity of demographics, disciplines, expe- rience, expertise, and backgrounds). GOVERN 3.2: Policies and procedures are in place to define and differentiate roles and responsibilities for human-AI configura- tions and oversight of AI systems. GOVERN 4: Organizational teams are committed to a cultureGOVERN 4.1: Organizational policies and practices are in place to foster a critical thinking and safety-first mindset in the design, development, deployment, and uses of AI systems to minimize potential negative impacts.Categories Subcategories Continued on next page Page 23 NIST AI 100-1 AI RMF 1.0 Table 1: Categories and subcategories for the GOVERN function."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_62",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nOrganizational teams are committed to a cultureGOVERN 4.1: Organizational policies and practices are in place to foster a critical thinking and safety-first mindset in the design, development, deployment, and uses of AI systems to minimize potential negative impacts.Categories Subcategories Continued on next page Page 23 NIST AI 100-1 AI RMF 1.0 Table 1: Categories and subcategories for the GOVERN function. (Continued) that considers and communicates AI risk.GOVERN 4.2: Organizational teams document the risks and po- tential impacts of the AI technology they design, develop, deploy, evaluate, and use, and they communicate about the impacts more broadly. GOVERN 4.3: Organizational practices are in place to enable AI testing, identification of incidents, and information sharing. GOVERN 5: Processes are in place for robust engagement with relevant AI actors.GOVERN 5.1: Organizational policies and practices are in place to collect, consider, prioritize, and integrate feedback from those external to the team that developed or deployed the AI system regarding the potential individual and societal impacts related to AI risks. GOVERN 5.2: Mechanisms are established to enable the team that developed or deployed AI systems to regularly incorporate adjudicated feedback from relevant AI actors into system design and implementation."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_63",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nto collect, consider, prioritize, and integrate feedback from those external to the team that developed or deployed the AI system regarding the potential individual and societal impacts related to AI risks. GOVERN 5.2: Mechanisms are established to enable the team that developed or deployed AI systems to regularly incorporate adjudicated feedback from relevant AI actors into system design and implementation. GOVERN 6:Policies and procedures are in place to address AI risks and benefits arising from third-party software and data and other supply chain issues.GOVERN 6.1: Policies and procedures are in place that address AI risks associated with third-party entities, including risks of in- fringement of a third-party’s intellectual property or other rights. GOVERN 6.2: Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be high-risk.Categories Subcategories 5.2 Map The MAP function establishes the context to frame risks related to an AI system. The AI lifecycle consists of many interdependent activities involving a diverse set of actors (See Figure 3). In practice, AI actors in charge of one part of the process often do not have full visibility or control over other parts and their associated contexts. The interdependencies between these activities, and among the relevant AI actors, can make it difficult to reliably anticipate impacts of AI systems."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_64",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\ninterdependent activities involving a diverse set of actors (See Figure 3). In practice, AI actors in charge of one part of the process often do not have full visibility or control over other parts and their associated contexts. The interdependencies between these activities, and among the relevant AI actors, can make it difficult to reliably anticipate impacts of AI systems. For example, early decisions in identifying purposes and objectives of an AI system can alter its behavior and capabilities, and the dynamics of de- ployment setting (such as end users or impacted individuals) can shape the impacts of AI system decisions. As a result, the best intentions within one dimension of the AI lifecycle can be undermined via interactions with decisions and conditions in other, later activities. Page 24 NIST AI 100-1 AI RMF 1.0 This complexity and varying levels of visibility can introduce uncertainty into risk man- agement practices. Anticipating, assessing, and otherwise addressing potential sources of negative risk can mitigate this uncertainty and enhance the integrity of the decision process. The information gathered while carrying out the MAP function enables negative risk pre- vention and informs decisions for processes such as model management, as well as an initial decision about appropriateness or the need for an AI solution. Outcomes in the MAP function are the basis for the MEASURE and MANAGE functions."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_65",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nand enhance the integrity of the decision process. The information gathered while carrying out the MAP function enables negative risk pre- vention and informs decisions for processes such as model management, as well as an initial decision about appropriateness or the need for an AI solution. Outcomes in the MAP function are the basis for the MEASURE and MANAGE functions. Without contex- tual knowledge, and awareness of risks within the identified contexts, risk management is difficult to perform. The MAP function is intended to enhance an organization’s ability to identify risks and broader contributing factors. Implementation of this function is enhanced by incorporating perspectives from a diverse internal team and engagement with those external to the team that developed or deployed the AI system. Engagement with external collaborators, end users, potentially impacted communities, and others may vary based on the risk level of a particular AI system, the makeup of the internal team, and organizational policies."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_66",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nof this function is enhanced by incorporating perspectives from a diverse internal team and engagement with those external to the team that developed or deployed the AI system. Engagement with external collaborators, end users, potentially impacted communities, and others may vary based on the risk level of a particular AI system, the makeup of the internal team, and organizational policies. Gathering such broad perspec- tives can help organizations proactively prevent negative risks and develop more trustwor- thy AI systems by: • improving their capacity for understanding contexts; • checking their assumptions about context of use; • enabling recognition of when systems are not functional within or out of their in- tended context; • identifying positive and beneficial uses of their existing AI systems; • improving understanding of limitations in AI and ML processes; • identifying constraints in real-world applications that may lead to negative impacts; • identifying known and foreseeable negative impacts related to intended use of AI systems; and • anticipating risks of the use of AI systems beyond intended use. After completing the MAP function, Framework users should have sufficient contextual knowledge about AI system impacts to inform an initial go/no-go decision about whether to design, develop, or deploy an AI system."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_67",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nimpacts; • identifying known and foreseeable negative impacts related to intended use of AI systems; and • anticipating risks of the use of AI systems beyond intended use. After completing the MAP function, Framework users should have sufficient contextual knowledge about AI system impacts to inform an initial go/no-go decision about whether to design, develop, or deploy an AI system. If a decision is made to proceed, organizations should utilize the MEASURE and MANAGE functions along with policies and procedures put into place in the GOVERN function to assist in AI risk management efforts. It is incum- bent on Framework users to continue applying the MAP function to AI systems as context, capabilities, risks, benefits, and potential impacts evolve over time. Practices related to mapping AI risks are described in the NIST AI RMF Playbook. Table 2 lists the MAP function’s categories and subcategories. Page 25 NIST AI 100-1 AI RMF 1.0 Table 2: Categories and subcategories for the MAP function. MAP 1:Context is established and understood.MAP 1.1:Intended purposes, potentially beneficial uses, context- specific laws, norms and expectations, and prospective settings in which the AI system will be deployed are understood and docu- mented."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_68",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nPlaybook. Table 2 lists the MAP function’s categories and subcategories. Page 25 NIST AI 100-1 AI RMF 1.0 Table 2: Categories and subcategories for the MAP function. MAP 1:Context is established and understood.MAP 1.1:Intended purposes, potentially beneficial uses, context- specific laws, norms and expectations, and prospective settings in which the AI system will be deployed are understood and docu- mented. Considerations include: the specific set or types of users along with their expectations; potential positive and negative im- pacts of system uses to individuals, communities, organizations, society, and the planet; assumptions and related limitations about AI system purposes, uses, and risks across the development or product AI lifecycle; and related TEVV and system metrics. MAP 1.2: Interdisciplinary AI actors, competencies, skills, and capacities for establishing context reflect demographic diversity and broad domain and user experience expertise, and their par- ticipation is documented. Opportunities for interdisciplinary col- laboration are prioritized. MAP 1.3: The organization’s mission and relevant goals for AI technology are understood and documented. MAP 1.4: The business value or context of business use has been clearly defined or – in the case of assessing existing AI systems – re-evaluated. MAP 1.5: Organizational risk tolerances are determined and documented."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_69",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nticipation is documented. Opportunities for interdisciplinary col- laboration are prioritized. MAP 1.3: The organization’s mission and relevant goals for AI technology are understood and documented. MAP 1.4: The business value or context of business use has been clearly defined or – in the case of assessing existing AI systems – re-evaluated. MAP 1.5: Organizational risk tolerances are determined and documented. MAP 1.6: System requirements (e.g., “the system shall respect the privacy of its users”) are elicited from and understood by rel- evant AI actors. Design decisions take socio-technical implica- tions into account to address AI risks. MAP 2: Categorization of the AI system is performed.MAP 2.1: The specific tasks and methods used to implement the tasks that the AI system will support are defined (e.g., classifiers, generative models, recommenders). MAP 2.2: Information about the AI system’s knowledge limits and how system output may be utilized and overseen by humans is documented. Documentation provides sufficient information to assist relevant AI actors when making decisions and taking subsequent actions.Categories Subcategories Continued on next page Page 26 NIST AI 100-1 AI RMF 1.0 Table 2: Categories and subcategories for the MAP function."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_70",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nMAP 2.2: Information about the AI system’s knowledge limits and how system output may be utilized and overseen by humans is documented. Documentation provides sufficient information to assist relevant AI actors when making decisions and taking subsequent actions.Categories Subcategories Continued on next page Page 26 NIST AI 100-1 AI RMF 1.0 Table 2: Categories and subcategories for the MAP function. (Continued) MAP 2.3: Scientific integrity and TEVV considerations are iden- tified and documented, including those related to experimental design, data collection and selection (e.g., availability, repre- sentativeness, suitability), system trustworthiness, and construct validation. MAP 3:AI capabilities, targeted usage, goals, and expected benefits and costs compared with appropriate benchmarks are understood.MAP 3.1: Potential benefits of intended AI system functionality and performance are examined and documented. MAP 3.2: Potential costs, including non-monetary costs, which result from expected or realized AI errors or system functionality and trustworthiness – as connected to organizational risk toler- ance – are examined and documented. MAP 3.3: Targeted application scope is specified and docu- mented based on the system’s capability, established context, and AI system categorization."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_71",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nand performance are examined and documented. MAP 3.2: Potential costs, including non-monetary costs, which result from expected or realized AI errors or system functionality and trustworthiness – as connected to organizational risk toler- ance – are examined and documented. MAP 3.3: Targeted application scope is specified and docu- mented based on the system’s capability, established context, and AI system categorization. MAP 3.4: Processes for operator and practitioner proficiency with AI system performance and trustworthiness – and relevant technical standards and certifications – are defined, assessed, and documented. MAP 3.5: Processes for human oversight are defined, assessed, and documented in accordance with organizational policies from theGOVERN function. MAP 4:Risks and benefits are mapped for all components of the AI system including third-party software and data.MAP 4.1: Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or soft- ware – are in place, followed, and documented, as are risks of in- fringement of a third party’s intellectual property or other rights. MAP 4.2: Internal risk controls for components of the AI sys- tem, including third-party AI technologies, are identified and documented."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_72",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nAI technology and legal risks of its components – including the use of third-party data or soft- ware – are in place, followed, and documented, as are risks of in- fringement of a third party’s intellectual property or other rights. MAP 4.2: Internal risk controls for components of the AI sys- tem, including third-party AI technologies, are identified and documented. MAP 5:Impacts to individuals, groups, communities, organizations, and society are characterized.MAP 5.1: Likelihood and magnitude of each identified impact (both potentially beneficial and harmful) based on expected use, past uses of AI systems in similar contexts, public incident re- ports, feedback from those external to the team that developed or deployed the AI system, or other data are identified and documented.Categories Subcategories Continued on next page Page 27 NIST AI 100-1 AI RMF 1.0 Table 2: Categories and subcategories for the MAP function. (Continued) MAP 5.2: Practices and personnel for supporting regular en- gagement with relevant AI actors and integrating feedback about positive, negative, and unanticipated impacts are in place and documented.Categories Subcategories 5.3 Measure The MEASURE function employs quantitative, qualitative, or mixed-method tools, tech- niques, and methodologies to analyze, assess, benchmark, and monitor AI risk and related impacts. It uses knowledge relevant to AI risks identified in the MAP function and informs the MANAGE function."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_73",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nAI actors and integrating feedback about positive, negative, and unanticipated impacts are in place and documented.Categories Subcategories 5.3 Measure The MEASURE function employs quantitative, qualitative, or mixed-method tools, tech- niques, and methodologies to analyze, assess, benchmark, and monitor AI risk and related impacts. It uses knowledge relevant to AI risks identified in the MAP function and informs the MANAGE function. AI systems should be tested before their deployment and regu- larly while in operation. AI risk measurements include documenting aspects of systems’ functionality and trustworthiness. Measuring AI risks includes tracking metrics for trustworthy characteristics, social impact, and human-AI configurations. Processes developed or adopted in the MEASURE function should include rigorous software testing and performance assessment methodologies with associated measures of uncertainty, comparisons to performance benchmarks, and formal- ized reporting and documentation of results. Processes for independent review can improve the effectiveness of testing and can mitigate internal biases and potential conflicts of inter- est. Where tradeoffs among the trustworthy characteristics arise, measurement provides a trace- able basis to inform management decisions."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_74",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\ntesting and performance assessment methodologies with associated measures of uncertainty, comparisons to performance benchmarks, and formal- ized reporting and documentation of results. Processes for independent review can improve the effectiveness of testing and can mitigate internal biases and potential conflicts of inter- est. Where tradeoffs among the trustworthy characteristics arise, measurement provides a trace- able basis to inform management decisions. Options may include recalibration, impact mitigation, or removal of the system from design, development, production, or use, as well as a range of compensating, detective, deterrent, directive, and recovery controls. After completing the MEASURE function, objective, repeatable, or scalable test, evaluation, verification, and validation (TEVV) processes including metrics, methods, and methodolo- gies are in place, followed, and documented. Metrics and measurement methodologies should adhere to scientific, legal, and ethical norms and be carried out in an open and trans- parent process. New types of measurement, qualitative and quantitative, may need to be developed. The degree to which each measurement type provides unique and meaningful information to the assessment of AI risks should be considered. Framework users will en- hance their capacity to comprehensively evaluate system trustworthiness, identify and track existing and emergent risks, and verify efficacy of the metrics."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_75",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nparent process. New types of measurement, qualitative and quantitative, may need to be developed. The degree to which each measurement type provides unique and meaningful information to the assessment of AI risks should be considered. Framework users will en- hance their capacity to comprehensively evaluate system trustworthiness, identify and track existing and emergent risks, and verify efficacy of the metrics. Measurement outcomes will be utilized in the MANAGE function to assist risk monitoring and response efforts. It is in- cumbent on Framework users to continue applying the MEASURE function to AI systems as knowledge, methodologies, risks, and impacts evolve over time. Page 28 NIST AI 100-1 AI RMF 1.0 Practices related to measuring AI risks are described in the NIST AI RMF Playbook. Table 3 lists the MEASURE function’s categories and subcategories. Table 3: Categories and subcategories for the MEASURE function. MEASURE 1: Appropriate methods and metrics are identified and applied.MEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for imple- mentation starting with the most significant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented. MEASURE 1.2: Appropriateness of AI metrics and effectiveness of existing controls are regularly assessed and updated, including reports of errors and potential impacts on affected communities."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_76",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nenumerated during the MAP function are selected for imple- mentation starting with the most significant AI risks. The risks or trustworthiness characteristics that will not – or cannot – be measured are properly documented. MEASURE 1.2: Appropriateness of AI metrics and effectiveness of existing controls are regularly assessed and updated, including reports of errors and potential impacts on affected communities. MEASURE 1.3: Internal experts who did not serve as front-line developers for the system and/or independent assessors are in- volved in regular assessments and updates. Domain experts, users, AI actors external to the team that developed or deployed the AI system, and affected communities are consulted in support of assessments as necessary per organizational risk tolerance. MEASURE 2:AI systems are evaluated for trustworthy characteristics.MEASURE 2.1:Test sets, metrics, and details about the tools used during TEVV are documented. MEASURE 2.2: Evaluations involving human subjects meet ap- plicable requirements (including human subject protection) and are representative of the relevant population. MEASURE 2.3: AI system performance or assurance criteria are measured qualitatively or quantitatively and demonstrated for conditions similar to deployment setting(s). Measures are documented. MEASURE 2.4: The functionality and behavior of the AI sys- tem and its components – as identified in the MAP function – are monitored when in production."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_77",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nsubject protection) and are representative of the relevant population. MEASURE 2.3: AI system performance or assurance criteria are measured qualitatively or quantitatively and demonstrated for conditions similar to deployment setting(s). Measures are documented. MEASURE 2.4: The functionality and behavior of the AI sys- tem and its components – as identified in the MAP function – are monitored when in production. MEASURE 2.5: The AI system to be deployed is demonstrated to be valid and reliable. Limitations of the generalizability be- yond the conditions under which the technology was developed are documented.Categories Subcategories Continued on next page Page 29 NIST AI 100-1 AI RMF 1.0 Table 3: Categories and subcategories for the MEASURE function. (Continued) MEASURE 2.6: The AI system is evaluated regularly for safety risks – as identified in the MAP function. The AI system to be de- ployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if made to operate beyond its knowledge limits. Safety metrics re- flect system reliability and robustness, real-time monitoring, and response times for AI system failures. MEASURE 2.7: AI system security and resilience – as identified in the MAP function – are evaluated and documented. MEASURE 2.8: Risks associated with transparency and account- ability – as identified in the MAP function – are examined and documented."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_78",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nits knowledge limits. Safety metrics re- flect system reliability and robustness, real-time monitoring, and response times for AI system failures. MEASURE 2.7: AI system security and resilience – as identified in the MAP function – are evaluated and documented. MEASURE 2.8: Risks associated with transparency and account- ability – as identified in the MAP function – are examined and documented. MEASURE 2.9: The AI model is explained, validated, and docu- mented, and AI system output is interpreted within its context – as identified in the MAP function – to inform responsible use and governance. MEASURE 2.10: Privacy risk of the AI system – as identified in theMAP function – is examined and documented. MEASURE 2.11: Fairness and bias – as identified in the MAP function – are evaluated and results are documented. MEASURE 2.12: Environmental impact and sustainability of AI model training and management activities – as identified in the MAP function – are assessed and documented. MEASURE 2.13: Effectiveness of the employed TEVV met- rics and processes in the MEASURE function are evaluated and documented. MEASURE 3: Mechanisms for tracking identified AI risks over time are in place.MEASURE 3.1: Approaches, personnel, and documentation are in place to regularly identify and track existing, unanticipated, and emergent AI risks based on factors such as intended and ac- tual performance in deployed contexts."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_79",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nthe employed TEVV met- rics and processes in the MEASURE function are evaluated and documented. MEASURE 3: Mechanisms for tracking identified AI risks over time are in place.MEASURE 3.1: Approaches, personnel, and documentation are in place to regularly identify and track existing, unanticipated, and emergent AI risks based on factors such as intended and ac- tual performance in deployed contexts. MEASURE 3.2: Risk tracking approaches are considered for settings where AI risks are difficult to assess using currently available measurement techniques or where metrics are not yet available.Categories Subcategories Continued on next page Page 30 NIST AI 100-1 AI RMF 1.0 Table 3: Categories and subcategories for the MEASURE function. (Continued) MEASURE 3.3: Feedback processes for end users and impacted communities to report problems and appeal system outcomes are established and integrated into AI system evaluation metrics. MEASURE 4: Feedback about efficacy of measurement is gathered and assessed.MEASURE 4.1:Measurement approaches for identifying AI risks are connected to deployment context(s) and informed through consultation with domain experts and other end users. Ap- proaches are documented. MEASURE 4.2: Measurement results regarding AI system trust- worthiness in deployment context(s) and across the AI lifecycle are informed by input from domain experts and relevant AI ac- tors to validate whether the system is performing consistently as intended. Results are documented."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_80",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nto deployment context(s) and informed through consultation with domain experts and other end users. Ap- proaches are documented. MEASURE 4.2: Measurement results regarding AI system trust- worthiness in deployment context(s) and across the AI lifecycle are informed by input from domain experts and relevant AI ac- tors to validate whether the system is performing consistently as intended. Results are documented. MEASURE 4.3: Measurable performance improvements or de- clines based on consultations with relevant AI actors, in- cluding affected communities, and field data about context- relevant risks and trustworthiness characteristics are identified and documented.Categories Subcategories 5.4 Manage The MANAGE function entails allocating risk resources to mapped and measured risks on a regular basis and as defined by the GOVERN function. Risk treatment comprises plans to respond to, recover from, and communicate about incidents or events. Contextual information gleaned from expert consultation and input from relevant AI actors – established in GOVERN and carried out in MAP – is utilized in this function to decrease the likelihood of system failures and negative impacts. Systematic documentation practices established in GOVERN and utilized in MAP and MEASURE bolster AI risk management efforts and increase transparency and accountability. Processes for assessing emergent risks are in place, along with mechanisms for continual improvement."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_81",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nestablished in GOVERN and carried out in MAP – is utilized in this function to decrease the likelihood of system failures and negative impacts. Systematic documentation practices established in GOVERN and utilized in MAP and MEASURE bolster AI risk management efforts and increase transparency and accountability. Processes for assessing emergent risks are in place, along with mechanisms for continual improvement. After completing the MANAGE function, plans for prioritizing risk and regular monitoring and improvement will be in place. Framework users will have enhanced capacity to man- age the risks of deployed AI systems and to allocate risk management resources based on assessed and prioritized risks. It is incumbent on Framework users to continue to apply the MANAGE function to deployed AI systems as methods, contexts, risks, and needs or expectations from relevant AI actors evolve over time. Page 31 NIST AI 100-1 AI RMF 1.0 Practices related to managing AI risks are described in the NIST AI RMF Playbook. Table 4 lists the MANAGE function’s categories and subcategories. Table 4: Categories and subcategories for the MANAGE function. MANAGE 1:AI risks based on assessments and other analytical output from the MAP and MEASURE functions are prioritized, responded to, and managed.MANAGE 1.1: A determination is made as to whether the AI system achieves its intended purposes and stated objectives and whether its development or deployment should proceed."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_82",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\ncategories and subcategories. Table 4: Categories and subcategories for the MANAGE function. MANAGE 1:AI risks based on assessments and other analytical output from the MAP and MEASURE functions are prioritized, responded to, and managed.MANAGE 1.1: A determination is made as to whether the AI system achieves its intended purposes and stated objectives and whether its development or deployment should proceed. MANAGE 1.2: Treatment of documented AI risks is prioritized based on impact, likelihood, and available resources or methods. MANAGE 1.3: Responses to the AI risks deemed high priority, as identified by the MAP function, are developed, planned, and doc- umented. Risk response options can include mitigating, transfer- ring, avoiding, or accepting. MANAGE 1.4: Negative residual risks (defined as the sum of all unmitigated risks) to both downstream acquirers of AI systems and end users are documented. MANAGE 2: Strategies to maximize AI benefits and minimize negative impacts are planned, prepared, implemented, documented, and informed by input from relevant AI actors.MANAGE 2.1: Resources required to manage AI risks are taken into account – along with viable non-AI alternative systems, ap- proaches, or methods – to reduce the magnitude or likelihood of potential impacts. MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems. MANAGE 2.3: Procedures are followed to respond to and recover from a previously unknown risk when it is identified."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_83",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nare taken into account – along with viable non-AI alternative systems, ap- proaches, or methods – to reduce the magnitude or likelihood of potential impacts. MANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems. MANAGE 2.3: Procedures are followed to respond to and recover from a previously unknown risk when it is identified. MANAGE 2.4: Mechanisms are in place and applied, and respon- sibilities are assigned and understood, to supersede, disengage, or deactivate AI systems that demonstrate performance or outcomes inconsistent with intended use. MANAGE 3:AI risks and benefits from third-party entities are managed.MANAGE 3.1: AI risks and benefits from third-party resources are regularly monitored, and risk controls are applied and documented. MANAGE 3.2: Pre-trained models which are used for develop- ment are monitored as part of AI system regular monitoring and maintenance.Categories Subcategories Continued on next page Page 32 NIST AI 100-1 AI RMF 1.0 Table 4: Categories and subcategories for the MANAGE function."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_84",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nAI risks and benefits from third-party resources are regularly monitored, and risk controls are applied and documented. MANAGE 3.2: Pre-trained models which are used for develop- ment are monitored as part of AI system regular monitoring and maintenance.Categories Subcategories Continued on next page Page 32 NIST AI 100-1 AI RMF 1.0 Table 4: Categories and subcategories for the MANAGE function. (Continued) MANAGE 4:Risk treatments, including response and recovery, and communication plans for the identified and measured AI risks are documented and monitored regularly.MANAGE 4.1: Post-deployment AI system monitoring plans are implemented, including mechanisms for capturing and eval- uating input from users and other relevant AI actors, appeal and override, decommissioning, incident response, recovery, and change management. MANAGE 4.2: Measurable activities for continual improvements are integrated into AI system updates and include regular engage- ment with interested parties, including relevant AI actors. MANAGE 4.3: Incidents and errors are communicated to relevant AI actors, including affected communities. Processes for track- ing, responding to, and recovering from incidents and errors are followed and documented.Categories Subcategories 6."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_85",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nand change management. MANAGE 4.2: Measurable activities for continual improvements are integrated into AI system updates and include regular engage- ment with interested parties, including relevant AI actors. MANAGE 4.3: Incidents and errors are communicated to relevant AI actors, including affected communities. Processes for track- ing, responding to, and recovering from incidents and errors are followed and documented.Categories Subcategories 6. AI RMF Profiles AI RMF use-case profiles are implementations of the AI RMF functions, categories, and subcategories for a specific setting or application based on the requirements, risk tolerance, and resources of the Framework user: for example, an AI RMF hiring profile or an AI RMF fair housing profile . Profiles may illustrate and offer insights into how risk can be managed at various stages of the AI lifecycle or in specific sector, technology, or end-use applications. AI RMF profiles assist organizations in deciding how they might best manage AI risk that is well-aligned with their goals, considers legal/regulatory requirements and best practices, and reflects risk management priorities. AI RMF temporal profiles are descriptions of either the current state or the desired, target state of specific AI risk management activities within a given sector, industry, organization, or application context. An AI RMF Current Profile indicates how AI is currently being managed and the related risks in terms of current outcomes."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_86",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nand best practices, and reflects risk management priorities. AI RMF temporal profiles are descriptions of either the current state or the desired, target state of specific AI risk management activities within a given sector, industry, organization, or application context. An AI RMF Current Profile indicates how AI is currently being managed and the related risks in terms of current outcomes. A Target Profile indicates the outcomes needed to achieve the desired or target AI risk management goals. Comparing Current and Target Profiles likely reveals gaps to be addressed to meet AI risk management objectives. Action plans can be developed to address these gaps to fulfill outcomes in a given category or subcategory. Prioritization of gap mitigation is driven by the user’s needs and risk management processes. This risk-based approach also enables Framework users to compare their approaches with other approaches and to gauge the resources needed (e.g., staffing, funding) to achieve AI risk management goals in a cost- effective, prioritized manner. Page 33 NIST AI 100-1 AI RMF 1.0 AI RMF cross-sectoral profiles cover risks of models or applications that can be used across use cases or sectors. Cross-sectoral profiles can also cover how to govern, map, measure, and manage risks for activities or business processes common across sectors such as the use of large language models, cloud-based services or acquisition."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_87",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nPage 33 NIST AI 100-1 AI RMF 1.0 AI RMF cross-sectoral profiles cover risks of models or applications that can be used across use cases or sectors. Cross-sectoral profiles can also cover how to govern, map, measure, and manage risks for activities or business processes common across sectors such as the use of large language models, cloud-based services or acquisition. This Framework does not prescribe profile templates, allowing for flexibility in implemen- tation. Page 34 NIST AI 100-1 AI RMF 1.0 Appendix A: Descriptions of AI Actor Tasks from Figures 2 and 3 AI Design tasks are performed during the Application Context and Data and Input phases of the AI lifecycle in Figure 2. AI Design actors create the concept and objectives of AI systems and are responsible for the planning, design, and data collection and processing tasks of the AI system so that the AI system is lawful and fit-for-purpose. Tasks include ar- ticulating and documenting the system’s concept and objectives, underlying assumptions, context, and requirements; gathering and cleaning data; and documenting the metadata and characteristics of the dataset."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_88",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nand objectives of AI systems and are responsible for the planning, design, and data collection and processing tasks of the AI system so that the AI system is lawful and fit-for-purpose. Tasks include ar- ticulating and documenting the system’s concept and objectives, underlying assumptions, context, and requirements; gathering and cleaning data; and documenting the metadata and characteristics of the dataset. AI actors in this category include data scientists, do- main experts, socio-cultural analysts, experts in the field of diversity, equity, inclusion, and accessibility, members of impacted communities, human factors experts (e.g., UX/UI design), governance experts, data engineers, data providers, system funders, product man- agers, third-party entities, evaluators, and legal and privacy governance. AI Development tasks are performed during the AI Model phase of the lifecycle in Figure 2. AI Development actors provide the initial infrastructure of AI systems and are responsi- ble for model building and interpretation tasks, which involve the creation, selection, cali- bration, training, and/or testing of models or algorithms. AI actors in this category include machine learning experts, data scientists, developers, third-party entities, legal and privacy governance experts, and experts in the socio-cultural and contextual factors associated with the deployment setting. AI Deployment tasks are performed during the Task and Output phase of the lifecycle in Figure 2."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_89",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\ncreation, selection, cali- bration, training, and/or testing of models or algorithms. AI actors in this category include machine learning experts, data scientists, developers, third-party entities, legal and privacy governance experts, and experts in the socio-cultural and contextual factors associated with the deployment setting. AI Deployment tasks are performed during the Task and Output phase of the lifecycle in Figure 2. AI Deployment actors are responsible for contextual decisions relating to how the AI system is used to assure deployment of the system into production. Related tasks include piloting the system, checking compatibility with legacy systems, ensuring regu- latory compliance, managing organizational change, and evaluating user experience. AI actors in this category include system integrators, software developers, end users, oper- ators and practitioners, evaluators, and domain experts with expertise in human factors, socio-cultural analysis, and governance. Operation and Monitoring tasks are performed in the Application Context/Operate and Monitor phase of the lifecycle in Figure 2. These tasks are carried out by AI actors who are responsible for operating the AI system and working with others to regularly assess system output and impacts."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_90",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\npractitioners, evaluators, and domain experts with expertise in human factors, socio-cultural analysis, and governance. Operation and Monitoring tasks are performed in the Application Context/Operate and Monitor phase of the lifecycle in Figure 2. These tasks are carried out by AI actors who are responsible for operating the AI system and working with others to regularly assess system output and impacts. AI actors in this category include system operators, domain experts, AI designers, users who interpret or incorporate the output of AI systems, product developers, evaluators and auditors, compliance experts, organizational management, and members of the research community. Test, Evaluation, Verification, and Validation (TEVV) tasks are performed throughout the AI lifecycle. They are carried out by AI actors who examine the AI system or its components, or detect and remediate problems. Ideally, AI actors carrying out verification Page 35 NIST AI 100-1 AI RMF 1.0 and validation tasks are distinct from those who perform test and evaluation actions. Tasks can be incorporated into a phase as early as design, where tests are planned in accordance with the design requirement. • TEVV tasks for design, planning, and data may center on internal and external vali- dation of assumptions for system design, data collection, and measurements relative to the intended context of deployment or application."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_91",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nperform test and evaluation actions. Tasks can be incorporated into a phase as early as design, where tests are planned in accordance with the design requirement. • TEVV tasks for design, planning, and data may center on internal and external vali- dation of assumptions for system design, data collection, and measurements relative to the intended context of deployment or application. • TEVV tasks for development (i.e., model building) include model validation and assessment. • TEVV tasks for deployment include system validation and integration in production, with testing, and recalibration for systems and process integration, user experience, and compliance with existing legal, regulatory, and ethical specifications. • TEVV tasks for operations involve ongoing monitoring for periodic updates, testing, and subject matter expert (SME) recalibration of models, the tracking of incidents or errors reported and their management, the detection of emergent properties and related impacts, and processes for redress and response. Human Factors tasks and activities are found throughout the dimensions of the AI life- cycle. They include human-centered design practices and methodologies, promoting the active involvement of end users and other interested parties and relevant AI actors, incor- porating context-specific norms and values in system design, evaluating and adapting end user experiences, and broad integration of humans and human dynamics in all phases of the AI lifecycle."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_92",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nthroughout the dimensions of the AI life- cycle. They include human-centered design practices and methodologies, promoting the active involvement of end users and other interested parties and relevant AI actors, incor- porating context-specific norms and values in system design, evaluating and adapting end user experiences, and broad integration of humans and human dynamics in all phases of the AI lifecycle. Human factors professionals provide multidisciplinary skills and perspectives to understand context of use, inform interdisciplinary and demographic diversity, engage in consultative processes, design and evaluate user experience, perform human-centered evaluation and testing, and inform impact assessments. Domain Expert tasks involve input from multidisciplinary practitioners or scholars who provide knowledge or expertise in – and about – an industry sector, economic sector, con- text, or application area where an AI system is being used. AI actors who are domain experts can provide essential guidance for AI system design and development, and inter- pret outputs in support of work performed by TEVV and AI impact assessment teams. AI Impact Assessment tasks include assessing and evaluating requirements for AI system accountability, combating harmful bias, examining impacts of AI systems, product safety, liability, and security, among others. AI actors such as impact assessors and evaluators provide technical, human factor, socio-cultural, and legal expertise."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_93",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nand inter- pret outputs in support of work performed by TEVV and AI impact assessment teams. AI Impact Assessment tasks include assessing and evaluating requirements for AI system accountability, combating harmful bias, examining impacts of AI systems, product safety, liability, and security, among others. AI actors such as impact assessors and evaluators provide technical, human factor, socio-cultural, and legal expertise. Procurement tasks are conducted by AI actors with financial, legal, or policy management authority for acquisition of AI models, products, or services from a third-party developer, vendor, or contractor. Governance and Oversight tasks are assumed by AI actors with management, fiduciary, and legal authority and responsibility for the organization in which an AI system is de- Page 36 NIST AI 100-1 AI RMF 1.0 signed, developed, and/or deployed. Key AI actors responsible for AI governance include organizational management, senior leadership, and the Board of Directors. These actors are parties that are concerned with the impact and sustainability of the organization as a whole. Additional AI Actors Third-party entities include providers, developers, vendors, and evaluators of data, al- gorithms, models, and/or systems and related services for another organization or the or- ganization’s customers or clients. Third-party entities are responsible for AI design and development tasks, in whole or in part."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_94",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nthat are concerned with the impact and sustainability of the organization as a whole. Additional AI Actors Third-party entities include providers, developers, vendors, and evaluators of data, al- gorithms, models, and/or systems and related services for another organization or the or- ganization’s customers or clients. Third-party entities are responsible for AI design and development tasks, in whole or in part. By definition, they are external to the design, devel- opment, or deployment team of the organization that acquires its technologies or services. The technologies acquired from third-party entities may be complex or opaque, and risk tolerances may not align with the deploying or operating organization. End users of an AI system are the individuals or groups that use the system for specific purposes. These individuals or groups interact with an AI system in a specific context. End users can range in competency from AI experts to first-time technology end users. Affected individuals/communities encompass all individuals, groups, communities, or organizations directly or indirectly affected by AI systems or decisions based on the output of AI systems. These individuals do not necessarily interact with the deployed system or application. Other AI actors may provide formal or quasi-formal norms or guidance for specifying and managing AI risks."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_95",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nexperts to first-time technology end users. Affected individuals/communities encompass all individuals, groups, communities, or organizations directly or indirectly affected by AI systems or decisions based on the output of AI systems. These individuals do not necessarily interact with the deployed system or application. Other AI actors may provide formal or quasi-formal norms or guidance for specifying and managing AI risks. They can include trade associations, standards developing or- ganizations, advocacy groups, researchers, environmental groups, and civil society organizations . The general public is most likely to directly experience positive and negative impacts of AI technologies. They may provide the motivation for actions taken by the AI actors. This group can include individuals, communities, and consumers associated with the context in which an AI system is developed or deployed. Page 37 NIST AI 100-1 AI RMF 1.0 Appendix B: How AI Risks Differ from Traditional Software Risks As with traditional software, risks from AI-based technology can be bigger than an en- terprise, span organizations, and lead to societal impacts. AI systems also bring a set of risks that are not comprehensively addressed by current risk frameworks and approaches. Some AI system features that present risks also can be beneficial. For example, pre-trained models and transfer learning can advance research and increase accuracy and resilience when compared to other models and approaches."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_96",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nterprise, span organizations, and lead to societal impacts. AI systems also bring a set of risks that are not comprehensively addressed by current risk frameworks and approaches. Some AI system features that present risks also can be beneficial. For example, pre-trained models and transfer learning can advance research and increase accuracy and resilience when compared to other models and approaches. Identifying contextual factors in the MAP function will assist AI actors in determining the level of risk and potential management efforts. Compared to traditional software, AI-specific risks that are new or increased include the following: • The data used for building an AI system may not be a true or appropriate representa- tion of the context or intended use of the AI system, and the ground truth may either not exist or not be available. Additionally, harmful bias and other data quality issues can affect AI system trustworthiness, which could lead to negative impacts. • AI system dependency and reliance on data for training tasks, combined with in- creased volume and complexity typically associated with such data. • Intentional or unintentional changes during training may fundamentally alter AI sys- tem performance. • Datasets used to train AI systems may become detached from their original and in- tended context or may become stale or outdated relative to deployment context."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_97",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nand reliance on data for training tasks, combined with in- creased volume and complexity typically associated with such data. • Intentional or unintentional changes during training may fundamentally alter AI sys- tem performance. • Datasets used to train AI systems may become detached from their original and in- tended context or may become stale or outdated relative to deployment context. • AI system scale and complexity (many systems contain billions or even trillions of decision points) housed within more traditional software applications. • Use of pre-trained models that can advance research and improve performance can also increase levels of statistical uncertainty and cause issues with bias management, scientific validity, and reproducibility. • Higher degree of difficulty in predicting failure modes for emergent properties of large-scale pre-trained models. • Privacy risk due to enhanced data aggregation capability for AI systems. • AI systems may require more frequent maintenance and triggers for conducting cor- rective maintenance due to data, model, or concept drift. • Increased opacity and concerns about reproducibility. • Underdeveloped software testing standards and inability to document AI-based prac- tices to the standard expected of traditionally engineered software for all but the simplest of cases."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_98",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\ncapability for AI systems. • AI systems may require more frequent maintenance and triggers for conducting cor- rective maintenance due to data, model, or concept drift. • Increased opacity and concerns about reproducibility. • Underdeveloped software testing standards and inability to document AI-based prac- tices to the standard expected of traditionally engineered software for all but the simplest of cases. • Difficulty in performing regular AI-based software testing, or determining what to test, since AI systems are not subject to the same controls as traditional code devel- opment. Page 38 NIST AI 100-1 AI RMF 1.0 • Computational costs for developing AI systems and their impact on the environment and planet. • Inability to predict or detect the side effects of AI-based systems beyond statistical measures. Privacy and cybersecurity risk management considerations and approaches are applicable in the design, development, deployment, evaluation, and use of AI systems. Privacy and cybersecurity risks are also considered as part of broader enterprise risk management con- siderations, which may incorporate AI risks."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_99",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nenvironment and planet. • Inability to predict or detect the side effects of AI-based systems beyond statistical measures. Privacy and cybersecurity risk management considerations and approaches are applicable in the design, development, deployment, evaluation, and use of AI systems. Privacy and cybersecurity risks are also considered as part of broader enterprise risk management con- siderations, which may incorporate AI risks. As part of the effort to address AI trustworthi- ness characteristics such as “Secure and Resilient” and “Privacy-Enhanced,” organizations may consider leveraging available standards and guidance that provide broad guidance to organizations to reduce security and privacy risks, such as, but not limited to, the NIST Cy- bersecurity Framework, the NIST Privacy Framework, the NIST Risk Management Frame- work, and the Secure Software Development Framework. These frameworks have some features in common with the AI RMF. Like most risk management approaches, they are outcome-based rather than prescriptive and are often structured around a Core set of func- tions, categories, and subcategories. While there are significant differences between these frameworks based on the domain addressed – and because AI risk management calls for addressing many other types of risks – frameworks like those mentioned above may inform security and privacy considerations in the MAP ,MEASURE , and MANAGE functions of the AI RMF."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_100",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\na Core set of func- tions, categories, and subcategories. While there are significant differences between these frameworks based on the domain addressed – and because AI risk management calls for addressing many other types of risks – frameworks like those mentioned above may inform security and privacy considerations in the MAP ,MEASURE , and MANAGE functions of the AI RMF. At the same time, guidance available before publication of this AI RMF does not compre- hensively address many AI system risks. For example, existing frameworks and guidance are unable to: • adequately manage the problem of harmful bias in AI systems; • confront the challenging risks related to generative AI; • comprehensively address security concerns related to evasion, model extraction, mem- bership inference, availability, or other machine learning attacks; • account for the complex attack surface of AI systems or other security abuses enabled by AI systems; and • consider risks associated with third-party AI technologies, transfer learning, and off- label use where AI systems may be trained for decision-making outside an organiza- tion’s security controls or trained in one domain and then “fine-tuned” for another. Both AI and traditional software technologies and systems are subject to rapid innovation. Technology advances should be monitored and deployed to take advantage of those devel- opments and work towards a future of AI that is both trustworthy and responsible."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_101",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nbe trained for decision-making outside an organiza- tion’s security controls or trained in one domain and then “fine-tuned” for another. Both AI and traditional software technologies and systems are subject to rapid innovation. Technology advances should be monitored and deployed to take advantage of those devel- opments and work towards a future of AI that is both trustworthy and responsible. Page 39 NIST AI 100-1 AI RMF 1.0 Appendix C: AI Risk Management and Human-AI Interaction Organizations that design, develop, or deploy AI systems for use in operational settings may enhance their AI risk management by understanding current limitations of human- AI interaction. The AI RMF provides opportunities to clearly define and differentiate the various human roles and responsibilities when using, interacting with, or managing AI systems. Many of the data-driven approaches that AI systems rely on attempt to convert or represent individual and social observational and decision-making practices into measurable quanti- ties. Representing complex human phenomena with mathematical models can come at the cost of removing necessary context. This loss of context may in turn make it difficult to understand individual and societal impacts that are key to AI risk management efforts. Issues that merit further consideration and research include: 1.Human roles and responsibilities in decision making and overseeing AI systems need to be clearly defined and differentiated."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_102",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nmodels can come at the cost of removing necessary context. This loss of context may in turn make it difficult to understand individual and societal impacts that are key to AI risk management efforts. Issues that merit further consideration and research include: 1.Human roles and responsibilities in decision making and overseeing AI systems need to be clearly defined and differentiated. Human-AI configurations can span from fully autonomous to fully manual. AI systems can autonomously make deci- sions, defer decision making to a human expert, or be used by a human decision maker as an additional opinion. Some AI systems may not require human oversight, such as models used to improve video compression. Other systems may specifically require human oversight. 2.Decisions that go into the design, development, deployment, evaluation, and use of AI systems reflect systemic and human cognitive biases. AI actors bring their cognitive biases, both individual and group, into the process. Biases can stem from end-user decision-making tasks and be introduced across the AI lifecycle via human assumptions, expectations, and decisions during design and modeling tasks. These biases, which are not necessarily always harmful, may be exacerbated by AI system opacity and the resulting lack of transparency. Systemic biases at the organizational level can influence how teams are structured and who controls the decision-making processes throughout the AI lifecycle."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_103",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nbe introduced across the AI lifecycle via human assumptions, expectations, and decisions during design and modeling tasks. These biases, which are not necessarily always harmful, may be exacerbated by AI system opacity and the resulting lack of transparency. Systemic biases at the organizational level can influence how teams are structured and who controls the decision-making processes throughout the AI lifecycle. These biases can also influence downstream decisions by end users, decision makers, and policy makers and may lead to negative impacts. 3.Human-AI interaction results vary. Under certain conditions – for example, in perceptual-based judgment tasks – the AI part of the human-AI interaction can am- plify human biases, leading to more biased decisions than the AI or human alone. When these variations are judiciously taken into account in organizing human-AI teams, however, they can result in complementarity and improved overall perfor- mance. Page 40 NIST AI 100-1 AI RMF 1.0 4.Presenting AI system information to humans is complex. Humans perceive and derive meaning from AI system output and explanations in different ways, reflecting different individual preferences, traits, and skills. The GOVERN function provides organizations with the opportunity to clarify and define the roles and responsibilities for the humans in the Human-AI team configurations and those who are overseeing the AI system performance."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_104",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nsystem information to humans is complex. Humans perceive and derive meaning from AI system output and explanations in different ways, reflecting different individual preferences, traits, and skills. The GOVERN function provides organizations with the opportunity to clarify and define the roles and responsibilities for the humans in the Human-AI team configurations and those who are overseeing the AI system performance. The GOVERN function also creates mechanisms for organizations to make their decision-making processes more explicit, to help counter systemic biases. The MAP function suggests opportunities to define and document processes for operator and practitioner proficiency with AI system performance and trustworthiness concepts, and to define relevant technical standards and certifications. Implementing MAP function cat- egories and subcategories may help organizations improve their internal competency for analyzing context, identifying procedural and system limitations, exploring and examining impacts of AI-based systems in the real world, and evaluating decision-making processes throughout the AI lifecycle. The GOVERN and MAP functions describe the importance of interdisciplinarity and demo- graphically diverse teams and utilizing feedback from potentially impacted individuals and communities."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_105",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nand subcategories may help organizations improve their internal competency for analyzing context, identifying procedural and system limitations, exploring and examining impacts of AI-based systems in the real world, and evaluating decision-making processes throughout the AI lifecycle. The GOVERN and MAP functions describe the importance of interdisciplinarity and demo- graphically diverse teams and utilizing feedback from potentially impacted individuals and communities. AI actors called out in the AI RMF who perform human factors tasks and activities can assist technical teams by anchoring in design and development practices to user intentions and representatives of the broader AI community, and societal values. These actors further help to incorporate context-specific norms and values in system design and evaluate end user experiences – in conjunction with AI systems. AI risk management approaches for human-AI configurations will be augmented by on- going research and evaluation. For example, the degree to which humans are empowered and incentivized to challenge AI system output requires further studies. Data about the fre- quency and rationale with which humans overrule AI system output in deployed systems may be useful to collect and analyze. Page 41 NIST AI 100-1 AI RMF 1.0 Appendix D: Attributes of the AI RMF NIST described several key attributes of the AI RMF when work on the Framework first began."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_106",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nsystem output requires further studies. Data about the fre- quency and rationale with which humans overrule AI system output in deployed systems may be useful to collect and analyze. Page 41 NIST AI 100-1 AI RMF 1.0 Appendix D: Attributes of the AI RMF NIST described several key attributes of the AI RMF when work on the Framework first began. These attributes have remained intact and were used to guide the AI RMF’s devel- opment. They are provided here as a reference. The AI RMF strives to: 1. Be risk-based, resource-efficient, pro-innovation, and voluntary. 2. Be consensus-driven and developed and regularly updated through an open, trans- parent process. All stakeholders should have the opportunity to contribute to the AI RMF’s development. 3. Use clear and plain language that is understandable by a broad audience, including senior executives, government officials, non-governmental organization leadership, and those who are not AI professionals – while still of sufficient technical depth to be useful to practitioners. The AI RMF should allow for communication of AI risks across an organization, between organizations, with customers, and to the public at large. 4. Provide common language and understanding to manage AI risks. The AI RMF should offer taxonomy, terminology, definitions, metrics, and characterizations for AI risk. 5. Be easily usable and fit well with other aspects of risk management."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_107",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nThe AI RMF should allow for communication of AI risks across an organization, between organizations, with customers, and to the public at large. 4. Provide common language and understanding to manage AI risks. The AI RMF should offer taxonomy, terminology, definitions, metrics, and characterizations for AI risk. 5. Be easily usable and fit well with other aspects of risk management. Use of the Framework should be intuitive and readily adaptable as part of an organization’s broader risk management strategy and processes. It should be consistent or aligned with other approaches to managing AI risks. 6. Be useful to a wide range of perspectives, sectors, and technology domains. The AI RMF should be universally applicable to any AI technology and to context-specific use cases. 7. Be outcome-focused and non-prescriptive. The Framework should provide a catalog of outcomes and approaches rather than prescribe one-size-fits-all requirements. 8. Take advantage of and foster greater awareness of existing standards, guidelines, best practices, methodologies, and tools for managing AI risks – as well as illustrate the need for additional, improved resources. 9. Be law- and regulation-agnostic. The Framework should support organizations’ abilities to operate under applicable domestic and international legal or regulatory regimes. 10. Be a living document."
  },
  {
    "id": "Artificial_Intelligence_Risk_Management_Framework_AI_RMF_10_chunk_108",
    "text": "Source: 5 Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf\n\nrequirements. 8. Take advantage of and foster greater awareness of existing standards, guidelines, best practices, methodologies, and tools for managing AI risks – as well as illustrate the need for additional, improved resources. 9. Be law- and regulation-agnostic. The Framework should support organizations’ abilities to operate under applicable domestic and international legal or regulatory regimes. 10. Be a living document. The AI RMF should be readily updated as technology, under- standing, and approaches to AI trustworthiness and uses of AI change and as stake- holders learn from implementing AI risk management generally and this framework in particular. Page 42 This publication is available free of charge from: https://doi.org/10.6028/NIST.AI.100-1"
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_0",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nDEPARTMENT OF DEFENSE Data, Analytics, and Artificial Intelligence Adoption Strategy Accelerating Decision Advantage Cleared for open publication ▪June 27, 2023, ▪Department of Defense ▪Office of Prepublication and Security Review TABLE OF CONTENTS DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY FOREWORD STRATEGIC ENVIRONMENT KEY OUTCOMES STRATEGIC GOALS IMPLEMENTATION CONCLUSION APPENDIX A: QUALITY DATA DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY2 3 5 7 14 17 19 1 DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY“America’s DNA is to innovate ... and it has repeate dly enabled us to dr ive an d master the future character o f warfare.” Kath leen H. Hicks Deputy Secretary of Defense FOREWORD The Department of Defense (DoD) has been investing in artificial intelligence (AI) and responsibly fielding data- and AI-enabled systems for over 60 years. Today, data, analytics, and AI technologies are increasingly available to DoD Components and providing value to our service members. Alongside industry’s advancements, DoD has for years made steady and swift improvements to its data foundation and analytics capabilities: experimenting with AI through research and development, integrating these technologies into business and warfighting functions, and laying the foundation for their use at scale."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_1",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nanalytics, and AI technologies are increasingly available to DoD Components and providing value to our service members. Alongside industry’s advancements, DoD has for years made steady and swift improvements to its data foundation and analytics capabilities: experimenting with AI through research and development, integrating these technologies into business and warfighting functions, and laying the foundation for their use at scale. As our investment, experimentation, and innovation continues and accelerates, our task now is to drive the diffusion of these technologies across the enterprise. Although our strategic competitors have ambitious aims for AI, the United States and its military possess strong structural advantages in talent, warfighting experience, technology availability, and systems integration — not to mention the values that guide everything we do. Equipping our people with the tools and resources to make better decisions faster will increase the efficiency of DoD business operations, make our warfighting capabilities and the people who command them more effective, and create opportunities to employ novel operational concepts. Responsibly and rapidly realizing the full promise of data, analytics, and AI is not the sole job of a single organization or program; it’s on all of us. Providing DoD data as an enterprise resource, for instance, requires more sharing and collaboration, not less."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_2",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nand the people who command them more effective, and create opportunities to employ novel operational concepts. Responsibly and rapidly realizing the full promise of data, analytics, and AI is not the sole job of a single organization or program; it’s on all of us. Providing DoD data as an enterprise resource, for instance, requires more sharing and collaboration, not less. We seek an agile strategic approach that guides decentralized action across DoD, inspires campaigns of learning, and leverages all our people, processes, and enabling technologies. As we have integrated analytics and AI applications, we have observed their benefits and learned crucial lessons about their limitations. From the boardroom to the battlefield, more work remains, such as improving data quality and network infrastructure. This Strategy serves as a guide for how we will strengthen the organizational environment in which DoD deploys data, analytics, and AI capabilities for enduring decision advantage. Successfully defending the nation depends on our people. As we have always done, DoD will continue to trust, support, empower, and invest in our people. We will not outpace our adversaries through imitation. We will succeed by leading with our strengths: our democratic values, our diverse and open society, our culture of ingenuity, our second-to-none innovation base, and our globe-spanning network of Allies and partners."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_3",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\non our people. As we have always done, DoD will continue to trust, support, empower, and invest in our people. We will not outpace our adversaries through imitation. We will succeed by leading with our strengths: our democratic values, our diverse and open society, our culture of ingenuity, our second-to-none innovation base, and our globe-spanning network of Allies and partners. Together, we will harness data, analytics, and AI for the defense, security, and prosperity of the American people and the world. Kathleen H. Hicks Deputy Secretary o f Defense 2 DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY STRATEGIC ENVIRONME NT As the 2022 National Defense Strategy (NDS) make s clear , the United State s possesse s strength s that our competitors cannot match, among them our diverse and open society, our culture of ingenuity, our innovation base, and our globe-spanning network of Allies and partners. The Department leverages these strengths by distributing authority, empowering leaders in our All-V olunteer Force to innovate at the edge and apply their own judgment to combine old and new capabilities into superior operational concepts. The latest advancements in data, analytics, and artificial intelligence (AI) technologies enable leaders to make better decisions faster, from the boardroom to the battlefield."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_4",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\npartners. The Department leverages these strengths by distributing authority, empowering leaders in our All-V olunteer Force to innovate at the edge and apply their own judgment to combine old and new capabilities into superior operational concepts. The latest advancements in data, analytics, and artificial intelligence (AI) technologies enable leaders to make better decisions faster, from the boardroom to the battlefield. Therefore, accelerating t he adoptio n of these technologies presents an unprecedented opportunity to equip leaders a t all levels of t he Department with th e data they need, and harness the full potentia l of the decision -making power of o ur people. The NDS also describes the need for the United States t o sustain and strengthen deterrence against the People’s Republic of China and other strategic competitors, which have widely c ommunicated their in tentions to field AI for military advantage. Accelerating adoption of data, analytics, and AI technologies will enable enduring decision advantage, allowing DoD leaders to prioritiz e investments to strengthen deterrence; link cross -cuttin g campaign outcomes that counter our competitors’ coerciv e measures; a nd deploy continuous advancements in technological capabilities to creatively address complex nationa l security challenges in this decisiv e decade. The urgency of the strategic environment and the scale at which the Department must operate are formidable."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_5",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nDoD leaders to prioritiz e investments to strengthen deterrence; link cross -cuttin g campaign outcomes that counter our competitors’ coerciv e measures; a nd deploy continuous advancements in technological capabilities to creatively address complex nationa l security challenges in this decisiv e decade. The urgency of the strategic environment and the scale at which the Department must operate are formidable. The Department is well-p ositioned to excel because it has established a foundation of strategic guidance informed by lessons learned from hands-o n initiatives ov er the last s everal years.1 The Department’s first AI Strategy, published in 2018, and revised Data Strategy, published in 2020, are two of these foundational efforts. The 2018 AI Strategy emphasized the need to build centralized infrastructure for AI development, to bridge AI technology developments from the Department’s research and engineering c ommunities, and to exercis e international leadership i n military ethics and AI safety. The 2020 Data Strategy en visioned the Department as a data -centric organization that can employ data supporting advanced capabilities for operational advantage and increased efficiency, and oriented enterprise data management activities toward the VAULTIS goal framework.2 1."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_6",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\ndevelopments from the Department’s research and engineering c ommunities, and to exercis e international leadership i n military ethics and AI safety. The 2020 Data Strategy en visioned the Department as a data -centric organization that can employ data supporting advanced capabilities for operational advantage and increased efficiency, and oriented enterprise data management activities toward the VAULTIS goal framework.2 1. This guidance includes the DoD AI Strategy (2018), the DoD Digital Modernization Strategy (2019), the DoD Data Strategy (2020), the DoD Enterprise DevSecOps Strategy Guide (2021), the DoD Software Modernization Strategy (2022), the Trusted AI and Autonomy Critical Technology Roadmap (2022), and the DoD Zero Trust Strategy (2022). 2. The 2020 DoD Data Strategy outlined the following seven goals (VAULTIS): Visible – Consumers can locate the needed data. Accessible – Consumers can retrieve the data. Understandable – Consumers can find descriptions of data to recognize the content, context, and applicability. Linked – Consumers can exploit complementary data elements through innate relationships. Trustworthy – Consumers can be confident in all aspects of data for decision-m aking. Interoperable – Consumers and producers have a common representation and comprehension of data. Secure – Consumers know that data is protecte d from unauthorized use and manipulation."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_7",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\ndata to recognize the content, context, and applicability. Linked – Consumers can exploit complementary data elements through innate relationships. Trustworthy – Consumers can be confident in all aspects of data for decision-m aking. Interoperable – Consumers and producers have a common representation and comprehension of data. Secure – Consumers know that data is protecte d from unauthorized use and manipulation. 3 DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY Since thes e strategies were published, industry has produced more tools, platforms, and services for federated environments, enabling more effective, decentralized data management, and analytics and AI development. Adoption of thes e commercia l offerings has allowed organizations within the Department to focus on necessary internal transformation efforts and deploy government-ow ned tools, services, and platforms for military use cases. The Department has matured collaboration with academia, industry, as well as Allies and partners, and promoted best practices on data management, responsible AI, and AI readiness. Experimentation and fielding have resulted in a deeper understanding of the degrees of data quality and availability required to develop and deploy advanced analytics and AI capabilities at scale. This DoD Data, Analytics, and AI Adoption Strategy builds upon and supersedes the 2018 AI Strategy and the 2020 Data Strategy to continue the Department’s digital transformation."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_8",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nAI, and AI readiness. Experimentation and fielding have resulted in a deeper understanding of the degrees of data quality and availability required to develop and deploy advanced analytics and AI capabilities at scale. This DoD Data, Analytics, and AI Adoption Strategy builds upon and supersedes the 2018 AI Strategy and the 2020 Data Strategy to continue the Department’s digital transformation. The Department will continuously seize opportunities presented by iterative technology advancements, at th e speed of relevance and at the scale of our global mission. To do so, the Department requires a unified approach across data, analytics, and AI activities; an educated, empowered workforce skilled at incorporating commercial teams and tools; continued advanced research and rapid experimentation; and effective integration with our Allies and partners. The Department cannot succeed alone. Our integration of data, analytics, and AI technologies is nested within broader U.S. government policy, the network of private sector and academic partners that promote innovation, and a global ecosystem. We need a systematic, agile approach to data, analytics, and AI adoption that is repeatable by all DoD Components. This strategy outlines our approach to improving the organizational environment within which our people can deploy data, analytics, and AI capabilities for enduring decision advantage."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_9",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\npolicy, the network of private sector and academic partners that promote innovation, and a global ecosystem. We need a systematic, agile approach to data, analytics, and AI adoption that is repeatable by all DoD Components. This strategy outlines our approach to improving the organizational environment within which our people can deploy data, analytics, and AI capabilities for enduring decision advantage. 4 DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY KEY OUTCOMES As a result of implementing this str ateg y, DoD leaders and warfighters w ill be able to make rapid, well -inf ormed decisions by expertly leveraging high -quality data, advanced ana lytics, and AI as part of a cont inuous, outcome -dri ven, a nd user -focused development, deployment, and feedbac k cycle. The Department’s investments in data, analytics, and AI will address key operational problems identified in the 2022 NDS, fill validated gaps to enhance the warfighting capabilities of the Joint Force, and strengthen the enterprise foundation required to sustain enduring advantages. Fielding data, analytics, and AI capabilities across this continuum from the boardroom to the battlefield recognizes that warfighting decision advantage is enabled by hundreds, or thousands, of decisions made by personnel and program offices at great distances from the frontline."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_10",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\ngaps to enhance the warfighting capabilities of the Joint Force, and strengthen the enterprise foundation required to sustain enduring advantages. Fielding data, analytics, and AI capabilities across this continuum from the boardroom to the battlefield recognizes that warfighting decision advantage is enabled by hundreds, or thousands, of decisions made by personnel and program offices at great distances from the frontline. Strengthening decision advantage for the Department’s warfighting and business operations is key to maintaining a resilient future force that can address a broader array of operational problems, dynamically campaign and deter, and prevail in conflict, if necessary. Decision advantage is a competitive condition characterized by the following outcomes: •Battlespace awareness and understanding •Adaptive force planning and application •Fast, precise, and resilient kill chains •Resilient sustainment support •Efficient enterprise business operations Agile, user-focused, product -centric development is essential to achieving these outcomes because humans and machines will work together in the responsible, effective employment of data, analytics, and AI -enabled capabilities. Today, there are multi -disciplinary teams throughout the Department that leverage common technology development best practices."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_11",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\napplication •Fast, precise, and resilient kill chains •Resilient sustainment support •Efficient enterprise business operations Agile, user-focused, product -centric development is essential to achieving these outcomes because humans and machines will work together in the responsible, effective employment of data, analytics, and AI -enabled capabilities. Today, there are multi -disciplinary teams throughout the Department that leverage common technology development best practices. These practices include: •Employing Agile development fundamental principles and approaches •Building intuitive interfaces to accelerate human adoption of new technology •Developing products with cross -functional team s focused on customer needs •Offering product portfolios with shared digital foundations •Experimenting with minimum viable products in operational environments to identify new concepts for use, improve capabili t y, and manage emergent risks More is needed now, and at scale. The Department will pursue a multi -disciplinary approach and implement these best practices to strengthen its technology, human capital, processes, and culture. This approach has implications analogous to pivoting from a heavy armor force to one with greater maneuverability. The Department will enhance its competitive edge through a vigorous and continuous capability delivery pipeline that can respond with agility to changing environments and technologies ."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_12",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nmulti -disciplinary approach and implement these best practices to strengthen its technology, human capital, processes, and culture. This approach has implications analogous to pivoting from a heavy armor force to one with greater maneuverability. The Department will enhance its competitive edge through a vigorous and continuous capability delivery pipeline that can respond with agility to changing environments and technologies . DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY 5 The Department’s agile approach to adoption (Figure 1) ensures a tight feedback loop between technology developers and users through a continuous cycle of iteration, innovation, and improvement of solutions that enable decision advantage. Practicing agility and learning by doing will accelerate deployment speed –measured in hours or days, not months or years. Creating effective, iterative feedback loops among developers, users, subject matter experts, and test and evaluation (T&E) experts will ensure capabilities are more stable, secure, ethical, and trustworthy. An agile approach to adoption emphasizes speed of delivery and continuous improvement, prioritizing outcomes over processes. Valuing speed necessitates organizational agility and learning through early and ongoing real -world feedback. The Department will move toward greater integration, transparency, and knowledge sharing across organizational boundaries."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_13",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nand test and evaluation (T&E) experts will ensure capabilities are more stable, secure, ethical, and trustworthy. An agile approach to adoption emphasizes speed of delivery and continuous improvement, prioritizing outcomes over processes. Valuing speed necessitates organizational agility and learning through early and ongoing real -world feedback. The Department will move toward greater integration, transparency, and knowledge sharing across organizational boundaries. Increased diffusion of data, analytics, and AI technologies will introduce technical vulnerabilities that require rigorous protection measures . These risks will be managed not by flawless forecasting, but by continuous deployment powered by campaigns of learning. Developing capability in this way enables responsibility , ensuring not only the sustained quality, stability, and security of DoD systems, but also providing the means by which engineers can reduce unintended bias and instill justified confidence with their users. Figure 1: Employing an Agile Approach to Adoption to Scale Decision Advantage Outcomes The Department’s agile approach to adoption ensures a tight feedback loop between technology developers and users through a continuous cycle of iteration, innovation, and improvement of solutions that enable decision advantage."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_14",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nthe means by which engineers can reduce unintended bias and instill justified confidence with their users. Figure 1: Employing an Agile Approach to Adoption to Scale Decision Advantage Outcomes The Department’s agile approach to adoption ensures a tight feedback loop between technology developers and users through a continuous cycle of iteration, innovation, and improvement of solutions that enable decision advantage. DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY 6 STRATEGIC GOALS The Department will focus strategic efforts on several interdependent goals that support the DoD AI Hierarchy of Needs (Figure 2). The AI Hierarchy of Needs is a pyramid with quality data as its foundation since all analytic and AI capabilities require trusted, high -quality data to support decision makers. The next layer in the Hierarchy is insightful analytics and metrics, the foundational models and visualizations required for DoD leaders to understand their domain and the key variables impacting outcomes in those domains. At the top of the pyramid is Responsible AI, the Department’s dynamic approach to the design, development, deployment, and use of AI capabilities in accordance with the DoD AI Ethical Principles while delivering better, faster insights and improved mission outcomes. 3The layers of the Hierarchy are supported by robust sets of processes. Increased data quality and insightful analytics are achievable through effective enterprise data governance."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_15",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\npyramid is Responsible AI, the Department’s dynamic approach to the design, development, deployment, and use of AI capabilities in accordance with the DoD AI Ethical Principles while delivering better, faster insights and improved mission outcomes. 3The layers of the Hierarchy are supported by robust sets of processes. Increased data quality and insightful analytics are achievable through effective enterprise data governance. Sound assurance processes for testing, evaluation, validation, and verification are imperative for Responsible AI. Around the pyramid are enablers, such as digital talent management, that help sustain the Hierarchy of Needs. The Hierarchy is helpful as a framework for assessing DoD AI readiness, and for guiding the Department’s goals to accelerate adoption of data, analytics, and AI technologies to build enduring decision advantage. These interdependent goals, and their supporting activities and investments, cut across technology, human capital, process, and culture areas, and are described in further detail on the next few pages.Figure 2: Strategic Goals and the AI Hierarchy of Needs 3."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_16",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nreadiness, and for guiding the Department’s goals to accelerate adoption of data, analytics, and AI technologies to build enduring decision advantage. These interdependent goals, and their supporting activities and investments, cut across technology, human capital, process, and culture areas, and are described in further detail on the next few pages.Figure 2: Strategic Goals and the AI Hierarchy of Needs 3. For more information on the Department’s Responsible AI plan, see the “US Department of Defense Responsible Artificial Intelligence Strategy and Implementation Pathway.” DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY 7 IMPROVE FOUNDATIONAL DATA MANAGEMENT: Increase the quality and availability of relevant DoD data to support advanced analytics and artificial intelligence capabilities. Consisten t with the Deput y Secretar y of Defense’s Memorandum on Creating Data Advantage, the Departmen t will value data as a product, ensuring the responsib le collection, storage, and management of relevant data to support enterprise needs. All DoD data is an enterprise resource. The Department will adapt and implement open standard architectures while abiding by existing DoD cybersecurity policies and heed industry best practices for data ethics, data protection, and design as technology evolves. The Department will also continu e to make its data more visible, accessible, understandable, linked, trustworthy, interoperable, and secure (VAULTIS)."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_17",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nenterprise needs. All DoD data is an enterprise resource. The Department will adapt and implement open standard architectures while abiding by existing DoD cybersecurity policies and heed industry best practices for data ethics, data protection, and design as technology evolves. The Department will also continu e to make its data more visible, accessible, understandable, linked, trustworthy, interoperable, and secure (VAULTIS). Components will assess their data across lifecycles using the data quality dimensions and the VAULTIS framework first outlined in the 2020 DoD Data Strategy.4 The Department’s data management focus will initially prioritize improving data quality and managing data as a product in support of the Secretary of Defense's priority areas. To improve DoD data quality across the enterprise, the Department will develop and implement a decentralized network among data providers and users. This network will consist of both process-based and technical components, distributing ownership across data domains and treating data as a product. Instead of designating a centralized data team responsible for managing all data across the enterprise, data domain owners and data product teams will be responsible for managing the data products they own and produce. Data products will be designed, built, and maintained with the needs and requirements of its users in mind, just like a traditional product."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_18",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nas a product. Instead of designating a centralized data team responsible for managing all data across the enterprise, data domain owners and data product teams will be responsible for managing the data products they own and produce. Data products will be designed, built, and maintained with the needs and requirements of its users in mind, just like a traditional product. By treating data as a product, DoD Components can stimulate a culture of data sharing and reuse under appropriate circumstances, which breaks down data silos and promotes cross- functional collaboration. This product orientation ensures that data is properly managed and governed, with clear accountability, quality and interface standards, and access controls. While this data managemen t approach will not reduce DoD’s organizational complexity, over time it will improve operatio nal and analytical data quality, reduce data backlogs, lower data storage costs, and reduce data redundancy. These improvements will allow DoD organizations to better leverage their data products and make more effective, data-dr iven decision -making. 4. See Appendix A for further detail."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_19",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nthis data managemen t approach will not reduce DoD’s organizational complexity, over time it will improve operatio nal and analytical data quality, reduce data backlogs, lower data storage costs, and reduce data redundancy. These improvements will allow DoD organizations to better leverage their data products and make more effective, data-dr iven decision -making. 4. See Appendix A for further detail. DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY 8 DELIVER CAPABILITIES FOR ENTERPRISE BUSINESS AND JOINT WARFIGHTING IMPACT: Enhance and/or generate business analytics and warfighting capabilities with data, analytics, and AI technologies for improved decision advantage outcomes An integrated, agile approach with a strong focus on data quality will ensu re the Department fields responsible solutions that most appropriately address organizational needs. There is an urgent need to surge digital support to address Joint capability gaps at the operational to strategic levels in direct support of operational commands. Building momentum toward transformation requires demonstrating tangible, near-term results. For example, a user requesting an advanced decision support m odel with recurring excursion capability could field a simpler analytics dashboard in the near-t erm to better understand current state and shape more sophisticated questions."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_20",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\naddress Joint capability gaps at the operational to strategic levels in direct support of operational commands. Building momentum toward transformation requires demonstrating tangible, near-term results. For example, a user requesting an advanced decision support m odel with recurring excursion capability could field a simpler analytics dashboard in the near-t erm to better understand current state and shape more sophisticated questions. The Department will continue to focus on advancing business analytics, to continuously improve data quality through use, and to provide the more complete picture DoD personnel need to make better reactive and proactive decisions. The Department will design and test analytics and AI-enabled solutions side-by-side with stakeholders , business and warfighter, and demonstrate capabilities via robust campaigns of learning to account for different operational environments. Some users may have access to abundant data and high-sp eed processing while other users face limited bandwidth at the tactical edge. Designers will identify these constraints early in the development process. The Department will conduct continuous experiments, and integrated multi-la teral exercises with high -impact Joint Force use cases that can inform additional investments in interoperab le enterprise-le vel, warfighting capabilities. Components will advocate for investments in data, analytics, and AI that will generate these capabilities."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_21",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nbandwidth at the tactical edge. Designers will identify these constraints early in the development process. The Department will conduct continuous experiments, and integrated multi-la teral exercises with high -impact Joint Force use cases that can inform additional investments in interoperab le enterprise-le vel, warfighting capabilities. Components will advocate for investments in data, analytics, and AI that will generate these capabilities. Capabilities deemed successfu l after rigorous testing will receive clear pathways to sustainment and wide-sc ale adoption. STRENGTHEN GOVERNANCE AND REMOVE POLICY BARRIERS: Ensure responsible behavior, processes, and outcomes while accelerating the pace of adoption for data, analytics, and AI technologies across the Department The Department’s approach to integrated data, analytics, and AI governance will account for the scale of the organization, its distributed authority structure, and high degrees of variance in data maturity among Components. Further, the Department’s information enterprise is vast and global, with strong dependencies among different IT syste ms, support teams, progra ms, and activitie s. For example , a key pillar of the 2022 DoD Zero Trust Strategy hinges upon the establishment of ef fectiv e enterpris e data governance, and the fielding of analytics and AI to secur e our networks, applications assets, and services. Similarly, records management processes and procedures are another dependency."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_22",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nIT syste ms, support teams, progra ms, and activitie s. For example , a key pillar of the 2022 DoD Zero Trust Strategy hinges upon the establishment of ef fectiv e enterpris e data governance, and the fielding of analytics and AI to secur e our networks, applications assets, and services. Similarly, records management processes and procedures are another dependency. The 2023 DoD Records Strategy makes clear that records are data and will be curated, automated, and governed. Treating records in this way will increase trust in data and analytics products. Thes e examples of dependencies underscor e the complexity of the Department’s policy en vironment and the necessity of consensus building. The Do D data, analytics, and AI leadership community will build consensus around responsib le development practices that enab le mission owners a nd other governance bodies while serving a s a demanding customer of enabling capabilities. Data, a nalytics, and AI governance w ill be risk-adjusted, streamlined, and data-d riven, and focused on collaborative learning. Generat ing consensus and collaboratio n is c ritical to mitigat ing know n and emergent policy barriers and aligning technical interfaces to hasten responsible adoption."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_23",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\na nd other governance bodies while serving a s a demanding customer of enabling capabilities. Data, a nalytics, and AI governance w ill be risk-adjusted, streamlined, and data-d riven, and focused on collaborative learning. Generat ing consensus and collaboratio n is c ritical to mitigat ing know n and emergent policy barriers and aligning technical interfaces to hasten responsible adoption. 9 DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY 13In support of a collaborativ e approach to enterprise governance, D oD Components will identify clear leaders for data - related transformation, strengthening accountability across the Department. Enterprise-l evel governance initiatives will prioritiz e key a reas including data management, cybersecurity, r equirements, joint interoperability, records management, and Responsible AI. The success of these areas requires C omponents to continu e to follow responsible security procedures, review current policies and processes on data a ggregation and classification, revis e issuances as needed, and comply with updated guidance. The Department will approach reforms with speed and responsibility: targeting identified policy revisions to improv e agility, s peed of capability deployment, and scalability; while upholding a steadfast c ommitment to lawful and ethica l behavior; and protecting privacy and civil liberties."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_24",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nand processes on data a ggregation and classification, revis e issuances as needed, and comply with updated guidance. The Department will approach reforms with speed and responsibility: targeting identified policy revisions to improv e agility, s peed of capability deployment, and scalability; while upholding a steadfast c ommitment to lawful and ethica l behavior; and protecting privacy and civil liberties. Components’ efforts to implement this Strategy w ill be supported by governance policies, processes, a nd structures that are mission - driven, responsiv e to need, minimally prescriptive, and based on best practices. The Department will reduce institutional barriers, including those that unnecessarily in hibit collective research and development, planning, interoperability, intelligence, and information sharing. The Department will lead across the U.S. government to inform technology and information release processes, expand release authorizations, and redefine dissemination controls to facilitate information exchange for mutual benefit. INVEST IN INTEROPERABLE, FEDERATED INFRASTRUCTURE: Optimize the Department’s federated infrastructure to support scaling data, analytics, and AI adoption and improve interoperability. The Department will invest in abundant, flexible, secure, and jointly interoperable infrastructure that is scalable for the needs of users."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_25",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\ntechnology and information release processes, expand release authorizations, and redefine dissemination controls to facilitate information exchange for mutual benefit. INVEST IN INTEROPERABLE, FEDERATED INFRASTRUCTURE: Optimize the Department’s federated infrastructure to support scaling data, analytics, and AI adoption and improve interoperability. The Department will invest in abundant, flexible, secure, and jointly interoperable infrastructure that is scalable for the needs of users. Data, analytics, an d AI capability development requires tremendous computing power and demand will grow exponentially as adoption scales. When appropriate, this infrastructure will be au tomated, including measures to implement DoD technology policies (e.g., Continuous Authorization to Operate), its status reporting, and, critically, user access to mission- relevant data, analytics, Figure 3: Balancing Tradeoffs with Shared Services DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY 10and AI platforms. Though government-led and designed, DoD infrastructure will adopt open standard architectures for industry and trusted partners to facilitate collaborative and continuous experimentation. As described in the DoD Software Modernization Strategy, the Department is an “enterprise of enterprises.” Thus, the Department’s infrastructure supporting data, analytics, and AI technologies will remain federated."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_26",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nDATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY 10and AI platforms. Though government-led and designed, DoD infrastructure will adopt open standard architectures for industry and trusted partners to facilitate collaborative and continuous experimentation. As described in the DoD Software Modernization Strategy, the Department is an “enterprise of enterprises.” Thus, the Department’s infrastructure supporting data, analytics, and AI technologies will remain federated. The Department will continue to centralize some decisions and services while others remain decentralized to address unique mission needs. To strike the optimal balance of platforms and services, the Department will assess infrastructure based on outcome commonality and implementation complexity (depicted in Figure 3). While it is important to strive for en terprise scaling economies, leaders must also understand the extent to which their Component's data, analytics, and AI requirements are truly specialized. Organizations with common digital service requirements and joint use cases, particularly when migration would be relatively simple, will move quickly to adopt shared services to meet their needs. Organizations’ infrastructure must remain decentralized if they have highly specialized requirements or if leaders determin e that the costs outweigh the benefits of consolidating within a shared platform or suite of services. One notab le exception to this logic is AI-specific infrastructure."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_27",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nparticularly when migration would be relatively simple, will move quickly to adopt shared services to meet their needs. Organizations’ infrastructure must remain decentralized if they have highly specialized requirements or if leaders determin e that the costs outweigh the benefits of consolidating within a shared platform or suite of services. One notab le exception to this logic is AI-specific infrastructure. The scarcity of expertise required to customize safe and reliable AI-enabled systems remains a limiting factor. Thus, DoD Components will seek to centralize certain AI development platforms for continuous experimentation and deployment, and then maximize the adoption of responsib le AI shared services. ADVANCE THE DATA, ANALYTICS, AND AI ECOSYSTEM: Strengthen intergovernmental, academic, industry, and international partnerships to enable adoption of data, analytics, and AI technology. DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY 11The Department will advance progress toward a robust nation al and international ecosystem that facilitates improved intergovernmental, academic, industry, and international collaboration on data, analytics, and AI technology. The Department cannot succeed alone. Through domestic and international engagements, the Department will collaborate on common challenges, further shared interests, promote democratic norms and values, and increase interoperability with partners."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_28",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nADOPTION STRATEGY 11The Department will advance progress toward a robust nation al and international ecosystem that facilitates improved intergovernmental, academic, industry, and international collaboration on data, analytics, and AI technology. The Department cannot succeed alone. Through domestic and international engagements, the Department will collaborate on common challenges, further shared interests, promote democratic norms and values, and increase interoperability with partners. The Department will cooperate with Allies and partners to leverage comparative advantages and allow for interoperability in tactics, institutions, and strategies related to data, analytics, and AI. Where appropriate, the Department will continue exporting key technologies and sharing data to ensure our Allies and partners remain agile and capab le of rapidly employing advanced analytics and AI innovations. To obtain and integrate proven solutions in collaboration with industry, the Department will follow an “adopt-buy-cre ate” framework aligned with the DoD Software Modernization Strategy and Office of Management and Budget (OMB) Circular A-13 0, Managing Information as a Strategic Resource. DoD leaders will first seek to adopt solutions that are already Joint- or Component-s ponsored before exploring capabilities availab le on the open market."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_29",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nsolutions in collaboration with industry, the Department will follow an “adopt-buy-cre ate” framework aligned with the DoD Software Modernization Strategy and Office of Management and Budget (OMB) Circular A-13 0, Managing Information as a Strategic Resource. DoD leaders will first seek to adopt solutions that are already Joint- or Component-s ponsored before exploring capabilities availab le on the open market. When DoD-o wned shared services are unavailable, the Department will challenge vendors to solve specific business and mission problems, while designing acquisition strategies to avoid vendor lock-i n. DoD customers with clean , high -quality data can seek commercially available analytics and AI capabilities while retaining appropriate data rights. Government contracts for commercial solutions will ensure the Department’s capability pipelines address evolving requirements while balancing protection of industry intellectual property. Commercial solutions may not meet all mission requirements, but they can provide best-i n-class capabilities for many dual-u se applications. It is often in the Department’s interest to procure software and support for these commercial solutions, freeing up DoD engineers for inherently governmental challenges. Fielding web -based, cloud-based, and/or Application Programming Interface (API)- first applications create more opportunities for rapid, enterprise scalability; continuous integration and delivery; and increased economies of scale."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_30",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nprovide best-i n-class capabilities for many dual-u se applications. It is often in the Department’s interest to procure software and support for these commercial solutions, freeing up DoD engineers for inherently governmental challenges. Fielding web -based, cloud-based, and/or Application Programming Interface (API)- first applications create more opportunities for rapid, enterprise scalability; continuous integration and delivery; and increased economies of scale. APIs also allow for a more open exchange with diverse data sources, regardless of origin, giving DoD leaders and warfighters greater access to the information they need to make more timely and accurate decisions. The Department will only create solutions when those applications aid DoD-s pecific missions and cannot be readily adopted from commercial or existing solutions. Thes e Defense-s pecific applications often involv e real- time, mission-critical , embedde d softwar e couple d to customize d DoD hardware . Creatin g an ecosyste m that fosters competition and collaboration is essential for the development and deployment of AI-enabled systems, particularly next generation capabilities for use in Joint warfighting. When supported with open standard architectures, the Department’s data, analytics, and AI ecosystem will facilitate commercial competition based on model performance and promote collaboration with trusted international and intergovernmental partners."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_31",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\n. Creatin g an ecosyste m that fosters competition and collaboration is essential for the development and deployment of AI-enabled systems, particularly next generation capabilities for use in Joint warfighting. When supported with open standard architectures, the Department’s data, analytics, and AI ecosystem will facilitate commercial competition based on model performance and promote collaboration with trusted international and intergovernmental partners. Commercial models verified, validated, accredited, and fielded through this process can then be customized for DoD use. Program managers will consider acquisition strategies that leverage international partnerships and supportability planning to improve economies of scale, strengthen the defense industrial base, and enhance Ally and partner capabilities. Further, the Department will embrace initiatives aimed at creating standard language necessary for data, analytics, and AI technology contract problem statements and agreements. When applicable, the DoD will leverage resources such as the federated data and model catalog and AI- enabled enterprise tools to expedite acquisitions. The Department will mature and expand acquisitions policies that increase government visibility of the ownership, labeling, maintenance, and classification of data. The Department has made progress on acquisition innovation and will continue to encourage personnel to embrace risk and learn by doing."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_32",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nleverage resources such as the federated data and model catalog and AI- enabled enterprise tools to expedite acquisitions. The Department will mature and expand acquisitions policies that increase government visibility of the ownership, labeling, maintenance, and classification of data. The Department has made progress on acquisition innovation and will continue to encourage personnel to embrace risk and learn by doing. Contracting must be as agile as the industry with which it is engaging. The Department will continue to adapt best practices from nontraditional partners to ensure cutting edge solutions are delivered responsibly at th e speed of relevance. DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY 12 EXPAND DIGITAL TALENT MANAGEMENT : increase hiring, training, and retention for the most critical data, analytics, and AI -related work roles. The Department’s ability to oversee and adopt data, analytics, and AI capabilities depends on the strength of its workforce, and continued growth in technical skills. The Department will ensure it is identifying and employing the talent it already possesses, then focus resources on those initiatives and tools that best attract, recruit, train, and retain a truly innovative workforce across digital talent work roles."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_33",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nto oversee and adopt data, analytics, and AI capabilities depends on the strength of its workforce, and continued growth in technical skills. The Department will ensure it is identifying and employing the talent it already possesses, then focus resources on those initiatives and tools that best attract, recruit, train, and retain a truly innovative workforce across digital talent work roles. The Department will also identify and train nontechnical personn el who will lead and oversee a culture of innovation that advances the responsible use and adoption of data, analytics, a nd AI capabilities. The Department’s infrastructur e and digital ecosystem remain obstacles t o hiring talent from the cutting edge of the private sector. While the Department takes all necessary steps to enhance its technical foundation, talent management efforts and resources will focus on upskilling and reskilling Service members and civilians in the work roles that DoD Components have determined are the most important for addressing the needs of the Department. For instance, Service members and civilians with domain knowledge and basic digital skills will be upskilled or reskilled with targeted training and hands-o n opportunities to serve in work roles s uch as data architect, data steward, and user experience designer within the newly expanding Department-l evel workforce framework."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_34",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nare the most important for addressing the needs of the Department. For instance, Service members and civilians with domain knowledge and basic digital skills will be upskilled or reskilled with targeted training and hands-o n opportunities to serve in work roles s uch as data architect, data steward, and user experience designer within the newly expanding Department-l evel workforce framework. Components will draw personnel identified for upskilling and reskilling opportunities from the Department’s Total Force. Active and Reserve Service members often possess high-d emand digital skills not directly aligned to their occupational specialty. To retain talent, the Department will create more flexible service structures that cultivate and reward strengths and avoid penalizing personnel for selecting non-t raditional career paths. While the DoD digital workforce grows and strengthens through upskilling and reskilling, the Department will also think differently about maturing pipelines to attract, recruit, and flexibly hire digital talent. Components will use existing hiring authorities and retention tools at their disposal, and institute reforms where appropriate to allow for maximum flexibility in garnering digital talent."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_35",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nselecting non-t raditional career paths. While the DoD digital workforce grows and strengthens through upskilling and reskilling, the Department will also think differently about maturing pipelines to attract, recruit, and flexibly hire digital talent. Components will use existing hiring authorities and retention tools at their disposal, and institute reforms where appropriate to allow for maximum flexibility in garnering digital talent. Additionally, the Department will execute a series of pilots to identify organic talent, validate barriers and blockers presented, and establish a cadre of Service members and civilians from across the DoD enterprise to build and apply digital solutions for the most difficult missions. DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY 13 IMPLEMENTATION 14 DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY The Chief Digital and Artificial Intelligenc e Offic e (CDAO) w ill lead and oversee th e implementation of this Strategy. The CDAO will collaborate on implementation with Components through the CDAO Council, the senior leadership body that governs and coordinates the Department’s integrated data, analytics, and AI enterprise.5 For c ertain issues, the CDAO Council recommends decisions on data, analytics, and AI to the Deputy’s Management Action Group, the Deputy's Innovation Steering Group, and the Deputy’s Workforce Council."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_36",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nthis Strategy. The CDAO will collaborate on implementation with Components through the CDAO Council, the senior leadership body that governs and coordinates the Department’s integrated data, analytics, and AI enterprise.5 For c ertain issues, the CDAO Council recommends decisions on data, analytics, and AI to the Deputy’s Management Action Group, the Deputy's Innovation Steering Group, and the Deputy’s Workforce Council. The CDAO will conduct an annual review of the Strategy and report results through the CDAO Council. The CDAO Council and supporting forums will ensure the exchange of challenges, lessons, and best practices gleaned from across the Department, and oversee initiatives for d igital talent development, leadership, and culture as critical en ablers. IMPLEMENTATION PLANNING GUIDANCE 5. Standing membership for the Council is at the Deputy and/or Vice level (or their delegated representatives) of the following organizations: the Offices of the Under Secretary of Defense for Research & Engineering, Acquisition & Sustainment, Policy, Comptroller, Personnel & Readiness , and Intelligence & Security; the Office of Cost Assessment and Program Evaluation; the Office of the Chief Information Officer; the Joint Chiefs ofStaff J 3 and J 6; the Combatant Commands; the Military Departments; and the National Guard Bureau."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_37",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nthe Offices of the Under Secretary of Defense for Research & Engineering, Acquisition & Sustainment, Policy, Comptroller, Personnel & Readiness , and Intelligence & Security; the Office of Cost Assessment and Program Evaluation; the Office of the Chief Information Officer; the Joint Chiefs ofStaff J 3 and J 6; the Combatant Commands; the Military Departments; and the National Guard Bureau. DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY 15DoD Components have assigned oversight for data, analytics, and AI differently based on their missions, governing laws and applicable procedures, and organizational structures. The state of data maturity across the Department varies significantly from Component to Component. Thus, Components will tailor implementation accordin g to self-assessed data maturity levels, mission parameters, and pertinen t laws. This strategy does not prescribe that Components reorganize in the same fashion as the DoD CDAO. However, within 60 days of publication, Components will designate their team or office of primary responsibility for implementing this strategy and identify any teams or offices with contingent responsibilities. After analyzing the goals of this strategy, Component leaders may determine that multiple teams will be responsible for implementation."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_38",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nprescribe that Components reorganize in the same fashion as the DoD CDAO. However, within 60 days of publication, Components will designate their team or office of primary responsibility for implementing this strategy and identify any teams or offices with contingent responsibilities. After analyzing the goals of this strategy, Component leaders may determine that multiple teams will be responsible for implementation. Based on lessons learned from implementing the previous DoD AI and Data Strategies, outcomes-b ased performan ce indicators will be established, refined, and monitored in coordination with the CDAO Council as an integrated part of the Department’s enterprise performance analytics framework. To further aid Component-l evel decision-making and execution, the CDAO will publish expanded implementation guidance and additional appendices to this strategy. The expanded implementation guidance will outline the process by which the CDAO and CDAO Council collaborate with the Components to create agreed upon strategic performance measures linked to this Strategy’s key outcomes and strategic goals. This collaborative process will ensure measures are supported by authoritative data sources and maximize the use of automated data collection methods for efficient performance monitoring."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_39",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nThe expanded implementation guidance will outline the process by which the CDAO and CDAO Council collaborate with the Components to create agreed upon strategic performance measures linked to this Strategy’s key outcomes and strategic goals. This collaborative process will ensure measures are supported by authoritative data sources and maximize the use of automated data collection methods for efficient performance monitoring. Where Authoritative Data Sources do not exist, the CDAO will assist in their construction and maturation until these sources meet senior leader decision requirements.IMPLEMENTATION RISK MANAGEMENT Data, a nalytics, a nd AI-enabled technologies are having profound impacts on the ways we work, live, and engage with one another. Aided by training and user-f riendly interfaces, the integration of these capabilities within the Department’s systems and activities will contin ue to increase until they are nearly ubiquitous. The anticipated breadth of adoption by the Department and its competitors, and the nonlinear evolution of thes e technologies, present strategists with unique foresight challenges, especially for resource planning. For data, analytics, and AI technologies, Components will identify and adopt resourcing schemes, processes, and assessment tools that offer leaders maximum flexibility to compliantly deliver iteratively developed capabilities at speed."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_40",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nubiquitous. The anticipated breadth of adoption by the Department and its competitors, and the nonlinear evolution of thes e technologies, present strategists with unique foresight challenges, especially for resource planning. For data, analytics, and AI technologies, Components will identify and adopt resourcing schemes, processes, and assessment tools that offer leaders maximum flexibility to compliantly deliver iteratively developed capabilities at speed. Each iteration or release cycle will incrementally reduce risk while rapid feedback loops ensure that Components more consistently meet user demands. By staying adaptive, the Department can maintain a deep understanding of the specific needs of end users and adjust more quickly to changes in the security environment. This strategy’s learning -based, agile approach to adoption and emphasis on data quality also mitigate implementation risks. Though strategic success depends upon a high degr ee of decentralized execution, the CDAO Counci l and Componen t leader s can learn from one anothe r and coordinat e to manage critica l dependencies among the goals in this strategy and parall el goals in other DoD strategies. As the warfighting use cases for analytics and AI technologies continue to expand, we can expect our strategic competitors to field them to enhance their capabilities. Our adversaries will also continu e to target U.S. technologies for theft and exploitation."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_41",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\ne to manage critica l dependencies among the goals in this strategy and parall el goals in other DoD strategies. As the warfighting use cases for analytics and AI technologies continue to expand, we can expect our strategic competitors to field them to enhance their capabilities. Our adversaries will also continu e to target U.S. technologies for theft and exploitation. Therefore, the Department will employ development approaches that allow us to move quickly, protect our advantages, and abide by our laws, policies, and values. The Department recognizes the privacy and civil liberties challenges posed by data, analytics, and AI capabilities and will establish transparent governance and compliance processe s that address the full scop e of these potentia l risks . By focusin g on data governanc e and data qualit y for analytics and AI development, the Department can mitigate certain risks, including the replication of unintended bias across the enterprise. Component leaders and technologists remain committed to the objectives of the DoD Responsib le AI Strategy & Implementation Pathway and to developing AI capabilities that are responsible , equitable , traceable , reliable , and governable ."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_42",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\ndata qualit y for analytics and AI development, the Department can mitigate certain risks, including the replication of unintended bias across the enterprise. Component leaders and technologists remain committed to the objectives of the DoD Responsib le AI Strategy & Implementation Pathway and to developing AI capabilities that are responsible , equitable , traceable , reliable , and governable . 1919 DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY 16IMPLEMENTATION CONCLUSION DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY 17 The Department’s scale and warfighting mission are unique, but organizations from all sectors have overcome similar challenges and have harnessed the benefits of digital transformation. DoD leaders will have access to high quality data, advanced analytics, and AI capabilities to make timely and well-i nformed d ecisions to defend the homeland, deter aggression, and win in conflict. Our military c ompetitors are integrating thes e same technologies for t heir own advantage. We cannot afford to wait and, moreover, we cannot succeed alone. This strategy’s approach embraces the need for speed, agility , learning, and responsibility. Pursuing this agile approach and focusing a ctivities on the goals outlined in this strategy will allow the Department to adopt data, analytics, and AI- enabled capabilities at the pace and scale required to build enduring decision advantage."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_43",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nafford to wait and, moreover, we cannot succeed alone. This strategy’s approach embraces the need for speed, agility , learning, and responsibility. Pursuing this agile approach and focusing a ctivities on the goals outlined in this strategy will allow the Department to adopt data, analytics, and AI- enabled capabilities at the pace and scale required to build enduring decision advantage. If we confront our challenges holistically and refuse to accept the status quo, we will accelerate data, analytics, and AI adoption and continuously deploy creativ e solutions for the defense, security, and prosperity of the American people. 18 DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY APPENDIX A: QUALITY DATA This appendix provides additiona l guidelines for improvin g the Department’s foundational data management to increas e the quality and availability of relevant DoD data. User needs and local requirements are the basis of data quality. Therefore, Components and subordinate organizations will develop data quality implementation guidance and associated metrics. Since this appendix retains the VAULTIS framework, existing Component-l evel implementation plans based on the 2020 Data Strategy are still sound. However, over time, Components will evolve their data management plans to align more closely with this Strategy."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_44",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nlocal requirements are the basis of data quality. Therefore, Components and subordinate organizations will develop data quality implementation guidance and associated metrics. Since this appendix retains the VAULTIS framework, existing Component-l evel implementation plans based on the 2020 Data Strategy are still sound. However, over time, Components will evolve their data management plans to align more closely with this Strategy. As Components develop and implement their data quality plans, data sets targeted for improvement will be founded on metadata to allow for data search and discovery; prioritized for relevance and mission value; acted upon such that improvement efforts are appropriately resourced; monitored to measure and report quality levels on priority data sets across their lifecycles; and corrected through cyclical processes to continuously address quality degradation. Two tools for use in data management planning are the data quality dimensions and the VAULTIS framework. These tools represent interrelated and mutually supporting concepts that apply across data’s lifecycle, from creation to disposal. Poor quality data will inevitably undermine data trustworthiness, raise security concerns, and negate th e utility of the VAULTIS framework. Conversely, even high-q uality data that does not align to the VAULTIS framework will be of limited value to analytical and AI efforts. 19 DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY 1."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_45",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nacross data’s lifecycle, from creation to disposal. Poor quality data will inevitably undermine data trustworthiness, raise security concerns, and negate th e utility of the VAULTIS framework. Conversely, even high-q uality data that does not align to the VAULTIS framework will be of limited value to analytical and AI efforts. 19 DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY 1. DATA QUALITY DIMENSIONS Data owners may categorize data sets at different levels of quality over time because of age, prioritization, initial condition, and other factors. Therefore, data quality dimensions are relative, and owners will assess the dimensions across the data’s lifecycle. The table below provides sample assessment questions for each dimension. 20 DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGYAPPENDIX A: QUALITY DATA Dimension Assessment Questions Accuracy: Data that correctly reflect proven, true values or the specified action, person, or entity. Accuracy includes data structure, content, and variability. How frequently do values not align to their assignedformat?  How frequently do data values match ground truth?  How is error measured? Is it tolerable for the specifiedpurpose? Completeness: The data present at a specified time contain the expected information or statistics, as measured at the data set, row, or column level.  Is there known data that would make the set more complete?"
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_46",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nalign to their assignedformat?  How frequently do data values match ground truth?  How is error measured? Is it tolerable for the specifiedpurpose? Completeness: The data present at a specified time contain the expected information or statistics, as measured at the data set, row, or column level.  Is there known data that would make the set more complete?  Does the data set contain sufficient breadth ofinformation to contextualize the data for its purpose?  What fields in the data expect some null values? Howoften are null values present? Conformity: Data sets follow agreed upon internal policies, standards, procedures, and architectural requirements. Does the data’s format match the applicablestandard(s)?  Is the data set architecture published and available?  Are there database constraints implemented inaccordance with internal policies, standards, andprocedures to prevent erroneous input? Consistency: The degree to which a value is uniformly represented within and across data sets. Are there other data sets that reference values in thisdata set?  Are there discrepancies? Uniqueness: Ensures there is a one-to -one alignment between each observed event and the record that describes such an event. Are there other Authoritative Data Sources that servethe same function?  Are there duplicate records in this data set?"
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_47",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nrepresented within and across data sets. Are there other data sets that reference values in thisdata set?  Are there discrepancies? Uniqueness: Ensures there is a one-to -one alignment between each observed event and the record that describes such an event. Are there other Authoritative Data Sources that servethe same function?  Are there duplicate records in this data set? Integrity : A data set’s pedigree, provenance, and lineage are known and aligned with relevant business rules. Are there opportunities for data to be tampered with,misreported, degraded, corrupted, poisoned, orotherwise altered during the collection, storage,processing, or transmission processes?  How often are data quality checks conducted to addresspoor data quality?  Does the data cleaning process result in data that can betrusted? Timeliness: Measures the time between an event occurring and the data’s availability for use. How frequently do supported data consumers requireupdates?  Does the data purpose require reduced latency? 2. VAULTIS FRAMEWORK The VAULTIS framework discussed in the 2020 DoD Data Strategy remains a useful tool for Components to organize and monitor their data management plans."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_48",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\ndata that can betrusted? Timeliness: Measures the time between an event occurring and the data’s availability for use. How frequently do supported data consumers requireupdates?  Does the data purpose require reduced latency? 2. VAULTIS FRAMEWORK The VAULTIS framework discussed in the 2020 DoD Data Strategy remains a useful tool for Components to organize and monitor their data management plans. The key attributes and associated assessment questions include: 21 DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGYAPPENDIX A: QUALITY DATA Attribute Assessment Questions Visible: Consumers can locate the needed data. Are authorized users able to discover the existence of data that is of particular interest or value?  Are data stewards, data custodians, and functional data managers assigned responsibility for identifying, registering, and exposing data to make it easily discoverable across the enterprise, and to appropriate external partners?  Are users able to discover and rapidly identify who is responsible forspecific data products, the location of data products, the types of data products available, and the means of accessing the data products? Accessible: Consumers can retrieve the data. Are authorized users able to obtain the data they need when they needit?  Are data, including warfighting, intelligence, and business data, accessible to authorized users?"
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_49",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nand rapidly identify who is responsible forspecific data products, the location of data products, the types of data products available, and the means of accessing the data products? Accessible: Consumers can retrieve the data. Are authorized users able to obtain the data they need when they needit?  Are data, including warfighting, intelligence, and business data, accessible to authorized users? Understandable: Consumers can find descriptions of data to recognize the content, context, and applicability. Are tools in place that allow users to securely aggregate, compare, and analyze the data?  Are the data labeled and formatted appropriately to support large scale analytics?  Does the metadata associated with the data contain the contextualrelationships and business rules? Linked: Consumers can exploit complementary data elements through innate relationships. Are the data linked such that relationships and dependencies can beuncovered and maintained?  Does the organization use industry best practices for open data standards, data catalogs, and metadata tagging?  Are the data unnecessarily siloed or do they support connections acrossdisparate sources? Trustworthy: Consumers can be confident in all aspects of their use of the data for decision - making. Do the data represent a source of truth?  Must the data undergo additional vetting to ensure it can supportdecision -making?"
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_50",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nopen data standards, data catalogs, and metadata tagging?  Are the data unnecessarily siloed or do they support connections acrossdisparate sources? Trustworthy: Consumers can be confident in all aspects of their use of the data for decision - making. Do the data represent a source of truth?  Must the data undergo additional vetting to ensure it can supportdecision -making?  Can users interpret and analyze data without concern for flawedassumptions, resulting in potentially fatal outcomes?  Does the data reflect metadata or context necessary to enableconsumers to make appropriate judgments about whether or how to rely on the data? Taken together, thes e guidelines provid e a foundation for or ganizations to greatly enhanc e the quality of high priority data sets in effective and efficient ways. Absent an organized approach based on tested criteria, Components will face significant challenges developing the level of data quality required to address analytics and artificial in telligence requirements. As such, organizations will use collaborative forums, such as th e CDAO Council and its supporting forums, to flatten communications, enhance visibility, and ensure alignment across approaches to data quality improvement and maintenance."
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_51",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nan organized approach based on tested criteria, Components will face significant challenges developing the level of data quality required to address analytics and artificial in telligence requirements. As such, organizations will use collaborative forums, such as th e CDAO Council and its supporting forums, to flatten communications, enhance visibility, and ensure alignment across approaches to data quality improvement and maintenance. 22 DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGYAPPENDIX A: QUALITY DATA Attribute Assessment Questions Interoperable: Consumers and producers have a common representation and comprehension of data. Can the data be exchanged between systems and users while maintaining its quality and usability?  Do the data have semantic as well as syntactic interoperability based on common data formats and machine -to-machine communications? Secure: Consumers understand data safeguarding responsibilities, follow classification management procedures, and know that data is protected from unauthorized use and manipulation. Are the data protected while at rest, in motion, and in use (withinapplications, with analytics, etc.)?  Does the organization use a disciplined approach to data protection, such as attribute -based access control, across the enterprise?  Are protective mechanisms (e.g., security controls) in place forcredentialed users to ensure that access is permitted in accordance with applicable laws, regulations, and policies?"
  },
  {
    "id": "2023_Data_Analytics_and_Artificial_Intelligence_Adoption_Strategy_chunk_52",
    "text": "Source: 6 2023 Data, Analytics, and Artificial Intelligence Adoption Strategy.pdf\n\nthe data protected while at rest, in motion, and in use (withinapplications, with analytics, etc.)?  Does the organization use a disciplined approach to data protection, such as attribute -based access control, across the enterprise?  Are protective mechanisms (e.g., security controls) in place forcredentialed users to ensure that access is permitted in accordance with applicable laws, regulations, and policies?  Are classified management procedures in place to ensure that data,aggregated or not, are safeguarded and in accordance with laws,regulations, and policies? 2626 DOD DATA, ANALYTICS, AND ARTIFICIAL INTELLIGENCE ADOPTION STRATEGY"
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_0",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\n1 DEPARTMENT OF ENERGY AI COMPLIANCE PLANS PER OMB M -24-10, ON ADVANCING GOVERNANCE, INNOVATION, AND RISK MANAGEMENT FOR AGENCY USE OF ARTIFICIAL INTELLIGENCE Prepared by Helena Fu , Acting Chief Artificial Intelligence (AI) Officer (CAIO) , and Bridget Carper, Responsible AI Official (RAIO) of the Department of Energy . 1. STRENGTHENING AI GOVERNANCE General The Office of Critical and Emerging Technologies (CET) and the Office of the Chief Information Officer (OCIO) have undertaken efforts to update the Department of Energy’s (DOE ’s) internal AI -related guidelines and policies consistent with the Office of Management and Budget (OMB) Memorandum M-24-10. The following efforts are planned or in place today: Designation of an Acting Chief AI Officer (CAIO) and Responsible AI Official (RAIO) • DOE has designated a n Acting CAIO consistent with mandated policies by M-24-10. Helena Fu serves as Director of DOE’s Office of Critical and Emerging Technologies (CET) and is also the Department’s Acting CAIO . As the Acting CAIO, Helena is the senior advisor on AI to Departmental leadership and is responsible for coordination, innovation, and risk management in DOE’s development and deployment of AI. • DOE has designated a RAIO who is charged with deploying responsible AI practices and guidelines at DOE. Bridget Carper serves as DOE’s Deputy Chief Information Officer for Architecture, Engineering, Technology, and Innovation and is also the Department’s RAIO."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_1",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\non AI to Departmental leadership and is responsible for coordination, innovation, and risk management in DOE’s development and deployment of AI. • DOE has designated a RAIO who is charged with deploying responsible AI practices and guidelines at DOE. Bridget Carper serves as DOE’s Deputy Chief Information Officer for Architecture, Engineering, Technology, and Innovation and is also the Department’s RAIO. As the RAIO, Bridget maps AI activities through a risk management program and collaborates with officials to establish processes that evaluate the performance of AI systems, ensuring DOE’s compliance through the AI Hub. Convening AI Agency Governance Bodies • The AI Advancement Council (AIAC ) is the principal forum for collaboration and coordination of AI- related activities . The AIAC provides oversight and strategic direction for DOE’ s use of AI. • The Rights- and Safety -Impacting AI Working Group was stood up to support the development of new DOE internal guidelines for reviewing rights- and safety -impacting AI use cases. • The AI and Cybersecurity Working Group is dedicated to reviewing potential cybersecurity threats of AI, understanding where AI can support new cybersecurity applications, and developing cybersecurity and AI guidance. AI Use Case Inventories & Reporting • Consistent with M -24-10, DOE will be conducting an annual inventory of AI use cases across the Department’s program offices, 17 N ational Labs, P ower Marketing Administrations, and field sites."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_2",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\ndedicated to reviewing potential cybersecurity threats of AI, understanding where AI can support new cybersecurity applications, and developing cybersecurity and AI guidance. AI Use Case Inventories & Reporting • Consistent with M -24-10, DOE will be conducting an annual inventory of AI use cases across the Department’s program offices, 17 N ational Labs, P ower Marketing Administrations, and field sites. To support the preparation of this data call, an AI Use 2 Case Inventory Working Group convenes AI leadership across DOE. Group activities include review ing OMB guidance and past use case inventories . • A new component of the AI Use Case Inventory includes reporting on human rights- and safety -impacting use cases. DOE ’s Rights- and Safety -Impacting AI Working Group is developing guidelines for evaluating human rights- and safety - impacting use cases . Development of AI Guidelines & Policies • DOE published Version 2 of the Gen erative AI (GenAI) Reference Guide in June 2024. The guide provides an overview of the key benefits, considerations, risks, and best practices associated with the responsible development, implementation, and use of GenAI technology. Constructed by over 30 DOE offices, sites, and labs, the DOE GenAI Reference Guide Version 2 reflects the latest guidance, including the October 2023 Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial • Intelligence (EO 14110) and OMB M -24-10 guidance."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_3",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nand best practices associated with the responsible development, implementation, and use of GenAI technology. Constructed by over 30 DOE offices, sites, and labs, the DOE GenAI Reference Guide Version 2 reflects the latest guidance, including the October 2023 Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial • Intelligence (EO 14110) and OMB M -24-10 guidance. This guide is focused on helping DOE stakeholders understand responsible use of GenAI technology, the legal framework and obligations for responsible use, and key considerations for mitigating risk. DOE will continue to revise and refresh the guide as needed. • DOE will be taking steps to incorporate principles from the recently re leased National Institute of Standards and Technology ( NIST ) AI 600- 1, Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile and the NIST AI RMF Playbook. • DOE will be conducting discovery on the agency's AI Risks and promoting collaboration on mitigating risks. In addition, we will be leveraging the CAIO Council's Risk Management Working Group for common experiences and recommended responses. • DOE plans to update the 2022 version of its A rtificial Intelligence and Risk Management Playbook ( AI RMP) , which is closely aligned with the NIST Risk Management Framework (RMF) and tailored to addressing AI issues relevant to DOEs mission space."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_4",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nwe will be leveraging the CAIO Council's Risk Management Working Group for common experiences and recommended responses. • DOE plans to update the 2022 version of its A rtificial Intelligence and Risk Management Playbook ( AI RMP) , which is closely aligned with the NIST Risk Management Framework (RMF) and tailored to addressing AI issues relevant to DOEs mission space. • DOE will be developing an AI policy to communicate requirements for ethical AI use, transparency in AI deployment, and risk management. This policy will align to requirements outlined in M-24-10. AI Governance Bodies DOE AI Advancement Council (AIAC) The DOE AIAC is the principal forum for improving collaboration and coordination of broad AI-related activities (i) across the DOE enterprise and (ii) with external stakeholders. The AIAC provides oversight and strategic direction to DOE’s AI- related sub -groups, such as the AI Working Group—a program -level mechanism with subject matter expert participation for cross - DOE coordination and strategy development on AI issues. Sub-groups may make recommendations to the Council within assigned areas of responsibility and esca late issues when required. The Council will resolve policy conflicts elevated by the sub-groups. The Council will: 3 • Develop governance for DOE’s research, development, deployment, and utilization of AI technologies and tools, including methods for remov ing barriers to the Department ’s use of AI and for m anag ing its associated risks."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_5",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nassigned areas of responsibility and esca late issues when required. The Council will resolve policy conflicts elevated by the sub-groups. The Council will: 3 • Develop governance for DOE’s research, development, deployment, and utilization of AI technologies and tools, including methods for remov ing barriers to the Department ’s use of AI and for m anag ing its associated risks. • Provide guidance on the current and future state of strategic AI directions to advance the Department’s missions. • Facilitate information sharing, planning, coordination, and communication of AI activities across the Department and to external stakeholders. • Address and coordinate on significant AI policy issues and provide recommendations that require input from multiple perspectives. • Contribute to DOE efforts to develop goals, priorities, and metrics for guiding and evaluating activities on AI, consistent with the requirements of the National AI Initiative Act of 2020 and EO 14110. • Provide recommendations to a coordinated, cross -Department annual budget request for AI initiatives, encompassing all AI research, development, and deployment activities. • Identify and define priority areas of AI research and development. • Advise DOE senior leadership on opportunities for AI innovations to move to demonstration and applications in support of DOE missions."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_6",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nAct of 2020 and EO 14110. • Provide recommendations to a coordinated, cross -Department annual budget request for AI initiatives, encompassing all AI research, development, and deployment activities. • Identify and define priority areas of AI research and development. • Advise DOE senior leadership on opportunities for AI innovations to move to demonstration and applications in support of DOE missions. • Discuss and implement approaches to workforce training to recruit, train, and retain AI talent at the Department and within the broader DOE complex. • Coordinate on AI partnerships with stakeholder groups —including academia and industry—that enhance national, local, and Tribal partnerships and foster long- term economic growth and job creation for DOE’s AI investments. • Identify opportunities to improve the quality and availability of standardized, secure, aggregate, and privacy -protected datasets for AI activities. AIAC Membership The Council is chaired by the Deputy Secretary, vice -chaired by DOE’s Acting CAIO , and includes the following members, as directed by OMB M -24-10."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_7",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nfoster long- term economic growth and job creation for DOE’s AI investments. • Identify opportunities to improve the quality and availability of standardized, secure, aggregate, and privacy -protected datasets for AI activities. AIAC Membership The Council is chaired by the Deputy Secretary, vice -chaired by DOE’s Acting CAIO , and includes the following members, as directed by OMB M -24-10. (Note: All members of the Council must be f ederal employees.) • Deputy Secretary (Chair) • Chief Artificial Intelligence Officer (Vice -chair) • Chief of Staff to the Secretary • Under Secretary for Infrastructure • Under Secretary for Science and Innovation • Under Secretary for Nuclear Security and Administrator of the National Nuclear Security Administration (NNSA) • Director, Office of Critical and Emerging Technologies • Responsible AI Official • Assistant Secretary for Electricity • Assistant Secretary for Energy Efficiency and Renewable Energy • Assistant Secretary for Fossil Energy and Carbon Management • Assistant Secretary for Nuclear Energy • Assistant Secretary for Environmental Management • Director, Indian Energy Policy and Programs • Director, Office of Management 4 • Director, Office of Legacy Management • Director, Advanced Research Projects Agency – Energy • Chief Information Officer (CIO) • Associate Administrator for Information Management and Chief Information Officer (NA) • Director, Office of Advanced Simulation and Computing & Institutional Research and Development (NA) • Director, Office of Intelligence and Counterintelligence • General Counsel • Director, Office of Enterprise Assessments • Chief Financial Officer • Power Marketing Administration Administrators • Director for Environment, Health, Safety, and Security, to include representation for the Senior Agency Official for Insider Threat • Director, Office of Cybersecurity, Energy Security, and Emergency Response • Director, Office of Science • Director, Office of Advanced Scientific Computing Research (SC) • Director, Office of Technology Transitions • Director, Office of Policy • Chief Human Capital Officer • Director, Office of Project Management • Director, Office of Energy Justice and Equity • Director, Office of Small and Disadvantaged Business Utilization • Assistant Secretary for Congressional and Intergovernmental Affairs • Secretary of Energy (Ex Officio) The following will participate in Council activities as needed: • Senior Advisors in the Office of the Secretary • Assistant Secretary for International Affairs • Senior Procurement Executive • Administrator of the Energy Information Administration • Principal Assistant Deputy Administrator for Research, Development, Test, and Evaluation (NNSA) • Inspector General • Power Marketing Administration C hief I nformation O fficers AIAC Governance The Council provides oversight and strategic direction to DOE’s AI -related sub -groups, such as the AI Working Group— a program -level mechanism with subject matter expert participation for cross -DOE coordination and strategy development on AI issues."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_8",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nfor Research, Development, Test, and Evaluation (NNSA) • Inspector General • Power Marketing Administration C hief I nformation O fficers AIAC Governance The Council provides oversight and strategic direction to DOE’s AI -related sub -groups, such as the AI Working Group— a program -level mechanism with subject matter expert participation for cross -DOE coordination and strategy development on AI issues. Sub- groups may make recommendations to the Council within assigned areas of responsibility and escalate issues when required. The Council will resolve policy conflicts e levated by the sub -groups. External Engagement 5 The Chair and Vice-chair may request broader participation from non-governmental entities such as National Labs and contractors, depending upon the topic or activity, for the purpose of receiving information from such stakeholders or when those stakeholders are presenting their individual advice and recommendations to DOE. To avoid any appearance that non-governmental entities are fixed members of the AIA C, or that the AI AC is giving preferential treatment to any individual or group, the AIAC must avoid the regular and systematic participation of the same external stakeholders in AIAC meetings. These engagements are limited to the provision of individual advice and recommendations; non-governmental stakeholders may not participate in the group decision-making process."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_9",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nare fixed members of the AIA C, or that the AI AC is giving preferential treatment to any individual or group, the AIAC must avoid the regular and systematic participation of the same external stakeholders in AIAC meetings. These engagements are limited to the provision of individual advice and recommendations; non-governmental stakeholders may not participate in the group decision-making process. Other routes for engagement with external experts include the Secretary of Energy Advisory Board (SEAB) and the AI Working Group. The SEAB is composed primarily of members of academia, industry, and non-governmental organizations. The SEAB provides advice and recommendations to the Secretary of Energy on the Administration's energy policies, the Department's basic and applied research and development ac tivities, economic and national security policy, and on any other activities and operations of DOE , as the Secretary may direct. The duties of the Board are solely advisory. The Secretary has directed the SEAB to assess the Department’s role in AI development and deployment, as well as the growing energy demands of AI technologies. The AI Working Group is a working-level group composed of individuals across the DOE complex and the 17 N ational L aboratories dedic ated to execution of EO 14110 as well as general AI development, deployment, and governance issues within the Department."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_10",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nthe Department’s role in AI development and deployment, as well as the growing energy demands of AI technologies. The AI Working Group is a working-level group composed of individuals across the DOE complex and the 17 N ational L aboratories dedic ated to execution of EO 14110 as well as general AI development, deployment, and governance issues within the Department. AI Use Case Inventories DOE has prepared and reported annual AI use case inventories since 2021 and has proven processes and tools in place to ensure information is comprehensive, complete, and adheres to OMB guidance. DOE will follow existing OCIO processes and procedures to conduct the annual inventory of AI use c ases. A key component of DOE ’s approach is leverag ing a D ata Call Application (DCA) capability for IT- related data calls . Using DCA enables reporting entities to easily update, add, remove, or carryover inventories from previous AI use case data collections. DCA also provides quality control mechanisms, including error checking. The DCA tool also includes an approval hierarchy that increases complete and accurate r eporting. All Departmental El ements (DE s) and components are tasked to respond to the annual AI use case da ta call. OCIO develops and proactively communicates the data call schedule and requirements to all DOE stakeholders to ensure timely and accurate inputs."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_11",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nincluding error checking. The DCA tool also includes an approval hierarchy that increases complete and accurate r eporting. All Departmental El ements (DE s) and components are tasked to respond to the annual AI use case da ta call. OCIO develops and proactively communicates the data call schedule and requirements to all DOE stakeholders to ensure timely and accurate inputs. In addition, t he O CIO team hosts informational webinars at the onset of the data call period and holds biweekly office hours sessions to provide continuous data call and DCA support. Once the DEs have completed and approved their inventories, personnel in OCIO—in coordination with CET—will conduct a comprehensive verification and validation review prior to submitting to OMB. DOE also established an AI Use Case Inventory Working Group to aid in a consistent approach to the inventory process. The working group brings together AI leadership across DEs to share lessons learned and review new guidance. 6 Reporting on AI Use Cases Not Subject to Inventory DOE will collect AI use cases throughout the Department based on OMB final instructions. During the validation and verification phase, DOE will determine if any use cases a meet the criteria for exclusion based on M-24- 10 guidance. DOE will maintain a comprehensive AI use case inventory and report externally only those use cases that meet reporting criteria in M-24-10. DOE will validate previously reported use cases on an annual basis."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_12",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nOMB final instructions. During the validation and verification phase, DOE will determine if any use cases a meet the criteria for exclusion based on M-24- 10 guidance. DOE will maintain a comprehensive AI use case inventory and report externally only those use cases that meet reporting criteria in M-24-10. DOE will validate previously reported use cases on an annual basis. DOE sites will review and verify previously reported use cases and will be prompted to reconfirm each use case’s status as reporta ble or non-reportable. Any use case that no longer meets the criteria of non- reportable will be reclassified and included in the DOE use case inventory as appropriate. 2. ADVANCING RESPONSIBLE AI INNOVATION Removing Barriers to the Responsible Use of AI Cybersecurity and IT Infrastructure DOE is challenged with providing tools and maintaining compliance with evolving cybersecurity standards in the wake of evolving threat vectors. Staff are unable to access and utilize the advanced AI tools and services provided by leading cloud service providers (CSPs) as many critical services are awaiting FedR AMP authorization. Furthermore, there are feature parity gaps between the commercial offerings and the federal government -specific cloud environments. While this feature gap is closing, it is likely that the gap will continue as CSPs roll out new services and capabilities."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_13",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nadvanced AI tools and services provided by leading cloud service providers (CSPs) as many critical services are awaiting FedR AMP authorization. Furthermore, there are feature parity gaps between the commercial offerings and the federal government -specific cloud environments. While this feature gap is closing, it is likely that the gap will continue as CSPs roll out new services and capabilities. Furthering the challenge is that existing cloud management security practices elongate the timeline between a service achieving FedR AMP approval and when the Department can offer those services to developers within the context of the existing managed cloud environments. The IT infrastructure barrier extends beyond the serverless CSP services to the availability and timeliness of securing virtual machines with the requisite Graphics Processing Unit (GPU) hardware to develop, train, manage, and deploy advanced AI models. This challenge is industry-wide; however, it will impact the rollout and adoption of more advanced customized use cases that require dedicated GPU hardware. Data Ensuring access to high-quality and well-curated data for AI training and consumption is a work in progress. Legacy databases, data warehouses, and other data stores were designed based on requirements at the time and do not adequately reflect modern data management practices."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_14",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nwill impact the rollout and adoption of more advanced customized use cases that require dedicated GPU hardware. Data Ensuring access to high-quality and well-curated data for AI training and consumption is a work in progress. Legacy databases, data warehouses, and other data stores were designed based on requirements at the time and do not adequately reflect modern data management practices. Particularly, the use of data for AI was not contemplated or a prioritized requirement when designing and building our existing infrastructure. As a result, DOE faces obstacles in ensuring that data used for AI training and use in AI models is high quality, well-curated, and easily accessible. The existing data infrastructure lacks the necessary integration, governance, and management capabilitie s to support AI adoption effectively. This is evidenced through fragmented data sources, inconsistent data quality, and inconsistent and insufficient data interoperability standards. Internal Guidance for the Use of Generative AI 7 DOE developed and published the GenAI Reference Guide to provide an overview of the key benefits, considerations, risks, and best practices associated with the responsible development, implementation, and use of GenAI technology. This guide is focused on helping stakeholders across the DOE enterprise understand the principles for using GenAI technology responsibly, the legal framework and obligations for responsible use, and key considerations for mitigating risks."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_15",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nGenAI Reference Guide to provide an overview of the key benefits, considerations, risks, and best practices associated with the responsible development, implementation, and use of GenAI technology. This guide is focused on helping stakeholders across the DOE enterprise understand the principles for using GenAI technology responsibly, the legal framework and obligations for responsible use, and key considerations for mitigating risks. It provides guidelines for safeguards and oversight mechanisms, including keeping a human in the loop throughout the AI lifecycle, developing review processes, and ensuring foundational security. AI Talent DOE has been at the forefront of advancements in technology and science since its inception. For decades , our scientists, engineers, and technologists have been advancing developments in AI, and the Department is committed to attracting, retaining, and training a workforce that will help the United States lead the world in AI innovation responsibly. To develop the next generation of AI talent, including in the f ederal government, DOE and the National Science Foundation (NSF) have established a pilot program to train 500 new researchers by 2025 to meet the rising demand for AI talent. To ensure effective coordination, t he Office of Human Capital (HC) was designated as the Agency AI Talent Lead for DOE and is responsible for working across the Department to align AI positions toward a common goal."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_16",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nScience Foundation (NSF) have established a pilot program to train 500 new researchers by 2025 to meet the rising demand for AI talent. To ensure effective coordination, t he Office of Human Capital (HC) was designated as the Agency AI Talent Lead for DOE and is responsible for working across the Department to align AI positions toward a common goal. HC has several existing and planned initiatives aimed at increasing the Department’s AI talent and capacity. DOE completed the government- wide AI Talent and AI Enabling Talent Data Call and is now completing its internal workforce planning using this exercise to identify and track its federal AI positions and vacancies . HC plans to update position descriptions to reflect those add itional job responsibilities. Once complete, HC will assign AI work roles from the Department of Deference Cyber Workforce Framework to better identify the skillsets associated with those positions. Additionally, the Department will provide resources and training to develop AI talent across its energy, environmental, and nuclear workforc e and to al so achieve AI literacy for non - practitioners to help ensure the responsible use of AI."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_17",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nassign AI work roles from the Department of Deference Cyber Workforce Framework to better identify the skillsets associated with those positions. Additionally, the Department will provide resources and training to develop AI talent across its energy, environmental, and nuclear workforc e and to al so achieve AI literacy for non - practitioners to help ensure the responsible use of AI. DOE plans to leverage Office of Personnel Management ( OPM )-provided gov- to-gov AI fundamentals training , the recently announced AI training series offered through the General Service s Administration ( GSA) AI Co mmunity of Practice, and the AI coursework available to employees in DOE ’s Learning M anagement System . Further, DOE is prioritizing AI workforce hiring. FY26 IT budget guidance provided to DEs states that they should consider identifying a dedicated subject matter expert (or experts ) to support rapidly evolving technologies, including Gen AI. The AI expert would develop or support product development, ensure proper integration into existing technical environments, and collaborate on innovative initiatives."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_18",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nanagement System . Further, DOE is prioritizing AI workforce hiring. FY26 IT budget guidance provided to DEs states that they should consider identifying a dedicated subject matter expert (or experts ) to support rapidly evolving technologies, including Gen AI. The AI expert would develop or support product development, ensure proper integration into existing technical environments, and collaborate on innovative initiatives. 8 AI Sharing and Collaboration DOE developed a generative AI tool, PolicyAI , which is being researched within government agencies for searching and summarizing historical National Environmental Policy Act ( NEPA) documents, for assistance in drafting new Environmental Impact Studies (EIS) to deploy new clean energy projects, for analyzing public comments, and for increasing access to public comment reviews. The investments in AI for permitting will augment existin g research and analysis tasks for NEPA reviews while keeping a human in the loop for decision-making. DOE kicked off this initiative with 12 federal agencies. DOE’s Office of Scientific and Technical Information (OSTI) fulfills agency -wide responsibilities to collect, preserve, and disseminate both unclassified and classified scientific and technical information (STI) emanating from DOE-funded research and development activities."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_19",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nexistin g research and analysis tasks for NEPA reviews while keeping a human in the loop for decision-making. DOE kicked off this initiative with 12 federal agencies. DOE’s Office of Scientific and Technical Information (OSTI) fulfills agency -wide responsibilities to collect, preserve, and disseminate both unclassified and classified scientific and technical information (STI) emanating from DOE-funded research and development activities. To serve this mission, OSTI developed DOE CODE , a public software services platform and search tool for software and code resulting from DOE-funded research that provides functionality for collaboration, archiving, and discovery of scientific and business software funded by DOE. This platform serves as a mechanism for shar ing AI code with the public, as all DOE N ational L aboratories , facilities, and contractors are required to announce their software using DOE CODE. For sharing internally within the Department , DOE CODE offers a GitLab instance as a repository option for DOE-funded developers. Registered users can create and import their own repositories. The repository service can be helpful when developers need controlled access to code (e.g., not open source or not yet public), or for collaboration between developers from multiple labs or institutions."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_20",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nFor sharing internally within the Department , DOE CODE offers a GitLab instance as a repository option for DOE-funded developers. Registered users can create and import their own repositories. The repository service can be helpful when developers need controlled access to code (e.g., not open source or not yet public), or for collaboration between developers from multiple labs or institutions. Additionally, DOE’s Office of Technology Transitions (OTT) launched the Visual Intellectual Property Search database, known as VIPS, in July 2024 to make it easier for the public to perform intellectual property (IP) searches and find new technologies developed at DOE’s 17 National Laboratories and several additional DOE plants and sites. Within this database, members of the public and other federal agencies can search for AI and machine learning IP generated by DOE . Entries include open- source code that can be used to access models and AI assets. DOE promotes code sharing, models, and other AI assets internally through several AI working groups, including the H eadquarters and National Lab Subgroup, AI Community of Interest, and AI Community of Practice. Harmonization of Artificial Intelligence Requirements DOE is engaged in the process of aligning AI guidelines and frameworks to reduce barriers, improve compliance, and foster innovation across the Department."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_21",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nDOE promotes code sharing, models, and other AI assets internally through several AI working groups, including the H eadquarters and National Lab Subgroup, AI Community of Interest, and AI Community of Practice. Harmonization of Artificial Intelligence Requirements DOE is engaged in the process of aligning AI guidelines and frameworks to reduce barriers, improve compliance, and foster innovation across the Department. The goal is to create a consistent set of guardrails that facilitate the development, deployment, and use of AI technologies while ensuring safety, security, fairness, and transparency. These aspects are being socialized across the Department using existing channels of communication, including working groups and standing cadences between leaders of from DEs and National Labs. 9 3. MANAGING RISKS FROM THE USE OF ARTIFICIAL INTELLIGENCE Determining Which Artificial Intelligence Is Presumed to Be Safety -Impacting or Rights- Impacting To ensure compliance with OMB guidance, DOE created the Rights- and Safety -Impacting AI Working Group. This group r epresent s AI equities from across the Department and will support efforts to identify rights and safety impacting AI use cases. The group will first develop a checklist to guide the Department in determining if an AI use case is rights and safety impacting. This checkli st will be shared with all Departmental Elements (DEs) for immediate use as AI efforts are planned ."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_22",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nfrom across the Department and will support efforts to identify rights and safety impacting AI use cases. The group will first develop a checklist to guide the Department in determining if an AI use case is rights and safety impacting. This checkli st will be shared with all Departmental Elements (DEs) for immediate use as AI efforts are planned . In accordance with the Federal Information Technology Acquisition Reform Act (FITARA) requirements, the OCIO reviews and approves IT acquisition strategies. As part of that review process, OCIO will request completion of the checklist for AI acquisitions to identify those t hat may be rights or safety impacting. The Department also plans to develop AI policy communication roles and responsibilities for AI use. The policy will include a Contractor Requirements Document to levy the same minimum risk management practices on contractors developing AI use cases for the Department. C reate a use case checklist for defining safety and rights impacting use cases. During the annual AI use case inventory process, DEs will be asked to identify and report rights and safety impacting use cases. DOE will be developing additional processes to address AI use cases that may arise outside of the annual reporting cycle. Implementation of Risk Management Practices and Termination of Non- Compliant AI DOE’s Rights- and Safety -Impacting AI Working Group will provide recommendations on implementation of risk management practices ."
  },
  {
    "id": "DOE_AI_Compliance_Plan_92324_chunk_23",
    "text": "Source: 7 DOE AI Compliance Plan 9.23.24.pdf\n\nasked to identify and report rights and safety impacting use cases. DOE will be developing additional processes to address AI use cases that may arise outside of the annual reporting cycle. Implementation of Risk Management Practices and Termination of Non- Compliant AI DOE’s Rights- and Safety -Impacting AI Working Group will provide recommendations on implementation of risk management practices . Based on self-reporting, DOE will work with the use c ase o wner to determin e if a use case meets criteria as rights or safety impacting and confirm that the minimum risk management practices are i mplemented . If the use case owner is unable to implement the risk management practices, then the Acting CAIO will determine if a waiver is appropriate, or if use case termination may be required. Minimum Risk Management Practices The DOE Rights- and Safety -Impacting AI Working Group will facilitate the implementation of minimum risk management practices . DOE will evaluate use cases collected during the annual AI use case inventory data call and use cases self -reported throughout the year to determine which use cases meet criteria as rights or safety impacting and confirm that the minimum risk management practices are implemented ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_0",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n1 U.S. Department of Health and Human Services: Strategic Plan for the Use of Artificial Intelligence in Health, Human Services, and Public Health Strategic Plan January 2025 United States Department of Health and Human Services 2 Contents Acknowledgements and Disclaimer ................................ ................................ ................................ ................................ .. 4 Letter from the Deputy Secretary ................................ ................................ ................................ ................................ ..... 5 Introduction ................................ ................................ ................................ ................................ ................................ ......... 6 1 Medical Research and Discovery ................................ ................................ ................................ ............................. 18 1.1 Introduction and Context ................................ ................................ ................................ ................................ .. 18 1.2 Stakeholders Engaged in the Medical Research and Discovery AI Value Chain ................................ ............. 20 1.3 Opportunities for the Application of AI in Medical Research and Discovery ................................ .................. 22 1.4 Trends of AI in Medical Research and Discovery ................................ ................................"
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_1",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nMedical Research and Discovery ................................ ................................ ................................ ............................. 18 1.1 Introduction and Context ................................ ................................ ................................ ................................ .. 18 1.2 Stakeholders Engaged in the Medical Research and Discovery AI Value Chain ................................ ............. 20 1.3 Opportunities for the Application of AI in Medical Research and Discovery ................................ .................. 22 1.4 Trends of AI in Medical Research and Discovery ................................ ................................ ............................. 23 1.5 Potential Use Cases and Risks for AI in Medical Research and Discovery ................................ ..................... 25 1.6 Action Plan ................................ ................................ ................................ ................................ ....................... 32 1.7 Conclusion ................................ ................................ ................................ ................................ ........................ 48 2 Medical Product Development, Safety, and Effectiveness ................................ ................................ ..................... 48 2.1 Introduction and Context ................................ ................................ ................................"
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_2",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nin Medical Research and Discovery ................................ ................................ ............................. 23 1.5 Potential Use Cases and Risks for AI in Medical Research and Discovery ................................ ..................... 25 1.6 Action Plan ................................ ................................ ................................ ................................ ....................... 32 1.7 Conclusion ................................ ................................ ................................ ................................ ........................ 48 2 Medical Product Development, Safety, and Effectiveness ................................ ................................ ..................... 48 2.1 Introduction and Context ................................ ................................ ................................ ................................ .. 49 2.2 Stakeholders Engaged in Medical Product Development, Safety, and Effectiveness ................................ ....... 50 2.3 Opportunities for the Application of AI in Medical Product Development, Safety, and Effectiveness ............. 52 2.4 Trends in AI in Medical Product Development, Safety, and Effectiveness ................................ ....................... 54 2.5 Potential Use Cases and Risks for AI in Medical Products and Their Development ................................ ....... 55 2.6 Action Plan ................................"
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_3",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nMedical Product Development, Safety, and Effectiveness ................................ ....... 50 2.3 Opportunities for the Application of AI in Medical Product Development, Safety, and Effectiveness ............. 52 2.4 Trends in AI in Medical Product Development, Safety, and Effectiveness ................................ ....................... 54 2.5 Potential Use Cases and Risks for AI in Medical Products and Their Development ................................ ....... 55 2.6 Action Plan ................................ ................................ ................................ ................................ ....................... 60 2.7 Conclusion ................................ ................................ ................................ ................................ ........................ 75 3 Healthcare Delivery ................................ ................................ ................................ ................................ .................. 76 3.1 Introduction and Context ................................ ................................ ................................ ................................ .. 76 3.2 Stakeholders Engaged in the Healthcare Delivery AI Value Chain ................................ ................................ .. 77 3.3 Opportunities for the Application of AI in Healthcare Delivery ................................ ................................ ......."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_4",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n................................ ................................ ................................ ................................ ....................... 60 2.7 Conclusion ................................ ................................ ................................ ................................ ........................ 75 3 Healthcare Delivery ................................ ................................ ................................ ................................ .................. 76 3.1 Introduction and Context ................................ ................................ ................................ ................................ .. 76 3.2 Stakeholders Engaged in the Healthcare Delivery AI Value Chain ................................ ................................ .. 77 3.3 Opportunities for the Application of AI in Healthcare Delivery ................................ ................................ ....... 80 3.4 Trends in AI in Healthcare Delivery ................................ ................................ ................................ ................. 81 3.5 Potential Use Cases and Risks for AI in Healthcare Delivery ................................ ................................ ......... 82 3.6 Action Plan ................................ ................................ ................................ ................................ ....................... 95 3.7 Conclusion ................................"
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_5",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI Value Chain ................................ ................................ .. 77 3.3 Opportunities for the Application of AI in Healthcare Delivery ................................ ................................ ....... 80 3.4 Trends in AI in Healthcare Delivery ................................ ................................ ................................ ................. 81 3.5 Potential Use Cases and Risks for AI in Healthcare Delivery ................................ ................................ ......... 82 3.6 Action Plan ................................ ................................ ................................ ................................ ....................... 95 3.7 Conclusion ................................ ................................ ................................ ................................ ...................... 109 4 Human Services Delivery ................................ ................................ ................................ ................................ ........ 110 4.1 Introduction and Context ................................ ................................ ................................ ................................ . 110 4.2 Stakeholders Engaged in the Human Services Delivery AI Value Chain ................................ ........................ 111 4.3 Opportunities for the Application of AI in Human Services Delivery ................................ ............................."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_6",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n................................ ................................ ................................ ....................... 95 3.7 Conclusion ................................ ................................ ................................ ................................ ...................... 109 4 Human Services Delivery ................................ ................................ ................................ ................................ ........ 110 4.1 Introduction and Context ................................ ................................ ................................ ................................ . 110 4.2 Stakeholders Engaged in the Human Services Delivery AI Value Chain ................................ ........................ 111 4.3 Opportunities for the Application of AI in Human Services Delivery ................................ ............................. 113 3 4.4 Trends in AI in Human Services Delivery ................................ ................................ ................................ ........ 115 4.5 Potential Use Cases and Risks for AI in Human Services Delivery ................................ ................................ 116 4.6 Action Plan ................................ ................................ ................................ ................................ ..................... 123 4.7 Conclusion ................................ ................................ ................................"
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_7",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n................................ ........................ 111 4.3 Opportunities for the Application of AI in Human Services Delivery ................................ ............................. 113 3 4.4 Trends in AI in Human Services Delivery ................................ ................................ ................................ ........ 115 4.5 Potential Use Cases and Risks for AI in Human Services Delivery ................................ ................................ 116 4.6 Action Plan ................................ ................................ ................................ ................................ ..................... 123 4.7 Conclusion ................................ ................................ ................................ ................................ ...................... 133 5 Public Health ................................ ................................ ................................ ................................ ........................... 134 5.1 Introduction and Context ................................ ................................ ................................ ................................ 134 5.2 Stakeholders Engaged in the Public Health AI Value Chain ................................ ................................ .......... 135 5.3 Opportunities for the Application of AI in Public Health ................................ ................................ ..............."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_8",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nPlan ................................ ................................ ................................ ................................ ..................... 123 4.7 Conclusion ................................ ................................ ................................ ................................ ...................... 133 5 Public Health ................................ ................................ ................................ ................................ ........................... 134 5.1 Introduction and Context ................................ ................................ ................................ ................................ 134 5.2 Stakeholders Engaged in the Public Health AI Value Chain ................................ ................................ .......... 135 5.3 Opportunities for the Application of AI in Public Health ................................ ................................ ............... 139 5.4 Trends in AI in Public Health ................................ ................................ ................................ ......................... 141 5.5 Potential Use Cases and Risks for AI in Public Health ................................ ................................ .................. 142 5.6 Action Plan ................................ ................................ ................................ ................................ ....................."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_9",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nin the Public Health AI Value Chain ................................ ................................ .......... 135 5.3 Opportunities for the Application of AI in Public Health ................................ ................................ ............... 139 5.4 Trends in AI in Public Health ................................ ................................ ................................ ......................... 141 5.5 Potential Use Cases and Risks for AI in Public Health ................................ ................................ .................. 142 5.6 Action Plan ................................ ................................ ................................ ................................ ..................... 150 5.7 Conclusion ................................ ................................ ................................ ................................ ...................... 162 6 Cybersecurity and Critical Infrastructure Protection ................................ ................................ ......................... 163 6.1 Introduction and Context ................................ ................................ ................................ ................................ 163 6.2 Stakeholders Engaged in the Cybersecurity and Critical I nfrastructure in the Health and Human Services Ecosystem ................................ ................................ ................................ ................................ ........."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_10",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n.................. 142 5.6 Action Plan ................................ ................................ ................................ ................................ ..................... 150 5.7 Conclusion ................................ ................................ ................................ ................................ ...................... 162 6 Cybersecurity and Critical Infrastructure Protection ................................ ................................ ......................... 163 6.1 Introduction and Context ................................ ................................ ................................ ................................ 163 6.2 Stakeholders Engaged in the Cybersecurity and Critical I nfrastructure in the Health and Human Services Ecosystem ................................ ................................ ................................ ................................ ......... 164 6.3 Trends in Cybersecurity and Critical Infrastructure Protection ................................ ................................ ..... 165 6.4 Action Plan ................................ ................................ ................................ ................................ ..................... 167 6.5 Conclusion ................................ ................................ ................................ ................................ ...................... 171 7 Internal Operations ................................"
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_11",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n................................ ................................ ................................ 163 6.2 Stakeholders Engaged in the Cybersecurity and Critical I nfrastructure in the Health and Human Services Ecosystem ................................ ................................ ................................ ................................ ......... 164 6.3 Trends in Cybersecurity and Critical Infrastructure Protection ................................ ................................ ..... 165 6.4 Action Plan ................................ ................................ ................................ ................................ ..................... 167 6.5 Conclusion ................................ ................................ ................................ ................................ ...................... 171 7 Internal Operations ................................ ................................ ................................ ................................ ................. 172 7.1 Introduction and Context ................................ ................................ ................................ ................................ 172 7.2 Opportunities and Risks ................................ ................................ ................................ ................................ .. 172 7.3 Governance ................................ ................................ ................................"
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_12",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nin Cybersecurity and Critical Infrastructure Protection ................................ ................................ ..... 165 6.4 Action Plan ................................ ................................ ................................ ................................ ..................... 167 6.5 Conclusion ................................ ................................ ................................ ................................ ...................... 171 7 Internal Operations ................................ ................................ ................................ ................................ ................. 172 7.1 Introduction and Context ................................ ................................ ................................ ................................ 172 7.2 Opportunities and Risks ................................ ................................ ................................ ................................ .. 172 7.3 Governance ................................ ................................ ................................ ................................ ..................... 174 7.4 Internal Process Improvement and Innovation ................................ ................................ ............................... 175 7.5 Workforce and Talent ................................ ................................ ................................ ................................ ......"
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_13",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n................................ ................................ ................................ ...................... 171 7 Internal Operations ................................ ................................ ................................ ................................ ................. 172 7.1 Introduction and Context ................................ ................................ ................................ ................................ 172 7.2 Opportunities and Risks ................................ ................................ ................................ ................................ .. 172 7.3 Governance ................................ ................................ ................................ ................................ ..................... 174 7.4 Internal Process Improvement and Innovation ................................ ................................ ............................... 175 7.5 Workforce and Talent ................................ ................................ ................................ ................................ ...... 177 7.6 Conclusion ................................ ................................ ................................ ................................ ...................... 178 Conclusion ................................ ................................ ................................ ................................ ................................ ......."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_14",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand Context ................................ ................................ ................................ ................................ 172 7.2 Opportunities and Risks ................................ ................................ ................................ ................................ .. 172 7.3 Governance ................................ ................................ ................................ ................................ ..................... 174 7.4 Internal Process Improvement and Innovation ................................ ................................ ............................... 175 7.5 Workforce and Talent ................................ ................................ ................................ ................................ ...... 177 7.6 Conclusion ................................ ................................ ................................ ................................ ...................... 178 Conclusion ................................ ................................ ................................ ................................ ................................ ....... 179 Appendix A: Glossary of Terms ................................ ................................ ................................ ................................ ..... 180 Appendix B: Select Federal Policies and Regulations ................................ ................................ ................................ ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_15",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n..................... 174 7.4 Internal Process Improvement and Innovation ................................ ................................ ............................... 175 7.5 Workforce and Talent ................................ ................................ ................................ ................................ ...... 177 7.6 Conclusion ................................ ................................ ................................ ................................ ...................... 178 Conclusion ................................ ................................ ................................ ................................ ................................ ....... 179 Appendix A: Glossary of Terms ................................ ................................ ................................ ................................ ..... 180 Appendix B: Select Federal Policies and Regulations ................................ ................................ ................................ . 194 4 Acknowledgements and Disclaimer Acknowledgements HHS would like to thank the HHS AI Task Force, Steering Committee, working group co -leads, and writers for their contributions to this document and many hours of work above and beyond expectations. We are grateful to the many colleagues across HHS who prov ided thoughtful comments and engaged in developing the Strategic Plan."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_16",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n194 4 Acknowledgements and Disclaimer Acknowledgements HHS would like to thank the HHS AI Task Force, Steering Committee, working group co -leads, and writers for their contributions to this document and many hours of work above and beyond expectations. We are grateful to the many colleagues across HHS who prov ided thoughtful comments and engaged in developing the Strategic Plan. The Department would also like to share its enormous gratitude to the HHS AI Task Force Project Management Office for its leadership, coordination, and direction. Finally, HHS would lik e to acknowledge the broad set of stakeholders from across the sector who volunteered their time and perspectives to inform this Strategic Plan. We sincerely appreciate their constructive and critical contributions. Disclaimer The U.S. Department of Health and Human Services AI Strategic Plan does not modify or interpret any requirements under the Federal Food, Drug, and Cosmetic Act (FD&C Act), the Public Health Service Act, Food and Drug Administration (FDA) regulations, or ot hers. Nor does this document constitute a guidance document within the meaning of Section 701(h) of the FD&C Act (21 USC. 371(h)), 21 CFR 10.115, or others. Further, this document does not establish any rights or obligations with respect to any member of t he public. 5 Letter from the Deputy Secretary Artificial intelligence (AI) has had an undeniable influence on health, human services, and public health. At the U.S."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_17",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe meaning of Section 701(h) of the FD&C Act (21 USC. 371(h)), 21 CFR 10.115, or others. Further, this document does not establish any rights or obligations with respect to any member of t he public. 5 Letter from the Deputy Secretary Artificial intelligence (AI) has had an undeniable influence on health, human services, and public health. At the U.S. Department of Health and Human Services (HHS), we have been steadfast in our efforts to responsibly leverage AI to advance our mission ac ross critical areas within HHS and throughout the sector. At HHS, we are optimistic about the transformational potential of AI. These technologies hold an unparalleled ability to drive innovation by accelerating scientific breakthroughs, improving medical product safety and effectiveness, improving health outcomes through care delivery, increasing access to human services, and optimizing public health. However, our optimism is tempered with a deep sen se of responsibility. We need to ensure that Americans are safeguarded from risks. Deployment and adoption of AI should benefit the American people, and we must hold stakeholders across the ecosystem accountable to achieve this goal. AI creates vast opport unities to improve our country’s health and human services and better serve the American people, and HHS is already taking active steps to motivate the ethical and responsible use of AI so that it might improve people’s lives."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_18",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nshould benefit the American people, and we must hold stakeholders across the ecosystem accountable to achieve this goal. AI creates vast opport unities to improve our country’s health and human services and better serve the American people, and HHS is already taking active steps to motivate the ethical and responsible use of AI so that it might improve people’s lives. We are excited to introduce the HHS AI Strategic Plan, which presents our approach to catalyze innovation, promote trustworthy AI development, democratize technologies and resources, and cultivate AI -empowered workforces and organization cultures. This Pla n represents a significant milestone in our ongoing commitment to harness the power of AI to strengthen our nation’s health and well -being. We will continue to do our part at HHS, as detailed in this Plan, using available resources and levers to successfully deploy AI in health, human services, and public health. But success requires a whole -of-nation approach in partnership with industry, aca demia, patients, and countless others. We look to the rest of the ecosystem to join us in this mission. Deputy Secretary Andrea Palm 6 Introduction Purpose of the Plan HHS’s vision is to be a global leader in innovating and adopting responsible AI to achieve unparalleled advances in the health and well -being of all Americans."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_19",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npartnership with industry, aca demia, patients, and countless others. We look to the rest of the ecosystem to join us in this mission. Deputy Secretary Andrea Palm 6 Introduction Purpose of the Plan HHS’s vision is to be a global leader in innovating and adopting responsible AI to achieve unparalleled advances in the health and well -being of all Americans. This HHS AI Strategic Plan (hereafter referred to as “Strategic Plan” or “Plan”) provides a framework and roadmap to ensure that HHS fulfills its obligation to the Nation and pioneers the responsible use of AI to improve people’s lives. Over the past 50 years, the U.S. has undergone a profound change in the way individuals interact with digital technologies. AI holds tremendous promise and potential risk for health and human services. While AI has existed in some form since the mid -20th century, AI has become ubiquitous in recent years . This is also true for healthcare and will increasingly be true in human services delivery. New and emerging technologies are making it even more possible to predict diseases before symptoms appear, identify new drug targets with the potential to transform the standard of care, and more effectively match human services to people who need them the most. Given the trajectory of this technology, the potential for AI to fundamentally change health and human services will become even greater."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_20",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ntechnologies are making it even more possible to predict diseases before symptoms appear, identify new drug targets with the potential to transform the standard of care, and more effectively match human services to people who need them the most. Given the trajectory of this technology, the potential for AI to fundamentally change health and human services will become even greater. This Strategic Plan defines AI as outlined in section 5002(3) of the National Artificial Intelligence Initiative Act (15 U.S.C. 9401(3)): a machine -based system that can, for a given set of human -defined objectives, make predictions, recommendations, or dec isions influencing real or virtual environments.1 Within this definition, AI can take many forms. In the healthcare sector, basic algorithms for performing tasks or solving problems have been widely used for decades."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_21",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe National Artificial Intelligence Initiative Act (15 U.S.C. 9401(3)): a machine -based system that can, for a given set of human -defined objectives, make predictions, recommendations, or dec isions influencing real or virtual environments.1 Within this definition, AI can take many forms. In the healthcare sector, basic algorithms for performing tasks or solving problems have been widely used for decades. Advances in AI and machine learning (ML) capabilities are strengthening algorithms to go beyond narrow rules and become more predictive and general by analyzing or “learning” from available data to tailor model output more precisely to the characteristics of a specific individual or subpopulation.2 Generative AI (GenAI), another type of AI, refers to technologies that analyze and learn from data to create (“generate”) something new, such as data, text, images, sounds, or other types of information.3 Private sector interest and investment have fueled the rapid growth of AI and health AI (technologies used in health and human services) capabilities. AI technology , and in particular GenAI, has been growing rapidly over the last several years, with industry and academic settings producing over 60 notable ML models in 2023 alone.4 Venture capital and private AI investments have increased substantially, accounting for over $55B in U.S."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_22",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nrapid growth of AI and health AI (technologies used in health and human services) capabilities. AI technology , and in particular GenAI, has been growing rapidly over the last several years, with industry and academic settings producing over 60 notable ML models in 2023 alone.4 Venture capital and private AI investments have increased substantially, accounting for over $55B in U.S. venture capital funding across industries in Q2 2024.5 Investment in GenAI is projected to grow by up to 42% year over year through 2032, leading to a potential $1.3T market across industries.6 For healthcare, start -ups have raised approximately $30B for AI over the last three years.7 There is an additional need for investment in human services delivery to meet population needs (e.g., the World Health Organization [WHO] estimates that 3.5B people will require assistive technology by 2050, some of which may be enabled by AI).8 To ensure the responsible use of AI, entities in the U.S. have seen an increase in the number of regulations that mention AI (25 in 2023, an increase 1 While this definition will be used as the basis of this Strategic Plan, alternative definitions may at times be used by HHS operating and staff divisions."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_23",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nmay be enabled by AI).8 To ensure the responsible use of AI, entities in the U.S. have seen an increase in the number of regulations that mention AI (25 in 2023, an increase 1 While this definition will be used as the basis of this Strategic Plan, alternative definitions may at times be used by HHS operating and staff divisions. 2 https://www.fda.gov/science -research/science -and-research -special -topics/real -world -evidence 3 https://www.fda.gov/science -research/artificial -intelligence -and-medical -products/fda -digital -health -and-artificial -intelligence -glossary -educational -resource HHS recognizes that there exist additional terms to describe AI (e.g., Foundational Model, Constitutional AI); for simplicity, th is Plan primarily addresses traditional and GenAI ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_24",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nalternative definitions may at times be used by HHS operating and staff divisions. 2 https://www.fda.gov/science -research/science -and-research -special -topics/real -world -evidence 3 https://www.fda.gov/science -research/artificial -intelligence -and-medical -products/fda -digital -health -and-artificial -intelligence -glossary -educational -resource HHS recognizes that there exist additional terms to describe AI (e.g., Foundational Model, Constitutional AI); for simplicity, th is Plan primarily addresses traditional and GenAI . 4 https://aiindex.stanford.edu/report/ 5 https://www.reuters.com/business/finance/ai -deals -lift-us-venture -capital -funding -highest -level -two-years -data-shows -2024 -07-03/ 6 https://www.bloomberg.com/company/press/generative -ai-to-become -a-1-3-trillion -market -by-2032 -research -finds/ 7 https://www.aha.org/aha -center -health -innovation -market -scan/2024 -09-17-top-4-health -care-ai-investment -trends -watch 8 https://www.who.int/news -room/fact -sheets/detail/assistive -technology 7 of 56% from 2022).9 Global, multinational, and other governmental entities around the world, including the United Nations, Group of Seven (G7), Organisation for Economic Co -operation and Development (OECD), and WHO, are likewise making guidance and strategies for the use of AI a priority."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_25",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nhttps://www.aha.org/aha -center -health -innovation -market -scan/2024 -09-17-top-4-health -care-ai-investment -trends -watch 8 https://www.who.int/news -room/fact -sheets/detail/assistive -technology 7 of 56% from 2022).9 Global, multinational, and other governmental entities around the world, including the United Nations, Group of Seven (G7), Organisation for Economic Co -operation and Development (OECD), and WHO, are likewise making guidance and strategies for the use of AI a priority. AI has paved the way for an increasing array of scientific breakthroughs and, in some cases, may surpass human performance in tasks like image classification and visual reasoning.10 AI also has the potential to dramatically improve the ability to identify relevant factors or predict outcomes. Furthermore, advances in AI and ML fuel the increased use of predictive models in the “back office” of health and human services, such as appoi ntment scheduling and evidence and literature reviews for research. AI has or will directly or indirectly affect every American’s experience in health and human services."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_26",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nimprove the ability to identify relevant factors or predict outcomes. Furthermore, advances in AI and ML fuel the increased use of predictive models in the “back office” of health and human services, such as appoi ntment scheduling and evidence and literature reviews for research. AI has or will directly or indirectly affect every American’s experience in health and human services. Therefore, AI development should take a “human -centered design” approach that ensures it focuses on providing real benefits for people who use or receive services supported by AI.11 Some of the benefits —to be discussed in greater detail below —include: • Accelerating scientific breakthroughs that could increase the quality and length of life • Being used as part of a medical product or to develop medical products to improve safety and effectiveness • Improving clinical outcomes and enhancing safety through innovations in healthcare delivery • Improving equity and empowering participants through enhanced health and human services benefits delivery • Forecasting risks and rapidly mobilizing resources to predict and respond to public health threats Such potential does not come without risks. While AI can significantly improve many aspects of health and human services, it also presents possible risks that could lead to adverse impacts and outcomes. Depending on the data and model quality , AI can produce outputs that are incorrect or incomplete."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_27",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nrapidly mobilizing resources to predict and respond to public health threats Such potential does not come without risks. While AI can significantly improve many aspects of health and human services, it also presents possible risks that could lead to adverse impacts and outcomes. Depending on the data and model quality , AI can produce outputs that are incorrect or incomplete. When important decisions are made in part or in whole based on AI that is not accurate, people can be harmed or denied access, and resources can be misused. Further, researchers have found that AI can introduce and propagate bias, which may misclassify people’s needs, negatively impact physical or mental health outcomes, and increase costs.12, 13, 14 Responsible AI use should also ensure equitable access and beneficence, safeguard protected information , and involve appropriate consent where applicable , while also considering potential unintended negative impacts on society or the environment. It is important to note that these risks and considerations may manifest differently depending on the complexity of AI used (e.g., simple rule -based algorithms will carry different considerations than large language models [LLMs ]). Regardless, AI use in health and human services must ensure and be accountable to appropriate human oversight, and AI should be viewed a s a tool to support and inform efforts rather than the sole answer to problems in the existing landscape."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_28",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nof AI used (e.g., simple rule -based algorithms will carry different considerations than large language models [LLMs ]). Regardless, AI use in health and human services must ensure and be accountable to appropriate human oversight, and AI should be viewed a s a tool to support and inform efforts rather than the sole answer to problems in the existing landscape. The federal government is working to assess the potential of AI while ensuring it is safe and equitable for all Americans. Maximizing opportunities and mitigating risks is core to HHS’s long -standing mission: Enhance the health and well -being of all Americans by supporting effective health and human services and foste ring sound, sustained advances in the sciences underlying medicine, public health, and social services. This mission is supported by and connected to the missions of our community partners, sta te, tribal, local, and territorial 9 https://aiindex.stanford.edu/report/ 10 https://aiindex.stanford.edu/report/ 11 https://digital.gov/topics/human -centered -design/ Human -centered design refers to the philosophy and method that places people’s experiences at the heart of service design."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_29",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsound, sustained advances in the sciences underlying medicine, public health, and social services. This mission is supported by and connected to the missions of our community partners, sta te, tribal, local, and territorial 9 https://aiindex.stanford.edu/report/ 10 https://aiindex.stanford.edu/report/ 11 https://digital.gov/topics/human -centered -design/ Human -centered design refers to the philosophy and method that places people’s experiences at the heart of service design. 12 https://www.iso.org/obp/ui/#iso:std:iso -iec:tr:24027:ed -1:v1:en Bias is defined as “systematic difference in treatment of certain objects, people, or groups in comparison to others, where treatment is any kind of action, including perception, observation, representation, prediction, o r decision.” 13 https://pubmed.ncbi.nlm.nih.gov/31649194/ Obermeyer , Z., Powers , B., V ogeli , C., Mullainathan , S. Dissecting racial bias in an algorithm used to manage the health of populations. Science. 2019 Oct 25;366(6464):447 -453. 14 https://www.nimhd.nih.gov/resources/understanding -health -disparities/diversity -and-inclusion -in-clinical -trials.html 8 governments (STLTs), academia, and private sector partners. It requires HHS to continue aligning efforts and priorities to ensure quality and safety and address the Nation’s evolving health and human service needs while finding a balance that encourages innovation and deploys the necess ary guardrails."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_30",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nhealth of populations. Science. 2019 Oct 25;366(6464):447 -453. 14 https://www.nimhd.nih.gov/resources/understanding -health -disparities/diversity -and-inclusion -in-clinical -trials.html 8 governments (STLTs), academia, and private sector partners. It requires HHS to continue aligning efforts and priorities to ensure quality and safety and address the Nation’s evolving health and human service needs while finding a balance that encourages innovation and deploys the necess ary guardrails. Similarly, it requires empowering end users (people, including patients, healthcare providers, and others) to shape how new technologies are responsibly integrated into their care and services by fostering col laboration throughout the innovation pipeline. Recent advances in the capabilities, breadth of applicability, ease of use, and speed of adoption of AI also suggest it may affect health and human services faster and with greater impact than anticipated. HHS and its operating and staff divisions (“divisions”) recognize the value and importance of operating at an enterprise level rather than just through isolated uses within specific units for standalone purposes. It is critical for HHS to set a clear strategy to ensure health and human services organizations are well positioned to take advantage of AI according to consistent principles and objectives. A clear strategy is also necessary to manage the portfolio of AI investments and ensure HHS builds upon synergies between its divisions."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_31",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nuses within specific units for standalone purposes. It is critical for HHS to set a clear strategy to ensure health and human services organizations are well positioned to take advantage of AI according to consistent principles and objectives. A clear strategy is also necessary to manage the portfolio of AI investments and ensure HHS builds upon synergies between its divisions. HHS plays a crucial role in the sector : an investor in research and discovery, a health industry regulator, a catalyst for innovation in delivering health and human services, a provider of healthcare and human services delivery, and a protector of patient safety, rights, and privacy. As AI adoption varies across industries within HHS’s purview, a responsible approach for development and adoption is required. HHS will use the existing regulatory structure to clarify guidance, offer new g uidance where needed, and update oversight mechanisms as necessary in response to technological innovation. HHS will also seek new regulatory authorities where appropriate. While the evolving nature of AI will likely challenge regulatory paradigms, HHS will continue to use all available levers , including policy , funding, education and outreach , and others to meet the new technological reality and support stakeholders in the health and human services ecosystem."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_32",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nin response to technological innovation. HHS will also seek new regulatory authorities where appropriate. While the evolving nature of AI will likely challenge regulatory paradigms, HHS will continue to use all available levers , including policy , funding, education and outreach , and others to meet the new technological reality and support stakeholders in the health and human services ecosystem. Organization and Use of the Plan Organization of the Strategic Plan The Strategic Plan is specifically focused on articulating HHS’s vision and goals for AI in health , human services , and public health . As one of the largest federal entities in the U.S. government, HHS divisions and activities cover the entire continuum of health and human services, from bench -side research to bedside care delivery; from drug discovery to surveillance; and from childhoo d poverty prevention to benefits for seniors and people with disabilities. Given this expansive purview, the Strategic Plan presents a unifying framework composed of seven domains to promote alignment across HHS policies, programs, and activities involving AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_33",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nentire continuum of health and human services, from bench -side research to bedside care delivery; from drug discovery to surveillance; and from childhoo d poverty prevention to benefits for seniors and people with disabilities. Given this expansive purview, the Strategic Plan presents a unifying framework composed of seven domains to promote alignment across HHS policies, programs, and activities involving AI. 9 • Primary domains represent specific parts of the HHS value chain, including: o Medical Research and Discovery: Fundamental and pre -clinical research on the basic mechanisms of disease and life processes, their translation to medical innovations and clinical applications,15 and their context to use in healthcare delivery as a whole o Medical Product Development, Safety, and Effectiveness: Drug, biological product, and medical device development, clinical trials and regulatory approval, manufacturing, and ongoing safety and effectiveness monitoring o Healthcare Delivery: Provision of healthcare services to individuals and populations to diagnose, treat, manage, and prevent diseases and promote health and well -being, as well as financing to support this delivery o Human Services Delivery: Provision of social services and assistance to individuals and families to meet basic needs for health, welfare, self -sufficiency, safety, and well -being o Public Health: Protection and improvement of the well-being of populations through preventing disease, prolonging life, and promoting health through the organized efforts and informed choices of society, organizations, public and private communities, and individuals • Additional domains are functional areas that span primary domains and are required to implement the Strategic Plan: o Cybersecurity and Critical Infrastructure Protection: Protection and advancement of systems ’ security critical to health and human service functions to support the use of AI o Internal Operations: Policies, programs, and infrastructure used by HHS divisions for internal operations and functions enabling HHS to implement the Strategic Plan and accommodate rapid technological advancements Within each primary domain, chapters follow a consistent structure: • Introduction and context to AI in the domain • Stakeholders engaged in the domain’s AI value chain • Opportunities for the application of AI • Trends in AI • Potential use cases and risks • Action plan This full version of the Plan is deliberately expansive to provide context and tangible examples for readers seeking a more detailed orientation."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_34",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n• Introduction and context to AI in the domain • Stakeholders engaged in the domain’s AI value chain • Opportunities for the application of AI • Trends in AI • Potential use cases and risks • Action plan This full version of the Plan is deliberately expansive to provide context and tangible examples for readers seeking a more detailed orientation. It includes more comprehensive discussion of the opportunities, trends, use cases and risks, including full, g ranular action plans. For a high -level perspective, please see the Overview that was developed to increase accessibility and utility to a broad set of readers. HHS Use of the Strategic Plan HHS’s overarching objective is to set in motion a coordinated public -private approach to improving the quality, safety, efficiency, accessibility, equitability, and outcomes in health and human services through the innovative, safe, and responsible development and use of AI. 15 HHS recognizes that the Medical Research and Discovery pipeline contains overlaps with Medical Product Development, Safety, a nd Effectiveness “development.” However, for purposes of this Plan, AI use in pre -clinical research will be addressed in the Medical Research and Discovery chapter . Further steps will appear in the Medical Product Development, Safety, and Effectiveness chapter . Additionally, information on biosecurity will appear in the Medical Product Development, Safety, and Effectiveness chapter ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_35",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nProduct Development, Safety, a nd Effectiveness “development.” However, for purposes of this Plan, AI use in pre -clinical research will be addressed in the Medical Research and Discovery chapter . Further steps will appear in the Medical Product Development, Safety, and Effectiveness chapter . Additionally, information on biosecurity will appear in the Medical Product Development, Safety, and Effectiveness chapter . 10 HHS will accomplish this objective by focusing on four key goals: 1. Catalyzing health AI innovation and adoption to unlock new ways to improve people’s lives 2. Promoting trustworthy AI development and ethical and responsible use to avoid potential harm 3. Democratizing AI technologies and resources to promote access 4. Cultivating AI -empowered workforces and organization cultures to effectively and safely use AI Exhibit 1: Goals and Structure of the Strategic Plan As detailed in Exhibit 1, within each primary domain, chapters describe how HHS will focus on these four recurring goals through current and planned actions that will guide and support their execution. These actions will span a variety of levers available to HHS and its divisions , including regulations, policies and guidance, grants, funding programs, public education and outreach, and internal infrastructure, procurement, and operations."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_36",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nwithin each primary domain, chapters describe how HHS will focus on these four recurring goals through current and planned actions that will guide and support their execution. These actions will span a variety of levers available to HHS and its divisions , including regulations, policies and guidance, grants, funding programs, public education and outreach, and internal infrastructure, procurement, and operations. It is important to note that new policies are not the only way to support the responsible use of AI; existing approaches may be updated to address emerging concerns while ensuring that AI use remains compliant with current regulations (e.g., patient privacy). By orchestrating the use of these levers across its value chains, HHS aims to maximize coordination and strategically align its divisions and the rest of the health and human services ecosystem toward the achievement of HHS’ s strategic vision and the realization of the opportunities for AI to improve people’s lives. 11 Opportunities for AI to Improve People’s Lives AI has the potential to improve people’s lives and to support HHS’s broader mission across areas."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_37",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncoordination and strategically align its divisions and the rest of the health and human services ecosystem toward the achievement of HHS’ s strategic vision and the realization of the opportunities for AI to improve people’s lives. 11 Opportunities for AI to Improve People’s Lives AI has the potential to improve people’s lives and to support HHS’s broader mission across areas. A few examples include :16 • Accelerating scientific breakthroughs that could ultimately increase the quality and length of life : Since 2000, the average timeline between Phase 1 clinical trials and regulatory approval has been approximately ten years, with even longer lead times for basic research and drug discovery.17 Incorporating AI throughout the clinical discovery and development process offers tremendous hope in focus ing on safe and effective targets, identifying populations and diseases for which products may be most effective, assessing the representativeness of the data and data models , and correcting for undersampling of populations, and more, ultimately shortening the development timeline and reducing overall costs. • Being used as part of a medical product or to develop medical products to improve safety and effectiveness : AI can be used as part of a medical product or to develop safe and effective medical products."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_38",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndata and data models , and correcting for undersampling of populations, and more, ultimately shortening the development timeline and reducing overall costs. • Being used as part of a medical product or to develop medical products to improve safety and effectiveness : AI can be used as part of a medical product or to develop safe and effective medical products. In particular, AI -enabled medical devices , such as over-the-counter hearing aid s, have the potential to be used by patients, healthcare providers , and other end users to help augment care and improve outcomes .18,19 Additionally, AI supports the ability to learn from data collected during clinical use which can help support improving medical product accuracy and performance over time,20 potentially leading to improved accuracy and monitoring (e.g., lower misdiagnosis rates, higher ability to detect adverse effects early). Similarly, AI can be leveraged to help develop drugs and biological products (e.g., identifying targets, assessing biomarkers and endpoints)."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_39",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsupports the ability to learn from data collected during clinical use which can help support improving medical product accuracy and performance over time,20 potentially leading to improved accuracy and monitoring (e.g., lower misdiagnosis rates, higher ability to detect adverse effects early). Similarly, AI can be leveraged to help develop drugs and biological products (e.g., identifying targets, assessing biomarkers and endpoints). • Improving clinical outcomes and enhancing safety through innovations in healthcare delivery: Medical errors, including incorrect and/or delayed diagnoses, may contribute to adverse outcomes.21, 22 AI has the potential to accelerate diagnoses and head off safety events by rapidly processing expansive and disparate information, detecting patterns not always apparent to human observation, and directing clinicians to higher likelihood diagnoses and/or s afety issues tailored to individual circumstances through clinical decision support and other tools . AI can also enhance care models and health services research to develop innovations that better enable clinicians, payers, and patients."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_40",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsafety events by rapidly processing expansive and disparate information, detecting patterns not always apparent to human observation, and directing clinicians to higher likelihood diagnoses and/or s afety issues tailored to individual circumstances through clinical decision support and other tools . AI can also enhance care models and health services research to develop innovations that better enable clinicians, payers, and patients. • Improving equity and empowering patients and members of the public through improved health and human services benefits delivery: Today, many individuals and communities face barriers to care given socioeconomic status, language, geographic location, and other factors.23 AI has the potential to improve access to benefits and services for all individuals; for example, individuals for whom language is a barrier to receiving healthcare or human services may benefit from interpreter access through real -time, automated translation.24 AI can also help individuals with disabilities perform simple or complex tasks, such as language technologies which can support individuals with speech impairments by optimizing speech patterns and turning them into fluent conversations.25 • Forecasting risks and rapidly mobilizing resources to predict and respond to public health threats: HHS has seen a significant uptick in the adoption of AI in response to public health crises such as the COVID -19 pandemic."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_41",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ntasks, such as language technologies which can support individuals with speech impairments by optimizing speech patterns and turning them into fluent conversations.25 • Forecasting risks and rapidly mobilizing resources to predict and respond to public health threats: HHS has seen a significant uptick in the adoption of AI in response to public health crises such as the COVID -19 pandemic. At scale, AI has the potential to improve global infrastructure for predicting future 16 The chapters that follow detail the types of benefits specific to each domain. 17 https:// www."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_42",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npredict and respond to public health threats: HHS has seen a significant uptick in the adoption of AI in response to public health crises such as the COVID -19 pandemic. At scale, AI has the potential to improve global infrastructure for predicting future 16 The chapters that follow detail the types of benefits specific to each domain. 17 https:// www. mckinsey.com/industries/life -sciences/our -insights/generative -ai-in-the-pharmaceutical -industry -moving -from -hype -to-reality 18 https://www.fda.gov/medical -devices/software -medical -device -samd/artificial -intelligence -and-machine -learning -software -medical -device 19 https://www.fda.gov/news -events/press -announcements/fda -authorizes -first-over-counter -hearing -aid-software 20 https://www.fda.gov/medical -devices/software -medical -device -samd/artificial -intelligence -and-machine -learning -software -medical -device 21 https://jamanetwork.com/journals/jamainternalmedicine/article -abstract/2813854 22 https://patientsafetyj.com/article/116529 -patient -safety -trends -in-2023 -an-analysis -of-287-997-serious -events -and-incidents -from -the-nation -s-largest -event - reporting -database 23 https://www.cdc.gov/health -equity/what -is/index.html 24 https://pubmed.ncbi.nlm.nih.gov/37904073/ Bakdash, L., Abid, A., Gourisankar, A ., Henry, T . L. Chatting Beyond ChatGPT: Advancing Equity Through AI -Driven Language Interpretation ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_43",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n20 https://www.fda.gov/medical -devices/software -medical -device -samd/artificial -intelligence -and-machine -learning -software -medical -device 21 https://jamanetwork.com/journals/jamainternalmedicine/article -abstract/2813854 22 https://patientsafetyj.com/article/116529 -patient -safety -trends -in-2023 -an-analysis -of-287-997-serious -events -and-incidents -from -the-nation -s-largest -event - reporting -database 23 https://www.cdc.gov/health -equity/what -is/index.html 24 https://pubmed.ncbi.nlm.nih.gov/37904073/ Bakdash, L., Abid, A., Gourisankar, A ., Henry, T . L. Chatting Beyond ChatGPT: Advancing Equity Through AI -Driven Language Interpretation . J GEN INTERN MED 39, 492 –495 (2024) 25 https://www.forbes.com/councils/forbesbusinesscouncil/2023/06/16/empowering -individuals -with-disabilities -through -ai-technology/ 12 disease outbreaks, enabling public health teams to develop effective countermeasures at scale prior to the first incidence of disease in new geographies . AI can be leveraged to improve public health through other means, such as identification of factors likely to impact health and human services (e.g., predicting natural disasters before they occur, which may reduce impact). Promoting Ethical and Responsible Use of AI The use of AI also carries several inherent challenges and risks. HHS is committed to developing, sharing, and promoting trustworthy AI that improves health and wellness outcomes."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_44",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthrough other means, such as identification of factors likely to impact health and human services (e.g., predicting natural disasters before they occur, which may reduce impact). Promoting Ethical and Responsible Use of AI The use of AI also carries several inherent challenges and risks. HHS is committed to developing, sharing, and promoting trustworthy AI that improves health and wellness outcomes. In support of this commitment, HHS is identifying existing practices to ensu re trustworthy AI and addressing inconsistencies across domains. While it is not in the scope of this Plan to present a comprehensive approach to ethical and responsible use of health AI for every potential use case, HHS lays out overall considerations in this Plan that apply across the ecosystem. HHS expects all organizations to maximally promote ethical and responsible use of AI. Stakeholders should collectively work toward mitigating risks of inadvertent harms, such as falsely identifying patient conditi ons, breaching confidentiality of patient information (either directly or through reidentification of encrypted and/or deidentified patient data), misdirecting use of resources (particularly during public health emergencies), unintentionally developing pot entially harmful medical products, or negatively contributing to social or environmental impacts."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_45",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nuse of AI. Stakeholders should collectively work toward mitigating risks of inadvertent harms, such as falsely identifying patient conditi ons, breaching confidentiality of patient information (either directly or through reidentification of encrypted and/or deidentified patient data), misdirecting use of resources (particularly during public health emergencies), unintentionally developing pot entially harmful medical products, or negatively contributing to social or environmental impacts. Stakeholders should also promote equity by reducing biases and increasing access for populations (e.g., geographic communities, persons with disabilities). HHS will build on existing risk management and governance frameworks such as the National Institute of Standards and Technology (NIST) AI Risk Management Framework and Assistant Secretary for Technology Policy/Office of the National Coordinator for Health Information Technology (hereafter “ASTP” or “ASTP/ONC” ) Health Data, Technology, and Interoperability: Certification Program Updates, Algorithm Transparency, and Information Sharing (HTI -1) Final Rule (89 FR 1192). The NIST Framework asserts that holistic AI risk management requires risk mapping, measurement, and management to inform actions and governance. The HTI -1 Final Rule lays out a risk mapping approach for transparency of key information to assess benefits and risks of AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_46",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand Interoperability: Certification Program Updates, Algorithm Transparency, and Information Sharing (HTI -1) Final Rule (89 FR 1192). The NIST Framework asserts that holistic AI risk management requires risk mapping, measurement, and management to inform actions and governance. The HTI -1 Final Rule lays out a risk mapping approach for transparency of key information to assess benefits and risks of AI. Both NIST and certain poli cies finalized in the HTI -1 Final Rule are informed by the FA VES principles (fair, appropriate, valid, effective, and safe). FAVES principles26 Fair: Model outcomes do not exhibit prejudice or favoritism toward an individual or group based on their inherent or acquired characteristics. Appropriate: Model and process outputs are well matched to produce results appropriate for specific contexts and populations to which they are applied. Valid: Model and process outputs have been shown to estimate targeted values accurately and as expected in both internal and external data. Effective: Model outcomes have demonstrated benefits in real -world conditions. Safe: Model outcomes are free from any known unacceptable risks, and the probable benefits outweigh any probable risks."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_47",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nfor specific contexts and populations to which they are applied. Valid: Model and process outputs have been shown to estimate targeted values accurately and as expected in both internal and external data. Effective: Model outcomes have demonstrated benefits in real -world conditions. Safe: Model outcomes are free from any known unacceptable risks, and the probable benefits outweigh any probable risks. 26 https://www.healthit.gov/sites/default/files/2023 -12/Health_Sector_AI_Commitments_FINAL_120923.pdf 13 FA VES is not an exhaustive list of all risk areas that can be considered, but its principles provide a foundation upon which AI development and use may be evaluated by describing the broad characteristics of high -quality AI within the context of health and human services.27 Chapters of this Plan will discuss risks and mitigation strategies to ensure safe and trustworthy use. As AI advances rapidly, HHS will continue to revisit principles and engage stakeholders to respond to the challenges of AI. All individuals share respons ibility to monitor for risks and support FA VES models and the use of AI. Applicability to State, Tribal, Local, and Territorial Health and Human Services Organizations In many cases, AI is deployed in individual STLTs as well as community -based organizations (CBOs)."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_48",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto revisit principles and engage stakeholders to respond to the challenges of AI. All individuals share respons ibility to monitor for risks and support FA VES models and the use of AI. Applicability to State, Tribal, Local, and Territorial Health and Human Services Organizations In many cases, AI is deployed in individual STLTs as well as community -based organizations (CBOs). HHS recognizes that each organization has unique needs based on patient and population health factors and that, in some situations, organizations have differing responsibilities (e.g., some STLTs and CBOs provide direct services, whereas others do not). HHS will maintain a flexible approach that supports innovation while ensuring safe and responsible development and use. In this way, HHS and industr y partners can learn from STLT and other entities as they increase their use of AI and identify new ways of improving health and human services. Relevant entities and potential actions are discussed in more detail in the domain -specific chapters. In April 2024, HHS published a plan for promoting the responsible use of AI in automated and algorithmic systems by STLT governments in the administration of public benefits.28 In this plan, HHS provides recommendations to STLTs on how they should choose, procure, design, govern, and manage AI in the administration of public benefits and services."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_49",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nin the domain -specific chapters. In April 2024, HHS published a plan for promoting the responsible use of AI in automated and algorithmic systems by STLT governments in the administration of public benefits.28 In this plan, HHS provides recommendations to STLTs on how they should choose, procure, design, govern, and manage AI in the administration of public benefits and services. The April 2024 plan also outlines HHS’s plans to support STLTs in developing their own policies and practices for using AI in automated and algorithmic systems for public benefits programs and services. HHS maintains alignment with those recommendations in this strategy and describes additional priorities to support and enable STLT’s sa fe and responsible development and use of AI. HHS Roles and Responsibilities Relevant to AI In alignment with the potential for AI to enhance the health and well -being of all Americans, HHS set up the Office of the Chief Artificial Intelligence Officer and established the role of the Chief AI Officer (CAIO) in March 2021. Located with ASTP, t he primary functions of the CAIO are to drive implementation of the Strategic Plan, oversee the HHS AI governance structure, coordinate HHS’s response to federal AI mandates, and foster AI - related collaboration. The CAIO has a vital role at HHS and within the federal government to maintain American leadership in AI ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_50",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nin March 2021. Located with ASTP, t he primary functions of the CAIO are to drive implementation of the Strategic Plan, oversee the HHS AI governance structure, coordinate HHS’s response to federal AI mandates, and foster AI - related collaboration. The CAIO has a vital role at HHS and within the federal government to maintain American leadership in AI . Fulfilling this commitment to AI within a department as vast and far -reaching as HHS requires coordination across divisions and department -wide alignment of responsible AI principles and resources. The CAIO will serve as this coordinating function, aligning the different divisions’ diverse capabilities to advance the Strategic Plan. The CAIO will also monitor how cross -collaboration between d ivisions can create new opportunities for AI in health and human services, filling in gaps that a more diffuse strategy may miss. ASTP more broadly will also play a role in cross -HHS coordination of AI implementation and adoption. 27 Risk of individual AI use cases or processes may need to be assessed along dimensions not included in the FAVES framework. 28 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 14 HHS divisions below will play multiple roles in assessing opportunities for AI ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_51",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nstrategy may miss. ASTP more broadly will also play a role in cross -HHS coordination of AI implementation and adoption. 27 Risk of individual AI use cases or processes may need to be assessed along dimensions not included in the FAVES framework. 28 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 14 HHS divisions below will play multiple roles in assessing opportunities for AI . Below is a brief description of each operating division and its key AI activities: • Administration for Children and Families (ACF): Administers over 60 programs that provide benefits and services to support families and children, including promoting economic and social well -being. ACF’s role in the HHS AI Strategic Plan will focus on ensuring effective and equitable delivery of human services to children and families. • Administration for Community Living (ACL): Supports programs for populations with complex needs, particularly older adults and people with disabilities, and administers various programs, including nutrition services, elder support services, and elder rights programs. ACL’s role in the HHS AI Strategic Plan will focus on ensuring effective and equitable delivery of human services to individuals with complex needs."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_52",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand families. • Administration for Community Living (ACL): Supports programs for populations with complex needs, particularly older adults and people with disabilities, and administers various programs, including nutrition services, elder support services, and elder rights programs. ACL’s role in the HHS AI Strategic Plan will focus on ensuring effective and equitable delivery of human services to individuals with complex needs. • Agency for Healthcare Research and Quality ( AHRQ): Provides funding and programs to enhance quality, accessibility, equity, affordability, and safety in healthcare, including improvements in primary care and assistance in access to social welfare and public health services; management and oversight of the Patient Safety Organization program; award of investigator -initiated health services research funding inclusive of digital healthcare research, such as health AI and clinical decision support; and execution of national expenditure surveys capturing utiliz ation, expenditures, and sources of payment and health insurance coverage. AHRQ’s role in the HHS AI Strategic Plan will focus on promoting and conducting research on the adoption of safe AI and appropriate use in workflows to enable high -quality care. • Advanced Research Projects Agency for Health (ARPA -H): Advances high -potential, high -impact biomedical and health research that cannot be readily accomplished through traditional research or commercial activities."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_53",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAHRQ’s role in the HHS AI Strategic Plan will focus on promoting and conducting research on the adoption of safe AI and appropriate use in workflows to enable high -quality care. • Advanced Research Projects Agency for Health (ARPA -H): Advances high -potential, high -impact biomedical and health research that cannot be readily accomplished through traditional research or commercial activities. ARPA -H’s role in the HHS AI Strategic Plan will focus on issuing awards to catalyze cutting -edge research. • Administration for Strategic Preparedness and Response (ASPR) : Leads the nation’s medical and public health preparedness for, response to, and recovery from disasters and other public health emergencies and collaborates with healthcare and public health stakeholders (e.g., STLTs and hospitals) and others to improve the country’ s readiness and response. ASPR’s role in the HHS AI Strategic Plan will focus on coordinating the use of AI in public health emergencies (in collaboration with the Centers for Disease Control and Prevention [CDC] and other stakeholders). • Centers for Disease Control and Prevention (CDC): Detects and responds to new and emerging health threats, conducts research, issues guidance, and designs programs that address the Nation’s largest health problems, promote healthy and safe behaviors, communities, and environments, and train the public he alth workforce."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_54",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n(in collaboration with the Centers for Disease Control and Prevention [CDC] and other stakeholders). • Centers for Disease Control and Prevention (CDC): Detects and responds to new and emerging health threats, conducts research, issues guidance, and designs programs that address the Nation’s largest health problems, promote healthy and safe behaviors, communities, and environments, and train the public he alth workforce. CDC’s role in the HHS AI Strategic Plan will focus on researching the efficacy of AI in disease prevention and implementing AI in public health efforts. • Center s for Medicare & Medicaid Services (CMS): Administers the Medicare program, the federal portion of the Medicaid and CHIP programs, and the Health Insurance Marketplace ®,29 which together provide health coverage to approximately 50% of Americans. Additionally, CMS approves and oversees program waivers and demonstrations, develops and tests healthcare payment and service delivery models, develops health and safety standards for providers of healthcare services, implements quality initiatives, and promotes the adoption and use of health information technology, among other responsibilities."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_55",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand the Health Insurance Marketplace ®,29 which together provide health coverage to approximately 50% of Americans. Additionally, CMS approves and oversees program waivers and demonstrations, develops and tests healthcare payment and service delivery models, develops health and safety standards for providers of healthcare services, implements quality initiatives, and promotes the adoption and use of health information technology, among other responsibilities. CMS’ s role in the HHS AI Strategic Plan will focus on determination of coverage for AI -enabled healthcare services as appropriate (using payment and regulatory policy to ensure trustworthy, responsible use of AI by payers and providers), oversight and certification of state information technology systems and data collection standards, and the provision of tec hnical assistance to providers, states, and other stakeholders. • Food and Drug Administration (FDA): Regulates medical products (including drugs, biological products, and medical devices) by evaluating their safety and effectiveness before and after marketing. FDA also advances public health by, among other things, fostering innovations that can help acc elerate patient access to safe, effective, and innovative medical products. FDA also has the responsibility in maintaining the safety 29 Health Insurance Marketplace® is a registered service mark of the U.S. Department of Health and Human Services."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_56",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ntheir safety and effectiveness before and after marketing. FDA also advances public health by, among other things, fostering innovations that can help acc elerate patient access to safe, effective, and innovative medical products. FDA also has the responsibility in maintaining the safety 29 Health Insurance Marketplace® is a registered service mark of the U.S. Department of Health and Human Services. 15 of our nation ’s food supply (human and animal), cosmetics, and products that emit radiation. In addition, FDA regulates the manufacturing, marketing, and distribution of tobacco products to protect public health. FDA’s role in HHS’s AI strategy will be focused on developing risk -based approaches to regulatory oversight of AI -enabled medical products and the AI used to develop medical products , issuing guidance for industry, and strengthening regulatory cooperation with international regulators. • Health Resources and Services Administration ( HRSA): Provides equitable healthcare to the nation’s highest -need communities, including through programs that support people with low incomes, people with HIV , pregnant women, children, parents, rural communities, transplant patients, and the health workforce."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_57",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI used to develop medical products , issuing guidance for industry, and strengthening regulatory cooperation with international regulators. • Health Resources and Services Administration ( HRSA): Provides equitable healthcare to the nation’s highest -need communities, including through programs that support people with low incomes, people with HIV , pregnant women, children, parents, rural communities, transplant patients, and the health workforce. This includes more than 31 million people cared for at HRSA -supported health centers, more than 58 million pregnant women, infants, and children, more than 560,000 people with HIV , more than 1,900 rural counties and municipalities across the country, and ne arly 22,000 healthcare providers through loan repayment and scholarship programs. HRSA’s role in the HHS AI Strategic Plan will focus on ensuring the equitable use of AI to benefit underserved communities and educating and training future generations of healthcare professionals. • Indian Health Service (IHS): Provides primary and acute care for tribal nations and communities, representing approximately 2.8 million American Indians and Alaska Natives through a network of more than 600 hospitals, clinics, and health stations on or near Indian reservations. IHS’s role in the HHS AI Strategic Plan will focus on implementing AI in healthcare delivery within these populations and ensuring the applicability of AI guidance to relevant STLTs."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_58",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nfor tribal nations and communities, representing approximately 2.8 million American Indians and Alaska Natives through a network of more than 600 hospitals, clinics, and health stations on or near Indian reservations. IHS’s role in the HHS AI Strategic Plan will focus on implementing AI in healthcare delivery within these populations and ensuring the applicability of AI guidance to relevant STLTs. • National Institutes of Health (NIH): Conducts and funds biomedical research and provides leadership and direction for programs designed to improve the Nation’s health. NIH’s role in the HHS AI Strategic Plan will focus on conducting and funding research to advance AI in biomedical, behavioral , and health research , developing and evaluating necessary standards, supporting the development of best practices for the training of AI models, developing and training AI workforce , and promot ing the responsible use of AI. • Substance Abuse and Mental Health Services Administration (SAMHSA ): Leads efforts to reduce the impact of mental and substance use disorders on individuals, families, and communities. SAMHSA provides funding, guidance, and resources to support prevention, treatment, and recovery services, ensuring equitable access to care ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_59",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndeveloping and training AI workforce , and promot ing the responsible use of AI. • Substance Abuse and Mental Health Services Administration (SAMHSA ): Leads efforts to reduce the impact of mental and substance use disorders on individuals, families, and communities. SAMHSA provides funding, guidance, and resources to support prevention, treatment, and recovery services, ensuring equitable access to care . SAMHSA’s role in the HHS AI Strategic Plan will focus on providing grant funding and guidance to STLT communities and collecting, analyzing, and distributing behavioral health data to eva luate programs, improve policies, and raise awareness of resources on prevention, harm reduction, treatment, and recovery. SAMHSA will additionally support the adoption of AI by behavioral health clinicians and health systems. 16 HHS divisions have many areas of complementary and interdependent responsibilities. While operating divisions may span multiple areas, the following schematic depicts a general overview of division equities in each domain: Exhibit 2: Overview of Equities of HHS Operating Divisions Note: This schematic directionally indicates which divisions engage in which domains, necessitating coordination and collaboration. It is not meant to be an exhaustive indication of each division’s equities , and divisions may play roles across domains in varied ways ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_60",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nschematic depicts a general overview of division equities in each domain: Exhibit 2: Overview of Equities of HHS Operating Divisions Note: This schematic directionally indicates which divisions engage in which domains, necessitating coordination and collaboration. It is not meant to be an exhaustive indication of each division’s equities , and divisions may play roles across domains in varied ways . In addition to the operating divisions listed above, HHS staff divisions will play a large role in ensuring the success of the Strategic Plan. For example, ASTP oversees the adoption of data and technology standards for the access, exchange, and use of clinical information in healthcare, public health, and human services. It also guides the regulation of health information technology (e.g., electronic health records) in various federal programs and supports interoperability for government and industry constituents. ASTP’s role will focus on cross -HHS policy and coordination of AI implementation and adoption. The Office for Civil Rights (OCR) enforces federal civil rights laws (e.g., Section 1557 Final Rule), conscience and religious freedom laws, the Health Insurance Portability and Accountability Act (HIPAA) Privacy, Security, and Breach Notification Rules, and the Patient Safety Act and Rule, which together prote ct fundamental rights of nondiscrimination, conscience, religious freedom, and health information privacy."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_61",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nimplementation and adoption. The Office for Civil Rights (OCR) enforces federal civil rights laws (e.g., Section 1557 Final Rule), conscience and religious freedom laws, the Health Insurance Portability and Accountability Act (HIPAA) Privacy, Security, and Breach Notification Rules, and the Patient Safety Act and Rule, which together prote ct fundamental rights of nondiscrimination, conscience, religious freedom, and health information privacy. OCR’s role will be to provide education on protecting individuals’ rights throughout AI development and use. The Office of the Assistant Secretary fo r Planning and Evaluation, the Office of Global Affairs, and the Office of the Assistant Secretary for Health have additional equities. The Office of the Chief Information Officer will also have a notable role in supporting internal uses of AI at HHS. This is not an exhaustive list of all HHS staff divisions or the entirety of work each will perform, but a way to highlight the extensive workstreams and responsibilities across the Department and articulate the importance of coordination. Individual as well a s collaborative efforts across all HHS divisions will be critical in supporting this Strategic Plan. 17 Action Plan Summary The following chapters will articulate existing and planned activities that support these goals."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_62",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nof work each will perform, but a way to highlight the extensive workstreams and responsibilities across the Department and articulate the importance of coordination. Individual as well a s collaborative efforts across all HHS divisions will be critical in supporting this Strategic Plan. 17 Action Plan Summary The following chapters will articulate existing and planned activities that support these goals. These actions are organized into themes that detail HHS’s aspirations for the future of AI as articulated in the table below.30 Key goals that actions support Themes of actions across chapters (non -exhaustive, detailed Action Plans appear in each chapter) 1. Catalyzing health AI innovation and adoption to unlock new ways to improve people’s lives • Expanding breadth of AI use across the value chains in each domain • Modernizing infrastructure to implement AI and support adoption • Enhancing collaboration and public -private partnerships to promote AI adoption • Clarifying regulatory oversight and coverage/payment determinator processes for AI • Supporting gathering evidence on outcomes (e.g., efficacy, safety) of AI interventions and best practices 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_63",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nlives • Expanding breadth of AI use across the value chains in each domain • Modernizing infrastructure to implement AI and support adoption • Enhancing collaboration and public -private partnerships to promote AI adoption • Clarifying regulatory oversight and coverage/payment determinator processes for AI • Supporting gathering evidence on outcomes (e.g., efficacy, safety) of AI interventions and best practices 2. Promoting trustworthy AI development and ethical and responsible use to avoid potential harm • Building and disseminating evidence that supports mitigating risks to equity, biosecurity, data security, and privacy • Setting clear standards that guide the use of federal resources in the context of trustworthy AI use • Supporting organizational governance for risk management of AI • Refining regulatory frameworks to address adaptive AI technologies • Promoting external evaluation, monitoring, and transparency reporting and fostering other mechanisms for quality assurance of health AI 3."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_64",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nbiosecurity, data security, and privacy • Setting clear standards that guide the use of federal resources in the context of trustworthy AI use • Supporting organizational governance for risk management of AI • Refining regulatory frameworks to address adaptive AI technologies • Promoting external evaluation, monitoring, and transparency reporting and fostering other mechanisms for quality assurance of health AI 3. Democratizing AI technologies and resources to promote access • Increasing access to responsibly curated data and infrastructure, including providing support for organizations where appropriate • Supporting information -sharing mechanisms to disseminate standards, best practices, and foster collaboration to improve access • Developing user -friendly, customizable, and open -source AI tools • Enhancing capabilities of STLTs and other community organizations, including providing resources or other mechanisms where appropriate 4."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_65",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n• Increasing access to responsibly curated data and infrastructure, including providing support for organizations where appropriate • Supporting information -sharing mechanisms to disseminate standards, best practices, and foster collaboration to improve access • Developing user -friendly, customizable, and open -source AI tools • Enhancing capabilities of STLTs and other community organizations, including providing resources or other mechanisms where appropriate 4. Cultivating AI - empowered workforces and organization cultures to effectively and safely use AI • Improving training in governance and management of AI • Developing and retaining a robust AI talent pipeline • Equipping professionals with access to resources and research to support their respective health and human services organizations • Using AI to mitigate labor workforce shortages and address burnout and attrition HHS’s vision is to be a global leader in the innovative and responsible development and adoption of AI to achieve unparalleled advances in the health and well -being of all Americans. The following chapters of this Strategic Plan detail specific actions to achieve that vision."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_66",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nservices organizations • Using AI to mitigate labor workforce shortages and address burnout and attrition HHS’s vision is to be a global leader in the innovative and responsible development and adoption of AI to achieve unparalleled advances in the health and well -being of all Americans. The following chapters of this Strategic Plan detail specific actions to achieve that vision. 30 Some themes and actions may be repeated across chapters when they apply across domains 18 1 Medical Research and Discovery 1.1 Introduction and Context Medical research and discovery are fundamental to advancing health by driving the development of innovative drugs,31 biological products,32 medical devices,33 including some software -based behavioral interventions,34 and other tools that improve individuals’ and communities’ health outcomes and access to quality care .35 This chapter of the Plan will focus on the research and discovery of medical products36 and the research and discovery of AI technologies that can be leveraged in biomedicine."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_67",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe development of innovative drugs,31 biological products,32 medical devices,33 including some software -based behavioral interventions,34 and other tools that improve individuals’ and communities’ health outcomes and access to quality care .35 This chapter of the Plan will focus on the research and discovery of medical products36 and the research and discovery of AI technologies that can be leveraged in biomedicine. The next stages of the medical product life cycle , including clinical trials, as well as research in other fields , such as health systems, human services delivery, and public health , will be discussed in other chapters and are not in the scope of this chapter.37 In recent years, medical technology and pharmaceutical companies, academic and research institutions, and other organizations have increasingly leveraged AI to bolster their medical research and discovery activities and create AI-driven tools, but the full opportunity of existing AI technology is not captured today . While further advancements could unlock additional benefits , action is required to catalyze safe and responsible uptake of AI that more fully realizes the potential of AI in medical research and discovery settings. Accordingly, this chapter of the Plan explains the industry trends, AI use cases and risks, and actions that HHS could pursue to help safely activate AI adoption in medical research and discovery."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_68",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nadditional benefits , action is required to catalyze safe and responsible uptake of AI that more fully realizes the potential of AI in medical research and discovery settings. Accordingly, this chapter of the Plan explains the industry trends, AI use cases and risks, and actions that HHS could pursue to help safely activate AI adoption in medical research and discovery. HHS provides high-level context on medical research and discovery and an overview of AI in the space, including the stakeholders involved and key opportunities for AI uptake. Medical research and discovery provide the data and the confidence to evaluate diagnostics, therapeutics, treatments, vaccines, technologies, and other tools in humans for the diagnosis, prevention, mitigation, and treatment of disease . At a high level, they can be described in a value chain that includes three phases: basic research, discovery (which can vary between different types of medical products), and pre -clinical studies. See Section 1.5 “Potential Use Cases and Risks for AI in Medical Research and Discovery” below for a detailed discussion of this value chain and its constituent phases. Across all aspects of medical research and discovery, HHS plays an active role in spurring activity and promoting safety and quality."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_69",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nvary between different types of medical products), and pre -clinical studies. See Section 1.5 “Potential Use Cases and Risks for AI in Medical Research and Discovery” below for a detailed discussion of this value chain and its constituent phases. Across all aspects of medical research and discovery, HHS plays an active role in spurring activity and promoting safety and quality. Nearly 83% of NIH’s funding is awarded for extramural research and research support ;38 furthermore, NIH follows the HHS Common Rule39 and has its own policies to ensure the safety of human research subjects, maintain data security and quality, and provide additional protections for vulnerable 31 See Appendix A: “Glossary of terms” for the definition of “drug” used in this Plan. 32 See Appendix A: “Glossary of terms” for the definition of “biological product” used in this Plan. 33 See Appendix A: “Glossary of terms” for the definition of “medical device” used in this Plan. 34 Note that some software -based behavioral interventions are medical devices under FDA’s statute, whereas others, such as those software functions that are “intended for maintaining or encouraging a healthy lifestyle” and are “unrelated to the diagnosis, cure, mitigation, preventi on, or treatment of a disease or condition,” are not. See sections 201(h) and 520(o)(1)(B) of the FD&C Act."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_70",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nPlan. 34 Note that some software -based behavioral interventions are medical devices under FDA’s statute, whereas others, such as those software functions that are “intended for maintaining or encouraging a healthy lifestyle” and are “unrelated to the diagnosis, cure, mitigation, preventi on, or treatment of a disease or condition,” are not. See sections 201(h) and 520(o)(1)(B) of the FD&C Act. 35 https://ncses.nsf.gov/pubs/nsb20221/u -s-and-global -research -and-development 36 Drugs, biological products, and medical devices in this Plan are referred to as “medical products” when discussed collectivel y. See Appendix A: “Glossary of terms” for the definition of “medical products” used in this Plan for additional details. 37 Note that research pertaining to health systems, care delivery, and non -device behavioral interventions will be discussed in the “Healthcare Delivery” chapter; research pertaining to human services delivery will be discussed in the “Human Services Delive ry” chapter; and research pertaining to public health will be discussed in the “Public Health” chapter. Furthermore , where relevant, clinical trials will be discussed in the “Medical Product Development, Safety, and Effectiveness” chapter and are not in the scope of this chapter."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_71",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n“Healthcare Delivery” chapter; research pertaining to human services delivery will be discussed in the “Human Services Delive ry” chapter; and research pertaining to public health will be discussed in the “Public Health” chapter. Furthermore , where relevant, clinical trials will be discussed in the “Medical Product Development, Safety, and Effectiveness” chapter and are not in the scope of this chapter. 38 https://www.nih.gov/about -nih/what -we-do/budget 39 https://www.hhs.gov/ohrp/regulations -and-policy/regulations/common -rule/index.html 19 communities participating in research.40 Additional divisions also play transformative roles: in FY 2023, ARPA - H and AHRQ had budgets of $1.5B and $374M, respectively, to advance groundbreaking innovation in biomedicine and health.41, 42, 43 In addition, FDA regulates scientific studies that are designed to develop evidence to support the safety and effectiveness of investigational drugs (human and animal), biological products, and medical devices.44, 45 Though this summarizes a few of HHS divisions’ roles in medical research and discovery, many more engage in the space in other ways. As AI becomes increasingly used in medical research and discovery, HHS and its core engaged divisions will facilitate the safe and impactful uptake of equitable AI technologies across the ecosystem. 1.1.1 Action Plan Summary Later in this chapter, HHS articulates proposed actions to advance its four goals for the responsible use of AI in the sector."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_72",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nspace in other ways. As AI becomes increasingly used in medical research and discovery, HHS and its core engaged divisions will facilitate the safe and impactful uptake of equitable AI technologies across the ecosystem. 1.1.1 Action Plan Summary Later in this chapter, HHS articulates proposed actions to advance its four goals for the responsible use of AI in the sector. Below is a summary of the themes of actions within each goal. For full details of proposed actions please see section 1.6 Action Plan. Key goals that actions support Themes of proposed actions (not exhaustive, see 1.6 Action Plan for more details) 1. Catalyzing health AI innovation and adoption • Expanding the breadth of medical research and discovery AI use across disease areas and steps of the value chain • Enhancing coordination across geographies to harness AI to improve medical research and discovery • Fostering AI -ready data standards and datasets to bolster their usability for AI - empowered medical research and discovery 2. Promoting trustworthy AI development and ethical and responsible use • Building and disseminating evidence to mitigate biosecurity, data security, privacy, and data collection risks • Setting clear guidelines for safe and trustworthy AI use in medical research and discovery and the distribution and use of federal resources • Enabling safe and responsible organizational governance of AI risk management and transparency 3."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_73",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ntrustworthy AI development and ethical and responsible use • Building and disseminating evidence to mitigate biosecurity, data security, privacy, and data collection risks • Setting clear guidelines for safe and trustworthy AI use in medical research and discovery and the distribution and use of federal resources • Enabling safe and responsible organizational governance of AI risk management and transparency 3. Democratizing AI technologies and resources • Fostering intentional public engagement and public -private action to enhance sharing of best practices among all stakeholders • Increasing accessibility to responsibly curated AI -ready data , models and algorithms, and tooling and infrastructure for all 4. Cultivating AI - empowered workforces and organization cultures • Improving training in governance and management of AI in medical research and discovery • Developing and retaining a robust AI talent pipeline in medical research and discovery 40 https://grants.nih.gov/policy -and-compliance/policy -topics/human -subjects/policies -and-regulations 41."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_74",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto responsibly curated AI -ready data , models and algorithms, and tooling and infrastructure for all 4. Cultivating AI - empowered workforces and organization cultures • Improving training in governance and management of AI in medical research and discovery • Developing and retaining a robust AI talent pipeline in medical research and discovery 40 https://grants.nih.gov/policy -and-compliance/policy -topics/human -subjects/policies -and-regulations 41. https://arpa -h.gov/sites/default/files/2023 -10/FY_2023_NIH_ARPA -H_Operating_Plan.pdf 42 https://www.ahrq.gov/news/blog/ahrqviews/ahrq -2024 -proposed -budget.html 43 https://arpa -h.gov/about/faqs 44 https://www.fda.gov/patients/learn -about -drug-and-device -approvals/drug -development -process 45 Note that FDA also oversees clinical research to ensure trials are designed, conducted, analyzed, and reported according to f ederal law and FDA’s good clinical practice (GCP) regulations,45 and after research, discovery, and any clinical trials are completed, the FDA reviews the data and information provided for marketing authorization and monitors authorized products postmarket to help ensure they remain safe and effective (see “Medical Product Development, Safety, and Effectiveness” for additional details)."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_75",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nconducted, analyzed, and reported according to f ederal law and FDA’s good clinical practice (GCP) regulations,45 and after research, discovery, and any clinical trials are completed, the FDA reviews the data and information provided for marketing authorization and monitors authorized products postmarket to help ensure they remain safe and effective (see “Medical Product Development, Safety, and Effectiveness” for additional details). 20 1.2 Stakeholders Engaged in the Medical Research and Discovery AI Value Chain Medical research and discovery must ultimately meet the needs of current and future patients and their caregivers; therefore, corresponding AI use should advance research and eventual technologies that meet these needs. In addition to patients and medical providers, several key stakeholders engage with AI in medical research and discovery , ranging from developers of medical products to distributors, providers, payers, researchers, and many others. The Action Plan section at the end of this chapter includes approaches to engage these stakeholders to advance innovation while mitigating risks. Below is an illustrative diagram of example flows between stakeholders and a bulleted list with additional details on medical research and discovery stakeholders . Please note that neither the diagram nor the list captures all possible stakeholder roles and interactions. Please refer to other HHS documents for additional regulatory guidance and authority details ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_76",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto advance innovation while mitigating risks. Below is an illustrative diagram of example flows between stakeholders and a bulleted list with additional details on medical research and discovery stakeholders . Please note that neither the diagram nor the list captures all possible stakeholder roles and interactions. Please refer to other HHS documents for additional regulatory guidance and authority details . Exhibit 3: Stakeholders Engaged in Medical Research and Discovery Stakeholders (including partners) include: • HHS operating divisions (non -exhaustive):46 Divisions involved in AI for medical research and discovery include: o NIH : Supports biomedical and behavioral research within the U.S. and abroad, conducts research in its own laboratories and clinics, trains promising young researchers, and promotes collecting and sharing biomedical knowledge."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_77",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n3: Stakeholders Engaged in Medical Research and Discovery Stakeholders (including partners) include: • HHS operating divisions (non -exhaustive):46 Divisions involved in AI for medical research and discovery include: o NIH : Supports biomedical and behavioral research within the U.S. and abroad, conducts research in its own laboratories and clinics, trains promising young researchers, and promotes collecting and sharing biomedical knowledge. In recent years, these activities increasingly included AI related to medical research and discovery (e.g., making data available, catalyzing data science and AI 46 https://www.hhs.gov/about/agencies/hhs -agencies -and-offices/index.html 21 opportunities in biomedical research and discovery, increasing diversity in AI model development, and developing and implementing AI across biomedical research domains).47 o ARPA -H: Accelerates better health outcomes for everyone by supporting the development of high - impact solutions to society’s most challenging health problems, including those leveraging AI (e.g., using AI to speed up the discovery and development of antibiotics).48 o FDA : Helps ensure that human and animal drugs, biological products, and medical devices are safe and effective for their intended uses and that electronic products that emit radiation are safe. As AI becomes a more prominent aspect of medical research and discov ery, the FDA will continue to play a role in regulating products and supporting stakeholders."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_78",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nantibiotics).48 o FDA : Helps ensure that human and animal drugs, biological products, and medical devices are safe and effective for their intended uses and that electronic products that emit radiation are safe. As AI becomes a more prominent aspect of medical research and discov ery, the FDA will continue to play a role in regulating products and supporting stakeholders. o AHRQ : Focuses on improving the quality, safety, efficiency, and effectiveness of healthcare for all Americans through research, technology assessments, and work on dissemination and implementation. AHRQ will focus on promoting and conducting research on the safe adoption of AI that enables high-quality care, disseminating actionable, evidence -based AI knowledge, and provisioning evidence required for coverage decisions. • Other federal agencies: HHS also works closely with many other federal departments, such as the National Science Foundation (NSF) and the Department of Energy (DOE). • Patients, research participants, caregivers, and related advocacy groups (including residents and communities): Historically, considered the recipients or administrators of diagnostics, therapeutics, treatments, vaccines, technologies, and other tools designed by and/or embedded with various types of AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_79",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nagencies: HHS also works closely with many other federal departments, such as the National Science Foundation (NSF) and the Department of Energy (DOE). • Patients, research participants, caregivers, and related advocacy groups (including residents and communities): Historically, considered the recipients or administrators of diagnostics, therapeutics, treatments, vaccines, technologies, and other tools designed by and/or embedded with various types of AI. Though patient centricity is not novel, empowered patients may now also utilize AI to understand their personal health status better and advocate for their own care; they can be included in the research and discovery process (e.g., as collaborators in the early planning phases of a study).49 • Academic, non -profit, and other research workforce: Investigators developing evidence to drive forward the leading edge of biomedical knowledge, engineers designing and generating medical devices for application in the clinic, and subject matter experts that develop AI, apply AI in research workflows, and/ or integrate AI into the product development life cycle . They are among the primary users of AI in medical research and discovery."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_80",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nworkforce: Investigators developing evidence to drive forward the leading edge of biomedical knowledge, engineers designing and generating medical devices for application in the clinic, and subject matter experts that develop AI, apply AI in research workflows, and/ or integrate AI into the product development life cycle . They are among the primary users of AI in medical research and discovery. • Pharmaceutical, biotechnology, and medical device industry research workforce: Responsible for the design, development, and production of diagnostics, therapeutics, treatments, vaccines, technologies, and other tools for commercial use in healthcare delivery, including researchers and subject matter experts integrating AI into resear ch workflows and product design. They are among the primary users of AI in medical research and discovery. • Healthcare providers:50 Hospitals, clinics, and healthcare professionals who utilize medical products are often looped into medical research and discovery to provide clinical perspectives. Additionally, providers can serve as “humans in the loop” for medical research and discove ry value chains. • State, tribal, local, and territorial governments (STLTs): Regulatory agencies outside the federal government. While medical products are under the regulatory control of the FDA, the practice of medicine generally is under the jurisdiction of STLTs."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_81",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nresearch and discovery to provide clinical perspectives. Additionally, providers can serve as “humans in the loop” for medical research and discove ry value chains. • State, tribal, local, and territorial governments (STLTs): Regulatory agencies outside the federal government. While medical products are under the regulatory control of the FDA, the practice of medicine generally is under the jurisdiction of STLTs. Additionally, STLTs can fund medical research and discovery activities.51 • Distributors and wholesalers: Facilitate the distribution of medical products —which may have been researched and discovered by leveraging AI —to healthcare providers. • Contract research organizations (CROs): Provide outsourced research services, potentially more concentrated in clinical development, which is elaborated on in the Medical Product Development, Safety, 47 https://datascience.nih.gov/artificial -intelligence 48 https://arpa -h.gov/news -and-events/arpa -h-project -accelerate -discovery -and-development -new-antibiotics -using 49 https://heal.nih.gov/resources/engagement/understanding -pce 50 Note that healthcare providers do not just adopt medical products but also implement evidence generated from research into care delivery, as well as healthcare delivery models and practices. They are also often research sites or research participants. See the “Healthcare Delivery” chapter for additional information ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_82",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n48 https://arpa -h.gov/news -and-events/arpa -h-project -accelerate -discovery -and-development -new-antibiotics -using 49 https://heal.nih.gov/resources/engagement/understanding -pce 50 Note that healthcare providers do not just adopt medical products but also implement evidence generated from research into care delivery, as well as healthcare delivery models and practices. They are also often research sites or research participants. See the “Healthcare Delivery” chapter for additional information . 51 https://ncses.nsf.gov/surveys/state -government -research -development/2023 22 and Effectiveness chapter, and may develop or integrate AI into their medical research and discovery value chains or workflows. • Donors and private funders: Non-profit donors, such as foundations and for -profit funders, such as private equity, venture capital, and other funding organizations, play a role in medical research and discovery and ongoing development by supporting funding for upstream research. The se organizations may also support direct investment in aggregating datasets, developing platforms or AI tools, and using AI in the process. • AI-first technology developers: Engineers and organizations who build the AI tools (e.g., protein -folding software), models, data infrastructure, and platforms (e.g., electronic health records) that can be used throughout the medical research and discovery value chain. Developers include AI-first biotechs, big tech, and domain -specific players."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_83",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\naggregating datasets, developing platforms or AI tools, and using AI in the process. • AI-first technology developers: Engineers and organizations who build the AI tools (e.g., protein -folding software), models, data infrastructure, and platforms (e.g., electronic health records) that can be used throughout the medical research and discovery value chain. Developers include AI-first biotechs, big tech, and domain -specific players. HHS will engage stakeholders in the development or refinement of any funding mechanisms, policy guidelines, educational materials, or internal infrastructure relevant to AI in research and discovery to ensur e HHS promotes equity in the access, understanding, and impact potential of these technologies. Furthermore, working closely with STLTs, particularly their regulatory bodies for health and human services, will allow this Plan to be aligned across levels of gove rnment and throughout geographies. Engaging stakeholders throughout the ecosystem will be critical to executing this work. 1.3 Opportunities for the Application of AI in Medical Research and Discovery Responsible adoption and scaling of AI across the medical research and discovery value chain has the potential to improve health outcomes and access for Americans by: 1."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_84",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\naligned across levels of gove rnment and throughout geographies. Engaging stakeholders throughout the ecosystem will be critical to executing this work. 1.3 Opportunities for the Application of AI in Medical Research and Discovery Responsible adoption and scaling of AI across the medical research and discovery value chain has the potential to improve health outcomes and access for Americans by: 1. Bolstering the potential for basic research to derive novel biological insights that improve human health: Not all medical research and discovery is directly “translational” (i.e., aiming to produce results immediately actionable in medical care). In fact, “basic” research (i.e., aiming to understand a phenomenon or mechanism more deeply) has historically led to some of the most impactful downstream impacts on human health (e.g., CRISPR ).52, 53 By leveraging AI to examine links between diseases and core pathological processes with data from clinical use (e.g., in longevity research), explore more hypotheses based on rapid analysis of very large volumes of data, screen images to augment human inv estigation, and generate insights at high speed, new basic research discoveries could not only proliferate but also be of higher quality than those arrived at without the support of AI.54 Most importantly, this transformation could lead to better human health. 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_85",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nexplore more hypotheses based on rapid analysis of very large volumes of data, screen images to augment human inv estigation, and generate insights at high speed, new basic research discoveries could not only proliferate but also be of higher quality than those arrived at without the support of AI.54 Most importantly, this transformation could lead to better human health. 2. Increasing accessibility to drive innovation and potential ly reducing costs: Emerging evidence suggests that leveraging AI across the medical research and discovery value chain presents a financial opportunity, up to $26 B annually just for drugs55 with potential additional value for devices. If realized, such efficiencies could lower barriers to conducting medical research and discovery and/or free up capital for reinvestment into further medical research and discovery activities."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_86",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nreducing costs: Emerging evidence suggests that leveraging AI across the medical research and discovery value chain presents a financial opportunity, up to $26 B annually just for drugs55 with potential additional value for devices. If realized, such efficiencies could lower barriers to conducting medical research and discovery and/or free up capital for reinvestment into further medical research and discovery activities. For example, medi cal research and discovery costs can be driven substantially by “wet lab” real estate, a space where physical biological and chemical samples can be tested, which may cost nearly double the asking rent of traditional office space per square foot.56, 57 By leveraging AI to conduct some steps of medical research and discovery (e.g., protein folding modeling, simulations of biological interactions) in silico , the need for wet lab space could be reduced, which may 52 https://www.nih.gov/news -events/gene -editing -digital -press -kit 53 https://www.niaid.nih.gov/grants -contracts/basic -research -definition 54 https://pmc.ncbi.nlm.nih.gov/articles/PMC10018490/ 55 https://itif.org/publications/2020/12/07/fact -week -artificial -intelligence -can-save-pharmaceutical -companies -almost/ 56 https://www.cbre.com/press -releases/net -absorption -of-lab-space -grew -nationally -in-the-second -quarter 57 https://mktgdocs.cbre.com/2299/ebd1da98 -2b86 -4a75 -b3ed -b050fb52d383 -283656098/Q3_2024_U.S._Office_Figures_D3.pdf 23 lower costs required to engage in innovation."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_87",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nin silico , the need for wet lab space could be reduced, which may 52 https://www.nih.gov/news -events/gene -editing -digital -press -kit 53 https://www.niaid.nih.gov/grants -contracts/basic -research -definition 54 https://pmc.ncbi.nlm.nih.gov/articles/PMC10018490/ 55 https://itif.org/publications/2020/12/07/fact -week -artificial -intelligence -can-save-pharmaceutical -companies -almost/ 56 https://www.cbre.com/press -releases/net -absorption -of-lab-space -grew -nationally -in-the-second -quarter 57 https://mktgdocs.cbre.com/2299/ebd1da98 -2b86 -4a75 -b3ed -b050fb52d383 -283656098/Q3_2024_U.S._Office_Figures_D3.pdf 23 lower costs required to engage in innovation. AI can allow institutions with lower access to capital (e.g., start-ups, non -profits, academic research organizations) to participate in innovation, increas ing diversity in medical research and discovery that can lead to more breakthroughs. Furthermore, these potential reductions in cost could spur opportunities if reinvested. While costs and timelines vary from product to product, total development costs of some drugs , for example, can range from $300M to $4.5B each.58 If the potential $26B annua l financial opportunity is realized and reinvested, this could materially accelerate the availability of new innovations. 3."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_88",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nmore breakthroughs. Furthermore, these potential reductions in cost could spur opportunities if reinvested. While costs and timelines vary from product to product, total development costs of some drugs , for example, can range from $300M to $4.5B each.58 If the potential $26B annua l financial opportunity is realized and reinvested, this could materially accelerate the availability of new innovations. 3. Expanding the reach of medical research and discovery to meet unmet patient needs and support breakthrough innovations: AI may foster breakthrough innovations and the development of novel medical products that address the health needs of patients who have been historically underserved. Research and discovery activity today may focus on potentially more profitable therapeutic areas ( TA) rather than TAs with the most health need59, given the significant cost and time associated with the research and discovery of a single medical product (see trend 2 in Section 1.4 below for more details). Leveraging AI to expand research and discovery beyond such “safe bet” targets or diseases and to increase pipeline activity on potentially under -researched TAs while pursuing breakthrough innovations across other TAs could transfo rm outcomes and access for patients with underserved health needs. By leveling the field of targets or TAs “worth exploring,” AI could also reduce bias in basic medical research and discovery. 4."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_89",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand discovery beyond such “safe bet” targets or diseases and to increase pipeline activity on potentially under -researched TAs while pursuing breakthrough innovations across other TAs could transfo rm outcomes and access for patients with underserved health needs. By leveling the field of targets or TAs “worth exploring,” AI could also reduce bias in basic medical research and discovery. 4. Accelerating the timeline to develop new products and potentially access care: Currently, pre -clinical development for drugs , in particular , is estimated to take between six and ten years.60 In recent years, however, leveraging AI in medical research and discovery has shown promise in corresponding use cases (e.g., from years for humans to determine protein structures to mere seconds).61 If AI is successfully and responsibly adopted and scaled across the medical research and discovery value chain, these efficiencies could significantly reduce the time required to get medical products to patients, saving American lives, improving health outcomes, and more rapidly reaching underserved patients.62 As the world leader in medical research and discovery, the U.S. could accelerate access globally as well.63 1.4 Trends of AI in Medical Research and Discovery Adoption of AI in medical research and discovery is growing, following a few key trends: 1."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_90",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto get medical products to patients, saving American lives, improving health outcomes, and more rapidly reaching underserved patients.62 As the world leader in medical research and discovery, the U.S. could accelerate access globally as well.63 1.4 Trends of AI in Medical Research and Discovery Adoption of AI in medical research and discovery is growing, following a few key trends: 1. AI adoption is increasing yet inconsistent across the medical research and discovery value chain: To date, uptake has focused more on deterministic activities in discovery, particularly in target identification and lead generation (e.g., predicting protein folding, molecular interactions, and cellular disease processes). Specifically, in silico design, manipulation, and exploration of biomolecules and designs of devices may have achieved more adoption of AI than use cases in basic research or pre -clinical studies (see the Potential Use Cases and Risks for AI in Medical Research and Discovery section below for examples of use case adoption across the value chain).64 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_91",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncellular disease processes). Specifically, in silico design, manipulation, and exploration of biomolecules and designs of devices may have achieved more adoption of AI than use cases in basic research or pre -clinical studies (see the Potential Use Cases and Risks for AI in Medical Research and Discovery section below for examples of use case adoption across the value chain).64 2. AI uptake is potentially concentrated on TAs with stronger market incentives: Researchers face strong incentives, such as lucrative IP ownership, to focus medical research and discovery activities on profitable TAs that AI adoption does not necessarily address and may even exacerbate (e.g., more data leading to better models that a re leveraged for further research and discovery on lucrative TAs).65 AI investments may face similar incentives to focus on use cases related to exploring “high -confidence targets,” which could 58 https:/pmc.ncbi.nlm.nih.gov/articles/PMC11214120 59 https://pmc.ncbi.nlm.nih.gov/articles/PMC3796018/ 60 https://pmc.ncbi.nlm.nih.gov/articles/PMC5725284/ 61 https://pmc.ncbi.nlm.nih.gov/articles/PMC11292590/ 62 https://allofus.nih.gov/news -events/research -highlights/all -of-us-artificial -intelligence -help-speed -up-search -for-promising -medicines 63 https://ncses.nsf.gov/pubs/nsb20221/u -s-and-global -research -and-development 64 https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2819343 65 https://pmc.ncbi.nlm.nih.gov/articles/PMC3796018/ 24 include a concentration on known, rather than novel, targets.66 With the right interventions to overcome these structural incentives, however, AI could be leveraged toward less researched targets and TAs and achieve breakthrough innovations that meet unmet patient needs , which is a large opportunity as highlighted above in Section 1.3 , opport unity 3 “ expanding the reach of medical research and discovery to meet unmet patient needs and support breakthrough innovations .” 3."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_92",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\novercome these structural incentives, however, AI could be leveraged toward less researched targets and TAs and achieve breakthrough innovations that meet unmet patient needs , which is a large opportunity as highlighted above in Section 1.3 , opport unity 3 “ expanding the reach of medical research and discovery to meet unmet patient needs and support breakthrough innovations .” 3. Medical research and discovery are extend ing beyond traditional laboratories: While investigators use AI to expedite medical research and discovery, other players —such as technology companies —are also entering the research and discovery ecosystem with novel AI innovations . For example, defining the dynamic structure of proteins used to require crystallography, an arduous process through which proteins are crystalized with X -ray diffraction elucidating the position of their atoms, which required access to wet lab space. Recent investments led to the development of an open -source algorithm that can predict the structure of many proteins and how they fold and interact with other proteins and molecu les in the body.67 Some experiments can now be done significantly faster in silico . However, these first-pass results should still be validated through biological methods and/or have humans in the loop to ensure accuracy."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_93",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndevelopment of an open -source algorithm that can predict the structure of many proteins and how they fold and interact with other proteins and molecu les in the body.67 Some experiments can now be done significantly faster in silico . However, these first-pass results should still be validated through biological methods and/or have humans in the loop to ensure accuracy. While technology companies pursue solutions like these, pharmaceutical and medical technology companies are also building AI applications,68 which can be leveraged to transform the quality of tasks across the medical research and discovery value chain and accelerate the time it takes to accomplish them. 4. Data are fragmented, and infrastructure costs are rising: Successful adoption of AI in medical research and discovery requires access to large amounts of high -quality training data, which are critical to the foundation of ML and other models.69 Today, approximately 75% of scholarly documents, which contain data that could be leveraged in medical research and discovery AI models, is behind paywalls70 (which may change as public access policies71 are implemented) ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_94",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI in medical research and discovery requires access to large amounts of high -quality training data, which are critical to the foundation of ML and other models.69 Today, approximately 75% of scholarly documents, which contain data that could be leveraged in medical research and discovery AI models, is behind paywalls70 (which may change as public access policies71 are implemented) . The potentially large quantities of data that could be very useful for medical research and discovery that do not exist in the “scholarly record” are fragmented and difficult to aggregate and curate (e.g., real -world data).72 Furthermore, t he specialized hardware and computing required to utilize AI can be expensive73 and require high energy consumption. Entities with fewer resources to acquire this technology may be priced out, hindering equitable adoption and limiting innovation. These limitations will be compounded without equitable and safe access to data for AI in medical research and discovery. 5. Agentic AI and other autonomous systems are potentially growing : HHS is committed to using AI ethically and safely, including any potential adoption of agentic AI.74 While currently nascent, agentic AI — systems with autonomous problem -solving and collaborative capabilities —is poised to become part of the lab to help augment researchers’ activities across the medical research and discovery value chain."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_95",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI and other autonomous systems are potentially growing : HHS is committed to using AI ethically and safely, including any potential adoption of agentic AI.74 While currently nascent, agentic AI — systems with autonomous problem -solving and collaborative capabilities —is poised to become part of the lab to help augment researchers’ activities across the medical research and discovery value chain. Unlike traditional AI, which follows progra mmed rules, agentic AI can independently or collaboratively analyze, decide, and act. Agentic AI could make medical research and discovery faster and, in turn, make breakthrough innovations available to patients sooner."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_96",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncollaborative capabilities —is poised to become part of the lab to help augment researchers’ activities across the medical research and discovery value chain. Unlike traditional AI, which follows progra mmed rules, agentic AI can independently or collaboratively analyze, decide, and act. Agentic AI could make medical research and discovery faster and, in turn, make breakthrough innovations available to patients sooner. HHS is already taking action to get ahead of this trend; for example, ARPA -H has released a request for information to understand agentic AI and set its corresponding strategic direction for medical research and discovery.75 66 https://pubmed.ncbi.nlm.nih.gov/37479540/ 67 https://pmc.ncbi.nlm.nih.gov/articles/PMC11292590/ 68 https://www.nature.com/articles/d41586 -024-02842 -3 69 https://aspe.hhs.gov/training -data-machine -learning -enhance -patient -centered -outcomes -research -pcor-data-infrastructure 70 https://pmc.ncbi.nlm.nih.gov/articles/PMC6825414/ 71 https://sharing.nih.gov/public -access -policy 72 https://pmc.ncbi.nlm.nih.gov/articles/PMC6587701/ 73 https://cloud.nih.gov/resources/guides/cloud -introduction/why -the-cloud/ 74 https://arpa -h.gov/news -and-events/rfi -agentic -artificial -intelligence -systems 75 https://arpa -h.gov/news -and-events/rfi -agentic -artificial -intelligence -systems 25 1.5 Potential Use Cases and Risks for AI in Medical Research and Discovery The Medical Research and Discovery Value Chain In the U.S., medical research and discovery is a rigorous, multistep process aimed at bolstering knowledge of biology and ensuring the safety and efficacy of drugs, biological products, and medical devices before they reach the market."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_97",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-artificial -intelligence -systems 25 1.5 Potential Use Cases and Risks for AI in Medical Research and Discovery The Medical Research and Discovery Value Chain In the U.S., medical research and discovery is a rigorous, multistep process aimed at bolstering knowledge of biology and ensuring the safety and efficacy of drugs, biological products, and medical devices before they reach the market. While there can be variation, in general, it forms a three -step value chain: (1) basic research, (2) discovery, which has different steps for different types of products, and (3) pre -clinical testing.76 Clinical trials, where relevant, will be discussed in the Medical Product Development, Safety, and Effectiveness chapter and are not in the scope of this chapter. Similarly, research on health systems, care models, and behavioral interventions that are no t medical devices is not in the scope of this chapter and is included in Healthcare Delivery. Also , this value chain of medical research and discovery activities can inform additional areas, such as public health, healthcare delivery, and human services delivery, in an iterative feedback loop. Exhibit 4: Medical Research and Discovery Value Chain 1."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_98",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ninterventions that are no t medical devices is not in the scope of this chapter and is included in Healthcare Delivery. Also , this value chain of medical research and discovery activities can inform additional areas, such as public health, healthcare delivery, and human services delivery, in an iterative feedback loop. Exhibit 4: Medical Research and Discovery Value Chain 1. Basic research involves scientific exploration that can reveal fundamental mechanisms of biology, disease , or behavior77 to advance general knowledge or understanding of biological phenomena and observable facts, which are fundamental to advances in human health and one reason NIH funds basic research.78 The small steps forward at the leading edge of a field can lead to new biomarkers or mechanisms of action for developers to target and give investigators and the public confidence in eventually testing new drugs, biological products, medical devices, technologies, and other tools with human research participants outside this step of the value chain . 2. Discovery is the scientific exploration to diagnose, treat, or cure disease, which can vary by type of medical product as described below:79 a. For drugs80 and biological products81 (e.g., therapeutics, vaccines): i."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_99",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npublic confidence in eventually testing new drugs, biological products, medical devices, technologies, and other tools with human research participants outside this step of the value chain . 2. Discovery is the scientific exploration to diagnose, treat, or cure disease, which can vary by type of medical product as described below:79 a. For drugs80 and biological products81 (e.g., therapeutics, vaccines): i. Target identification and validation are important to the early stages of drug development, which generally relies on the initial identification of a suitable biological target for drug 76 Note that the value chain for drugs and biological products versus medical products differs in the Discovery step, detailed b elow. 77 https://ncats.nih.gov/about/about -translational -science/spectrum#basic -research 78 https://grants.nih.gov/policy -and-compliance/policy -topics/clinical -trials/besh 79 https://toolkit.ncats.nih.gov/module/discovery/ 80 See Appendix A: “Glossary of terms” for the definition of “drug” used in this Plan. 81 See Appendix A: “Glossary of terms” for the definition of “biological product” used in this Plan. 26 candidates.82 This includes finding the biological systems (e.g., neural circuits, endocrine , or immune pathways) that a therapeutic can regulate and ensuring that engagement of that target has a “potential therapeutic benefit. ”83, 84 If a target cannot be validated, it will not proceed in the drug development process. ii."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_100",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe definition of “biological product” used in this Plan. 26 candidates.82 This includes finding the biological systems (e.g., neural circuits, endocrine , or immune pathways) that a therapeutic can regulate and ensuring that engagement of that target has a “potential therapeutic benefit. ”83, 84 If a target cannot be validated, it will not proceed in the drug development process. ii. Hit and lead generation and optimization identify compounds or other treatment types with a desired biological activity that could produce an intended therapeutic response in conjunction with a validated target .85 This is followed by refinement to maintain favorable properties in lead compounds while improving on structural deficiencies . The goal of this step is to identify a compound for pre -clinical testing. b. For medical devices86 (e.g., diagnostics, some behavioral interventions as described below): i. Design and engineering are the process of creating a concept or idea for a new device.87 From here, researchers identify the steps needed to determine whether the concept is workable. The concept can then be built upon and refined through prototypes . Note : Some software -based behavioral interventions are medical devices under FDA’ s statute, whereas others, such as those software functions that are “intended for maintaining or encouraging a healthy lifestyle ” and are “unrelated to the diagnosis, cure, mitigation, prevention, or treatment of a disease or condition,” are not."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_101",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncan then be built upon and refined through prototypes . Note : Some software -based behavioral interventions are medical devices under FDA’ s statute, whereas others, such as those software functions that are “intended for maintaining or encouraging a healthy lifestyle ” and are “unrelated to the diagnosis, cure, mitigation, prevention, or treatment of a disease or condition,” are not. See sections 201(h) and 520(o)(1)(B) of the FD&C Act. Please see the Healthcare Delivery chapter for more information on research into non -device behavioral interventions . 3. Pre-clinical testing refers to in vitro and in vivo studies and is designed to advance potential therapeutics for human clinical research further .88 This is often done to determine any toxic or adverse effects before trials can be carried out in humans and ultimately be made available on the market.89 If a drug or device shows potential benefits, an investigator can submit to the FDA an investigational new drug application (drugs) or an investigational device exemption application (devices) to proceed to clinical trials, which are discussed in more detail in the Medical Product Development, Safety, and Effectiveness chapter.90, 91 AI Risks in Medical Research and Discovery Because medical research and discovery comprise precursor steps to the use of products and care delivery , any bias or other unaccounted -for risks from AI models leveraged in these steps could be propagated downstream, potentially reaching patients."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_102",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nare discussed in more detail in the Medical Product Development, Safety, and Effectiveness chapter.90, 91 AI Risks in Medical Research and Discovery Because medical research and discovery comprise precursor steps to the use of products and care delivery , any bias or other unaccounted -for risks from AI models leveraged in these steps could be propagated downstream, potentially reaching patients. It is , therefore , critical to consider, manage, and ultimately mitigate associated AI risks. Furthermore, it may be difficult to see adoption at scale without developing trustworthiness in the eyes of patients, caregivers, and providers concerning AI in research and technology . Engaging these communities proactively as the technology develops rapidly could be essential to fostering the safe adoption of these technologies. While the potential is large, future success will depend on how key actors work together to balance risk and manage uncertainty. Before detailing additional AI benefits and risks in medical research and discovery later in the chapter , three focus areas for managing risks are highlighted: biosecurity, data security, and AI hijacking. It is important to note that these risks are not yet fully understood and may evolve as technology advances, making it difficult to stratify and prioritize them against other risks."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_103",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndetailing additional AI benefits and risks in medical research and discovery later in the chapter , three focus areas for managing risks are highlighted: biosecurity, data security, and AI hijacking. It is important to note that these risks are not yet fully understood and may evolve as technology advances, making it difficult to stratify and prioritize them against other risks. 82 https://www.fda.gov/media/167973/download 83 https://www.ncbi.nlm.nih.gov/books/NBK195048/ 84 https://www.ncbi.nlm.nih.gov/books/NBK195039/ 85 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3058157/ 86 See Appendix A: “Glossary of terms” for the definition of “medical device” used in this Plan. 87 https://www.fda.gov/patients/device -development -process/step -1-device -discovery -and-concept 88 https://www.fda.gov/media/167973/download 89 https://toolkit.ncats.nih.gov/glossary/preclinical -studies/ 90 https://www.fda.gov/drugs/types -applications/investigational -new-drug-ind-application 91 https://www.fda.gov/medical -devices/premarket -submissions -selecting -and-preparing -correct -submission/investigational -device -exemption -ide 27 1. Biosecurity risks: In May 2024, the Executive Office of the President released the U.S. Government Policy for Oversight of Dual Use Research of Concern and Pathogens with Enhanced Pandemic Potential ,92 which articulates potential applications for the dual use of AI ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_104",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-studies/ 90 https://www.fda.gov/drugs/types -applications/investigational -new-drug-ind-application 91 https://www.fda.gov/medical -devices/premarket -submissions -selecting -and-preparing -correct -submission/investigational -device -exemption -ide 27 1. Biosecurity risks: In May 2024, the Executive Office of the President released the U.S. Government Policy for Oversight of Dual Use Research of Concern and Pathogens with Enhanced Pandemic Potential ,92 which articulates potential applications for the dual use of AI . This includes research conducted for legitimate purposes that generate knowledge, information, technologies, and products that can be utilized to improve care outcomes or research conducted for malicious purposes that could generate potentially harmful bioweapons or harmful pathogens, which present a biosecurity threat to the U.S. and the world. Action has already been taken to help mitigate this threat (see details in section Action Plan), and going forward, HHS and the U.S. government security apparatus can continue to coordinate closely with the research community, private companies (including manufacturers), and the publishing industry to build on the existing guidance from the Executive Office of the President and continue to work to strike the right balance between open science and public security.93 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_105",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nin section Action Plan), and going forward, HHS and the U.S. government security apparatus can continue to coordinate closely with the research community, private companies (including manufacturers), and the publishing industry to build on the existing guidance from the Executive Office of the President and continue to work to strike the right balance between open science and public security.93 2. Data security risks: The October 2024 White House Memorandum on Advancing the United States’s Leadership in Artificial Intelligence94 noted some particular risks in medical research in discovery: AI systems leveraged in the process may reveal aspects of their training data —either inadvertently or through deliberate manipulation by malicious actors —causing data spillage from models that m ay be trained on classified or controlled information when used on networks where such information is not permitted. Going forward, HHS will explore what policy and technical support are needed to ensure the responsible and safe use of these data in AI res earch and development. 3. AI hijacking : Malicious actors can hijack AI models and systems in medical research and discovery contexts by seizing control of agents or solutions to direct them toward harmful actions.95 This might be particularly relevant to AI use cases in basic research that analyzes large biomedical datasets or in the design and manipulation of drugs or devices."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_106",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand development. 3. AI hijacking : Malicious actors can hijack AI models and systems in medical research and discovery contexts by seizing control of agents or solutions to direct them toward harmful actions.95 This might be particularly relevant to AI use cases in basic research that analyzes large biomedical datasets or in the design and manipulation of drugs or devices. AI hijacking can include poisoning training data .96 Because AI hijacking can result in breaches of personal health information, controlled or confidential information, and proprietary or national security information , it is a cross -cutting risk and therefore is not listed across each use case in the following table . 1.5.1 Example Use Cases and Risks of AI across the Medical Research and Discovery Value Chain In the table s below, HHS highlights a non -exhaustive list of potential benefits and risks97 of AI across the medical research and discovery value chain . Please note that the use cases detailed below highlight existing or potential ways that AI can be used by a variety of stakeholders in this domain."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_107",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe Medical Research and Discovery Value Chain In the table s below, HHS highlights a non -exhaustive list of potential benefits and risks97 of AI across the medical research and discovery value chain . Please note that the use cases detailed below highlight existing or potential ways that AI can be used by a variety of stakeholders in this domain. For details on how HHS and its divisions are using AI, please reference the HHS AI Use Case Inventory 2024.98 92 https://aspr.hhs.gov/S3/Documents/USG -Policy -for-Oversight -of-DURC -and-PEPP -May2024 -508.pdf 93 https://aspr.hhs.gov/S3/Pages/OSTP -Framework -for-Nucleic -Acid -Synthesis -Screening.aspx 94 https://www.whitehouse.gov/briefing -room/presidential -actions/2024/10/24/memorandum -on-advancing -the-united -states -leadership -in-artificial -intelligence - harnessing -artificial -intelligence -to-fulfill -national -security -objectives -and-fostering -the-safety -security/ 95 https://ieeexplore.ieee.org/document/9131724 96 https://pmc.ncbi.nlm.nih.gov/articles/PMC10984073/ 97 https://osp.od.nih.gov/policies/artificial -intelligence/ 98 https://www.healthit.gov/hhs -ai-usecases 28 Functional component 1: Basic research Advances general knowledge or understanding of biological phenomena and observable facts Potential use cases (non- exhaustive) Potential risks (non-exhaustive) Advanced generative and analytical models that can accelerate the timeline to breakthrough discoveries and expand inventories of potential hypotheses E.g., analyzing medical texts and other data sources to generate novel biological insights Analysis and synthesis of significant amounts of information from existing scientific research, publications, and other data sources leveraging AI99 E.g., analysis of repositories of large biological datasets to create and refine hypotheses to explore Advanced processing of large datasets to better understand a condition, biological mechanism, or other health topic can increase the likelihood of a breakthrough discovery100 E.g., analysis of potential disease genes, RNA, and proteins involved in disease Foundational models that can analyze large volumes of genetics data and use ML to identify which biomolecules might be involved in disease101 Bias and validity —potential to introduce bias or produce inaccurate results E.g., insights that are not generalizable due to analyzing biased or low -quality data The results of AI -driven basic research may only be as good as the analyzed data ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_108",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nanalyze large volumes of genetics data and use ML to identify which biomolecules might be involved in disease101 Bias and validity —potential to introduce bias or produce inaccurate results E.g., insights that are not generalizable due to analyzing biased or low -quality data The results of AI -driven basic research may only be as good as the analyzed data . If datasets do not sufficiently represent the population, results may not be generalizable. This bias can then be propagated throughout the rest of the medical research and discovery value chain, even making its way into medical products used in clinical trials and more. Additionally, there can b e potential nefarious manipulation of data or model quality through data poisoning, in which an attacker alt ers training data to caus e AI to “behave in an undesirable way, ” which could impact the validity and accuracy of results .102 E.g., hypotheses that do not accurately reflect data or literature Poor data quality, management, and/or oversight from investigators not necessarily well - versed in AI could lead to insight generation that is not reflective of reality ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_109",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ntraining data to caus e AI to “behave in an undesirable way, ” which could impact the validity and accuracy of results .102 E.g., hypotheses that do not accurately reflect data or literature Poor data quality, management, and/or oversight from investigators not necessarily well - versed in AI could lead to insight generation that is not reflective of reality . Privacy, safety, and transparency —potential confidential, sensitive, classified, or personal data breaches or unauthorized disclosures E.g., intentional or unintentional release or re -identification of personal or confidential information AI models can potentially be trained on confidential or other sensitive data that may create risks of leaking information that would otherwise be kept private. As a specific example, if training data contains clinical images and/or medical records that are protected health information [PHI]),103 data breeches can result in PHI being used for training made available to AI users, leading to potential regulatory and policy concerns (e.g., HIPAA ).104 Additionally, as the amount of data collected and analyzed by models increases, even if data is originally de -identified, so does the risk of bad actors (intentionally) or even algorithms (unintentionally) re -identifying knowing or unknowing participants. When integrating multiple datasets or models, data that was otherwise de - identified in each, when combined, may be re -identifiable."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_110",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nHIPAA ).104 Additionally, as the amount of data collected and analyzed by models increases, even if data is originally de -identified, so does the risk of bad actors (intentionally) or even algorithms (unintentionally) re -identifying knowing or unknowing participants. When integrating multiple datasets or models, data that was otherwise de - identified in each, when combined, may be re -identifiable. Furthermore, consent issues can arise when an AI model uses PHI in one analysis, for which authorization was obtained from patients, is accidentally or intentionally used in subsequent AI analyses not authorized by patients. Such a risk may require new consent and authorization frameworks and more transparency in the future. E.g., lack of transparency on how clinical data, which may include personal data, could be used in basic research AI models leveraged in or to inform basic research could use identifiable or de-identified patient data (e.g., to train disease models) . The people whose data could be leveraged may not know how their data is used or disclosed, the corresponding potential impacts of that use and disclosure, and any accompanying risks. Mechanisms for appropriate authorization and transparency regarding data use will become increasingly important with increasing AI adoption in basic research."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_111",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nor de-identified patient data (e.g., to train disease models) . The people whose data could be leveraged may not know how their data is used or disclosed, the corresponding potential impacts of that use and disclosure, and any accompanying risks. Mechanisms for appropriate authorization and transparency regarding data use will become increasingly important with increasing AI adoption in basic research. 99 https://www.fda.gov/media/167973/download 100 https://pmc.ncbi.nlm.nih.gov/articles/PMC9501106/ 101 https://scopeblog.stanford.edu/2022/06/10/using -ai-to-find-disease -causing -genes/ 102 https://pmc.ncbi.nlm.nih.gov/articles/PMC10984073/ 103 See Appendix A: “Glossary of terms” for the definition of “protected health information (PHI)” used in this Plan. 104 https://www.hhs.gov/hipaa/for -professionals/index.html 29 Potential use cases (non- exhaustive) Potential risks (non-exhaustive) E.g., model card inaccuracy as datasets and models are integrated One approach to AI transparency is to leverage model cards that describe model quality (e.g., data trained concerning demographics, time, quantity, and geography).105 As models and/or their associated datasets become integrated, their corresponding model cards may lose their accuracy because linked data and models can increase risks related to privacy, re-identifying information, and more."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_112",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nas datasets and models are integrated One approach to AI transparency is to leverage model cards that describe model quality (e.g., data trained concerning demographics, time, quantity, and geography).105 As models and/or their associated datasets become integrated, their corresponding model cards may lose their accuracy because linked data and models can increase risks related to privacy, re-identifying information, and more. Note that this risk may apply to multiple parts of the value chain but is described here due to the large datasets associated with AI use cases in basic research . Functional component 2: Discovery Scientific exploration to find therapies or develop products that may treat or cure disease, which can vary by type of medical product . See the above discovery description for more details on the type of medical product ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_113",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nbut is described here due to the large datasets associated with AI use cases in basic research . Functional component 2: Discovery Scientific exploration to find therapies or develop products that may treat or cure disease, which can vary by type of medical product . See the above discovery description for more details on the type of medical product . Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Predictive models that can leverage basic research insights to predict and prioritize potential therapeutic targets and leads E.g., analysis of systems biology to predict targets Using advanced analytics on structural and systems biology knowledge and available genomic, transcriptomic, proteomic, and other data sources from healthy persons and those with a specific disease of interest106 to predict novel targets107 E.g., analysis of drug -target interactions to help facilitate discovery through drug repurposing Exploration of drug -target interactions that help provide predictions about classes of drugs potentially interacting with the same targets or having a similar mechanism of action, which may help predict the toxicity of a molecule based on specific known fe atures. This strategy can help guide drug repurposing efforts that could utilize previously characterized compounds. Drug repurposing efforts utilizing AI can also potentially benefit from the increased availability of suitable RWD from various sources (e."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_114",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nwith the same targets or having a similar mechanism of action, which may help predict the toxicity of a molecule based on specific known fe atures. This strategy can help guide drug repurposing efforts that could utilize previously characterized compounds. Drug repurposing efforts utilizing AI can also potentially benefit from the increased availability of suitable RWD from various sources (e. g., electronic health records (EHRs), registries, and DHTs) to identify previously unknown effects of drugs on disease pathways .108 Bias and validity —potential to introduce bias or produce inaccurate results E.g., target identification lead generation based on non - representative datasets and covert AI social bias Models trained on poor -quality or non -representative datasets (e.g., biomarkers and biomolecules sourced from unbalanced racial or gender demographics) can lead to the identification of targets and leads that apply to only some populations, potentially per petuating social bias and exacerbating health inequities and group harms."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_115",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nlead generation based on non - representative datasets and covert AI social bias Models trained on poor -quality or non -representative datasets (e.g., biomarkers and biomolecules sourced from unbalanced racial or gender demographics) can lead to the identification of targets and leads that apply to only some populations, potentially per petuating social bias and exacerbating health inequities and group harms. While models have learned how to improve upon biases built through the data they are trained on, research has shown that covert biases are just as, if not more, present, which can ex acerbate health inequities and be more difficult to track .111 E.g., statistical and computational bias stemming from heterogenous or incorrect data In AI systems, statistical and computational bias can be present in the datasets and algorithmic processes used to develop AI applications . It can arise when algorithms are trained on one data type and cannot extrapolate beyond that data."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_116",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nacerbate health inequities and be more difficult to track .111 E.g., statistical and computational bias stemming from heterogenous or incorrect data In AI systems, statistical and computational bias can be present in the datasets and algorithmic processes used to develop AI applications . It can arise when algorithms are trained on one data type and cannot extrapolate beyond that data. The error may be due to heterogeneous data, representation of complex data in simpler mathematical representations, wrong data, algorithmic biases such as over - and under -fitting, the treatment of outliers, and data cleaning and imputation factors.112 E.g., inaccurate identification of compounds or devices Content generated by some AI (e.g., LLMs) can, by design, be based on information directly or inferred indirectly (often referred to as 105 https://pmc.ncbi.nlm.nih.gov/articles/PMC9284683/ 106 https://www.fda.gov/media/167973/download 107 https://pmc.ncbi.nlm.nih.gov/articles/PMC7591760/ 108 https://www.fda.gov/media/167973/download 111 https://hai.stanford.edu/news/covert -racism -ai-how-language -models -are-reinforcing -outdated -stereotypes 112 https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.1270.pdf 30 Potential use cases (non-exhaustive) Potential risks (non-exhaustive) E.g., recommendation of research targets and leads In silico drug design that enables researchers to predict antibody structures rapidly , assess the structure and function of amino acid mutagenesis, and accelerate de novo protein design (e.g., validating oncology targets via GenAI)109 E.g., design of nucleic acid and amino acid sequences with specific desired functions Leveraging AI platforms to create biomolecules with helpful functionality can increase efficacy and speed of drug development110 “hallucination”), which introduces potential for inaccuracies that are presented as accurate, sometimes even generating further inaccurate information that justifies inaccuracies when probed to explain further."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_117",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nvalidating oncology targets via GenAI)109 E.g., design of nucleic acid and amino acid sequences with specific desired functions Leveraging AI platforms to create biomolecules with helpful functionality can increase efficacy and speed of drug development110 “hallucination”), which introduces potential for inaccuracies that are presented as accurate, sometimes even generating further inaccurate information that justifies inaccuracies when probed to explain further. Using AI that does not aim to reduce this phe nomenon algorithmically (e.g., through retrieval -augmented generative models) could introduce this risk to medical research and discovery pipelines and propagate inaccuracies throughout the value chain if not otherwise appropriately solved for (e.g., with a human in the loop). E.g., unnecessary depletion of resources directed at unfounded targets or leads Hallucinations or other inaccuracies in AI analyses and predictions related to target identification or hit and lead generation and optimization can deplete financial and/or computational resources on targets or leads that are potentially unsuitable for further exploration ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_118",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\notherwise appropriately solved for (e.g., with a human in the loop). E.g., unnecessary depletion of resources directed at unfounded targets or leads Hallucinations or other inaccuracies in AI analyses and predictions related to target identification or hit and lead generation and optimization can deplete financial and/or computational resources on targets or leads that are potentially unsuitable for further exploration . In silico experimentation technologies that can predict behavior, design and manipulate products, and screen drug candidates for effectiveness E.g., protein folding prediction to aid in the design of products Models that can predict the structure of proteins based on large repositories of data using deep learning113 E.g., design and manipulation of biomolecules and medical devices In silico experimentation on the structure of biomolecules (e.g., DNA, RNA, and proteins) for testing candidate drugs and MoAs or on the structure of medical devices to help determine potential applicability before pre -clinical studies114 E.g., drug compound screening Prediction of the chemical properties and bioactivity of compounds and their efficacy and potential adverse events based on the compound’s specificity and affinity for a target115 Biosecurity threats —potential to create harmful products E.g., malicious or unintentional design of novel pathogenic or toxic biological and chemical agents, including nucleic acid sequences, proteins, and peptides Using AI on publicly available research data or leveraging design and folding AI technologies could be conducted for legitimate or malicious purposes and may generate —more easily than through traditional research activities that don’t use AI —novel pathogen ic or toxic agents that are not currently addressed by research oversight frameworks, such as the 2024 U.S."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_119",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsequences, proteins, and peptides Using AI on publicly available research data or leveraging design and folding AI technologies could be conducted for legitimate or malicious purposes and may generate —more easily than through traditional research activities that don’t use AI —novel pathogen ic or toxic agents that are not currently addressed by research oversight frameworks, such as the 2024 U.S. Government Policy for Oversight of Dual Use Research of Concern and Pathogens with Enhanced Pandemic Potential.116 DNA and RNA sequences of these agents may also not be detected by the current best match criteria in the OSTP Framework for Nucleic Acid Synthesis Screening, and others (e.g., proteins, peptides) may be able to defeat natural immune systems or existing medical interventions to treat disease .117 109 https://pubmed.ncbi.nlm.nih.gov/35679624/ 110 https://www.ucsf.edu/news/2023/01/424641/ai -technology -generates -original -proteins -scratch 113 https://directorsblog.nih.gov/2021/07/27/artificial -intelligence -accurately -predicts -protein -folding/ 114 https://www.nature.com/articles/s41392 -023-01381 -z 115 https://www.fda.gov/media/167973/download 116 https://www.whitehouse.gov/wp -content/uploads/2024/05/USG -Policy -for-Oversight -of-DURC -and-PEPP.pdf 117 https://www.whitehouse.gov/wp -content/uploads/2024/04/Nucleic -Acid_Synthesis_Screening_Framework.pdf 31 Functional component 3: Pre -clinical testing Investigations that evaluate a drug, procedure, or medical device in cell and/or animal models to determine any toxic or adverse effects before trials can be conducted in humans ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_120",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n113 https://directorsblog.nih.gov/2021/07/27/artificial -intelligence -accurately -predicts -protein -folding/ 114 https://www.nature.com/articles/s41392 -023-01381 -z 115 https://www.fda.gov/media/167973/download 116 https://www.whitehouse.gov/wp -content/uploads/2024/05/USG -Policy -for-Oversight -of-DURC -and-PEPP.pdf 117 https://www.whitehouse.gov/wp -content/uploads/2024/04/Nucleic -Acid_Synthesis_Screening_Framework.pdf 31 Functional component 3: Pre -clinical testing Investigations that evaluate a drug, procedure, or medical device in cell and/or animal models to determine any toxic or adverse effects before trials can be conducted in humans . Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Predictive models, analytical devices, and representation tools that accelerate timelines to care and bolster understanding of discoveries before going to trial E.g., prediction of drug and device efficacy and safety to determine fit for trials Multimodal data -based (e.g., registries, omics, knowledge graphs, RWD) comparisons of potential efficacy before clinical trials to mitigate risk and potentially save significant trial costs for potential failures118 E.g., medical imaging analysis of in vivo and in vitro testing Automated analysis of research images for identifying structures to help select drugs for clinical trials119 E.g., digital twins to increase diversity and sample size of in vivo and in vitro tests Virtual representations of objects, systems, or animal candidates can accelerate and strengthen pre -clinical research by enabling additional simulated testing120 E.g., life sciences workflow optimizations ML can be used to “predict millions of workflow configurations ” and optimize them to run as efficiently as possible on distributed computing data infrastructure , enabling faster discovery .121 Validity, bias, and effectiveness, including potential false positives and false negatives E.g., unintentionally propagating ineffective ideas or discarding promising solutions Without a human in the loop to assess the validity of millions (or more) of analyses of identified potential drugs, devices, and research subjects, errors in synthesis and prioritization of outcomes can lead to false positives and negatives in recommended results ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_121",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand effectiveness, including potential false positives and false negatives E.g., unintentionally propagating ineffective ideas or discarding promising solutions Without a human in the loop to assess the validity of millions (or more) of analyses of identified potential drugs, devices, and research subjects, errors in synthesis and prioritization of outcomes can lead to false positives and negatives in recommended results . E.g., degradation of model integrity and diverse representation as synthetic data is iterated on Using synthetic data, even with a positive intent to increase diversity, can erode model quality as it is analyzed and re- analyzed to produce additional synthetic data, and so on. This could jeopardize the accuracy and validity of results and ultimately not achieve the potential goals of increasing representation and/or reducing bias . Deskilling researchers and investigators122 E.g., reduction of human -led laboratory processes Automated generation of reliable, safe, and secure laboratory procedures and operations may lower the skill and training requirements for working with high - consequence biological materials, which could lead to the loss of important, highly skilled human ta lent."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_122",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe potential goals of increasing representation and/or reducing bias . Deskilling researchers and investigators122 E.g., reduction of human -led laboratory processes Automated generation of reliable, safe, and secure laboratory procedures and operations may lower the skill and training requirements for working with high - consequence biological materials, which could lead to the loss of important, highly skilled human ta lent. LLMs that can enhance the quality and speed process of regulatory submissions E.g., generative and analytical regulatory package writing Using GenAI to develop application materials based on pre- clinical research outcomes for investigational new drug applications and other pre-clinical trial steps that require extensive writing E.g., digital assistants to automate procedures and analyses Agent assistants that maintain, analyze, and synthesize outputs from scientific records during experimentation (e.g., ambient listening, the AI Scientist)123, 124 Potential lack of explainability of research results E.g., regulatory submission materials that do not correctly represent outcomes of pre-clinical research Traceability to the root data used by a model is not always available in AI technologies, which can reduce the verifiability of the results or intermediate conclusions of its outputs. This potential lack of validity can reduce stakeholders’ trust in result s (e.g., academia, industry, the general public, and regulators) ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_123",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthat do not correctly represent outcomes of pre-clinical research Traceability to the root data used by a model is not always available in AI technologies, which can reduce the verifiability of the results or intermediate conclusions of its outputs. This potential lack of validity can reduce stakeholders’ trust in result s (e.g., academia, industry, the general public, and regulators) . 118 https://pmc.ncbi.nlm.nih.gov/articles/PMC10720846/ 119 https://pmc.ncbi.nlm.nih.gov/articles/PMC7594889/ 120 https://pubmed.ncbi.nlm.nih.gov/37030076/ 121 https://www.anl.gov/article/accelerating -discovery -optimizing -workflows -to-advance -the-use-of-ai-for-science 122 Note that a conceptually similar risk in the context of AI use by clinicians is discussed in the Healthcare Delivery chapter . 123 https://www.nature.com/articles/d41586 -024-02842 -3 124 https://pubmed.ncbi.nlm.nih.gov/35584760/ 32 There are opportunities to develop and employ AI to improve medical research and discovery quality, quantity, and speed . From AI that supports focusing on hypotheses through target identification and optimization at the lab bench to analyzing large datasets, there is strong evidence for optimism. However, this enthusiasm must be balanced by the reality that these applicati ons have risks that deserve careful attention and mitigation strategies. Every stakeholder must monitor and mitigate risks ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_124",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nquantity, and speed . From AI that supports focusing on hypotheses through target identification and optimization at the lab bench to analyzing large datasets, there is strong evidence for optimism. However, this enthusiasm must be balanced by the reality that these applicati ons have risks that deserve careful attention and mitigation strategies. Every stakeholder must monitor and mitigate risks . HHS will use the following action plan to empower entities and individuals across the value chain to increase their adoption of AI safely, responsibly, equitably, and impactfully. 1.6 Action Plan In light of the evolving AI landscape in medical research and discovery, HHS has taken multiple steps to promote responsible AI use by providing resourcing to intramural and extramural research, advancing accessibility of streamlined datasets , develop ing workforce talent and capabilities , and many other actions to date . The Action Plan below follows the four goals that support HHS’s AI strategy : 1. catalyzing health AI innovation and adoption; 2. promoting trustworthy AI development and ethical and responsible use; 3. democratizing AI technologies and resources; and 4. cultivating AI -empowered workforces and organization cultures. For each goal, the Action Plan provides context, an overview of HHS and relevant other federal actions to date, and specific near - and long -term priorities HHS will take."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_125",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nhealth AI innovation and adoption; 2. promoting trustworthy AI development and ethical and responsible use; 3. democratizing AI technologies and resources; and 4. cultivating AI -empowered workforces and organization cultures. For each goal, the Action Plan provides context, an overview of HHS and relevant other federal actions to date, and specific near - and long -term priorities HHS will take. HHS recognizes that this Action Plan will require revisions over time as technologies evolve and is comm itted to providing structure and flexibility to ensure longstanding impact. 1.6.1 Catalyze Health AI Innovation and Adoption Increasing AI adoption in medical research and discovery can transform the quality and speed of innovation that ultimately improves patient outcomes. HHS has an opportunity to increase AI adoption by pursuing the following themes of actions : 1. Expanding the breadth of medical research and discovery AI use across disease areas and steps of the value chain 2. Enhancing coordination across geographies to harness AI to improve medical research and discovery 3. Fostering AI -ready data standards and datasets to bolster their usability for AI -empowered medical research and discovery Below, HHS discusses the context of each theme of action in more detail, corresponding actions to date, and plans to promote AI innovation and adoption in medical research and discovery. 1."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_126",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ngeographies to harness AI to improve medical research and discovery 3. Fostering AI -ready data standards and datasets to bolster their usability for AI -empowered medical research and discovery Below, HHS discusses the context of each theme of action in more detail, corresponding actions to date, and plans to promote AI innovation and adoption in medical research and discovery. 1. Expanding the breadth of medical research and discovery AI use across disease areas and steps of the value chain: Context: AI’s relatively higher uptake in discovery (e.g., in silico target identification, high -throughput screening of potential candidates) than in other parts of the value chain , coupled with the potential incentives AI faces to focus on disease areas with higher market potential , indicates an opportunity to catalyze further AI adoption by focusing on AI use cases across other parts of the value chain (e.g., basic research , preclinical studies ) and in the exploration of more disease areas (e.g., less researched, those with high unmet needs ). HHS is focused on expanding applications of AI in medical research and discovery while maintaining integrity in its resourcing programs , which can include resourcing, training, or additional policies or guidelines . HHS will 33 look to advance AI adoption that could help meet unmet patient needs and foster innovation across the full value chain more broadly."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_127",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nunmet needs ). HHS is focused on expanding applications of AI in medical research and discovery while maintaining integrity in its resourcing programs , which can include resourcing, training, or additional policies or guidelines . HHS will 33 look to advance AI adoption that could help meet unmet patient needs and foster innovation across the full value chain more broadly. HHS actions to date (non -exhaustive): • National Cancer Institute’s (NCI)125 Informatics Technology for Cancer Research funds research - driven informatics technology across the development life cycle to address priority needs in cancer research.126 These projects are increasingly developing or incorporating advanced AI methods. The program supports the development of critical tools and resources to improve the acquisition, analysis, visualization, and interpretation of data across the cancer research continuum, including cancer bi ology, cancer treatment and diagnosis, early cancer detection, risk assessment and prevention, cancer control and epidemiology, and cancer health equity."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_128",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncancer research.126 These projects are increasingly developing or incorporating advanced AI methods. The program supports the development of critical tools and resources to improve the acquisition, analysis, visualization, and interpretation of data across the cancer research continuum, including cancer bi ology, cancer treatment and diagnosis, early cancer detection, risk assessment and prevention, cancer control and epidemiology, and cancer health equity. • National Institute of Mental Health’s (NIMH’s) Theoretical and Computational Neuroscience Program supports basic experimental and theoretical research focusing on biophysically realistic computational approaches modeling dynamical processes in the brain, from single cell activity to neural systems regulating complex behaviors.127 • NIMH’s Translational Digital and Computational Psychiatry Program fosters innovative computational approaches to identify and validate novel mechanisms, biomarkers, and treatment targets for preventing and treating psychiatric disorders."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_129",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand Computational Neuroscience Program supports basic experimental and theoretical research focusing on biophysically realistic computational approaches modeling dynamical processes in the brain, from single cell activity to neural systems regulating complex behaviors.127 • NIMH’s Translational Digital and Computational Psychiatry Program fosters innovative computational approaches to identify and validate novel mechanisms, biomarkers, and treatment targets for preventing and treating psychiatric disorders. The program supports research projects that use advanced computational methods with behavioral, biological, and/or clinical data to decipher complex mechanisms involved in mental disorders and to conduct initial tests of novel tools to predict risk, clinical trajectories, a nd treatment response.128 • The ARPA -H TARGET program will expand the pool of candidate molecules with antibiotic potential using deep learning to filter for candidate biomolecules and GenAI to broaden the scope of possible pharmaceuticals.129 • ARPA -H’s Computational ADME -Tox and Physiology Analysis for Safer Therapeutics (CATALYST) program envisions a future where approval to begin first -in-human clinical trials can be based on in silico safety data.130 The program focuses on developing animal -free, sound experimental practice methods with specific attention to pharmacokinetics, including absorption, distribution, metabolism, and excretion (ADME), and pharmacodynamics for safety and toxicity."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_130",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-H’s Computational ADME -Tox and Physiology Analysis for Safer Therapeutics (CATALYST) program envisions a future where approval to begin first -in-human clinical trials can be based on in silico safety data.130 The program focuses on developing animal -free, sound experimental practice methods with specific attention to pharmacokinetics, including absorption, distribution, metabolism, and excretion (ADME), and pharmacodynamics for safety and toxicity. CATALYST wil l pursue novel technologies that reliably represent human physiology to reduce the failure rate of investigational new drug candidates. Such technologies will ensure that medicines reaching clinical trials have confident safety profiles and better protect diverse trial participants and future patients. • NIH’s Brain Research Through Advancing Innovative Neurotechnologies ® (BRAIN) Initiative: Theories, Models , and Methods for Analysis of Complex Data from the Brain develop s theories, computational models, and analytical tools to derive the understanding of brain function from complex neuroscience data. Proposed projects could develop tools to integrate existing theories or formulate new theories; conceptual frameworks to organize or fuse data to infer general principles of brain function; multiscale/multiphy sics models to generate new testable hypotheses to design/drive future experiments; new analytical methods to substantiate falsifiable hypotheses about brain function."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_131",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto derive the understanding of brain function from complex neuroscience data. Proposed projects could develop tools to integrate existing theories or formulate new theories; conceptual frameworks to organize or fuse data to infer general principles of brain function; multiscale/multiphy sics models to generate new testable hypotheses to design/drive future experiments; new analytical methods to substantiate falsifiable hypotheses about brain function. The tools developed were expected to be widely available for use and modification in the neuroscience research community .131 125 Note that NCI is a subsidiary of NIH ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_132",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nfuse data to infer general principles of brain function; multiscale/multiphy sics models to generate new testable hypotheses to design/drive future experiments; new analytical methods to substantiate falsifiable hypotheses about brain function. The tools developed were expected to be widely available for use and modification in the neuroscience research community .131 125 Note that NCI is a subsidiary of NIH . 126 https://www.cancer.gov/about -nci/organization/cssi/research/itcr 127 https://www.nimh.nih.gov/about/organization/dnbbs/behavioral -science -and-integrative -neuroscience -research -branch/theoretical -and-computational -neuroscience - program 128 https://www.nimh.nih.gov/about/organization/dtr/adult -psychopathology -and-psychosocial -interventions -research -branch/translational -digital -and-computational - psychiatry -program 129 https://arpa -h.gov/news -and-events/arpa -h-project -accelerate -discovery -and-development -new-antibiotics -using 130 https://arpa -h.gov/research -and-funding/programs/catalyst 131 https://grants.nih.gov/grants/guide/rfa -files/RFA -DA-23-039.html 34 HHS near -term priorities: • Explore resourcing for medical research and discovery leveraging AI to address TAs with unmet needs and/or identify and analyze novel rather than known targets."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_133",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n128 https://www.nimh.nih.gov/about/organization/dtr/adult -psychopathology -and-psychosocial -interventions -research -branch/translational -digital -and-computational - psychiatry -program 129 https://arpa -h.gov/news -and-events/arpa -h-project -accelerate -discovery -and-development -new-antibiotics -using 130 https://arpa -h.gov/research -and-funding/programs/catalyst 131 https://grants.nih.gov/grants/guide/rfa -files/RFA -DA-23-039.html 34 HHS near -term priorities: • Explore resourcing for medical research and discovery leveraging AI to address TAs with unmet needs and/or identify and analyze novel rather than known targets. • Explore resourcing research, training, and workshops focusing on basic and pre-clinical research areas with lower AI adoption, such as late -stage investigations closer to the regulatory approval process. • Continue to hold webinars, workshops, listening sessions, and more to socialize notices of funding opportunities (NOFOs) and requests for information.132 • Identify barriers to the adoption of AI across the value chain. o Convene stakeholders to delineate technical, economic, workforce, data availability, and regulatory hurdles to adopting AI across the medical research and discovery value chain. o Convene patients and other stakeholders to address transparency and build trust (see “enabling risk management and transparency of AI” under “ Promote Trustworthy AI Development and Ethical and Responsible Use ”)."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_134",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nacross the value chain. o Convene stakeholders to delineate technical, economic, workforce, data availability, and regulatory hurdles to adopting AI across the medical research and discovery value chain. o Convene patients and other stakeholders to address transparency and build trust (see “enabling risk management and transparency of AI” under “ Promote Trustworthy AI Development and Ethical and Responsible Use ”). • Explore potential mechanisms to reduce barriers to adoption (e.g., environmental considerations and costs associated with adoption). • Prioritize and explore resourcing for evidence -building to evaluate responsible AI medical research and discovery investments and maximize the efficacy of HHS spending. • Provide policy clarity and/or guidelines on acceptable uses of AI in federally funded pre-clinical research (e.g., uses of AI to replace animal -based studies). • Provide policy clarity and/or guidelines on the uses of AI toward drafting research grant applications and submissions to ensure fairness and transparency and to protect program integrity. • Adopt AI within HHS to streamline grant review, approval, and support process, subject to robust safeguards to protect program integrity, equity, and fairness. HHS long -term priorities: • Explore experimentation opportunities regarding economic frameworks for exchanging data and AI models that can make pricing affordable while allowing for fair compensation and safety of AI use. 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_135",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nprotect program integrity. • Adopt AI within HHS to streamline grant review, approval, and support process, subject to robust safeguards to protect program integrity, equity, and fairness. HHS long -term priorities: • Explore experimentation opportunities regarding economic frameworks for exchanging data and AI models that can make pricing affordable while allowing for fair compensation and safety of AI use. 2. Enhancing coordination across geographies to harness AI to improve medical research and discovery: Context: Multiple bodies internationally and in the U.S. have varying regulations that could impact the medical research and discovery space (e.g., General Data Protection Regulation, European Union AI Act, and HIPAA).133 Coordination between these bodies on their approach to AI in the context of medical research and discovery could reduce barriers to innovation while still maintaining the safety and efficacy of corresponding use cases. Without proactive coordination, achi eving realizable improvements in these areas will be diffuse and suboptimal given the complexity of the value chain and underlying economics and the considerable number of public and private sector stakeholders involved. HHS can bolster future innovation by engaging stakeholders —domestically and abroad —to promote further alignment across the value chain. 132 All materials must be digitally accessible and webinars and listening sessions must, at a minimum, have ASL interpreters."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_136",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsuboptimal given the complexity of the value chain and underlying economics and the considerable number of public and private sector stakeholders involved. HHS can bolster future innovation by engaging stakeholders —domestically and abroad —to promote further alignment across the value chain. 132 All materials must be digitally accessible and webinars and listening sessions must, at a minimum, have ASL interpreters. If recorded, the recording needs closed captions and audio descriptions. Furthermore, the NOFO and RFIs must include digital access ibility language to ensure all materials provided are conformant. 133 https://www.brookings.edu/articles/the -eu-and-us-diverge -on-ai-regulation -a-transatlantic -comparison -and-steps -to-alignment/ 35 HHS actions to date (non -exhaustive): • The NIH Common Fund’s Harnessing Data Science for Health Discovery and Innovation in Africa (DS-I Africa) program134 leverage s data science technologies and prior NIH investments to develop solutions to the continent’s most pressing public health problems through a robust ecosystem of new partners from academic, government, and private sectors. HHS near -term priorities: • Prioritize and explore resources for the most promising collaborative, multidisciplinary, and cross -border proposals for AI integration in basic and pre-clinical research."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_137",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nleverage s data science technologies and prior NIH investments to develop solutions to the continent’s most pressing public health problems through a robust ecosystem of new partners from academic, government, and private sectors. HHS near -term priorities: • Prioritize and explore resources for the most promising collaborative, multidisciplinary, and cross -border proposals for AI integration in basic and pre-clinical research. • Facilitate coordination across HHS divisions to share appropriate data, methodology, technologies, and resources related to medical research and discovery to enable stronger HHS innovation activities. HHS long -term priorities: • Define and establish policies and guidelines for cross -border AI in medical research and discovery collaboration that comply with U.S. standards. • Provide guidelines to other agencies and STLTs related to AI and data -sharing standards, as appropriate and authorized within HHS domains ,135 to enhance the possibility of stronger international collaboration in medical research and discovery. 3."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_138",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npriorities: • Define and establish policies and guidelines for cross -border AI in medical research and discovery collaboration that comply with U.S. standards. • Provide guidelines to other agencies and STLTs related to AI and data -sharing standards, as appropriate and authorized within HHS domains ,135 to enhance the possibility of stronger international collaboration in medical research and discovery. 3. Fostering AI -ready data standards and datasets to bolster their usability for AI -empowered medical research and discovery :136 (See Goal 3: “Democratize AI Technologies and Resources” theme of action 2: “Increasing accessibility to responsibly curated AI -ready data tooling and infrastructure for those who are less able to access them today ” for more information on data infrastructure and tooling) Context: Variability in the quality, volume, and representativeness of data used for training AI could lead to its underperformance due to bias and shortcut learning.137 While the healthcare delivery system generates a tremendous amount of clinical and administrative data, fragmentation of the industry poses considerable challenges to the aggregation of high -quality data for AI model development to support pre-clinical medical research and discovery. Additionally, models trained on clinical data that contain personal information are difficult to share broadly."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_139",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndue to bias and shortcut learning.137 While the healthcare delivery system generates a tremendous amount of clinical and administrative data, fragmentation of the industry poses considerable challenges to the aggregation of high -quality data for AI model development to support pre-clinical medical research and discovery. Additionally, models trained on clinical data that contain personal information are difficult to share broadly. Furthermore, proprietary or confidential molecular, chemical, and other non -clinical data could be fragmented a cross industry and academia. As a result, vast amounts of data that could be used for research cannot be easily tapped. By focusing on making this data AI -ready for medical research and discovery, HHS can empower further AI adoption in the spac e. HHS actions to date (non -exhaustive): • NIH’s Bridge2AI program funds studies to generate flagship datasets and best practices for the collection and preparation of AI -ready data to address biomedical and behavioral research challenges (e.g., generating new flagship biomedical and behavioral datasets that are ethically sour ced, trustworthy, well-defined, and accessible, developing software and standards to unify data attributes across multiple 134 https://commonfund.nih.gov/AfricaData 135 https://www.whitehouse.gov/wp -content/uploads/2017/11/Circular -119-1.pdf , https://www.govinfo.gov/app/details/PLAW -104publ113 ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_140",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto generate flagship datasets and best practices for the collection and preparation of AI -ready data to address biomedical and behavioral research challenges (e.g., generating new flagship biomedical and behavioral datasets that are ethically sour ced, trustworthy, well-defined, and accessible, developing software and standards to unify data attributes across multiple 134 https://commonfund.nih.gov/AfricaData 135 https://www.whitehouse.gov/wp -content/uploads/2017/11/Circular -119-1.pdf , https://www.govinfo.gov/app/details/PLAW -104publ113 . Under OMB Circular A - 119 and the National Technology Transfer and Advancement Act of 1995 (Public Law 104 -113), NIST has primary authority to coordinate standards, with reservations for other Federal functions with specific authority for domain -specific standards. That said, HHS agencies do have domain -specific standards. 136 This aligns with the 2024 -2030 Federal Health IT Strategic Plan Goal 2: Enhance the Delivery and Experience of Care, Objective D: Providers experience reduced regulatory and administrative burden, Strategy: Promote the safe, secure, and responsible use of AI tools and standards so th at healthcare providers and patients can expect trustworthy, relevant, and representative results from AI tools that provide better , more streamlined care delivery."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_141",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nHealth IT Strategic Plan Goal 2: Enhance the Delivery and Experience of Care, Objective D: Providers experience reduced regulatory and administrative burden, Strategy: Promote the safe, secure, and responsible use of AI tools and standards so th at healthcare providers and patients can expect trustworthy, relevant, and representative results from AI tools that provide better , more streamlined care delivery. 137 https://www.nature.com/articles/s41746 -024-01118 -4 “Shortcut learning refers to a phenomenon in which an AI model learns to solve a task based on spurious correlations present in the data as opposed to features directly related to the task itself.” 36 data sources and data types, creating automated tools to accelerate the creation of FAIR [Findable, Accessible, Interoperable, and Reusable] and ethically sourced datasets, providing resources to disseminate data, ethical principles, tools, and best practi ces, creating training materials and activities for workforce development that bridges the AI, biomedical, and behavioral research communities).138 • NIH developed ScHARe, a cloud -based data platform comprising federated social determinants of health (SDOH) datasets to accelerate research in health disparities, healthcare delivery, health outcomes, and AI bias mitigation strategies.139 • NIH, as a part of the National AI Research Resource (NAIRR) Pilot140 with NSF, National Center for Science and Engineering Statistics (NCSES), and the Department of Energy (DOE), leverag es large RWD sets to (1) build a synthetic data generator toolkit and framework to assess privacy risk and utility for using such data for evidence -building , and (2) link ed medical imaging data with clinical records that will build capacity for multimodal AI development."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_142",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nCenter for Science and Engineering Statistics (NCSES), and the Department of Energy (DOE), leverag es large RWD sets to (1) build a synthetic data generator toolkit and framework to assess privacy risk and utility for using such data for evidence -building , and (2) link ed medical imaging data with clinical records that will build capacity for multimodal AI development. • NIH’s BRAIN Initiative: Data Archives advance s research by creating a data archive with appropriate standards and summary information that is broadly available and accessible to the research community for further research. Teams work with the research community to incorporate software tools that allow users to analyze and visualize data and use appropriate standards to describe the data.141 • NIH’s BRAIN Initiative: Integration and Analysis of BRAIN Initiative Data developed informatics tools for analyzing, visualizing, and integrating data related to the BRAIN Initiative or to enhance our understanding of the brain. The tools were user -friendly in accessing and analyzing data from appropriate data archives and could analyze/visualize data without requiring users to download data.142 HHS near -term priorities: • Define and prioritize standards that maximize the findability , accessibility, interoperability, and reusability of research data (including common data elements, metadata, persistent identifiers, and security) with U.S."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_143",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nunderstanding of the brain. The tools were user -friendly in accessing and analyzing data from appropriate data archives and could analyze/visualize data without requiring users to download data.142 HHS near -term priorities: • Define and prioritize standards that maximize the findability , accessibility, interoperability, and reusability of research data (including common data elements, metadata, persistent identifiers, and security) with U.S. government partners (e.g., NIST due to their 2024 Research Data Framework [RDaF ],143 United States Core Data for Interoperability [USCDI]) to streamline training and refinement of algorithms with biomedical research data. • Accelerate alignment of federally funded research data standards (semantic, format, transport) with HHS -adopted standards for EHRs, healthcare providers, and payers (e.g., USCDI,144 USCDI+,145 HL7 Fast Healthcare Interoperability Resources [FHIR],146 CARIN147). • Develop open -source, open -standard tooling and infrastructure for AI data management, cross -standard data mapping, de -identification, etc. , to develop AI-ready datasets and tooling. • Accelerate work with standards development organizations and industry collaborations on standards to support AI development and use across the life cycle ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_144",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n(e.g., USCDI,144 USCDI+,145 HL7 Fast Healthcare Interoperability Resources [FHIR],146 CARIN147). • Develop open -source, open -standard tooling and infrastructure for AI data management, cross -standard data mapping, de -identification, etc. , to develop AI-ready datasets and tooling. • Accelerate work with standards development organizations and industry collaborations on standards to support AI development and use across the life cycle . • Convene a public -private community of practice for sharing best practices regarding data appropriate for AI model use in medical research and discovery , where stakeholders can also collaborate to identify enablers/barriers to access such data. • Explore potential safe ways to leverage and share AI models trained on clinical or other personal information without risking privacy, consent, or transparency. • Accelerate federated ML research, tooling, and implementation support; facilitate a public -private process to define open -industry standards and conventions for federated ML ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_145",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nstakeholders can also collaborate to identify enablers/barriers to access such data. • Explore potential safe ways to leverage and share AI models trained on clinical or other personal information without risking privacy, consent, or transparency. • Accelerate federated ML research, tooling, and implementation support; facilitate a public -private process to define open -industry standards and conventions for federated ML . 138 https://commonfund.nih.gov/bridge2ai 139 https://www.nimhd.nih.gov/resources/schare/ 140 https://nairrpilot.org/ 141 https://grants.nih.gov/grants/guide/rfa -files/RFA -MH-25-110.html 142 https://grants.nih.gov/grants/guide/rfa -files/RFA -MH-23-270.html 143 https://www.nist.gov/publications/nist -research -data-framework -rdaf-version -20 144 https://www.healthit.gov/isp/united -states -core-data-interoperability -uscdi 145 https://www.healthit.gov/topic/interoperability/uscdi -plus 146 https://www.healthit.gov/sites/default/files/page/2021 -04/What%20Is%20FHIR%20Fact%20Sheet.pdf 147 https://www.carinalliance.com/ 37 • Accelerate the development of a research exchange purpose in the Trusted Exchange Framework and Common AgreementTM (TEFCATM)148 to support high -scale, network -facilitated data exchange for research. HHS long -term priorities: • Establish the governance, legal, and analytical frameworks as a public resource for AI-ready medical research and discovery datasets ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_146",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nhttps://www.healthit.gov/topic/interoperability/uscdi -plus 146 https://www.healthit.gov/sites/default/files/page/2021 -04/What%20Is%20FHIR%20Fact%20Sheet.pdf 147 https://www.carinalliance.com/ 37 • Accelerate the development of a research exchange purpose in the Trusted Exchange Framework and Common AgreementTM (TEFCATM)148 to support high -scale, network -facilitated data exchange for research. HHS long -term priorities: • Establish the governance, legal, and analytical frameworks as a public resource for AI-ready medical research and discovery datasets . 1.6.2 Promote Trustworthy AI Development and Ethical and Responsible Use As AI adoption in medical research and discovery continues to advance rapidly , its associated risks may require close attention from HHS to ensure uptake is safe, responsible, and impactful for patients around the world. Key themes of action that HHS could address to ensure the trustworthy and safe use of AI in medical research and discovery include: 1. Building and disseminating evidence to mitigate biosecurity, data security, privacy, and data collection risks 2. Setting clear guidelines for safe and trustworthy AI use in medical research and discovery and the distribution and use of federal resources 3."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_147",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nof action that HHS could address to ensure the trustworthy and safe use of AI in medical research and discovery include: 1. Building and disseminating evidence to mitigate biosecurity, data security, privacy, and data collection risks 2. Setting clear guidelines for safe and trustworthy AI use in medical research and discovery and the distribution and use of federal resources 3. Enabling safe and responsible organizational governance of AI risk management and transparency Below, HHS discusses the context of each theme of action in more detail, corresponding actions to date, and plans to ensure the trustworthy and safe use of AI in medical research and discovery. 1. Building and disseminating evidence to mitigate biosecurity, data security, privacy, and data collection risks Context: As discussed in Section 1.5.1, AI in medical research and discovery could be used nefariously to create biosecurity and biosafety threats (e.g., potential novel pathogens). Additionally, confidential, sensitive, or classified information could be leaked —intentionally or unintentionally —through AI model training and deployment, and collecting sensitive patient data could require de -identification or authorization from patients, both of which can present challenges to gathering statistically powerful quantiti es of information for medical research and discovery."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_148",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto create biosecurity and biosafety threats (e.g., potential novel pathogens). Additionally, confidential, sensitive, or classified information could be leaked —intentionally or unintentionally —through AI model training and deployment, and collecting sensitive patient data could require de -identification or authorization from patients, both of which can present challenges to gathering statistically powerful quantiti es of information for medical research and discovery. The HIPAA Privacy Rule has specific provisions related to the use and disclosure of patient information for research149 (Note that the HIPAA Privacy Rule has provisions related to use and disclosures of PHI for a variety of circumstances which are further outlined in the Healthcare Delivery chapter), and AI models present unique considerations regarding adherence with priv acy protections. Potential patient concerns include lack of consent for the use of their de -identified data and transparency into how their consented personal data are used. AI makes it easier to re -identify information leveraging various datasets, including publicly available external data, which may require the adjustment of data -sharing policies and practices, especially with entities not subject to HIPAA. HHS and the federal government have taken action to approach this, and going forward, HHS will pursue further actions to continue protecting sensitive information regarding AI use in medical research and discovery."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_149",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-identify information leveraging various datasets, including publicly available external data, which may require the adjustment of data -sharing policies and practices, especially with entities not subject to HIPAA. HHS and the federal government have taken action to approach this, and going forward, HHS will pursue further actions to continue protecting sensitive information regarding AI use in medical research and discovery. 148 https://www.healthit.gov/topic/interoperability/policy/trusted -exchange -framework -and-common -agreement -tefca 149 https://www.hhs.gov/hipaa/for -professionals/special -topics/research/index.html 38 HHS actions to date (non -exhaustive): • NIH’s Data Management and Sharing Policy promotes the sharing of scientific data to help accelerate biomedical research discovery, in part, by enabling validation of research results, providing accessibility to high -value datasets, and promoting data reuse for future research studies . It also emphasizes the importance of good data management practices and establishes the expectation for maximizing the appropriate sharing of scientific data generated from NIH -funded or conducted research, with justified limitations or exceptions."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_150",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nbiomedical research discovery, in part, by enabling validation of research results, providing accessibility to high -value datasets, and promoting data reuse for future research studies . It also emphasizes the importance of good data management practices and establishes the expectation for maximizing the appropriate sharing of scientific data generated from NIH -funded or conducted research, with justified limitations or exceptions. 150 o NIH ’s Data Management and Sharing Policy Supplemental Information on Protecting Participant Privacy When Sharing Human Scientific Data outlines principles, best practices, and points to consider for researchers to protect the privacy of research participants when sharing participant data. The framework does not establish binding rules but rather provides a framework for sharing both iden tifiable and de -identified data as well as data obtained with consent and data where consent was not required.151 • Implementation of the Executive Office of the President’s National Biodefense Strategy,152 which explains how the U .S. Government will manage its activities more effectively to assess, prevent, protect against, respond to, and recover from biological threats, which could implicitly incorporate threats from AI use."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_151",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndata as well as data obtained with consent and data where consent was not required.151 • Implementation of the Executive Office of the President’s National Biodefense Strategy,152 which explains how the U .S. Government will manage its activities more effectively to assess, prevent, protect against, respond to, and recover from biological threats, which could implicitly incorporate threats from AI use. • HHS’s Screening Framework Guidance for Providers and Users of Synthetic Nucleic Acids describes its screening framework guidance, which sets forth baseline standards for the gene and genome synthesis industry, as well as best practices for all entities involved in the provision, use, and transfer of synthetic nucleic acids regarding screen ing orders and recipients and maintaining records.153 In addition, this guidance seeks to encourage best practices to address biosecurity concerns associated with the potential misuse of synthetic nucleic acids in order to bypass existing regulatory controls and commit unlawful acts. • Implementation of the Executive Office of the President’s Framework for Nucleic Acid Synthesis Screening,154 which is consistent with and responsive to the guidance in the HHS Screening Framework and fulfills provisions in the 2023 E xecutive Order on Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence that requires all researchers receiving U .S."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_152",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand commit unlawful acts. • Implementation of the Executive Office of the President’s Framework for Nucleic Acid Synthesis Screening,154 which is consistent with and responsive to the guidance in the HHS Screening Framework and fulfills provisions in the 2023 E xecutive Order on Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence that requires all researchers receiving U .S. government life sciences research funding to procure synthetic genetic materials only from companies that comply with sequence screening best practices (88 FR 7519).155 • HHS’s HIPAA Privacy Rule establishes the conditions under which PHI may be used or disclosed by covered entities for research purposes (45 CFR part 160 and subparts A and E of part 164 ).156 Under this Privacy Rule, covered entities are permitted to use and disclose PHI for research with individual authorization or without individual authorization under limited circumstances set forth in the Privacy Rule. While the Privacy Rule may not explici tly discuss AI, its safeguards apply whether AI is leveraged in medical research and discovery or not."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_153",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nE of part 164 ).156 Under this Privacy Rule, covered entities are permitted to use and disclose PHI for research with individual authorization or without individual authorization under limited circumstances set forth in the Privacy Rule. While the Privacy Rule may not explici tly discuss AI, its safeguards apply whether AI is leveraged in medical research and discovery or not. • The Belmont Report , written by the National Commission for the Protection of Human Subjects of Biomedical and Behavioral Research, is a statement of basic ethical principles and guidelines that should assist in resolving the ethical problems that surround the conduct of research with human subjects, which can apply regardless of the technologies being used in research and discovery, i ncluding but not limited to AI in medical research and discovery analyzing clinical data.157 150 https://grants.nih.gov/grants/guide/notice -files/NOT -OD-21-013.html 151 https://sharing.nih.gov/data -management -and-sharing -policy/protecting -participant -privacy -when -sharing -scientific -data 152 https://aspr.hhs.gov/biodefense/Pages/default.aspx 153 https://aspr.hhs.gov/legal/synna/Documents/SynNA -Guidance -2023.pdf 154 https://aspr.hhs.gov/S3/Documents/OSTP -Nucleic -Acid -Synthesis -Screening -Framework -Sep2024.pdf 155 https://www.federalregister.gov/documents/2023/11/01/2023 -24283/safe -secure -and-trustworthy -development -and-use-of-artificial -intelligence 156 https://www.hhs.gov/hipaa/for -professionals/special -topics/research/index.html 157 https://www.hhs.gov/ohrp/regulations -and-policy/belmont -report/read -the-belmont -report/index.html 39 HHS near -term priorities: • Iteratively monitor and evaluate potential nefarious uses to continuously refine guidelines and policies related to biosecurity and data breeches ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_154",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-scientific -data 152 https://aspr.hhs.gov/biodefense/Pages/default.aspx 153 https://aspr.hhs.gov/legal/synna/Documents/SynNA -Guidance -2023.pdf 154 https://aspr.hhs.gov/S3/Documents/OSTP -Nucleic -Acid -Synthesis -Screening -Framework -Sep2024.pdf 155 https://www.federalregister.gov/documents/2023/11/01/2023 -24283/safe -secure -and-trustworthy -development -and-use-of-artificial -intelligence 156 https://www.hhs.gov/hipaa/for -professionals/special -topics/research/index.html 157 https://www.hhs.gov/ohrp/regulations -and-policy/belmont -report/read -the-belmont -report/index.html 39 HHS near -term priorities: • Iteratively monitor and evaluate potential nefarious uses to continuously refine guidelines and policies related to biosecurity and data breeches . • Consider vetting predictive methodologies for use in amino and nucleic acid sequence screening per the Screening Framework Guidance .158 • Facilitate the public -private process to define open industry standards to accelerate the availability of privacy -enhancing technologies for data de -identification (e.g., privacy -preserving record linkage (PPRL), differential privacy). • Evaluate potential technical solutions that would allow developers and investigators to create and use models in a sandbox159 environment that would prevent data spillage to enable the safe testing and progression of AI use in medical research and discovery."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_155",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto accelerate the availability of privacy -enhancing technologies for data de -identification (e.g., privacy -preserving record linkage (PPRL), differential privacy). • Evaluate potential technical solutions that would allow developers and investigators to create and use models in a sandbox159 environment that would prevent data spillage to enable the safe testing and progression of AI use in medical research and discovery. • Explore the opportunities and risks of leveraging AI in data collection, including the quality of the data (e.g., EHRs potentially showcasing high -quality versus low -quality outcomes in some clinical settings versus others). • Explore potential data use authorization pathways that enable the use of patient data in iterative and potentially multi -use AI models while maintaining protections consistent with HHS values, regulations, and policies. • Explore resourcing for the evaluation of homomorphic encryption and data security, which enable the federation of data without allowing visibility into data linkages, for the safe use of AI in medical research and discovery settings. • Explore approaches to protect AI models used in medical research and discovery and sensitive health data from adversarial attacks. • Explore the development of mechanisms to prevent and reduce harm from the misuse of predictive analytics tools used in medical research and discovery."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_156",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nvisibility into data linkages, for the safe use of AI in medical research and discovery settings. • Explore approaches to protect AI models used in medical research and discovery and sensitive health data from adversarial attacks. • Explore the development of mechanisms to prevent and reduce harm from the misuse of predictive analytics tools used in medical research and discovery. • Provide guidelines on training models on patient, participant, genomics, and controlled access data since there is a high risk of data breach and privacy and confidentiality concerns. Consider soliciting community input to inform these guidelines. • Explore data -sharing protocols that protect sensitive health information. HHS long -term priorities: • Consider potential policy solutions or guidelines that enable medical research and discovery to leverage AI outside of controlled access environments while minimizing the risk of data spillage. • Provide policy clarity and/or guidelines on special considerations regarding AI in research, including definitions of AI developed specifically for research, usability for research of AI models, re - identification risks of patient data used and shared for research, and privacy and security implications for AI in research contexts."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_157",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nof controlled access environments while minimizing the risk of data spillage. • Provide policy clarity and/or guidelines on special considerations regarding AI in research, including definitions of AI developed specifically for research, usability for research of AI models, re - identification risks of patient data used and shared for research, and privacy and security implications for AI in research contexts. • Evaluate potential pathways to engage STLTs on common pathways for patients to authorize their data use in medical research and discovery to enhance diversity and representation in medical research and discovery while also designing long-term solutions to accelerate and amplify safe data collection and use. • Consider potential technical or policy solutions that minimize barriers to patient data collection while upholding data security and minimizing unauthorized use. 158 https://aspr.hhs.gov/legal/synna/Documents/SynNA -Guidance -2023.pdf 159 See Appendix A: “Glossary of terms” for the definition of “sandbox” used in this Plan. 40 2. Setting clear guidelines for safe and trustworthy AI use in medical research and discovery and the distribution and use of federal resources Context: Establishing and fostering trustworthy AI is paramount to the responsible adoption of AI in medical research and discovery."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_158",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-2023.pdf 159 See Appendix A: “Glossary of terms” for the definition of “sandbox” used in this Plan. 40 2. Setting clear guidelines for safe and trustworthy AI use in medical research and discovery and the distribution and use of federal resources Context: Establishing and fostering trustworthy AI is paramount to the responsible adoption of AI in medical research and discovery. Developing evidence for and d isseminating guidelines and regulatory expectations related to transparency and other ethical, legal, and social implications (ELSI) of AI models used in medical research and discovery , including those that leverage federal resources, may lead to safer and more trustworthy use of AI in the space. HHS has taken steps to address this challenge and will continue to build safeguards in the future. HHS actions to date (non -exhaustive): • HHS policymakers have established a regulatory framework, known as the Common Rule, to guide biomedical research. This framework will continue to support the ethical and responsible use of AI throughout the research life cycle .160 Appendix B includes specific web pages detailing how these regulations, policies, and best practices should be considered before , during, and after the development and use of AI in research. The main tenets of this policy framework include: o Protection of human subject research participants, which aims to safeguard research participants ’ rights, safety, and welfare ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_159",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nlife cycle .160 Appendix B includes specific web pages detailing how these regulations, policies, and best practices should be considered before , during, and after the development and use of AI in research. The main tenets of this policy framework include: o Protection of human subject research participants, which aims to safeguard research participants ’ rights, safety, and welfare . o Health information privacy policies, regulations, and best practices help protect the privacy and security of health data used in research, thereby fostering trust in healthcare research activities. o Biosecurity and biosafety oversight that continues to apply to the development or use of AI in biomedical research. o Policy and guidance around public access to research products and data management and sharing, which seek to maximize the responsible and appropriate sharing and management of research products while ensuring that researchers consider how human research participants ’ privacy, rights, and confidentiality will be protected. Responsible and appropriate sharing and management refer not exclusively to human data protections but also to other relevant laws, regulations, and policies that limit disclosure and rest rictions on sharing imposed by agreements. o Licensing, intellectual property, and technology transfer policy and resources related to intellectual property and software sharing to complement data sharing and delineate investigator rights."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_160",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nbe protected. Responsible and appropriate sharing and management refer not exclusively to human data protections but also to other relevant laws, regulations, and policies that limit disclosure and rest rictions on sharing imposed by agreements. o Licensing, intellectual property, and technology transfer policy and resources related to intellectual property and software sharing to complement data sharing and delineate investigator rights. • NIH’s Artificial Intelligence in Research Policy Considerations and Guidance details a robust system of policies and practices that guide stakeholders across the biomedical and behavioral research ecosystem.161 NIH’s policy framework is designed to responsibly guide and govern advancing science and emerging technologies, including developing and using AI technologies in research. The policies, best practices, and regulations discussed reflect this framework and should be considered before, during, and after the development and use of AI in research. It is not an exhaustive list of all policies and requirements that may apply to any NIH -supported research projects . Still, it can guide the research community regarding privacy, intellectual property, data management, participant protection , and more."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_161",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nregulations discussed reflect this framework and should be considered before, during, and after the development and use of AI in research. It is not an exhaustive list of all policies and requirements that may apply to any NIH -supported research projects . Still, it can guide the research community regarding privacy, intellectual property, data management, participant protection , and more. HHS near -term priorities: • Coordinate between midstream (e.g., NIH) and downstream (e.g., FDA) medical research and discovery agencies to enhance information sharing among agencies, where possible, and assist developers aiming to seek regulatory authorization. 160 https://www.hhs.gov/ohrp/regulations -and-policy/regulations/common -rule/index.html 161 https://osp.od.nih.gov/policies/artificial -intelligence/ 41 • Explore developing a common framework of expectations for addressing or providing transparency into how researchers using AI in medical research and discovery address ELSI in order to proceed to clinical trials and potential regulatory approval. • Consider supporting guidelines and educational tools to help AI developers as they work toward safety, security, and trust while creating AI technologies for use in medical research and discovery. • Explore targeting research resources, training, and workshops to further research on the ELSI of AI in medical research and discovery, including explainable AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_162",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nclinical trials and potential regulatory approval. • Consider supporting guidelines and educational tools to help AI developers as they work toward safety, security, and trust while creating AI technologies for use in medical research and discovery. • Explore targeting research resources, training, and workshops to further research on the ELSI of AI in medical research and discovery, including explainable AI. • Create opportunities for communities of practice (e.g., sandboxes)162 to evaluate ELSI of AI technologies in medical research and discovery internally at a reduced cost. HHS long -term priorities: • As necessary, implement updates and/or new policies to ensure responsible use of AI in both internal (e.g., through HHS and/or HHS grant or contract recipients ) and external (e.g., in industry and/or academia) medical research and discovery, including potential stratification of AI risks in medical research and discovery. • Continue prioritizing and exploring resourcing for evidence -building to evaluate ELSI of AI in medical research and discovery as the field continuously evolves. • Continually monitor advances in AI in medical research and discovery to periodically update and revise policy and/or guidelines to provide further clarity on AI use as it relates to later regulatory approval processes, ELSI, and drug and biological product approval and device marketing authorization requirements. 3."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_163",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nELSI of AI in medical research and discovery as the field continuously evolves. • Continually monitor advances in AI in medical research and discovery to periodically update and revise policy and/or guidelines to provide further clarity on AI use as it relates to later regulatory approval processes, ELSI, and drug and biological product approval and device marketing authorization requirements. 3. Enabling safe and responsible organizational governance of AI risk management and transparency: Context: The trustworthy use of AI relies on the assurance of model performance and characteristics and the implementation and associated workflows that determine how AI is used in practice. There is already considerable policy guidance on responsible research practices covering AI uses .163 However, a lack of risk management policies targeted specifically to the uses of AI in medical research and discovery may lead to poor AI performance regardless of the quality of the technology. Additionally, communities can help identify risks pertinent to their residents and align on transparency goals, which could lower the risk of people losing trust in how their data are used.164 Currently, there are limited standardized approaches for representing the characteristics of AI models used in medical research and discovery to better inform users and regulatory authorities about the potential pitfalls of specific AI models. HHS has approached this challenge by funding and researching such technologies ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_164",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncould lower the risk of people losing trust in how their data are used.164 Currently, there are limited standardized approaches for representing the characteristics of AI models used in medical research and discovery to better inform users and regulatory authorities about the potential pitfalls of specific AI models. HHS has approached this challenge by funding and researching such technologies . HHS will continue to share guidelines, develop policy, and explore resourcing activities that support these goals. HHS actions to date (non -exhaustive): • ARPA -H’s Performance and Reliability Evaluation for Continuous Modifications and Useability of Artificial Intelligence ( PRECISE -AI) program funds investigation to develop technology that can detect when AI used in real -world clinical care settings is out of alignment with underlying training data and, importantly, auto -correct it.165 162 See Appendix A: “Glossary of terms” for the definition of “sandbox” used in this Plan."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_165",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nReliability Evaluation for Continuous Modifications and Useability of Artificial Intelligence ( PRECISE -AI) program funds investigation to develop technology that can detect when AI used in real -world clinical care settings is out of alignment with underlying training data and, importantly, auto -correct it.165 162 See Appendix A: “Glossary of terms” for the definition of “sandbox” used in this Plan. 163 https://osp.od.nih.gov/policies/artificial -intelligence/ 164 The 2024 -2030 Federal Health IT Strategic Plan has a strategy related to this under Goal 1: Promote health and well-being , Objective B: Individuals and populations experience modern and equitable healthcare, Strategy: The federal government plans to promote education, outreach , and transparency about the use of AI technologies and how analysis and outputs of these technologi es are applied across the healthcare system so that individuals and healthcare providers are better informed about the use of AI technologies in healthcare, and have transparency into performance, quality, and privacy practic es."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_166",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nStrategy: The federal government plans to promote education, outreach , and transparency about the use of AI technologies and how analysis and outputs of these technologi es are applied across the healthcare system so that individuals and healthcare providers are better informed about the use of AI technologies in healthcare, and have transparency into performance, quality, and privacy practic es. 165 https://arpa -h.gov/research -and-funding/programs/precise -ai 42 • The Department of Veterans Affairs (V A) and FDA’s upcoming collaborative Virtual Health AI Lab will test medical AI applications in a virtual lab environment to ensure they work, are safe and effective for veterans and patients, and adhere to trustworthy AI principles.166, 167 • HHS’s Trustworthy AI Framework describes what approaches could be taken to address many ethical and other challenges related to AI in healthcare , including those that could apply to medical research and discovery.168 While not an official policy, it could clarify how HHS approaches addressing these challenges related to AI uptake."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_167",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npatients, and adhere to trustworthy AI principles.166, 167 • HHS’s Trustworthy AI Framework describes what approaches could be taken to address many ethical and other challenges related to AI in healthcare , including those that could apply to medical research and discovery.168 While not an official policy, it could clarify how HHS approaches addressing these challenges related to AI uptake. • AHRQ’s Digital Healthcare Equity Framework guides users in intentionally considering equity in healthcare solutions involving digital technologies and assessing whether these solutions are equitable at every digital healthcare life cycle phase .169 HHS near -term priorities: • Explore the opportunities and risks of leveraging AI in data collection, including the quality of the data (e.g., EHRs showcasing high -quality versus low -quality outcomes). • Explore synthetic data risk management technical or policy solutions that can reduce the potential degradation of synthetic data as it is iterated on through analyses and subsequent generation of additional synthetic data. • Develop plans for a quality assurance program for AI used in research aligned with the broader HHS quality assurance policy and program, including digital accessibility for all planning, development, and release. • Explore strategies to mitigate misuse and approaches to define and assess the risk of current AI models, datasets, and research results."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_168",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsubsequent generation of additional synthetic data. • Develop plans for a quality assurance program for AI used in research aligned with the broader HHS quality assurance policy and program, including digital accessibility for all planning, development, and release. • Explore strategies to mitigate misuse and approaches to define and assess the risk of current AI models, datasets, and research results. • In consultation with other federal agencies, update and refine risk management guidelines for federally funded research activities to proactively identify, assess, and mitigate risks associated with AI used in research. • Define, prioritize, and disseminate frameworks for testing, evaluating, validating, and verifying algorithms used in medical research and discovery. • Explore opportunities for encouraging transparency of AI model use and personal data use to stakeholders across the value chain whose data may contribute to groundbreaking research, including accompanying risks. • Train researchers and members of the public who are less skilled, less experienced, and less educated on AI topics to ensure they understand potential dual -use and other risks of AI used in medical research and discovery.170 • Explore potential applications of AI to dynamically assess the risk of AI used in medical research and discovery, given the dynamic nature of models and the static current risk management frameworks in place."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_169",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nless experienced, and less educated on AI topics to ensure they understand potential dual -use and other risks of AI used in medical research and discovery.170 • Explore potential applications of AI to dynamically assess the risk of AI used in medical research and discovery, given the dynamic nature of models and the static current risk management frameworks in place. HHS long -term priorities: • Explore privacy -enhancing technologies and their potential use in HHS -supported and HHS -conducted research involving AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_170",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nmedical research and discovery.170 • Explore potential applications of AI to dynamically assess the risk of AI used in medical research and discovery, given the dynamic nature of models and the static current risk management frameworks in place. HHS long -term priorities: • Explore privacy -enhancing technologies and their potential use in HHS -supported and HHS -conducted research involving AI. 166 https://www.politico.com/newsletters/future -pulse/2024/11/01/a -government -ai-lab-is-born-00186664 167 https://www.nextgov.com/artificial -intelligence/2024/10/va -announces -creation -new-ai-testing -ground -fda/400681/?oref=ng -homepage -river 168 https://www.hhs.gov/sites/default/files/hhs -trustworthy -ai-playbook.pdf 169 https://digital.ahrq.gov/health -it-tools -and-resources/digital -healthcare -equity/digital -healthcare -equity -framework -and-guide 170 Aligns with 2024 -2030 Federal Health IT Strategic Plan Goal 3: Accelerate Research and Innovation, Objective B: Individual and population -level research, analysis, and its application are enhanced by health IT, Strategy: The federal government plans to pro mote the increased transparency into the development and use of AI algorithms in healthcare settings for providers and patients so that researchers, technology developers, and other heal th IT users understand how the AI systems work, what kinds of data the y are being trained on, and how they are being used in decision -making to mitigate biases, risks, and inaccuracies in AI outputs."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_171",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ninto the development and use of AI algorithms in healthcare settings for providers and patients so that researchers, technology developers, and other heal th IT users understand how the AI systems work, what kinds of data the y are being trained on, and how they are being used in decision -making to mitigate biases, risks, and inaccuracies in AI outputs. 43 • Partner with industry to develop “research model card” frameworks for standardized representation of characteristics of AI models used in medical research and discovery, including (1) designed purpose , (2) key development inputs , (3) key model outputs , (4) external validation process and results; and (5) life cycle management plan and process. 1.6.3 Democratize AI Technologies and Resources AI approaches have the potential to “level the playing field” for researchers, helping to identify previously undetectable patterns in extensive, rich, multimodal, and complex datasets, not unlike how CRISPR has made gene editing widely available around the globe."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_172",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\noutputs , (4) external validation process and results; and (5) life cycle management plan and process. 1.6.3 Democratize AI Technologies and Resources AI approaches have the potential to “level the playing field” for researchers, helping to identify previously undetectable patterns in extensive, rich, multimodal, and complex datasets, not unlike how CRISPR has made gene editing widely available around the globe. However, access to a broader selection of researchers and applicability to a wider set of underinvest ed TAs may not happen on their own; federal government direction, incentives, and policies play a key role in ensuring that AI technologies are used for purposes that the market might not adequately or rapidly fulfill on its own (See Goal 1: “Catalyze Heal th AI Innovation and Adoption” theme of action 1: “ Expanding the breadth of medical research and discovery AI use across disease areas and steps of the value chain ” for more information) . While innovation has been expanding beyond the laboratory, some stakeholders may still lack the resources to engage with AI, with key themes of action, including: 1. Fostering intentional public engagement and public -private action to enhance sharing of best practices among all stakeholders 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_173",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI use across disease areas and steps of the value chain ” for more information) . While innovation has been expanding beyond the laboratory, some stakeholders may still lack the resources to engage with AI, with key themes of action, including: 1. Fostering intentional public engagement and public -private action to enhance sharing of best practices among all stakeholders 2. Increasing accessibility to responsibly curated AI -ready data , models and algorithms, and tooling and infrastructure for all Below, HHS discusses the context of each theme of action in more detail, together with corresponding actions and plans to ensure equitable access to AI technologies and resources. 1. Fostering intentional public engagement and public -private action to enhance sharing of best practices among all stakeholders: Context: Increasing collaborative partnerships between stakeholders (e.g., the industry, STLTs, academia, and the general public) and intentional public engagement throughout the innovation pipeline could enhance the potential of AI being equitably adopted across m edical research and discovery by sharing ideas, approaches, best practices, example applications, and key risks to mitigate between groups. HHS has already begun convening stakeholders and will continue to pursue actions to meet this challenge."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_174",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nSTLTs, academia, and the general public) and intentional public engagement throughout the innovation pipeline could enhance the potential of AI being equitably adopted across m edical research and discovery by sharing ideas, approaches, best practices, example applications, and key risks to mitigate between groups. HHS has already begun convening stakeholders and will continue to pursue actions to meet this challenge. HHS actions to date (non -exhaustive): • NIH’s AIM -AHEAD Program seeks to build partnerships with underrepresented communities to develop and use AI in behavioral and biomedical research to establish networks to address health disparities.171 This program spurs research and mentorship through projects that improve community engagement, leadership, and research fellowships (especially in underserved communities) and promote infrastructure development for AI in research. • NIH, NSF, NCSES, and DOE’s National AI Research Resource (NAIRR) Pilot is a cross -agency collaboration working to improve AI in research, including research into topics related to human health.172 It leverages large RWD sets to (1) build a synthetic data generator toolkit and framework to assess privacy risk and utility for using such data for evidence -building and (2) link medical imaging data with clinical records that will build capacity for multimodal AI development."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_175",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncollaboration working to improve AI in research, including research into topics related to human health.172 It leverages large RWD sets to (1) build a synthetic data generator toolkit and framework to assess privacy risk and utility for using such data for evidence -building and (2) link medical imaging data with clinical records that will build capacity for multimodal AI development. 171 https://datascience.nih.gov/artificial -intelligence/aim -ahead 172 https://nairrpilot.org/ 44 • NIH’s All of Us Research Program173 is a nationwide network of participant partners and researchers that aims to help ensure that people from all backgrounds can be included in research. Participants generously share information, which fuels thousands of studies to better understand health and disease , enabling more tailored and equitable approaches to care and creating new opportunities to leverage AI to advance precision medicine. • HHS is also developing challenges (i.e., innovation competitions), holding workshops (e.g., Evolving Landscape of Human Research with AI), and working with advisory committees to consult with members of the public to gather perspectives on tools that facilitate data access, combination, and analysis (e.g., AI, cloud computing).174, 175 HHS near -term priorities: • Promote and facilitate legal pathways for public -private partnerships (e.g., through the Foundation for the National Institutes of Health) between AI developers and NIH -funded investigators."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_176",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand working with advisory committees to consult with members of the public to gather perspectives on tools that facilitate data access, combination, and analysis (e.g., AI, cloud computing).174, 175 HHS near -term priorities: • Promote and facilitate legal pathways for public -private partnerships (e.g., through the Foundation for the National Institutes of Health) between AI developers and NIH -funded investigators. • Develop a vision and framework to incorporate public voices in all phases and types of clinical research.176 • Explore opportunities for public engagement and education in digestible forms about benefits, risks, and potential uses of AI in medical research and discovery to establish trust and promote uptake equitably. • Continue to engage stakeholders (see Exhibit 3), including the public and participants, as part of the medical research and discovery pipeline to gather their perspectives on AI applications. • Expand opportunities for collaboration and the implementation of initiatives for improving the AI readiness of NIH -supported data.177 • Facilitate public -private collaborations to foster AI knowledge and technology sharing by NIH -funded research institutions and underserved or underrepresented institutions. HHS long -term priorities: • Explore increasing resourcing for multi -institutional research collaborations, especially those embedding bioethicists and developers."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_177",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n• Expand opportunities for collaboration and the implementation of initiatives for improving the AI readiness of NIH -supported data.177 • Facilitate public -private collaborations to foster AI knowledge and technology sharing by NIH -funded research institutions and underserved or underrepresented institutions. HHS long -term priorities: • Explore increasing resourcing for multi -institutional research collaborations, especially those embedding bioethicists and developers. • Offer secure sandboxes178 and infrastructure to encourage collaborative research into the development and use of AI for medical discovery, provided they ensure the development of information and communication technology (ICT) conforms to HHS Digital Accessibility Guidelines.179 • Facilitate community engagement, which will seed, sprout, and sustain long -term relationships between investigators and public members that can be utilized for co -creation. New authorities may be needed to survey stakeholders (including through AI, accounting for, or obtaining exemptions from constraints from the Paperwork Reduction Act) . A new policy may be neces sary to responsibly regulate such partnerships . 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_178",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nengagement, which will seed, sprout, and sustain long -term relationships between investigators and public members that can be utilized for co -creation. New authorities may be needed to survey stakeholders (including through AI, accounting for, or obtaining exemptions from constraints from the Paperwork Reduction Act) . A new policy may be neces sary to responsibly regulate such partnerships . 2. Increasing accessibility to responsibly curated AI -ready data , models and algorithms, and tooling and infrastructure for all: (See Goal 1: “Catalyze Health AI Innovation and Adoption” theme of action 3: “Fostering AI -ready data standards and datasets to bolster their usability for AI -empowered medical research and discovery ” for more information on data standards and usability) 173 https://allofus.nih.gov/ 174 https://www.hhs.gov/ohrp/education -and-outreach/exploratory -workshop/2024 -workshop/index.html . 175 https://osp.od.nih.gov/policies/novel -and-exceptional -technology -and-research -advisory -committee -nextrac/ , https://www.hhs.gov/ohrp/sachrp - committee/recommendations/irb -considerations -use-artificial -intelligence -human -subjects -research/index.html , https://www.hhs.gov/ohrp/sachrp - committee/recommendations/attachment -e-july-25-2022 -letter/index.html NIH NExTRAC charges for data science and emerging technologies."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_179",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nbolster their usability for AI -empowered medical research and discovery ” for more information on data standards and usability) 173 https://allofus.nih.gov/ 174 https://www.hhs.gov/ohrp/education -and-outreach/exploratory -workshop/2024 -workshop/index.html . 175 https://osp.od.nih.gov/policies/novel -and-exceptional -technology -and-research -advisory -committee -nextrac/ , https://www.hhs.gov/ohrp/sachrp - committee/recommendations/irb -considerations -use-artificial -intelligence -human -subjects -research/index.html , https://www.hhs.gov/ohrp/sachrp - committee/recommendations/attachment -e-july-25-2022 -letter/index.html NIH NExTRAC charges for data science and emerging technologies. 176 https://osp.od.nih.gov/policies/novel -and-exceptional -technology -and-research -advisory -committee -nextrac This is the current charge of an NIH FACA called the NExTRAC. 177 https://datascience.nih.gov/artificial -intelligence/initiatives/Improving -AI-readiness -of-Existing -Data 178 See Appendix A: “Glossary of terms” for the definition of “sandbox” used in this Plan . 179 https://www.hhs.gov/web/section -508/index.html 45 Context: Effectively and efficiently harnessing AI requires financial, technical, and human resources. Though not a commodity, general -purpose AI technologies (e.g., LLMs) are widely available and will likely “raise the floor” of industrywide capabilities."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_180",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nhttps://datascience.nih.gov/artificial -intelligence/initiatives/Improving -AI-readiness -of-Existing -Data 178 See Appendix A: “Glossary of terms” for the definition of “sandbox” used in this Plan . 179 https://www.hhs.gov/web/section -508/index.html 45 Context: Effectively and efficiently harnessing AI requires financial, technical, and human resources. Though not a commodity, general -purpose AI technologies (e.g., LLMs) are widely available and will likely “raise the floor” of industrywide capabilities. The potential for more diverse researchers and use cases to apply these technologies in medical research and discovery could be hampered by resource availability, which could exacerbate an already prevalent “digital divide.” HHS has made data and tools more access ible and plans to continue iterating on these activities. HHS actions to date (non -exhaustive): • The NIH Science and Technology Research Infrastructure for Discovery, Experimentation, and Sustainability (STRIDES) Initiative180 provides HHS -funded behavioral and biomedical investigators with discounted access to commercial cloud services, including AI applications. STRIDES has already generated approximately $120M in cost savings for these researchers, who can also access the associated “Cloud Lab,” a sandbox181 with associated tutorials and data where researchers can experiment with these technologies at no cost."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_181",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nDiscovery, Experimentation, and Sustainability (STRIDES) Initiative180 provides HHS -funded behavioral and biomedical investigators with discounted access to commercial cloud services, including AI applications. STRIDES has already generated approximately $120M in cost savings for these researchers, who can also access the associated “Cloud Lab,” a sandbox181 with associated tutorials and data where researchers can experiment with these technologies at no cost. • The NIH Policy for Data Management and Sharing requires investigators to prospectively plan for maximizing appropriate sharing of “scientific data” (i.e., data of sufficient quality to validate and replicate research findings) and comply with the NIH -approved plan.182 Supplemental information accompanying the policy helps researchers select a data repository, budget for data management and sharing, and protect human research participant data.183, 184 • NIH’s All of Us Research Program,185 also referenced above in the theme of action “fostering intentional public engagement and public -private action to enhance sharing of best practices among all stakeholders ,” is additionally building a diverse database that can inform thousands of studies on various health conditions. The program has created one of the largest, most diverse, and most broadly accessible health research datasets ever assembled."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_182",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nreferenced above in the theme of action “fostering intentional public engagement and public -private action to enhance sharing of best practices among all stakeholders ,” is additionally building a diverse database that can inform thousands of studies on various health conditions. The program has created one of the largest, most diverse, and most broadly accessible health research datasets ever assembled. Data available to researchers include genomic data, survey responses, physical measurements, electronic healt h record information, and wearables data. The program’s cloud -based platform design encourages collabor ation across agencies, allowing researchers to leverage AI and related tools and expand their understanding of many health conditions. • ARPA -H’s Biomedical Data Fabric Toolbox ,186 in partnership with NIH, seeks to make it easier to connect biomedical research data from thousands of sources by (1) lowering barriers to high -fidelity, timely data collection in computer -readable forms, (2) preparing for multisource data analysis at scale, (3) advancing intuitive data exploration, (4) improving stakeholder access while maintaining privacy and security measures, and (5) ensuring generalizability of biomedical data fabric tools across disease types. These data must be findable, accessible, interoperable, and reusable."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_183",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nof sources by (1) lowering barriers to high -fidelity, timely data collection in computer -readable forms, (2) preparing for multisource data analysis at scale, (3) advancing intuitive data exploration, (4) improving stakeholder access while maintaining privacy and security measures, and (5) ensuring generalizability of biomedical data fabric tools across disease types. These data must be findable, accessible, interoperable, and reusable. • NIH’s Generalist Repository Ecosystem Initiative supports seven generalist repositories that work together to establish consistent metadata, develop use cases for data sharing and reuse, and train and educate researchers on how to share and reuse data, including for the development and use of AI.187 HHS near -term priorities: • Explore targeting research resources, training, and workshops to “expand the base” of AI -capable research institutions with a potential focus on data infrastructure. 180 https://datascience.nih.gov/strides 181 See Appendix A: “Glossary of terms” for the definition of “sandbox” used in this Plan ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_184",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto share and reuse data, including for the development and use of AI.187 HHS near -term priorities: • Explore targeting research resources, training, and workshops to “expand the base” of AI -capable research institutions with a potential focus on data infrastructure. 180 https://datascience.nih.gov/strides 181 See Appendix A: “Glossary of terms” for the definition of “sandbox” used in this Plan . 182 https://sharing.nih.gov/ 183 https://sharing.nih.gov/data -management -and-sharing -policy/sharing -scientific -data/data -sharing -approaches 184 https://sharing.nih.gov/data -management -and-sharing -policy/planning -and-budgeting -for-data-management -and-sharing/budgeting -for-data-management -sharing 185 https://allofus.nih.gov/protecting -data-and-privacy/precision -medicine -initiative -privacy -and-trust-principles 186 https://arpa -h.gov/research -and-funding/programs/arpa -h-bdf-toolbox 187 https://datascience.nih.gov/data -ecosystem/generalist -repository -ecosystem -initiative 46 • Explore resourcing for opportunities to continue supporting lower -resourced institutions to gain access to infrastructure (e.g., storage, computing, models) that is critical for AI adoption in medical research and discovery. • Expand the availability and capability of resources like NAIRR, GREI, and ScHARe . • Evaluate the expansion of the STRIDES program to include AI tools and models."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_185",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n46 • Explore resourcing for opportunities to continue supporting lower -resourced institutions to gain access to infrastructure (e.g., storage, computing, models) that is critical for AI adoption in medical research and discovery. • Expand the availability and capability of resources like NAIRR, GREI, and ScHARe . • Evaluate the expansion of the STRIDES program to include AI tools and models. • Expand the availability, capability, and knowledge and tool/technology sharing from federal data initiatives. • Develop as a public resource a federated, linked , centralized repository of AI -ready data for authorized stakeholders to engage in medical research and discovery. • Continue developing data platforms that can be leveraged publicly to generate insights through AI that guide medical research and discovery. HHS long -term priorities: • Increase capacity to assist investigators in refining standards for data management and sharing in line with the changing landscape of public access to research. • Build an internal database to track compliance, public comments, and other AI accessibility issues in medical research and discovery.188 1.6.4 Cultivate AI -Empowered Workforces and Organization Cultures Without sufficient AI experts to enable innovation at scale in medical research and discovery, a widescale adoption and an uptake may be unfeasible."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_186",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nwith the changing landscape of public access to research. • Build an internal database to track compliance, public comments, and other AI accessibility issues in medical research and discovery.188 1.6.4 Cultivate AI -Empowered Workforces and Organization Cultures Without sufficient AI experts to enable innovation at scale in medical research and discovery, a widescale adoption and an uptake may be unfeasible. To that end, HHS plans to spur workforce development externally and internally to empower continued responsible, safe innovation of AI across the medical research and discovery value chain. Current themes of action in the space include: 1. Improving training in governance and management of AI in medical research and discovery 2. Developing and retaining a robust AI talent pipeline in medical research and discovery Below, HHS’s current actions and future goals to create AI -empowered workforces and organizational cultures in medical research and discovery are described. 1. Improving training in the governance and management of AI in medical research and discovery: Context: Most individuals involved in AI will be responsible for managing and using such technologies rather than developing them. Ensuring that the medical research and discovery enterprise gets the most out of AI will require focusing on the technologies and, per haps more importantly, paying attention to their implementation, workflow integration, and life cycle management."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_187",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nin medical research and discovery: Context: Most individuals involved in AI will be responsible for managing and using such technologies rather than developing them. Ensuring that the medical research and discovery enterprise gets the most out of AI will require focusing on the technologies and, per haps more importantly, paying attention to their implementation, workflow integration, and life cycle management. Training the medical research and discovery workforce to manage and use such technologies responsibly will also be critical to harnessing AI t o advance the industry. HHS has addressed this challenge and will direct additional efforts to resolve this gap further and empower the industry. HHS actions to date (non -exhaustive): • FDA’s blog entry, “A Lifecycle Management Approach Toward Deliver ing Safe, Effective AI - Enabled Healthcare ,”189 provide d an overview of one potential approach to developing, validating , and maintaining ongoing governance of AI models for medical devices to ensure their safety and effectiveness. 188 https://www.consumerfinance.gov/data -research/consumer -complaints/ 189 https://www.fda.gov/medical -devices/digital -health -center -excellence/blog -lifecycle -management -approach -toward -delivering -safe-effective -ai-enabled -health -care 47 HHS near -term priorities: • Explore targeting resources, training, and workshops to include the governance, management, and use of AI technologies in research and technology."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_188",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nmaintaining ongoing governance of AI models for medical devices to ensure their safety and effectiveness. 188 https://www.consumerfinance.gov/data -research/consumer -complaints/ 189 https://www.fda.gov/medical -devices/digital -health -center -excellence/blog -lifecycle -management -approach -toward -delivering -safe-effective -ai-enabled -health -care 47 HHS near -term priorities: • Explore targeting resources, training, and workshops to include the governance, management, and use of AI technologies in research and technology. • Consider supporting guidelines or best practices for governance, life cycle management, and workflow integration of AI technologies in medical research and discovery. HHS long -term priorities: • Iteratively amend and publish updates to guidelines or training programs as appropriate. 2. Developing and retaining a robust AI talent pipeline in medical research and discovery: Context: To harness the potential of AI in medical research and discovery, the ecosystem may need a strong and diverse workforce pipeline capable of integrating models and algorithms into their inquiries."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_189",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-term priorities: • Iteratively amend and publish updates to guidelines or training programs as appropriate. 2. Developing and retaining a robust AI talent pipeline in medical research and discovery: Context: To harness the potential of AI in medical research and discovery, the ecosystem may need a strong and diverse workforce pipeline capable of integrating models and algorithms into their inquiries. Different types of AI are likely to shift the skillsets and roles needed fo r an effective medical research and discovery workforce as multimodal models become increasingly powerful and potentially automate many aspects of the scientific workflow (from observation and hypothesis development to data analysis and manuscript developm ent), human input and evaluation will be necessary at all stages. Investigators from all backgrounds may need baseline knowledge to develop and apply AI safely, responsibly, and effectively. Additionally, without clear incentives, interdisciplinary experts may continue to flow toward the technology sector, leaving gaps in non - profit, academic, and government laboratories focused on medical research and discovery. HHS has taken action to meet this challenge and plans to continue exploring opportunities."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_190",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nfrom all backgrounds may need baseline knowledge to develop and apply AI safely, responsibly, and effectively. Additionally, without clear incentives, interdisciplinary experts may continue to flow toward the technology sector, leaving gaps in non - profit, academic, and government laboratories focused on medical research and discovery. HHS has taken action to meet this challenge and plans to continue exploring opportunities. HHS actions to date (non -exhaustive): • NIH ’s AIM -AHEAD Program established a strong mentoring network to cultivate AI talent in medical research and discovery across the U.S.190 • The NIH DATA National Service Scholar Program hired data science professionals to NIH to increase efficiency, innovative research, tool development, and analytics in research .191 • NIH’s Administrative Supplements for Workforce Development at the Interface of Information Sciences, AI, and Biomedical Sciences supports the development and implementation of curricular or training activities at the interface of information science, AI, and biomedical sciences to develop the competencies and skills needed to make biomedical data findable, accessible, interoperable, and reusable and AI-ready.192 • National Library of Medicine’s (NLM’s)193 University -based Biomedical Informatics and Data Science Research Training Programs support research training in biomedical informatics and data science at graduate and post -doctoral educational institutions in the U.S.194 • NLM’s Short -Term Research Education Experiences to Attract Talented Students to Biomedical Informatics/Data Science Careers and Enhance Diversity supports educational activities that encourage talented undergraduate and master ’s students, including those from groups underrepresented in the biomedical and behavioral sciences, to pursue further training and careers in biomedical informatics and data science."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_191",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npost -doctoral educational institutions in the U.S.194 • NLM’s Short -Term Research Education Experiences to Attract Talented Students to Biomedical Informatics/Data Science Careers and Enhance Diversity supports educational activities that encourage talented undergraduate and master ’s students, including those from groups underrepresented in the biomedical and behavioral sciences, to pursue further training and careers in biomedical informatics and data science. NLM seeks to develop a cadre of diverse scientists capable of leading biomedical informatics and data science research with this program.195 190 https://datascience.nih.gov/artificial -intelligence/aim -ahead 191 https://datascience.nih.gov/data -scholars -2023 192 https://datascience.nih.gov/artificial -intelligence/initiatives/Workforce -Gap-Data-Governance -AI 193 Note that NLM is a subsidiary of NIH. 194 https://www.nlm.nih.gov/ep/GrantTrainInstitute.html 195 https://www.nlm.nih.gov/ep/R25_program.html 48 • NLM’s Data Science and Informatics (DSI) Scholars Program is an 8 - to 12 -week summer internship in which interns contribute their skills and perspectives to computational research projects in the biological sciences."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_192",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nhttps://datascience.nih.gov/artificial -intelligence/aim -ahead 191 https://datascience.nih.gov/data -scholars -2023 192 https://datascience.nih.gov/artificial -intelligence/initiatives/Workforce -Gap-Data-Governance -AI 193 Note that NLM is a subsidiary of NIH. 194 https://www.nlm.nih.gov/ep/GrantTrainInstitute.html 195 https://www.nlm.nih.gov/ep/R25_program.html 48 • NLM’s Data Science and Informatics (DSI) Scholars Program is an 8 - to 12 -week summer internship in which interns contribute their skills and perspectives to computational research projects in the biological sciences. DSI Scholars gain valuable experience in a collaborative research environment while training one -on-one with a research mentor.196 HHS near -term priorities: • Prioritize and explore resourcing for evidence -building to evaluate AI workforce development efforts and maximize the efficacy of HHS spending. • Increase and amplify training for researchers on developing responsible AI tools for medical research and discovery, including best practices for integrating AI -related coursework into biomedical research training curricula. • Integrate biosecurity resources or training to share with researchers new to utilizing AI. • Create education and training programs for providers on the use of AI in medical research and discovery and how patient data can be used and collected to propel further innovation safely ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_193",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nincluding best practices for integrating AI -related coursework into biomedical research training curricula. • Integrate biosecurity resources or training to share with researchers new to utilizing AI. • Create education and training programs for providers on the use of AI in medical research and discovery and how patient data can be used and collected to propel further innovation safely . • Evaluate the expansion of NIH ’s AIM -AHEAD Program to include recruitment and training for AI expertise in medical research and discovery. HHS long -term priorities: • Explore expanding resourcing mechanisms that emphasize the development and use of AI in biomedical research graduate training. • Explore resourcing for centers of excellence for data science and AI in research institutions across the U.S. that offer subsidized training and services for HHS -funded researchers. • Promote community -driven training for upskilling in prompt engineering, red teaming, and watermarking to maximize the utility of AI while maintaining scientific rigor and driving equity. 1.7 Conclusion Fostering innovation while managing risks in AI-driven medical research and discovery is crucial for advancing American health and human services. HHS understands that the potential of AI to enhance research outcomes, speed up the development of medical products, and improve patient care is vast; how ever, these benefits must be balanced against the risks of bias, data misuse, biosecurity, and other concerns."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_194",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nwhile managing risks in AI-driven medical research and discovery is crucial for advancing American health and human services. HHS understands that the potential of AI to enhance research outcomes, speed up the development of medical products, and improve patient care is vast; how ever, these benefits must be balanced against the risks of bias, data misuse, biosecurity, and other concerns. HHS is uniquely positioned to play a pivotal role in this landscape. HHS’s action plan —which includes initiatives exploring resourcing, public education, and workforce development —aims to address current challenges to AI adoption in medical research and discovery and advancing its safe and responsible use. By doing so, HHS can stimulate economic growth, create high -skilled jobs, and, most important ly, safeguard the health and well -being of all Americans and individuals globally. Through strategic leadership and collaboration with stakeholders across the value chain, HHS can guide the responsible integration of AI in medical research and discovery, h elping to ensure that the benefits of innovation are realized while associated risks are mitigated. HHS is committed to evolving its AI strategy in medical research and discovery as technologies and use cases continuously change to best improve medical res earch and discovery."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_195",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe value chain, HHS can guide the responsible integration of AI in medical research and discovery, h elping to ensure that the benefits of innovation are realized while associated risks are mitigated. HHS is committed to evolving its AI strategy in medical research and discovery as technologies and use cases continuously change to best improve medical res earch and discovery. 196 https://www.nlm.nih.gov/research/DDSI.html 49 2 Medical Product Development, Safety, and Effectiveness 2.1 Introduction and Context Medical products , including drugs,197 biological products,198 and medical devices ,199 including some software - based behavioral interventions ,200 play a crucial role in advancing health. As AI becomes increasingly advanced, it has the potential to further improve patient care by augmenting the capabilities of healthcare practitioners and bolstering product development across the life cycle from clinical trials to manufacturing and safety monitoring.201 The rapid advancement of AI technologies in the medical products space places HHS in a pivotal position. HHS can spur the successful adoption and scale -up of effective technologies while minimizing potential risks and harm associated with medical products throughout their life cycle .202 This chapter of the Plan will focus on medical products themselves and steps of the medical product lifecycle from clinical trials to regulatory review, manufacturing, and safety monitoring ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_196",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nin a pivotal position. HHS can spur the successful adoption and scale -up of effective technologies while minimizing potential risks and harm associated with medical products throughout their life cycle .202 This chapter of the Plan will focus on medical products themselves and steps of the medical product lifecycle from clinical trials to regulatory review, manufacturing, and safety monitoring . For more information on the research and discovery of medical products203 and the research and discovery of AI technologies that can be leveraged in biomedicine , please refer to the Medical Research and Discovery chapter. The role of AI in devices differs from other medical products. In drugs and biological products, it is generally helpful in producing information or data to support decision -making across the product development life cycle, from development to manufacturing and postmarket surveillance and monit oring . In devices, it may play three roles: in the development or maintenance of the device , as a stand -alone product that can perform one or more device purposes (e.g., diagnose, cure, mitigate, treat, or prevent disease) without being a part of a traditional hardware device , or as part of or integral to a device. Regulatory review for marketing authorization of these products in the U.S. is governed by a statutory and regulatory framework that helps ensure medical products are safe and effective for their intended use."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_197",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npurposes (e.g., diagnose, cure, mitigate, treat, or prevent disease) without being a part of a traditional hardware device , or as part of or integral to a device. Regulatory review for marketing authorization of these products in the U.S. is governed by a statutory and regulatory framework that helps ensure medical products are safe and effective for their intended use. Across the product life cycle, FDA reviews data and information about products before they are marketed to the public, conducts surveillance once pro ducts are available, and monitors product promotion and medical product quality.204 As of August 2024, FDA has authorized approximately 1,000 AI-enabled medical devices,205 and FDA has received over 550 submissions for drug and biological products with AI components.206 NIH also plays a critical role in advancing the development of medical products that increase access to better care. Though funding for clinical development can come from a variety of places, NIH alone makes an approximately $3B annual 197 See Appendix A: “Glossary of terms” for the definition of “drug” used in this Plan. 198 See Appendix A: “Glossary of terms” for the definition of “biological product” used in this Plan. 199 See Appendix A: “Glossary of terms” for the definition of “medical device” used in this Plan."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_198",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nvariety of places, NIH alone makes an approximately $3B annual 197 See Appendix A: “Glossary of terms” for the definition of “drug” used in this Plan. 198 See Appendix A: “Glossary of terms” for the definition of “biological product” used in this Plan. 199 See Appendix A: “Glossary of terms” for the definition of “medical device” used in this Plan. 200 Some software -based behavioral interventions are medical devices under FDA’s statute, whereas others, such as those software functions that are “ intended for maintaining or encouraging a healthy lifestyle” and are “unrelated to the diagnosis, cure, mitigation, prevention, or treatment of a disease or condition” are not. See sections 201(h) and 520(o)(1)(B) of the FD&C Act. 201 https://www.fda.gov/media/177030/download 202 https://www.hhs.gov/programs/topic -sites/ai/strategy/index.html 203 Drugs, biological products, and medical devices in this Plan are referred to as “medical products” when discussed collectivel y. See Appendix A: “Glossary of terms” for the definition of “medical products” used in this Plan for additional details."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_199",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nof a disease or condition” are not. See sections 201(h) and 520(o)(1)(B) of the FD&C Act. 201 https://www.fda.gov/media/177030/download 202 https://www.hhs.gov/programs/topic -sites/ai/strategy/index.html 203 Drugs, biological products, and medical devices in this Plan are referred to as “medical products” when discussed collectivel y. See Appendix A: “Glossary of terms” for the definition of “medical products” used in this Plan for additional details. 204 https://www.fda.gov/patients/learn -about -drug-and-device -approvals 205 https://www.fda.gov/medical -devices/software -medical -device -samd/artificial -intelligence -and-machine -learning -aiml-enabled -medical -devices 206 https://www.fda.gov/about -fda/center -drug-evaluation -and-research -cder/artificial -intelligence -drug-development 50 investment in clinical trials , making it the largest federal funder of clinical trials in the U.S.207 Regulatory oversight of medical products strives to maintain a balance between upholding safety and effectiveness and fostering innovation , including when AI is used in the medical product or across the medical product life cycle. 2.1.1 Action Plan Summary Later in this chapter, HHS articulates proposed actions to advance its four goals for the responsible use of AI in the sector. Below is a summary of the themes of actions within each goal. For full details of proposed actions please see section 2.6 Action Plan."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_200",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe medical product or across the medical product life cycle. 2.1.1 Action Plan Summary Later in this chapter, HHS articulates proposed actions to advance its four goals for the responsible use of AI in the sector. Below is a summary of the themes of actions within each goal. For full details of proposed actions please see section 2.6 Action Plan. Key goals that actions support Themes of proposed actions (not exhaustive, see 2.6 Action Plan for more details) 1. Catalyzing health AI innovation and adoption • Clarifying regulatory oversight of medical products • Providing clarity on payment models • Fostering public -private partnerships and intergovernmental collaborations to rapidly develop and share knowledge 2. Promoting trustworthy AI development and ethical and responsible use • Refining regulatory frameworks to address adaptive AI technologies in medical devices • Promoting equity in AI deployment to bolster safe and responsible use • Addressing AI -enabled software outside current device regulatory authorities • Fostering private or public mechanisms for quality assurance of health AI 3. Democratizing AI technologies and resources • Enabling collaborative development through public engagement • Aligning standards and information -sharing mechanisms across research and healthcare delivery 4."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_201",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n• Promoting equity in AI deployment to bolster safe and responsible use • Addressing AI -enabled software outside current device regulatory authorities • Fostering private or public mechanisms for quality assurance of health AI 3. Democratizing AI technologies and resources • Enabling collaborative development through public engagement • Aligning standards and information -sharing mechanisms across research and healthcare delivery 4. Cultivating AI - empowered workforces and organization cultures • Improving training in the governance and management of AI in medical products • Developing and retaining AI talent related to medical products 2.2 Stakeholders Engaged in Medical Product Development, Safety, and Effectiveness A range of stakeholders engage with AI in medical products and their development, ranging from patients and medical providers to developers of medical products, distributors, providers, payers, researchers, and many others. The Action Plan section at the end of this chapter includes approaches to engage these stakeholders to advance innovation while mitigating risks. Below is an illustrative diagram of example flows between stakeholders and a bulleted list with additional details on stakeholders involved in medical product development, safety, and effectiveness . Please note that neither the diagram nor the list capture s all possible stakeholder roles and interactions ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_202",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthis chapter includes approaches to engage these stakeholders to advance innovation while mitigating risks. Below is an illustrative diagram of example flows between stakeholders and a bulleted list with additional details on stakeholders involved in medical product development, safety, and effectiveness . Please note that neither the diagram nor the list capture s all possible stakeholder roles and interactions . Please refer to other HHS documents for additional details on regulatory guidance and authorities . 207 https://grants.nih.gov/policy -and-compliance/policy -topics/clinical -trials/why -changes 51 Exhibit 5: Stakeholders Engaged in Medical Product Development, Safety, and Effectiveness Stakeholders include, but are not limited to: • HHS operating divisions (non -exhaustive):208 o FDA: Helps ensure that human and animal drugs, biological products, and medical devices are safe and effective for their intended uses and that electronic products that emit radiation are safe. As AI becomes a more prominent aspect of medical products, their development, manufacturing operations, and use, FDA will continue to regulate and support stakeholders. o NIH: Supports biomedical and behavioral research within the U.S. and abroad, conducts research in its laboratories and clinics, trains promising young researchers, and promotes collecting and sharing biomedical knowledge, which have increasingly included AI related to medical products and the life cycle ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_203",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nmedical products, their development, manufacturing operations, and use, FDA will continue to regulate and support stakeholders. o NIH: Supports biomedical and behavioral research within the U.S. and abroad, conducts research in its laboratories and clinics, trains promising young researchers, and promotes collecting and sharing biomedical knowledge, which have increasingly included AI related to medical products and the life cycle . o CDC: Develops recommendations on using vaccines after the FDA approves them, continually monitors vaccines for safety once used clinically, and reports adverse effects (e.g., via the Vaccine Adverse Event Reporting System).209 o AHRQ: Supports research on interventions enabled by medical devices, such as patient -centered clinical decision support , and focuses on improving the quality, safety, efficiency, and effectiveness of healthcare for all Americans. • Other federal agencies: HHS also works closely with many other federal departments, such as the National Science Foundation (NSF) and the Department of Energy (DOE). • Patients, participants, and caregivers (including residents and communities): Use drugs, biological products, or medical devices developed using AI or including AI. Today, empowered patients may also utilize AI to better understand their personal health status and advocate for their own care."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_204",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nwith many other federal departments, such as the National Science Foundation (NSF) and the Department of Energy (DOE). • Patients, participants, and caregivers (including residents and communities): Use drugs, biological products, or medical devices developed using AI or including AI. Today, empowered patients may also utilize AI to better understand their personal health status and advocate for their own care. 208 https://www.hhs.gov/about/agencies/hhs -agencies -and-offices/index.html 209 https://www.cdc.gov/vaccines -children/about/developing -safe-effective -vaccines.html 52 • Pharmaceutical and medical technology research and manufacturing companies: Design, develop, and produce drugs, biological products, or medical devices for commercial use in healthcare delivery, including researchers and subject matter experts integrating AI into clinical trials and product design and manufacturing. They are amon g the primary users of AI in clinical trials and medical product manufacturing. These companies also use AI to support pharmacovigilance activities. • Healthcare providers and payers: Utilize medical products and provide clinical perspectives to clinical development efforts (e.g., hospitals, clinics, healthcare professionals) or decide which technologies are part of its payment mechanisms (e.g., payers). Additionally, providers can be “ humans in the loop” for AI use, which includes portions of the medical product life cycle ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_205",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI to support pharmacovigilance activities. • Healthcare providers and payers: Utilize medical products and provide clinical perspectives to clinical development efforts (e.g., hospitals, clinics, healthcare professionals) or decide which technologies are part of its payment mechanisms (e.g., payers). Additionally, providers can be “ humans in the loop” for AI use, which includes portions of the medical product life cycle . The use of AI in clinical settings is expanded on in the Healthcare Delivery chapter, as medical product use intended by manufacture rs and authorized by the FDA could be leveraged to provide healthcare for certain purposes while not changing their device, drug, or biological product status. • STLTs: Play oversight and funding roles outside of the federal government. FDA has regulatory oversight of medical products, while STLTs may have jurisdiction over different components of medical practice and healthcare delivery. • Academic, non -profit, and other research workforce: Develop evidence for the leading edge of biomedical knowledge, including engineers designing and generating medical devices for clinical applications, and subject matter experts developing AI, applying AI in clinical trial workflows, and/or integrating AI into the product development life cycle . They are among the primary users of AI in medical product development."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_206",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAcademic, non -profit, and other research workforce: Develop evidence for the leading edge of biomedical knowledge, including engineers designing and generating medical devices for clinical applications, and subject matter experts developing AI, applying AI in clinical trial workflows, and/or integrating AI into the product development life cycle . They are among the primary users of AI in medical product development. • Contract research organizations ( CROs ): Provide outsourced research services and may develop or integrate AI into their clinical trial workflows. As third parties, CROs should be engaged particularly on matters of security and privacy as they handle other organizations’ sensitive data in AI. AI is also used by these companies to support pharmacovigil ance activities that may be outsourced by drug manufacturers. • Distributors and wholesalers: Facilitate the distribution of medical products —which may include or have been researched and developed leveraging AI —to healthcare providers. • Donors and private funders: Support funding for product development and scale -up. They include non - profit donors, such as foundations, and for -profit funders, such as private equity, venture capital, and other funding organizations. These organizations may also support other investm ents in AI technologies or with other stakeholders."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_207",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nbeen researched and developed leveraging AI —to healthcare providers. • Donors and private funders: Support funding for product development and scale -up. They include non - profit donors, such as foundations, and for -profit funders, such as private equity, venture capital, and other funding organizations. These organizations may also support other investm ents in AI technologies or with other stakeholders. • AI developers: Build the AI tools, models, and platforms that can be used within medical products or across the medical product life cycle . 2.3 Opportunities for the Application of AI in Medical Product Development, Safety, and Effectiveness If adopted and scaled successfully and responsibly, AI use in medical product development, operations, and safety monitoring, as well as AI inclusion in the medical product itself, could improve overall care outcomes and the accessibility and efficiency of the process in multiple ways , such as : 1. Increasing the efficiency of clinical trials, which may accelerate the timeline to access safe and effective medical products : Leveraging AI in clinical trials may help predict a participant’s risk for adverse reactions , generate initial content of regulatory submissions and investigative brochures, and translate documentation to other languages ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_208",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe process in multiple ways , such as : 1. Increasing the efficiency of clinical trials, which may accelerate the timeline to access safe and effective medical products : Leveraging AI in clinical trials may help predict a participant’s risk for adverse reactions , generate initial content of regulatory submissions and investigative brochures, and translate documentation to other languages . Additionally, though there are methods to incorporate patient centricity without AI, using AI toward this goal may reduce the likelihood of candidate attrition.210 Furthermore , using AI to execute analyses can accelerate another core part of the clinical trial process. Together, these and other 210 https://pmc.ncbi.nlm.nih.gov/articles/PMC11006977/ 53 uses of AI in clinical trials can make medical products accessible to patients more rapidly. (See trend (A)( 1) in the section below for more details on AI uptake in clinical trials to date). 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_209",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nattrition.210 Furthermore , using AI to execute analyses can accelerate another core part of the clinical trial process. Together, these and other 210 https://pmc.ncbi.nlm.nih.gov/articles/PMC11006977/ 53 uses of AI in clinical trials can make medical products accessible to patients more rapidly. (See trend (A)( 1) in the section below for more details on AI uptake in clinical trials to date). 2. Improving the representativeness of clinical trials of those who use medical products: Today, as many as “86% of clinical trials do not reach recruitment targets within their specified time periods ,”211 which can lead to less effective medical interventions, potentially poorer health equity in pharmaceutical practices, and potentially billions of dollars in economic losses.212 Leveraging AI in clinical trial strategy, as appropriate, to analyze patient and other demographic data , to select sites , and to identify potential candidates that are representative of the population of interest has the potential to help enroll a more representative population in clinical trials. This can bolster the information submitted to the FDA for regulatory approval or marke ting authorization. Leveraging AI in clinical trial strategy can better serve historically underrepresented populations. 3."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_210",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n, to select sites , and to identify potential candidates that are representative of the population of interest has the potential to help enroll a more representative population in clinical trials. This can bolster the information submitted to the FDA for regulatory approval or marke ting authorization. Leveraging AI in clinical trial strategy can better serve historically underrepresented populations. 3. Being used as part of a medical product , being the medical product itself, or being used to develop medical products: AI can be used as part of a medical product or to develop safe and effective medical products. In particular, AI -enabled medical devices, such as over -the-counter hearing aids, have the potential to be used by patients, healthcare providers, and other end users to help augment care and improve outcomes.213, 214 (See trend (B)(1) in the section below for more details on AI -enabled medical devices). Additionally, AI supports the ability to learn from data collected during clinical use which can help support improving medical product accuracy and performance over time,215 potentially leading to improved accuracy and monitoring (e.g., lower misdiagnosis rates, higher ability to detect adverse effects early). Similarly, AI can be leveraged to develop drugs and biological products (e.g., identifying targets and assessing biomarkers and endpoints) as discussed in the Medical Research and Discovery chapter. 4."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_211",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nuse which can help support improving medical product accuracy and performance over time,215 potentially leading to improved accuracy and monitoring (e.g., lower misdiagnosis rates, higher ability to detect adverse effects early). Similarly, AI can be leveraged to develop drugs and biological products (e.g., identifying targets and assessing biomarkers and endpoints) as discussed in the Medical Research and Discovery chapter. 4. Strengthening supply chain, manufacturing, and other operations to ensure and expand access: In recent years, medical product supply shortages have impacted patients’ ability to access timely care that is critical for their health. For example, as of October 2024, there are over 100 active drug shortages, spanning from IV solutions to prescriptio n stimulants.216 Similarly, when demand for a specific medical product surges, increasing access by rapidly driving up supply may not be a quick process.217 AI can rationalize and streamline supply chain management and manufacturing processes, including the ability to analyze production schedules, forecast demand, estimate the impact of potential disruptions, and optimize inventory.218 By responsibly adopting AI into their operations, medical product manufacturers, distributors, and others can mitigate shortages, safeguard access to care, and prepare for expansion to additional patients when demand spikes. 5."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_212",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI can rationalize and streamline supply chain management and manufacturing processes, including the ability to analyze production schedules, forecast demand, estimate the impact of potential disruptions, and optimize inventory.218 By responsibly adopting AI into their operations, medical product manufacturers, distributors, and others can mitigate shortages, safeguard access to care, and prepare for expansion to additional patients when demand spikes. 5. Enhancing pharmacovigilance and postmarket surveillance and monitoring: Monitoring medical products is crucial to managing their safe and effective use. Today, data collection and analysis already leverage EHRs, administrative claims , and other sources of clinical data to collate large amounts of product safety data (e.g., FDA’s Adverse Event Reporting System [FAERS] and FDA’s Sentinel Initiative).219, 220 Some safety monitoring activities involve surveys and social media monitoring, which can take substantial resources and time.221 Leveraging AI to collect and/or analyze large datasets of adverse event reports, scraped social media data, or survey data could rapidly identify potential safety issues and accelerate the timeline for taking action to protect patients."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_213",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nReporting System [FAERS] and FDA’s Sentinel Initiative).219, 220 Some safety monitoring activities involve surveys and social media monitoring, which can take substantial resources and time.221 Leveraging AI to collect and/or analyze large datasets of adverse event reports, scraped social media data, or survey data could rapidly identify potential safety issues and accelerate the timeline for taking action to protect patients. Furthermore, this data and analysis could be leveraged to better understand the outcomes of medical product use and derive novel insights to enhance human health, 211 https://www.sciencedirect.com/science/article/pii/S155171441730753X#bb0020 212 https://www.ncbi.nlm.nih.gov/books/NBK584396/ 213 https://www.fda.gov/medical -devices/software -medical -device -samd/artificial -intelligence -and-machine -learning -software -medical -device 214 https://www.fda.gov/news -events/press -announcements/fda -authorizes -first-over-counter -hearing -aid-software 215 https://www.fda.gov/medical -devices/software -medical -device -samd/artificial -intelligence -and-machine -learning -software -medical -device 216 https://www.drugs.com/drug -shortages/ 217 https:/www.ncbi.nlm.nih.gov/books/NBK583734 218 https://www.fda.gov/media/167973/download?attachment 219 https://www.fda.gov/drugs/fdas -adverse -event -reporting -system -faers/fda -adverse -event -reporting -system -faers -public -dashboard 220 https://www.fda.gov/safety/fdas -sentinel -initiative 221 https://www.nsf.org/knowledge -library/post -market -surveillance -what -you-need-to-know -to-ensure -patient -safety 54 including the types of patients best served by a particular medical product."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_214",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n215 https://www.fda.gov/medical -devices/software -medical -device -samd/artificial -intelligence -and-machine -learning -software -medical -device 216 https://www.drugs.com/drug -shortages/ 217 https:/www.ncbi.nlm.nih.gov/books/NBK583734 218 https://www.fda.gov/media/167973/download?attachment 219 https://www.fda.gov/drugs/fdas -adverse -event -reporting -system -faers/fda -adverse -event -reporting -system -faers -public -dashboard 220 https://www.fda.gov/safety/fdas -sentinel -initiative 221 https://www.nsf.org/knowledge -library/post -market -surveillance -what -you-need-to-know -to-ensure -patient -safety 54 including the types of patients best served by a particular medical product. One caution, however, is that with potentially large quantities of clinical data, more noise could be generated, so parsing essential signals from the data is paramount.222 2.4 Trends in AI in Medical Product Development, Safety, and Effectiveness Stakeholders have begun to leverage AI in medical products and their development along two overarching trends: A. Leveraging AI in the development of medical products and their ongoing operations B. Embedding AI within products themselves or as standalone products Below, select non -exhaustive examples of adoption across (A) and (B) to date are discussed. A. AI in the development and operations of medical products 1."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_215",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI in medical products and their development along two overarching trends: A. Leveraging AI in the development of medical products and their ongoing operations B. Embedding AI within products themselves or as standalone products Below, select non -exhaustive examples of adoption across (A) and (B) to date are discussed. A. AI in the development and operations of medical products 1. AI uptake related to drugs and biological product development is increasing : There has been a growing use of AI in the drug and biological product development life cycle across a range of TAs."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_216",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nBelow, select non -exhaustive examples of adoption across (A) and (B) to date are discussed. A. AI in the development and operations of medical products 1. AI uptake related to drugs and biological product development is increasing : There has been a growing use of AI in the drug and biological product development life cycle across a range of TAs. In fact, FDA has seen a significant increase in the number of drug and biological product application submissions using AI components over the past few years, from just 3 in 2018 to 132 in 2021.223, 224 These submissions traverse the landscape of drug and biological product development ranging from clinical research to postmarket surveillance and monitoring and advanced pharmaceutical manufacturing.225 Use cases seen in recent FDA submissions focused on a range of topics, including but not limited to endpoint and biomarker assessment , anomaly detection , imaging, video, and voice analysis , patient risk stratification and management , dose selection and optimization , and adherence during clinical trials.226 Additional use cases span some of the most time -intensive aspects of clinical trials (e.g., site selection and candidate recruitment) and can help predict the success or failure of proposed trial designs.227 AI is also being leveraged to reduce the time associated with and to increase the quality of randomized controlled trials by selecting participants and minimizing errors.228 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_217",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ntrials.226 Additional use cases span some of the most time -intensive aspects of clinical trials (e.g., site selection and candidate recruitment) and can help predict the success or failure of proposed trial designs.227 AI is also being leveraged to reduce the time associated with and to increase the quality of randomized controlled trials by selecting participants and minimizing errors.228 2. Approaches to validate the credibility of health AI are heterogenous and inconsistently applied : The use of AI in the health domain , including in the development and operations of medical products, needs to be validated to ensure that it leads to safe and effective medical products, decisions , and actions . Today, there are many AI validation approaches, and in general, they focus on easy-to-measure quantitative performance metrics in narrow and highly controlled conditions and rarely use real patient data.229 The ease with which AI can be deployed to a wide and ever -expanding array of healthcare use cases is driving a potential need to establish nationally accepted standards and mechanisms for assuring the quality of AI systems. B. AI within or as the products 1. Applications of AI -enabled medical devices are expanding , with a focus on radiology: Within medical devices, AI has grown rapidly to cover new applications across the medical product ecosystem."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_218",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nhealthcare use cases is driving a potential need to establish nationally accepted standards and mechanisms for assuring the quality of AI systems. B. AI within or as the products 1. Applications of AI -enabled medical devices are expanding , with a focus on radiology: Within medical devices, AI has grown rapidly to cover new applications across the medical product ecosystem. As of August 2024, the FDA has reviewed and authorized approximately 1,000 AI - enabled medical devices to market in the U.S.,230 including 171 in 2023 and 258 in 2024,231, 232 222 https://psnet.ahrq.gov/perspective/artificial -intelligence -and-patient -safety -promise -and-challenges 223 https://ascpt.onlinelibrary.wiley.com/doi/10.1002/cpt.2668 224 https://www.fda.gov/news -events/fda -voices/harnessing -potential -artificial -intelligence 225 https://www.fda.gov/media/167973/download?attachment 226 https://ascpt.onlinelibrary.wiley.com/doi/full/10.1002/cpt.2668 227 https://www.nature.com/articles/d41586 -024-00753 -x 228 https://pmc.ncbi.nlm.nih.gov/articles/PMC7346875/ 229 https://pubmed.ncbi.nlm.nih.gov/39405325/ 230 https://www.fda.gov/medical -devices/software -medical -device -samd/artificial -intelligence -and-machine -learning -aiml-enabled -medical -devices 231 https://rad.washington.edu/news/fda -publishes -list-of-ai-enabled -medical -devices/ 232 https://www.fda.gov/medical -devices/software -medical -device -samd/artificial -intelligence -and-machine -learning -aiml-enabled -medical -devices 55 which indicate a 33% and 27% increase in authorized AI -enabled medical devices in the last two years, respectively.233 Over 75% of these devices are used in a radiology context, potentially due to the high number of predicate devices that may enable clearer paths to 510(k) clearance."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_219",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n232 https://www.fda.gov/medical -devices/software -medical -device -samd/artificial -intelligence -and-machine -learning -aiml-enabled -medical -devices 55 which indicate a 33% and 27% increase in authorized AI -enabled medical devices in the last two years, respectively.233 Over 75% of these devices are used in a radiology context, potentially due to the high number of predicate devices that may enable clearer paths to 510(k) clearance. Additionally, FDA -authorized devices use predictive AI rather than GenAI, which is more n ascent. See trend (A)( 1) for trends in drugs and biological products clinical development, the “Table of Example Use Cases and Risks Across Steps of the Medical Product Life Cycle That Are in the Scope of This Chapter ,” which follows for use cases in drugs and biological products clinical development, and the Medical Research and Discovery chapter generally for trends and use cases of AI in drugs and biological products discovery, which are potentially the most prevale nt and mature areas of uptake. 2.5 Potential Use Cases and Risks for AI in Medical Products and Their Development Below, parts of the medical product life cycle that are in the scope of this chapter are described similarly to the “value chains ” outlined in other chapters in this Plan to help guide the subsequent discussion on use cases and risks."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_220",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nmature areas of uptake. 2.5 Potential Use Cases and Risks for AI in Medical Products and Their Development Below, parts of the medical product life cycle that are in the scope of this chapter are described similarly to the “value chains ” outlined in other chapters in this Plan to help guide the subsequent discussion on use cases and risks. Note that pre -clinical steps of the medical product life cycle (e.g., basic research, discovery) are discussed in the Medical Research and Discovery chapter. Exhibit 6: Steps of the Medical Product Life Cycle That Are in the Scope of This Chapter The above diagram showcases the overarching medical product life cycle in the scope of this chapter, from clinical development to monitoring product safety postmarket . Development processes for drug and biological products and medical devices follow the same overarching steps, though processes differ within those steps, particularly in regulatory approval. Each step of the medical product life cycle shown in the exhibit above is explained below: 1. Clinical development differs between drugs and devices as summarized below: a."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_221",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndevelopment to monitoring product safety postmarket . Development processes for drug and biological products and medical devices follow the same overarching steps, though processes differ within those steps, particularly in regulatory approval. Each step of the medical product life cycle shown in the exhibit above is explained below: 1. Clinical development differs between drugs and devices as summarized below: a. Drugs and biological products : Before a clinical trial with a drug or biological product can proceed, an Investigational New Drug (IND) application for drugs and biological products must be submitted to the FDA.234 At a high level, drug development involves a series of clinical studies with human subjects to assess the safety and effectiveness of candidate technologies , generally divided into three phases : Phase I tests safety and dosage . Phase II evaluates preliminary efficacy and safety, and Phase III further evaluates efficacy and safety.235 In certain cases, such as with certain vaccines or drugs, the FDA may require a Phase IV trial or postmarket safety study to assess known or potential serious risks further .236 b. Medical devices : The device development program does not typically follow the same drug phasing sequence ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_222",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nefficacy and safety, and Phase III further evaluates efficacy and safety.235 In certain cases, such as with certain vaccines or drugs, the FDA may require a Phase IV trial or postmarket safety study to assess known or potential serious risks further .236 b. Medical devices : The device development program does not typically follow the same drug phasing sequence . If a particular device does require testing in clinical trials prior to FDA marketing authorization, it may require an investigational device exemption (IDE),237 although many software - 233 Only through August 2024, potentially higher by the end of the full year 234 https://www.fda.gov/drugs/types -applications/investigational -new-drug-ind-application 235 https://www.fda.gov/patients/drug -development -process/step -3-clinical -research 236 https://www.fda.gov/vaccines -blood -biologics/development -approval -process -cber/vaccine -development -101 237 https://www.fda.gov/medical -devices/premarket -submissions -selecting -and-preparing -correct -submission/investigational -device -exemption -ide 56 based device studies are not significant risk and proceed under the oversight of an institutional review board (IRB) only.238 2. Regulatory review may differ for drugs and biological products versus medical devices. Given the complexities of review processes, this Plan will not attempt to summarize steps but rather point to FDA’s resources on both below: a."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_223",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-device -exemption -ide 56 based device studies are not significant risk and proceed under the oversight of an institutional review board (IRB) only.238 2. Regulatory review may differ for drugs and biological products versus medical devices. Given the complexities of review processes, this Plan will not attempt to summarize steps but rather point to FDA’s resources on both below: a. Drugs and biological products : A detailed description of the development and approval process for drugs and biological products can accessed in the footnotes.239, 240 b. Medical devices : A detailed description of the marketing authorization process for medical devices can be accessed in the footnotes.241 3. Manufacturing and supply chain refers to the operational process of procuring necessary materials, using them to develop medical products, and distributing them downstream to customers after a product has marketing authorization. Manufacturers must comply with applicable regulatory requirements, which include FDA’s Quality System Regulation/Medical Device Current Good Manufacturing Practices (CGMP)242 and drug and biological product CGMP regulations ,243, 244, 245 which assures that medical products are not adulterated during production. 4. Market access, commercial, and other operations involve developing and distributing materials that explain the relevance and impact of the product if leveraged in various care situations for potential providers, payers, or other stakeholders."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_224",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nDevice Current Good Manufacturing Practices (CGMP)242 and drug and biological product CGMP regulations ,243, 244, 245 which assures that medical products are not adulterated during production. 4. Market access, commercial, and other operations involve developing and distributing materials that explain the relevance and impact of the product if leveraged in various care situations for potential providers, payers, or other stakeholders. These include logistics, sales, pricing, finance , health, economics, outcomes research , and other enabling stakeholder activities. FDA regulates the marketing of medical products, including but not limited to preventing false or misleading labeling of medical products.246 5. Postmarket monitoring for safety and effectiveness includes using medical products in clinical settings, consistently monitoring their safety, and identifying and mitigating issues to ensure ongoing patient safety."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_225",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nfinance , health, economics, outcomes research , and other enabling stakeholder activities. FDA regulates the marketing of medical products, including but not limited to preventing false or misleading labeling of medical products.246 5. Postmarket monitoring for safety and effectiveness includes using medical products in clinical settings, consistently monitoring their safety, and identifying and mitigating issues to ensure ongoing patient safety. Requirements for the postmarket monitoring of medical devices include reporting device malfu nctions, serious injuries or deaths, and inspecting establishments where devices are produced or distributed.247 With respect to drugs, the FDA carefully monitors performance through FAERS and the Sentinel Initiative.248, 249 Additionally, vaccines, in particular, are closely monitored via various surveillance systems, such as the Vaccine Adverse Event Reporting System, the FDA BEST (Biologics Effectiveness and Safety) program, and the CDC’s Vaccine Safety Datalink.250 AI uptake has tremendous potential to drive innovation in medical products and across the medical product life cycle to benefit patients, which should be implemented with careful attention to risk mitigation. While risks differ between AI related to drugs, biological products, and devices , a few high -level themes emerge that could be important to consider as technology rapidly advances."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_226",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI uptake has tremendous potential to drive innovation in medical products and across the medical product life cycle to benefit patients, which should be implemented with careful attention to risk mitigation. While risks differ between AI related to drugs, biological products, and devices , a few high -level themes emerge that could be important to consider as technology rapidly advances. In clinical development, AI can perpetuate biases inherent in the data on which it was trained or tuned. As part of manufacturing and supply chain, when using AI for tracking and managing the supply chain for manufacturing, potential risk may arise from inaccuracies in AI projections of supply needs, leading to insufficient produ ction. Insufficient production may lead to shortages , leaving people without access to medical products critical to their care."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_227",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nwhich it was trained or tuned. As part of manufacturing and supply chain, when using AI for tracking and managing the supply chain for manufacturing, potential risk may arise from inaccuracies in AI projections of supply needs, leading to insufficient produ ction. Insufficient production may lead to shortages , leaving people without access to medical products critical to their care. Given these themes and other 238 https://www.fda.gov/medical -devices/investigational -device -exemption -ide/ide -institutional -review -boards -irb 239 https://www.fda.gov/drugs/development -approval -process -drugs 240 https://www.fda.gov/vaccines -blood -biologics/development -approval -process -cber 241 https://www.fda.gov/medical -devices/device -advice -comprehensive -regulatory -assistance/how -study -and-market -your-device 242 https://www.fda.gov/medical -devices/postmarket -requirements -devices/quality -system -qs-regulationmedical -device -current -good -manufacturing -practices -cgmp 243 https://www.ecfr.gov/current/title -21/chapter -I/subchapter -C/part -210 244 https://www.ecfr.gov/current/title -21/chapter -I/subchapter -C/part -211 245 https://www.ecfr.gov/current/title -21/chapter -I/subchapter -F/part -600 246 https://www.fda.gov/medical -devices/overview -device -regulation/device -labeling 247 https://www.fda.gov/medical -devices/device -advice -comprehensive -regulatory -assistance/postmarket -requirements -devices 248 https://www.fda.gov/drugs/fdas -adverse -event -reporting -system -faers/fda -adverse -event -reporting -system -faers -public -dashboard 249 https://www.fda.gov/safety/fdas -sentinel -initiative 250 https://www.fda.gov/vaccines -blood -biologics/development -approval -process -cber/vaccine -development -101 57 risks described below, HHS is already working to safeguard against these risks and will continue to explore potential actions to encourage safe, innovative AI adoption in the space."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_228",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-regulatory -assistance/postmarket -requirements -devices 248 https://www.fda.gov/drugs/fdas -adverse -event -reporting -system -faers/fda -adverse -event -reporting -system -faers -public -dashboard 249 https://www.fda.gov/safety/fdas -sentinel -initiative 250 https://www.fda.gov/vaccines -blood -biologics/development -approval -process -cber/vaccine -development -101 57 risks described below, HHS is already working to safeguard against these risks and will continue to explore potential actions to encourage safe, innovative AI adoption in the space. 2.5.1 Table of Example Use Cases and Risks Across Steps of the Medical Product Life Cycle That Are in the Scope of This Chapter AI is being adopted across the medical product life cycle . In the table s below, HHS highlights a non -exhaustive list of potential benefits, uses, and risks across the steps that are in the scope of this chapter as described above . Parties should consider applicable statutory and regulatory requirements and consult relevant regulatory agencies when appropriate . Please note that the use cases detailed below highlight existing or potential ways that AI can be used by a variety of stakeholders in this domain."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_229",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nuses, and risks across the steps that are in the scope of this chapter as described above . Parties should consider applicable statutory and regulatory requirements and consult relevant regulatory agencies when appropriate . Please note that the use cases detailed below highlight existing or potential ways that AI can be used by a variety of stakeholders in this domain. F or details on how HHS and its divisions are using AI, please reference the HHS AI Use Case Inventory 2024.251 Functional component 1: Clinical development Includes studies with human participants to assess the safety and effectiveness of investigational medical products Please note that the Medical Research and Discovery chapter discusses basic research and pre -clinical development , which includes a discussion on use cases and risks of AI related to target identification, lead and hit generation and optimization ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_230",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n2024.251 Functional component 1: Clinical development Includes studies with human participants to assess the safety and effectiveness of investigational medical products Please note that the Medical Research and Discovery chapter discusses basic research and pre -clinical development , which includes a discussion on use cases and risks of AI related to target identification, lead and hit generation and optimization . Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Predictive and analytical models that can help improve the representativeness of the trial population E.g., site selection to maximize meeting enrollment goals Helping to identify clinical study sites with representative patients to help meet enrollment goals252 E.g., candidate selection to help ensure a representative trial population Leveraging advanced analytics to identify cohorts that are representative of the population that will use a product if approved253 Potential to misdirect the course of research E.g., “ false positives” or “false negatives” in clinical trials In technology that augments researchers in clinical trials, AI could identify safety events that are not true events or fail to identify serious safety events. If the researcher relies too heavily on the AI characterization or makes a human error in oversight of the AI, this may lead to misclassification and impact the ability to draw conclusions when analyzing data."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_231",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nIn technology that augments researchers in clinical trials, AI could identify safety events that are not true events or fail to identify serious safety events. If the researcher relies too heavily on the AI characterization or makes a human error in oversight of the AI, this may lead to misclassification and impact the ability to draw conclusions when analyzing data. Potential for bias E.g., lack of representativeness of population using a medical product While AI can advance medical product development by identifying participants, designing trials, analyzing outputs, and more, it may not be trained on data representing the population that Generative, representational, and predictive models that accelerate the timeline of clinical trials E.g., strategy for clinical trials design that increases the probability of success by reducing the likelihood of rework Leveraging generative and analytical models that can simulate potential trial designs and recommend a subset with the highest probability of success254 E.g., digital twins for faster, in silico experimentation Representing objects, systems, or candidates virtually can accelerate research by enabling simulated testing of products255 251 https://www.healthit.gov/hhs -ai-usecases 252 https://www.fda.gov/drugs/news -events -human -drugs/role -artificial -intelligence -clinical -trial-design -and-research -dr-elzarrad 253 https://www.fda.gov/drugs/news -events -human -drugs/role -artificial -intelligence -clinical -trial-design -and-research -dr-elzarrad 254 https://www.fda.gov/media/167973/download 255 https://datascience.nih.gov/tools -and-analytics/digital -twins 58 Potential use cases (non-exhaustive) Potential risks (non-exhaustive) E.g., endpoint assessment and biomarker identification Using AI as part of a clinical outcome assessment or to identify biomarkers that can potentially serve as endpoints in clinical trials256 E.g., image, video, and voice analysis to accelerate analyses and potentially bolster their quality Leveraging AI, “usually deep learning, for the analyses of imaging data, videos, or voices ” can contribute to faster and potentially more precise analyses257 E.g., patient risk stratification and dosage optimization to improve trial participant safety Predicting dosages and patients' risk for a specific severe adverse event “based on patient baseline information ” and subsequently using this prediction “to help determine the need of inpatient or outpatient monitoring for each patient ”258 may ultimately use the medical product clinically."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_232",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand potentially more precise analyses257 E.g., patient risk stratification and dosage optimization to improve trial participant safety Predicting dosages and patients' risk for a specific severe adverse event “based on patient baseline information ” and subsequently using this prediction “to help determine the need of inpatient or outpatient monitoring for each patient ”258 may ultimately use the medical product clinically. This could lead to research outcomes that are only relevant for a small group and potentially miss opportunities to address health disparities if AI models are not trained on representative data."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_233",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nbaseline information ” and subsequently using this prediction “to help determine the need of inpatient or outpatient monitoring for each patient ”258 may ultimately use the medical product clinically. This could lead to research outcomes that are only relevant for a small group and potentially miss opportunities to address health disparities if AI models are not trained on representative data. Functional component 2: Regulatory review Submission of documents to the FDA Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Leveraging generative models to accelerate the development and enhance the quality of medical writing E.g., auto-writing of clinical study reports (CSRs) to reduce researcher time spent drafting results Leveraging natural language processing (NLP) and ML algorithms to synthesize results that could be included in regulatory submissions to the FDA when appropriately confirmed by humans259 E.g., the generation of medical content across all documents that could be submitted for regulatory approval Generating first drafts of research or other medical documents from existing materials to increase the speed of document development and potentially bolster their quality when appropriately confirmed by humans260 Potential for inaccuracies that lower chances of approval E.g., misaligned syntheses of patient or candidate records and healthcare professional (HCP) or researcher notes Leveraging AI to synthesize or generate content related to patient records, sometimes with human -written notes involved, can lead to outputs that do not apply to the situation at hand because poor data quality can lead to poor outputs."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_234",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ninaccuracies that lower chances of approval E.g., misaligned syntheses of patient or candidate records and healthcare professional (HCP) or researcher notes Leveraging AI to synthesize or generate content related to patient records, sometimes with human -written notes involved, can lead to outputs that do not apply to the situation at hand because poor data quality can lead to poor outputs. Using such tools could require careful oversight regarding the types of data it analyzes and its output. Potential to introduce safety risks E.g., generating insights from research results in regulatory submissions that are not based on data Content generated by some AI ( e.g., LLMs) can be inferred rather than based on facts, leading to regulatory submissions that contain inaccurate information. If not caught, such inaccuracies can lead to marketing authorizations for medical products that are not safe and effective."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_235",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsafety risks E.g., generating insights from research results in regulatory submissions that are not based on data Content generated by some AI ( e.g., LLMs) can be inferred rather than based on facts, leading to regulatory submissions that contain inaccurate information. If not caught, such inaccuracies can lead to marketing authorizations for medical products that are not safe and effective. 256 https://ascpt.onlinelibrary.wiley.com/doi/full/10.1002/cpt.2668 257 https://ascpt.onlinelibrary.wiley.com/doi/full/10.1002/cpt.2668 258 https://ascpt.onlinelibrary.wiley.com/doi/full/10.1002/cpt.2668 259 https://pmc.ncbi.nlm.nih.gov/articles/PMC10492634/ 260 https://pmc.ncbi.nlm.nih.gov/articles/PMC10492634/ 59 Functional component 3: Manufacturing and supply chain Operations related to procurement, development of products, and distribution of those products downstream to customers Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Predictive and monitoring tools that enable advanced identification of problems or inefficiencies E.g., monitoring of manufacturing operations for real -time analysis and recommendations of actions to enhance operations Receiving real -time data on drug production processes to improve productivity, correct inefficiencies, control quality, and predict yields261 Potential to disrupt the supply of critical medical products E.g., disruptions to operations of critical drugs, biological products, and devices from AI -empowered monitoring of supply chain and manufacturing operations If not properly implemented and managed with expert human oversight, using AI to track and manage the supply chain for raw materials can result in inaccuracies in AI projections of supply needs, leading to insufficient production."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_236",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncritical medical products E.g., disruptions to operations of critical drugs, biological products, and devices from AI -empowered monitoring of supply chain and manufacturing operations If not properly implemented and managed with expert human oversight, using AI to track and manage the supply chain for raw materials can result in inaccuracies in AI projections of supply needs, leading to insufficient production. Insufficient production may lead to shortages , leaving people without access to medical products critical to their care. Optimization algorithms that help to ensure patient needs are met , and the likelihood of shortages or product waste is reduced E.g., maximization of production output of existing physical and operational infrastructure Predicting the performance of operations, people, and machinery with automated inventory tracking to mitigate stockouts and supply delay risks262 Potential for bias E.g., inequitable allocation of medical product supply Leveraging AI to plan demand, logistics, and production for drug and medical device needs could result in disparate allocations if data used in AI analysis is not sufficiently representative of the population of patients served by the corresponding product s. This could perpetuate existing health inequities and reinforce biases if impacted populations receive less access to the drugs, biological products, and devices needed for their health."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_237",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand production for drug and medical device needs could result in disparate allocations if data used in AI analysis is not sufficiently representative of the population of patients served by the corresponding product s. This could perpetuate existing health inequities and reinforce biases if impacted populations receive less access to the drugs, biological products, and devices needed for their health. Functional component 4: Market access, commercial, and other operations Connecting to potential healthcare providers and payers to explain the relevance and impact of medical products (includes pricing, finance, logistics, and enabling activities) Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Analytical and generative tools that streamline and bolster market entry activities E.g., co-pilots for patient and HCP representatives to reduce knowledge gaps Leveraging GenAI trained on details about all products to help answer questions quickly about topics patient and HCP representatives may be unfamiliar with E.g., identification of inaccurate information in marketing materials Using advanced analytics to scour the internet and other resources that promote medical products to compare against FDA -approved labeling and flag potential regulatory issues related to marketing Potential for bias E.g., creating marketing strategies and content that do not target demographics proportionately If analytical tools that scan the market and develop marketing approaches to ultimately connect patients with medical products are not trained on representative data, they can limit access to products for potentially already underserved demographics."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_238",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-approved labeling and flag potential regulatory issues related to marketing Potential for bias E.g., creating marketing strategies and content that do not target demographics proportionately If analytical tools that scan the market and develop marketing approaches to ultimately connect patients with medical products are not trained on representative data, they can limit access to products for potentially already underserved demographics. 261 https://www.fda.gov/media/165743/download 262 https://www.fda.gov/media/165743/download 60 Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Feedback and communication tools that facilitate answering questions and gathering input from patients and healthcare providers about medical products E.g., HCP engagement and experience Automating responses to HCP questions and providing dynamic feedback E.g., patient engagement and experience Streamlining communication with patients and automating follow -up interactions that do not require human interpretation E.g., generating communications based on speech or writing patterns that further promote health inequities Using GenAI to respond to HCP and patient questions or feedback could result in biased or inaccurate responses if not trained on appropriate data based on varying literacy levels , dialects, language spoken, and more, which can perpetuate existing inequities."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_239",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthat do not require human interpretation E.g., generating communications based on speech or writing patterns that further promote health inequities Using GenAI to respond to HCP and patient questions or feedback could result in biased or inaccurate responses if not trained on appropriate data based on varying literacy levels , dialects, language spoken, and more, which can perpetuate existing inequities. Functional component 5: Postmarket monitoring for safety and effectiveness Oversight and use of medical products in real -world settings to provide care and consistently monitor product safety Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Analytics tools that can provide immediate identification and reporting on efficacy, safety, and compliance E.g., real-time safety monitoring of medical product use Analyzing clinical data to identify potential adverse drug reactions or other safety signals from medical products may enable a quick response to protect patient safety .263 E.g., automated analysis and identification of patterns in nationwide adverse event reporting Advanced analytics models on adverse event report data are used to identify potential safety issues for medical products used in clinical settings."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_240",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAnalyzing clinical data to identify potential adverse drug reactions or other safety signals from medical products may enable a quick response to protect patient safety .263 E.g., automated analysis and identification of patterns in nationwide adverse event reporting Advanced analytics models on adverse event report data are used to identify potential safety issues for medical products used in clinical settings. E.g., streamlined pharmacovigilance reporting Categorizing incidents based on notes, auto -generating feedback insights, and identifying emerging concerns based on data collected from medical product use264 E.g., continuous compliance monitoring Automating compliance audits and ensuring standard operating procedures (SOPs) are followed Potential to lower quality of care E.g., inaccuracies in postmarket surveillance and monitoring In devices that operate as clinician augmentation (e.g., screening tools, AI assisting surgical tools), AI could pick up on anomalies, side effects, or adverse reactions in postmarket surveillance and monitoring that are not meaningfully related to the safety of the medical product or fail to identify legitimate anomalies, side effects, or adverse reactions. Similarly, pharmacovigilance analyses that leverage AI may identify “false positives” or “false negatives” as well."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_241",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nscreening tools, AI assisting surgical tools), AI could pick up on anomalies, side effects, or adverse reactions in postmarket surveillance and monitoring that are not meaningfully related to the safety of the medical product or fail to identify legitimate anomalies, side effects, or adverse reactions. Similarly, pharmacovigilance analyses that leverage AI may identify “false positives” or “false negatives” as well. Though HCPs and safety monitoring bodies can serve as humans i n the loop, there is a potential for overreliance on AI or human error in interpreting AI, which could lead to errors or inaccurate reporting of safety. There are opportunities to develop and use AI to improve outcomes at each medical product life cycle phase . Every party has an imperative to monitor and mitigate risks alongside innovating . HHS will use the following action plan to safely, responsibly, equitably, and impactfully foster the adoption of AI. 2.6 Action Plan In light of the evolving AI landscape in medical products and their development, HHS has taken multiple steps across providing regulatory clarity , forming public -private partnerships, and advancing equity in corresponding 263 https://pmc.ncbi.nlm.nih.gov/articles/PMC9790425/ 264 https://pmc.ncbi.nlm.nih.gov/articles/PMC9112260/ 61 AI technologies to promote responsible AI. The Action Plan below follows the four goals that support HHS’s AI strategy : 1. catalyzing health AI innovation and adoption; 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_242",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI landscape in medical products and their development, HHS has taken multiple steps across providing regulatory clarity , forming public -private partnerships, and advancing equity in corresponding 263 https://pmc.ncbi.nlm.nih.gov/articles/PMC9790425/ 264 https://pmc.ncbi.nlm.nih.gov/articles/PMC9112260/ 61 AI technologies to promote responsible AI. The Action Plan below follows the four goals that support HHS’s AI strategy : 1. catalyzing health AI innovation and adoption; 2. promoting trustworthy AI development and ethical and responsible use; 3. democratizing AI technologies and resources; and 4. cultivating AI -empowered workforces and organization cultures. For each goal, the Action Plan provides context, an overview of HHS and relevant other federal actions to date, and specific near - and long -term priorit ies HHS will take. HHS recognizes that this Action Plan will require revisions over time as technologies evolve and is committed to providing structure and flexibility to ensure longstanding impact . 2.6.1 Catalyze Health AI Innovation and Adoption To help capture the opportunity for AI to transform patient care access and outcomes, HHS plays an active role in furthering innovation and adoption in medical products and across the medical product life cycle . HHS has an opportunity to increase AI uptake in the space by pursuing the following themes of action : 1. Clarifying regulatory oversight of medical products 2. Providing clarity on payment models 3."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_243",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ntransform patient care access and outcomes, HHS plays an active role in furthering innovation and adoption in medical products and across the medical product life cycle . HHS has an opportunity to increase AI uptake in the space by pursuing the following themes of action : 1. Clarifying regulatory oversight of medical products 2. Providing clarity on payment models 3. Fostering public -private partnerships and intergovernmental collaborations to rapidly develop and share knowledge Below, HHS discusses the context for each area in more detail, corresponding actions to date, and plans to advance AI innovation and adoption across medical products. 1. Clarifying regulatory oversight of medical products: Context: There is large growth in the development of AI that can be used across the medical product life cycle . Regarding devices specifically, the rapid growth in the power and availability of new technologies has spurred the development of health information technology applications leveraging AI that fall outside medical device regulations."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_244",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nproducts. 1. Clarifying regulatory oversight of medical products: Context: There is large growth in the development of AI that can be used across the medical product life cycle . Regarding devices specifically, the rapid growth in the power and availability of new technologies has spurred the development of health information technology applications leveraging AI that fall outside medical device regulations. The 21st Century Cures Act (Cures Act)265 specifically removed from the FD&C Act266 the definition of “device” software functions intended for: • Administrative support of a healthcare facility • Maintaining or encouraging a healthy lifestyle unrelated to the diagnosis, cure, mitigation, prevention, or treatment of a disease or condition • Serve as electronic patient records • Transferring, storing, converting formats, or displaying test or other device data, results , or findings but not intended to interpret or analyze the m • Certain clinical decision support (CDS) software The types of CDS software (“non -device CDS”) that are not considered devices ,267, 268 such as applications which support or provide recommendations to an HCP and: • Do not acquire, process, or analyze medical images, signals, or patterns • Do not display, analyze, or print medical information beyond what would normally be communicated between healthcare professionals • Do not provide a specific output or directive 265 https://www.fda.gov/regulatory -information/selected -amendments -fdc-act/21st -century -cures -act 266 https://www.fda.gov/regulatory -information/laws -enforced -fda/federal -food-drug-and-cosmetic -act-fdc-act 267 https://www.fda.gov/medical -devices/software -medical -device -samd/your -clinical -decision -support -software -it-medical -device 268 Some CDS software may still be regulated as devices if they meet the definition of “device” in the FD&C Act."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_245",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nbetween healthcare professionals • Do not provide a specific output or directive 265 https://www.fda.gov/regulatory -information/selected -amendments -fdc-act/21st -century -cures -act 266 https://www.fda.gov/regulatory -information/laws -enforced -fda/federal -food-drug-and-cosmetic -act-fdc-act 267 https://www.fda.gov/medical -devices/software -medical -device -samd/your -clinical -decision -support -software -it-medical -device 268 Some CDS software may still be regulated as devices if they meet the definition of “device” in the FD&C Act. 21 USC 321(h). Any software or AI intended to diagnose, cure, mitigate, treat , or prevent disease is a device. 62 • Do not require the healthcare professional to rely primarily on the recommendations by providing the basis of the recommendations to inform decision -making ASTP’s HTI -1 Final Rule addresses the availability of AI in certain certified EHR systems, which , as of 2021, have been adopted by 9 6% of hospitals and 78% of physician offices across the country.269 The HTI -1 Final Rule does not create an approval process per se, but it does establish policies that require transparency on the part of certain certified health IT products regarding the technology offered in such products."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_246",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nEHR systems, which , as of 2021, have been adopted by 9 6% of hospitals and 78% of physician offices across the country.269 The HTI -1 Final Rule does not create an approval process per se, but it does establish policies that require transparency on the part of certain certified health IT products regarding the technology offered in such products. Starting on January 1, 2025, regulations finalized in the final rule require the availability of specific “source attribute” information for any decision support intervention technologies certified to 45 CFR 170.315(b)(11) (including AI-based decision support interventions) offered as part of the health IT product. These re quirements apply to AI-based technologies regardless of device definitions, use cases (e.g., clinical v ersus administrative) , or risk categories. As the growth of AI in health IT (e.g., EHRs) continues, there will be a need for greater clarity on regulatory boundaries and applicability to minimize business uncertainty that may hinder innovation. While this theme of action may be more pertinent to devices than drugs and biological products, the wide availability of AI is spurring growth across all medical products. As developers make investment and product roadmap decisions, there is a growing need for further clarity on th e definitions that determine regulatory pathways that could affect the cost and timing of device, drug, and biological product development ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_247",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nmore pertinent to devices than drugs and biological products, the wide availability of AI is spurring growth across all medical products. As developers make investment and product roadmap decisions, there is a growing need for further clarity on th e definitions that determine regulatory pathways that could affect the cost and timing of device, drug, and biological product development . HHS actions to date (non -exhaustive): • FDA’s Guidance on Artificial Intelligence -Enabled Device Software Functions: Lifecycle Management and Marketing Submission Recommendations270 provides recommendations regarding the contents of marketing submissions for devices that include AI -enabled device software functions including documentation and information that will support FDA’s evaluation of safety and effectiveness. The recommendatio ns reflect a comprehensive approach to the management of risk throughout the device total product life cycle (TPLC). To support the development of appropriate documentation for FDA’s assessment of the device, this draft guidance also proposes recommendatio ns for the design, development, and implementation of AI -enabled devices that manufacturers may wish to consider using throughout the TPLC."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_248",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nThe recommendatio ns reflect a comprehensive approach to the management of risk throughout the device total product life cycle (TPLC). To support the development of appropriate documentation for FDA’s assessment of the device, this draft guidance also proposes recommendatio ns for the design, development, and implementation of AI -enabled devices that manufacturers may wish to consider using throughout the TPLC. • FDA’s Guidance on Considerations for the Use of Artificial Intelligence to Support Regulatory Decision -Making for Drug and Biological Products271 provides recommendations to sponsors and other interested parties on the use of AI to produce information or data intended to support regulatory decision -making regarding safety, effectiveness, or quality for drugs. Specifically, this guidance provides a risk -based credibility assessment framework that may be used for establishing and e valuating the credibility of an AI model for a particular context of use (COU). • FDA’s Guidance on Marketing Submission Recommendations for a Predetermined Change Control Plan for Artificial Intelligence -Enabled Device Software Functions272 provides recommendations for predetermined change control plans ( PCCPs ) tailored to AI -enabled devices and intends to support iterative improvement through modification to AI -enabled devices while ensuring safety and effectiveness."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_249",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nmodel for a particular context of use (COU). • FDA’s Guidance on Marketing Submission Recommendations for a Predetermined Change Control Plan for Artificial Intelligence -Enabled Device Software Functions272 provides recommendations for predetermined change control plans ( PCCPs ) tailored to AI -enabled devices and intends to support iterative improvement through modification to AI -enabled devices while ensuring safety and effectiveness. 269 https://www.healthit.gov/data/quickstats/national -trends -hospital -and-physician -adoption -electronic -health -records 270 https://www.fda.gov/regulatory -information/search -fda-guidance -documents/artificial -intelligence -enabled -device -software -functions -lifecycle -management -and- marketing 271 https://www.fda.gov/regulatory -information/search -fda-guidance -documents/considerations -use-artificial -intelligence -support -regulatory -decision -making -drug- and-biological 272 https://www.fda.gov/regulatory -information/search -fda-guidance -documents/marketing -submission -recommendations -predetermined -change -control -plan- artificial -intelligence 63 • FDA ’s CDS Software Guidance for Industry and FDA Staff273 provides clarification on the 21st Century Cures Act legislation that excludes certain CDS software from the FDA’s device jurisdiction. This helps elucidate the complexities of certain unregulated uses of AI in healthcare technology."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_250",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-drug- and-biological 272 https://www.fda.gov/regulatory -information/search -fda-guidance -documents/marketing -submission -recommendations -predetermined -change -control -plan- artificial -intelligence 63 • FDA ’s CDS Software Guidance for Industry and FDA Staff273 provides clarification on the 21st Century Cures Act legislation that excludes certain CDS software from the FDA’s device jurisdiction. This helps elucidate the complexities of certain unregulated uses of AI in healthcare technology. • FDA’s “Artificial Intelligence and Medical Products: How CBER, CDER, CDRH, and OCP Are Working Together ” paper274 specifies how the Center for Biologics Evaluation and Research (CBER), Center for Drug Evaluation and Research (CDER), Center for Devices and Radiological Health (CDRH), and Office of Combination Products are working together to identify steps to foster collaboration, develop regulations, promote best practices, and support corresponding research efforts. • FDA’s Digital Health and Artificial Intelligence Glossary —Educational Resource275 is a publicly available resource that defines common terms in digital health, AI, and ML to provide internal and external consistency and education."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_251",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nRadiological Health (CDRH), and Office of Combination Products are working together to identify steps to foster collaboration, develop regulations, promote best practices, and support corresponding research efforts. • FDA’s Digital Health and Artificial Intelligence Glossary —Educational Resource275 is a publicly available resource that defines common terms in digital health, AI, and ML to provide internal and external consistency and education. • AHRQ’s Clinical Decision Support Innovation Collaborative has been advancing patient -centered clinical decision support (PC CDS), including exploring the impacts of AI on PCCDS and conducting pilot projects.276 HHS near -term priorities: • Continue to i ssue guidelines , supporting materials (e.g., FAQs), and/or discussion papers regarding the use of AI in medical product development and in medical products to provide further recommendations . • Consider new resourcing opportunities to research AI and CDS, including ways to understand better the benefits and risks of using clinical data in CDS software . 2. Providing clarity on payment models: Context: Across clinical disciplines (e.g., radiology and pathology), some devices incorporate AI with proven effectiveness; however, because many devices do not have established payment, full uptake potential has yet to be realized.277 Healthcare delivery payment and coverage policies can influence the economics underlying the adoption of AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_252",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nusing clinical data in CDS software . 2. Providing clarity on payment models: Context: Across clinical disciplines (e.g., radiology and pathology), some devices incorporate AI with proven effectiveness; however, because many devices do not have established payment, full uptake potential has yet to be realized.277 Healthcare delivery payment and coverage policies can influence the economics underlying the adoption of AI. While some medical products may have clear efficiency or productivity return on investment benefits where there is a market, there can be disconnects between patient benefits and financial incentives in the complex way healthcare gets paid for in the U.S. Purchasers and payers need evidence with outcomes and/or endpoints for patient populations relevant to coverage decisions and indications for use relevant to payers and beneficial for commercialization and patient access. Without a clear path for uptake in clinical settings, medical device developers may be less incentivized to continue innovating on these types of products."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_253",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ngets paid for in the U.S. Purchasers and payers need evidence with outcomes and/or endpoints for patient populations relevant to coverage decisions and indications for use relevant to payers and beneficial for commercialization and patient access. Without a clear path for uptake in clinical settings, medical device developers may be less incentivized to continue innovating on these types of products. In general, for an item or service to be considered for Medicare coverage, the item or service must fall within at least one benefit category established in the Social Security Act (the Act), the item or service must not be specifically excluded by the Act, and the item or service must be “reasonable and necessary for the diagnosis or treatment of illness or injury .”278 CMS may issue a National Coverage Decision (NCD) to describe the nationwide conditions for Medicare coverage for a specific item or service. Without an NCD, items and services are covered on a claim -by-claim basis at the discretion of the Medicare Administrative Contractors (MACs) or through a Local Coverage Determination."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_254",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nfor the diagnosis or treatment of illness or injury .”278 CMS may issue a National Coverage Decision (NCD) to describe the nationwide conditions for Medicare coverage for a specific item or service. Without an NCD, items and services are covered on a claim -by-claim basis at the discretion of the Medicare Administrative Contractors (MACs) or through a Local Coverage Determination. As of May 2024, CMS has established payment for at least eight AI-enabled devices through Current Procedural Terminology ( CPT®) and New Technology Add - 273 https://www.fda.gov/regulatory -information/search -fda-guidance -documents/clinical -decision -support -software 274 https://www.fda.gov/media/177030/download?attachment 275 https://www.fda.gov/science -research/artificial -intelligence -and-medical -products/fda -digital -health -and-artificial -intelligence -glossary -educational -resource 276 https://cdsic.ahrq.gov 277 https://www.massbio.org/wp -content/uploads/2024/09/FINAL -Vision -2030 -Strategy -Report.pdf 278 https:/www.cms.gov/medicare/coverage/councilontechinnov/downloads/innovators -guide -master -7-23-15.pdf 64 On Payment (NTAP) under the Medicare Inpatient Prospective Payment System (IPPS) ,279 less than 5% of FDA -authorized AI-based products.280 CMS also established payment pathways for hospital outpatient departments through separate payment of software -as-a-service add -on codes in 2022 ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_255",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-intelligence -glossary -educational -resource 276 https://cdsic.ahrq.gov 277 https://www.massbio.org/wp -content/uploads/2024/09/FINAL -Vision -2030 -Strategy -Report.pdf 278 https:/www.cms.gov/medicare/coverage/councilontechinnov/downloads/innovators -guide -master -7-23-15.pdf 64 On Payment (NTAP) under the Medicare Inpatient Prospective Payment System (IPPS) ,279 less than 5% of FDA -authorized AI-based products.280 CMS also established payment pathways for hospital outpatient departments through separate payment of software -as-a-service add -on codes in 2022 . Over time, the growth of value -based purchasing payment models may provide more built -in financial incentives for investment in AI in healthcare, but the growth of such programs is not rapid. Further clarifying existing pathways could spur established payment for more AI -enabled devices. HHS actions to date (non -exhaustive): • CMS’s NTAP281 provides for an add -on payment for certain new devices under the Medicare Inpatient Prospective Payment System (IPPS ),282 including those leveraging AI, with a few examples dating back to 2020 (e.g., ContactCT by Viz.ai , AI-driven triage software for large -vessel occlusion). Since then, additional AI software developers (e.g., RapidAI, AIdoc, Avicenna) have also been granted NTAP status ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_256",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nprovides for an add -on payment for certain new devices under the Medicare Inpatient Prospective Payment System (IPPS ),282 including those leveraging AI, with a few examples dating back to 2020 (e.g., ContactCT by Viz.ai , AI-driven triage software for large -vessel occlusion). Since then, additional AI software developers (e.g., RapidAI, AIdoc, Avicenna) have also been granted NTAP status . • CMS’ Transitional Coverage for Emerging Technologies (TCET) pathway helps people with Medicare access the latest medical advances, enables doctors and other clinicians to provide the best care for their patients, and benefits manufacturers who create innovative technologies.283 • CMS’ Medicare Pharmaceutical and Technology Ombudsman has been in place since late 2017. This ombudsman receives and assists with inquiries and complaints from pharmaceutical, biotechnology, medical device, diagnostic product manufacturers, and other stakeholders regarding coverage, coding, and/or payment for products covered by Medicare or for which Medicare coverage is being sough t.284 HHS near -term priorities: • Convene HHS divisions (e.g., CMS, NIH, FDA, and ASTP) to align on benefits, risks, and potential definitions of standardized, future -proof payment pathways for AI -enabled medical devices . • Expand the Early Payer Feedback Program to shorten the time to payment and coverage determinations with commercial and government insurers."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_257",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncoverage is being sough t.284 HHS near -term priorities: • Convene HHS divisions (e.g., CMS, NIH, FDA, and ASTP) to align on benefits, risks, and potential definitions of standardized, future -proof payment pathways for AI -enabled medical devices . • Expand the Early Payer Feedback Program to shorten the time to payment and coverage determinations with commercial and government insurers. • Issue guidelines to healthcare payers, providers, and other stakeholders on the pathways available to establish payment for AI -enabled devices. HHS long -term priorities: • Develop clear payment pathways for AI -enabled medical devices in the public sector to potentially spur similar activity in the private sector. • Iteratively reevaluate guidelines and payment pathways for AI -enabled medical devices as healthcare technology transforms to continue fostering adoption while mitigating risks . 3. Fostering public -private partnerships and intergovernmental collaborations to rapidly develop and share knowledge: Context: Regulatory bodies worldwide are taking different approaches to publish guidelines regarding AI in medical products. Medical product developers, manufacturers, and distributors who aim to serve patients globally could pursue innovation more efficiently with cooperative standards and guardrails to follow."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_258",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nfostering adoption while mitigating risks . 3. Fostering public -private partnerships and intergovernmental collaborations to rapidly develop and share knowledge: Context: Regulatory bodies worldwide are taking different approaches to publish guidelines regarding AI in medical products. Medical product developers, manufacturers, and distributors who aim to serve patients globally could pursue innovation more efficiently with cooperative standards and guardrails to follow. Regulatory processes that ensure the safety and effectiveness of medical products are critical to safeguarding the American public, and FDA’s medical product centers intend to continue administering programs that accelerate 279 https://www.nature.com/articles/s41746 -022-00609 -6/tables/1 280 https://www.fda.gov/medical -devices/software -medical -device -samd/artificial -intelligence -and-machine -learning -aiml-enabled -medical -devices 281 https://www.cms.gov/medicare/payment/prospective -payment -systems/acute -inpatient -pps/new -medical -services -and-new-technologies 282 https://www.cms.gov/cms -guide -medical -technology -companies -and-other -interested -parties/payment/ipps 283 https://www.cms.gov/newsroom/fact -sheets/final -notice -transitional -coverage -emerging -technologies -cms-3421 -fn 284 42 U.S.C. Section 1395b -9, https://www.cms.gov/center/special -topic/ombudsman/medicare -pharmaceutical -and-technology -ombudsman 65 innovation and provide regulatory guidelines for the use of AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_259",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-devices/software -medical -device -samd/artificial -intelligence -and-machine -learning -aiml-enabled -medical -devices 281 https://www.cms.gov/medicare/payment/prospective -payment -systems/acute -inpatient -pps/new -medical -services -and-new-technologies 282 https://www.cms.gov/cms -guide -medical -technology -companies -and-other -interested -parties/payment/ipps 283 https://www.cms.gov/newsroom/fact -sheets/final -notice -transitional -coverage -emerging -technologies -cms-3421 -fn 284 42 U.S.C. Section 1395b -9, https://www.cms.gov/center/special -topic/ombudsman/medicare -pharmaceutical -and-technology -ombudsman 65 innovation and provide regulatory guidelines for the use of AI. Furthermore, by continuing and building upon its interaction directly with the private sector, HHS can share knowledge in a way that unlocks further advancements in AI in medical products and across the medical product life cycle . HHS actions to date: • FDA’s engagement in public -private partnerships (PPPs) ,285, 286, 287 through collaborations with other government, academic, scientific, patient, and private sector organizations , advances science and innovation in how medical products are developed, evaluated, and manufactured. These ongoing efforts encourage the development of new tools, including AI, to facilitate innovation across the medical product life cycle ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_260",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto date: • FDA’s engagement in public -private partnerships (PPPs) ,285, 286, 287 through collaborations with other government, academic, scientific, patient, and private sector organizations , advances science and innovation in how medical products are developed, evaluated, and manufactured. These ongoing efforts encourage the development of new tools, including AI, to facilitate innovation across the medical product life cycle . Example PPPs that include potential AI -specific focus areas are: o BioFabUSA288 works to integrate innovative cell and tissue cultures with advances in biofabrication, automation, robotics, and analytical technologies to create disruptive research and development tools and FDA -compliant volume manufacturing processes. o The National Institute for Innovation in Biopharmaceuticals (NIIMBL)289 facilitates innovative manufacturing technologies and workforce development programs to foster efficiencies and impact in the life sciences industry. o Critical Institute Path (C -Path)290 is a non -profit organization dedicated to improving and streamlining drug development through fostering collaboration between private sector industry executives and scientists, academic researchers, regulators, and patient groups."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_261",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nThe National Institute for Innovation in Biopharmaceuticals (NIIMBL)289 facilitates innovative manufacturing technologies and workforce development programs to foster efficiencies and impact in the life sciences industry. o Critical Institute Path (C -Path)290 is a non -profit organization dedicated to improving and streamlining drug development through fostering collaboration between private sector industry executives and scientists, academic researchers, regulators, and patient groups. o Clinical Trials Transformation Initiative (CTTI)291 brings together organizations and individuals representing academia, clinical investigators, government and regulatory agencies, private sector industry, IRBs , patient advocacy groups, and others to develop evidence -based solutions to clinical research challenges. • NIH’s Advancing Health Research through Ethical, Multimodal Artificial Intelligence (AI) Initiative292 funds the development of ethically focused and data -driven multimodal AI approaches to more closely interpret and predict complex biological and behavioral systems and model intricate health systems to enhance our understanding of health and the ability t o detect and treat human diseases. • FDA’s Artificial Intelligence Program —Research on AI-based medical devices293 relies on the CDRH conducting regulatory science research to ensure patient access to safe and effective medical devices using AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_262",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nclosely interpret and predict complex biological and behavioral systems and model intricate health systems to enhance our understanding of health and the ability t o detect and treat human diseases. • FDA’s Artificial Intelligence Program —Research on AI-based medical devices293 relies on the CDRH conducting regulatory science research to ensure patient access to safe and effective medical devices using AI. Specific focus areas include methods to enhance model training, minimize bias, and develop methods to track safety postmarket. • FDA, NIH, and NSF launched the Foundations for Digital Twins as Catalyzers of Biomedical Technological Innovation (FDT -BioTech) program to catalyze biomedical innovation through synthetic data, which facilitates clinical trials by providing control data that may be challenging to obtain through traditional participant recruitment.294 • Across NIH, its institutes, centers, and offices are funding research295 to apply AI in many disease contexts including in wearable technology to help monitor and screen cognitive impairment ,296 to detect neurological disease through retinal imaging, and identify patients with potential substance misuse disorders."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_263",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ntrials by providing control data that may be challenging to obtain through traditional participant recruitment.294 • Across NIH, its institutes, centers, and offices are funding research295 to apply AI in many disease contexts including in wearable technology to help monitor and screen cognitive impairment ,296 to detect neurological disease through retinal imaging, and identify patients with potential substance misuse disorders. 285 https://www.fda.gov/emergency -preparedness -and-response/innovative -technologies/public -private -partnerships 286 https://www.fda.gov/drugs/science -and-research -drugs/scientific -public -private -partnerships -and-consortia 287 https://www.fda.gov/medical -devices/digital -health -center -excellence/digital -health -research -and-partnerships 288 https://www.fda.gov/emergency -preparedness -and-response/innovative -technologies/public -private -partnerships 289 https://www.fda.gov/emergency -preparedness -and-response/innovative -technologies/public -private -partnerships 290 https://c -path.org/c -path-awarded -fda-grant -to-establish -public -private -partnership -to-advance -treatments -for-rare-neurodegenerative -diseases/ 291 https://www.fda.gov/patients/learn -about -fda-patient -engagement/fda -patient -engagement -partnerships 292 https://datascience.nih.gov/sites/default/files/MAI -Solicitation -outline.pdf 293 https://www.fda.gov/medical -devices/medical -device -regulatory -science -research -programs -conducted -osel/artificial -intelligence -program -research -aiml-based - medical -devices 294 https://new.nsf.gov/funding/opportunities/fdt -biotech -foundations -digital -twins -catalyzers -biomedical 295 https://grants.nih.gov/funding/find -a-fit-for-your-research -nih-institutes -centers -offices 296 https://www.nia.nih.gov/research/milestones/diagnosis -assessment -and-disease -monitoring/enabling -tech-scalable -wearables 66 • NIH’s National Cancer Institute (NCI) -DOE collaboration as a part of the Cancer Moonshot297 accelerates advances in precision oncology and scientific computing, including the use of AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_264",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-programs -conducted -osel/artificial -intelligence -program -research -aiml-based - medical -devices 294 https://new.nsf.gov/funding/opportunities/fdt -biotech -foundations -digital -twins -catalyzers -biomedical 295 https://grants.nih.gov/funding/find -a-fit-for-your-research -nih-institutes -centers -offices 296 https://www.nia.nih.gov/research/milestones/diagnosis -assessment -and-disease -monitoring/enabling -tech-scalable -wearables 66 • NIH’s National Cancer Institute (NCI) -DOE collaboration as a part of the Cancer Moonshot297 accelerates advances in precision oncology and scientific computing, including the use of AI. HHS near -term priorities: • Leverage and continue to build upon existing initiatives around the use of AI in medical products and across the medical product life cycle . • Explore approaches to a PPP that advances innovation, commercialization, and risk -mitigation methods for AI in medical products and across the medical product life cycle to help promote safe, responsible, fair, privacy -protecting, and trustworthy AI in the space as articulated in E.O. 11410.298 • Evaluate approaches to continue expanding the Total Product Life Cycle Advisory Pilot (TAP)299 and Early Payer Feedback Program (EPFP) to accelerate the identification of innovation, adoption, and commercialization barriers to AI, especially for developers less familiar with device marketing authorization processes and payer coverage decision -making."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_265",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nprivacy -protecting, and trustworthy AI in the space as articulated in E.O. 11410.298 • Evaluate approaches to continue expanding the Total Product Life Cycle Advisory Pilot (TAP)299 and Early Payer Feedback Program (EPFP) to accelerate the identification of innovation, adoption, and commercialization barriers to AI, especially for developers less familiar with device marketing authorization processes and payer coverage decision -making. o Coordinate with strategic investments targeting underinvested TAs. HHS long -term priorities: • Continue monitoring and evaluating trends and emerging issues to detect potential knowledge gaps and opportunities that may permit timely adaptations that provide clarity for using AI in the medical product life cycle . • Continue working closely with global collaborators to promote international cooperation on standards, guidelines, and best practices to encourage collaboration in using and evaluating AI across the medical product landscape. • Explore resourcing for developing educational initiatives to support regulatory bodies, healthcare professionals, patients, researchers, and private sector industry as they navigate the safe and responsible use of AI in medical product s and their development. • Explore resourcing to support regulatory science efforts to develop additional methodologies for evaluating AI algorithms, identifying and mitigating bias, and ensuring their robustness and resilience to changing clinical inputs and conditions."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_266",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsupport regulatory bodies, healthcare professionals, patients, researchers, and private sector industry as they navigate the safe and responsible use of AI in medical product s and their development. • Explore resourcing to support regulatory science efforts to develop additional methodologies for evaluating AI algorithms, identifying and mitigating bias, and ensuring their robustness and resilience to changing clinical inputs and conditions. 2.6.2 Promote Trustworthy AI Development and Ethical and Responsible Use HHS will promote the trustworthy, ethical, and responsible use of AI in medical products or across the medical product life cycle as follows : 1. Refining regulatory frameworks to address adaptive AI technologies in medical devices 2. Promoting equity in AI deployment to bolster safe and responsible use 3. Addressing AI -enabled software outside current device regulatory authorities 4. Fostering private or public mechanisms for quality assurance of health AI Below, HHS discusses the context of each area in more detail, corresponding actions to date, and forward -looking plans to ensure AI use is trustworthy and safe for use in medical products and across the medical product life cycle ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_267",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI -enabled software outside current device regulatory authorities 4. Fostering private or public mechanisms for quality assurance of health AI Below, HHS discusses the context of each area in more detail, corresponding actions to date, and forward -looking plans to ensure AI use is trustworthy and safe for use in medical products and across the medical product life cycle . 297 https://datascience.cancer.gov/collaborations/nci -department -energy -collaboration 298 https://www.federalregister.gov/documents/2023/11/01/2023 -24283/safe -secure -and-trustworthy -development -and-use-of-artificial -intelligence 299 https://www.fda.gov/medical -devices/how -study -and-market -your-device/total -product -life-cycle -advisory -program -tap 67 1. Refining regulatory frameworks to address adaptive AI in medical devices Context: The FDA’s traditional paradigm of medical device regulation may not have been designed for adaptive AI technologies that could continuously change and optimize device performance in real time to improve patient healthcare . The current regulatory approach is to monitor the performance and safety of a device as configured at marketing authorization300 and may not address adaptive technologies such as AI, which may deviate considerably from what was originally presented for authorization. Most FDA -authorized medical devices come through the 510(k) -pathway based on demonstrating substantial equivalence to a lawfully marketed “predicate” device."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_268",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nThe current regulatory approach is to monitor the performance and safety of a device as configured at marketing authorization300 and may not address adaptive technologies such as AI, which may deviate considerably from what was originally presented for authorization. Most FDA -authorized medical devices come through the 510(k) -pathway based on demonstrating substantial equivalence to a lawfully marketed “predicate” device. As the complexity of such technologies increases, more specific and explicit premarket demonstrations of the safety and effectiveness of such products may help account for adaptive AI and other technologies. The highly iterative, autonomous, and adaptive nature of these tools may benefit from a total product life cycle (TPLC) ,301 a regulatory approach that facilitates a rapid product improvement cycle and allows these devices to improve while continually providing effective safeguards . With appropriately tailored regulatory oversight, AI can deliver safe and effective functionality that improves the quality of patient care. HHS actions to date (non -exhaustive): • FDA’s Action Plan for Artificial Intelligence and Machine Learning Based Software as a Medical Device (SaMD)302 from 2021 outlined a multipronged approach to advance the agency’s oversight of these technologies ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_269",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\neffective safeguards . With appropriately tailored regulatory oversight, AI can deliver safe and effective functionality that improves the quality of patient care. HHS actions to date (non -exhaustive): • FDA’s Action Plan for Artificial Intelligence and Machine Learning Based Software as a Medical Device (SaMD)302 from 2021 outlined a multipronged approach to advance the agency’s oversight of these technologies . FDA has: o Issued draft guidance on marketing submission recommendations for predetermined change control plans for AI -enabled device software functions.303 o Published Guiding Principles on Good Machine Learning Practice for Medical Device Development304 with our partners from Health Canada and the U.K.’s Medicines and Healthcare products Regulatory Agency (MHRA). o Hosted a public workshop on Transparency of AI-enabled Medical Devices.305 o Released a “Spotlight: Digital Health Regulatory Science Opportunities.” The Spotlight highlights common digital health interest areas , including AI and ML, among other topics . It presents these current regulatory science areas of interest in digital health for all to consider.306 • ARPA -H’s Performance and Reliability Evaluation for Continuous Modifications and Useability of Artificial Intelligence ( PRECISE -AI) program307 funds investigation to develop technology that can detect when AI -enabled tools used in clinical care settings are out of alignment with underlying training data and auto -correct them."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_270",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nregulatory science areas of interest in digital health for all to consider.306 • ARPA -H’s Performance and Reliability Evaluation for Continuous Modifications and Useability of Artificial Intelligence ( PRECISE -AI) program307 funds investigation to develop technology that can detect when AI -enabled tools used in clinical care settings are out of alignment with underlying training data and auto -correct them. HHS near -term priorities: • Explore policies for using AI to produce information for regulatory decision -making, including potential approaches to defining questions of interest, contexts of use, model risks, and model output credibility. • Explore “model card” approaches across various regulatory frameworks for AI. 300 https://www.fda.gov/medical -devices/510k -clearances/medical -device -safety -and-510k -clearance -process 301 https://www.fda.gov/about -fda/cdrh -transparency/total -product -life-cycle -medical -devices The use of AI in the medical product life cycle for the development of drugs, biological products, devices, or combination products may differ. For example, for drugs and biological products, the end product is typically the drug or biological product its elf, which will generally not include AI in that end product. For devices, the end product is the device, which may itself be AI-enabled. When describing the life cycle of a medical device, including AI -enabled devices, the term “Total Product Life Cycle, ” or TPLC, is often used."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_271",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe end product is typically the drug or biological product its elf, which will generally not include AI in that end product. For devices, the end product is the device, which may itself be AI-enabled. When describing the life cycle of a medical device, including AI -enabled devices, the term “Total Product Life Cycle, ” or TPLC, is often used. For more information, see Total Product Life Cycle for Medical Devices, September 6, 2023 (link at the beginning of this footnote). 302 https://www.fda.gov/media/145022/download 303 https://www.fda.gov/regulatory -information/search -fda-guidance -documents/predetermined -change -control -plans -medical -devices 304 https://www.fda.gov/media/153486/download 305 https://www.nature.com/articles/s41746 -023-00992 -8 306 https://www.fda.gov/media/162644/download 307 https://arpa -h.gov/research -and-funding/programs/precise -ai 68 • Develop standards, guidelines, and innovative science -based approaches to assess the safety, effectiveness, and/or performance of AI -enabled medical devices . • Explore resourcing for research on evaluating and monitoring AI performance in medical devices. • Explore resourcing for evaluating and using robust AI tools to model drift in medical devices as a potential complement to the ARPA -H PRECISE -AI program. • Incorporate AI for regulatory submissions by sponsors and FDA internal review processes."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_272",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nof AI -enabled medical devices . • Explore resourcing for research on evaluating and monitoring AI performance in medical devices. • Explore resourcing for evaluating and using robust AI tools to model drift in medical devices as a potential complement to the ARPA -H PRECISE -AI program. • Incorporate AI for regulatory submissions by sponsors and FDA internal review processes. HHS long -term priorities: • Continue refining and developing considerations for evaluating the safe, effective, responsible, and ethical use of AI in the medical product life cycle (e.g., AI provides adequate transparency and addresses safety, effectiveness, and cybersecurity concerns). 2. Promoting equity in AI deployment to bolster safe and responsible use Context: FDA is taking steps to advance health equity in the context of medical products.308 ASTP requirements on certified health IT products do include health equity components;309 However, the scope of ASTP regulations is limited to certified health IT or products , including certified health IT. As the use of AI in medical products and across the medical product life cycle continues to increase, HHS can consider approaches to bolster health equity in this area."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_273",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nASTP requirements on certified health IT products do include health equity components;309 However, the scope of ASTP regulations is limited to certified health IT or products , including certified health IT. As the use of AI in medical products and across the medical product life cycle continues to increase, HHS can consider approaches to bolster health equity in this area. HHS actions to date: • FDA’s Artificial Intelligence and Medical Products: How CBER, CDER, CDRH, and OCP Are Working Together paper310 discusses how FDA’s medical product centers work closely with developers, patient groups, academia, global regulators, and other stakeholders to cultivate a patient - centered regulatory approach emphasizing collaboration and health equity. The paper also describes FDA’s support for projects considering health inequities associated with using AI in medical product development to promote equity and ensure data representativeness, leveraging ongoing diversity, equity, and inclusion efforts. • ASTP’s blog post Embracing Health Equity by Design311 discusses a multifaceted approach to equity in healthcare IT. It includes using the right data, selecting the appropriate tools, and ensuring interoperability between systems to reduce bias and ensure all groups are represented proportionately in health t echnology."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_274",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npromote equity and ensure data representativeness, leveraging ongoing diversity, equity, and inclusion efforts. • ASTP’s blog post Embracing Health Equity by Design311 discusses a multifaceted approach to equity in healthcare IT. It includes using the right data, selecting the appropriate tools, and ensuring interoperability between systems to reduce bias and ensure all groups are represented proportionately in health t echnology. • AHRQ’s Digital Healthcare Equity Framework and Practical Guide for Implement ation helps organizations intentionally consider equity in developing and using digital healthcare technologies and solutions. The Guide is a resource for digital healthcare developers, vendors , healthcare systems, clinical providers, and payers ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_275",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nbetween systems to reduce bias and ensure all groups are represented proportionately in health t echnology. • AHRQ’s Digital Healthcare Equity Framework and Practical Guide for Implement ation helps organizations intentionally consider equity in developing and using digital healthcare technologies and solutions. The Guide is a resource for digital healthcare developers, vendors , healthcare systems, clinical providers, and payers . It includes steps and real -world examples for advancing equity across the Digital Healthcare Life Cycle phases .312 Applicable federal law s to date : • Section 1557 of the Affordable Care Act prohibits discrimination based on race, color, national origin, sex, age, and disability in certain health programs and activities through patient care decision support tools, including AI.313 (See Appendix B for additional , non -exhaustive federal policies and regulations ) 308 www.fda.gov/media/180608/download?attachment 309 https://www.healthit.gov/buzz -blog/health -it/embracing -health -equity -by-design 310 https://www.fda.gov/media/177030/download?attachment 311 https://www.healthit.gov/buzz -blog/health -it/embracing -health -equity -by-design 312 https://digital.ahrq.gov/health -it-tools -and-resources/digital -healthcare -equity 313 https://www.hhs.gov/civil -rights/for -individuals/section -1557/index.html 69 HHS near -term priorities: • Explore resourcing for internal and external projects, highlighting different points where bias can be introduced in the AI development life cycle and how it can be addressed through risk management."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_276",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-it/embracing -health -equity -by-design 310 https://www.fda.gov/media/177030/download?attachment 311 https://www.healthit.gov/buzz -blog/health -it/embracing -health -equity -by-design 312 https://digital.ahrq.gov/health -it-tools -and-resources/digital -healthcare -equity 313 https://www.hhs.gov/civil -rights/for -individuals/section -1557/index.html 69 HHS near -term priorities: • Explore resourcing for internal and external projects, highlighting different points where bias can be introduced in the AI development life cycle and how it can be addressed through risk management. • Disseminate research on best practices for documenting and ensuring that data used to train and test AI models are fit for use and adequately represent the target population to help bolster equity considerations that promote safe and responsible AI use . • Explore resourcing for projects considering health inequities associated with using AI in medical product development to promote equity and ensure data representativeness, leveraging ongoing diversity, equity, and inclusion efforts , to help ensure ethical and trustworthy use of AI in medical products and their development . • Explore resourcing for clinical trials leveraging AI to address areas of unmet need or those where the pipeline does not meet the burden."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_277",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI in medical product development to promote equity and ensure data representativeness, leveraging ongoing diversity, equity, and inclusion efforts , to help ensure ethical and trustworthy use of AI in medical products and their development . • Explore resourcing for clinical trials leveraging AI to address areas of unmet need or those where the pipeline does not meet the burden. HHS long -term priorities: • Continue to e xplore resourcing for internal and external projects, highlighting different points where bias can be introduced in the AI development life cycle and how it can be addressed through risk management. 3. Addressing AI -enabled software outside current device regulatory authorities Context: An increasing number of AI tools in health IT could fall outside FDA regulation, including certain EHR - integrated AI decision support tools (e.g., appointment no -show prediction) and AI algorithms deployed by health plans and insurance issuers for utilization management and prior authorization. Authority over the regulation of health IT, which is not medical devices, belongs part ly to the ASTP/ ONC . Tools that do not meet the FDA’s device definition may not undergo regulatory review, validation, or testing.314 This is an area that HHS will continue to monitor closely."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_278",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nby health plans and insurance issuers for utilization management and prior authorization. Authority over the regulation of health IT, which is not medical devices, belongs part ly to the ASTP/ ONC . Tools that do not meet the FDA’s device definition may not undergo regulatory review, validation, or testing.314 This is an area that HHS will continue to monitor closely. HHS actions to date: • ASTP /ONC’s HTI -1 Final Rule315 finalized policies that require certain certified health IT (such as EHR health IT products certified to the certification criterion at 45 CFR 170.315(b)(11)) to enable users to access information about the design, development, training, and evaluation of AI (called predictive decision support interventions or PDSIs) to help users determine whether the tool is appropriate for their care setting and patient population. • FDA CDS Software Guidance for Industry and FDA Staff316 provides clarification on the 21st Century Cures Act legislation that excludes certain CDS software from the FDA’s device jurisdiction, which helps elucidate the complexities of certain uses of AI in healthcare technology that are not regulated as devices. HHS near -term priorities: • Assess mechanisms to ensure appropriate oversight of AI outside FDA regulatory authority and continuously monitor advances in the ecosystem ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_279",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe 21st Century Cures Act legislation that excludes certain CDS software from the FDA’s device jurisdiction, which helps elucidate the complexities of certain uses of AI in healthcare technology that are not regulated as devices. HHS near -term priorities: • Assess mechanisms to ensure appropriate oversight of AI outside FDA regulatory authority and continuously monitor advances in the ecosystem . • Explore approaches for: o “Model card” information for AI -based technologies outside of FDA’s jurisdiction o Bolstering the validation of AI -based models with clinical data o Including health equity considerations in regulatory pathways 314 https://www.fda.gov/regulatory -information/search -fda-guidance -documents/clinical -decision -support -software 315 https://www.healthit.gov/topic/laws -regulation -and-policy/health -data-technology -and-interoperability -certification -program . 316 https://www.fda.gov/regulatory -information/search -fda-guidance -documents/clinical -decision -support -software 70 o Public -private collaboration models for rigorous, standards -based, pre -, and postmarket quality assurance of AI -based technologies outside of FDA’s jurisdiction HHS long -term priorities: • Iteratively monitor and reevaluate regulatory oversight mechanisms of AI in medical and health technologies outside of FDA’s jurisdiction as the field rapidly evolves ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_280",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nhttps://www.fda.gov/regulatory -information/search -fda-guidance -documents/clinical -decision -support -software 70 o Public -private collaboration models for rigorous, standards -based, pre -, and postmarket quality assurance of AI -based technologies outside of FDA’s jurisdiction HHS long -term priorities: • Iteratively monitor and reevaluate regulatory oversight mechanisms of AI in medical and health technologies outside of FDA’s jurisdiction as the field rapidly evolves . • Explore opportunities to collect feedback about AI in medical and health technologies outside FDA’s jurisdiction to monitor the potential impacts of such technologies on healthcare. 4. Fostering private or public mechanisms for quality assurance of health AI Context: Despite the promise of AI tools in medicine, the ability to prospectively test AI tools across diverse datasets and deploy AI in multiple clinical care settings to ensure consistency, accuracy, and generalizability in improving health outcomes can be limited by the availability of such datasets and inconsistent monitoring in clinical use. Testing of AI to identify potential biases, disparities, or inconsistencies in AI model performance and optimizing AI models for diverse healthcare environments can be imp roved through increased availability of data and improved monitoring capabilities."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_281",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto ensure consistency, accuracy, and generalizability in improving health outcomes can be limited by the availability of such datasets and inconsistent monitoring in clinical use. Testing of AI to identify potential biases, disparities, or inconsistencies in AI model performance and optimizing AI models for diverse healthcare environments can be imp roved through increased availability of data and improved monitoring capabilities. The absence of standardized quality assurance (QA) protocols designed to evaluate performance in real -world settings to ensure continued patient and provider safety increase s the risk of inconsistent implementation across sites and unintended consequences.317, 318 Even AI tools that received regulatory clearance for clinical use may underperform when deployed in new clinical settings due to poor generalization or when used for a purpose other than its authorized intended use. These cases highlight the challenges AI tools face in medicine due to biases in development data (e.g., training, tuning, internal test sets used by the developer to create the tool) and the potential distribution shifts in the characteristics of external, previously unused test sets or patient cases."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_282",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ngeneralization or when used for a purpose other than its authorized intended use. These cases highlight the challenges AI tools face in medicine due to biases in development data (e.g., training, tuning, internal test sets used by the developer to create the tool) and the potential distribution shifts in the characteristics of external, previously unused test sets or patient cases. For the safe and effective integration of AI tools into the clinical workflow, “transparency319 from manufacturers about the development process ,” and the implementation of QA programs could be necessary.320 HHS actions to date: • FDA’s collaboration with the Department of Veterans Affairs ,321 announced in October 2024 , will be an “interagency testing ground ” for healthcare -related AI tools. The lab will “serve as an asset for federal agencies and the private sector ‘to be able to test applications of AI in a virtual lab environment to ensure not only that they work and that they're safe and effective for veterans and patients, ’ but that they also ‘adhere to trustworthy AI principles ,’” according to V A Undersecretary for Health Shereef Elnahal. HHS near -term priorities: • Collaborate with public and private networks on testing health AI to provide shared resources and infrastructure that encourage safe and effective development, transparency, reporting, and ongoing monitoring of health AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_283",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\neffective for veterans and patients, ’ but that they also ‘adhere to trustworthy AI principles ,’” according to V A Undersecretary for Health Shereef Elnahal. HHS near -term priorities: • Collaborate with public and private networks on testing health AI to provide shared resources and infrastructure that encourage safe and effective development, transparency, reporting, and ongoing monitoring of health AI. • Consider supporting guidelines and educational tools to help AI developers as they work toward safety, security, and trust while creating AI technologies for use in medical products and across the medical product life cycle . 317 https://pmc.ncbi.nlm.nih.gov/articles/PMC5438240/ 318 https://aapm.onlinelibrary.wiley.com/doi/10.1002/mp.16188 319 See FDA’s “ Transparency for Machine Learning -Enabled Medical Devices: Guiding Principles ” for more information on “transparency” in th is context: https://www.fda.gov/medical -devices/software -medical -device -samd/transparency -machine -learning -enabled -medical -devices -guiding -principles 320 https://pmc.ncbi.nlm.nih.gov/articles/PMC10928809/#ubae003 -B19 321 https://www.nextgov.com/artificial -intelligence/2024/10/va -announces -creation -new-ai-testing -ground -fda/400681/?oref=ng -homepage -river 71 HHS long -term priorities: • Explore resourcing to develop regulatory science approaches to assess the accuracy and reliability of AI models once deployed in a healthcare environment."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_284",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ninformation on “transparency” in th is context: https://www.fda.gov/medical -devices/software -medical -device -samd/transparency -machine -learning -enabled -medical -devices -guiding -principles 320 https://pmc.ncbi.nlm.nih.gov/articles/PMC10928809/#ubae003 -B19 321 https://www.nextgov.com/artificial -intelligence/2024/10/va -announces -creation -new-ai-testing -ground -fda/400681/?oref=ng -homepage -river 71 HHS long -term priorities: • Explore resourcing to develop regulatory science approaches to assess the accuracy and reliability of AI models once deployed in a healthcare environment. 2.6.3 Democratize AI Technologies and Resources To effectively capture the value of AI in medical products across the medical product life cycle while mitigating associated risks, technology uptake and innovation could benefit from equitable access throughout the ecosystem across a diverse set of players (e.g., medical technology companies, academia, non -profits, and public sector entities) and st akeholders (e.g., from different demographic backgrounds). Without such accessibility, capturing the full value potential of AI in the space might not be feasib le or fully account for risks. HHS plans to play a key role in mitigating this by integrating equity principles into the expansion of AI in medical products along the following key themes of action : 1. Enabling collaborative development through public engagement 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_285",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsuch accessibility, capturing the full value potential of AI in the space might not be feasib le or fully account for risks. HHS plans to play a key role in mitigating this by integrating equity principles into the expansion of AI in medical products along the following key themes of action : 1. Enabling collaborative development through public engagement 2. Aligning standards and information -sharing mechanisms across research and healthcare delivery Below, HHS discusses the context of each theme of action in more detail, corresponding actions to date, and plans to ensure equitable access to AI technologies and resources in medical products. 1. Enabling collaborative development through public engagement Context: Increased stakeholder collaboration could democratize AI technologies and best practices in medical products and across the medical product life cycle . A lack of collaboration between stakeholders (e.g., private sector industry, STLTs, academia, and the general public) and intentional public engagement throughout the medical products life cycle could limit the potential of AI to be equitably adopted broadly across medical products and their development."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_286",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndemocratize AI technologies and best practices in medical products and across the medical product life cycle . A lack of collaboration between stakeholders (e.g., private sector industry, STLTs, academia, and the general public) and intentional public engagement throughout the medical products life cycle could limit the potential of AI to be equitably adopted broadly across medical products and their development. 72 HHS actions to date: • NIH’s AIM -AHEAD Program is designed to support mutually beneficial triadic partnerships among (1) local, state, and tribal accredited health departments; (2) limited -resource higher education institutions; and (3) a data -science -oriented organization with an accessible data libr ary to collaboratively conduct health -equity -related AI studies.322 These critical and trusted organizations can benefit from enhancing their AI capabilities to advance public health, from early detection and monitoring, predictive analytics, disease surveillance and monitoring, and outbreak detection to healthcare resource allocation and personalized interventions. Partnerships among public healt h department professionals, academic researchers, and data -science/ AI experts can further leverage data - driven insights that contribute to more effective and efficient public health strategies to improve community health outcomes."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_287",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nadvance public health, from early detection and monitoring, predictive analytics, disease surveillance and monitoring, and outbreak detection to healthcare resource allocation and personalized interventions. Partnerships among public healt h department professionals, academic researchers, and data -science/ AI experts can further leverage data - driven insights that contribute to more effective and efficient public health strategies to improve community health outcomes. • The Department of Energy and the NIH’s collaboration through the National Artificial Intelligence Research Resource (NAIRR) Secure Pilot will “enable research that involves sensitive data, which require special handling and protections. The NAIRR Secure pilot will assemble exemplar privacy/security -preserving resources (e.g., data enclaves, secure compute resources, and privacy - preserving tools) and develop requirements for the future NAIRR Secure. ”323 HHS near -term priorities: • Develop a vision and framework for incorporating public voices in all parts of the medical products life cycle .324 • Convene a public -private community of practice for sharing best practices and identifying enablers/barriers to AI adoption in clinical studies. • Refine and develop a more robust STLT engagement strategy regarding medical products where appropriate to ensure best practices on AI are shared between all levels of government."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_288",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nvoices in all parts of the medical products life cycle .324 • Convene a public -private community of practice for sharing best practices and identifying enablers/barriers to AI adoption in clinical studies. • Refine and develop a more robust STLT engagement strategy regarding medical products where appropriate to ensure best practices on AI are shared between all levels of government. HHS long -term priorities: • Offer secure sandboxes325 to encourage collaborative innovation in developing and using AI for medical products. • Engage in public and private collaborations, fostering long-term relationships between the private sector industry, providers, and the public that can be tapped for co -creation. • Explore resourcing for multi -institutional collaboration mechanisms, especially those potentially under - resourced organizations that could benefit from knowledge or infrastructure sharing. 2. Aligning standards and information -sharing mechanisms across research and healthcare delivery Context: Clear standards for data, metadata, and pathways to share information can make AI innovation easier to access."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_289",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthat can be tapped for co -creation. • Explore resourcing for multi -institutional collaboration mechanisms, especially those potentially under - resourced organizations that could benefit from knowledge or infrastructure sharing. 2. Aligning standards and information -sharing mechanisms across research and healthcare delivery Context: Clear standards for data, metadata, and pathways to share information can make AI innovation easier to access. A lack of clear standards can make data across private sector industries, academia, non -profits, governments, and other players unusable or non -transferable to AI models, stifling AI uptake in medical products and across the medical product life cycle .326 Barriers to sharing data can be more prohibitive to innovation for stakeholders with less access to resources than for those with higher resources who can fund data collection or data cleaning activities. 322 https://datascience.nih.gov/artificial -intelligence/aim -ahead 323 https://nairrpilot.org/nairr -secure 324 https://osp.od.nih.gov/policies/novel -and-exceptional -technology -and-research -advisory -committee -nextrac , This is the current charge of an NIH FACA called the NExTRAC. 325 See Appendix A: “Glossary of terms” for the definition of “sandbox” used in this Plan."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_290",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nresources than for those with higher resources who can fund data collection or data cleaning activities. 322 https://datascience.nih.gov/artificial -intelligence/aim -ahead 323 https://nairrpilot.org/nairr -secure 324 https://osp.od.nih.gov/policies/novel -and-exceptional -technology -and-research -advisory -committee -nextrac , This is the current charge of an NIH FACA called the NExTRAC. 325 See Appendix A: “Glossary of terms” for the definition of “sandbox” used in this Plan. 326 https://pmc.ncbi.nlm.nih.gov/articles/PMC2213488/ 73 HHS actions to date (non -exhaustive): • ARPA -H’s Imaging Data Partnership with the CDRH of FDA aims to streamline access to affordable, high-quality medical imaging data.327 The agencies work together to develop a medical imaging data marketplace to accelerate AI and ML innovation by removing barriers to obtaining data that align with regulatory quality standards and appropriately represent the relevant portions of the U.S. p opulation."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_291",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nARPA -H’s Imaging Data Partnership with the CDRH of FDA aims to streamline access to affordable, high-quality medical imaging data.327 The agencies work together to develop a medical imaging data marketplace to accelerate AI and ML innovation by removing barriers to obtaining data that align with regulatory quality standards and appropriately represent the relevant portions of the U.S. p opulation. • ARPA -H’s Biomedical Data Fabric toolbox seeks to facilitate the connection of biomedical research data from thousands of sources, advancing the collection and usability of biomedical datasets originating from thousands of different research labs, clinical care centers, and other data sources and accelera ting technical innovation across the health ecosystem.328 By (1) lowering barriers to high -fidelity, timely data collection in computer -readable forms, (2) preparing for multisource data analysis at scale, (3) advancing intuitive data exploration, (4) improving stakeholder access while maintaining privacy and security measures, and (5) ensuring generalizability of biomedical data fabric tools across disease types, ARPA -H is democratizing access to data. These data must be findable, accessible, interoperable, and reusable ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_292",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-fidelity, timely data collection in computer -readable forms, (2) preparing for multisource data analysis at scale, (3) advancing intuitive data exploration, (4) improving stakeholder access while maintaining privacy and security measures, and (5) ensuring generalizability of biomedical data fabric tools across disease types, ARPA -H is democratizing access to data. These data must be findable, accessible, interoperable, and reusable . NIH’s Generalist Repository Ecosystem Initiative (GREI) supports seven established generalist repositories that work together to establish consistent metadata, develop use cases for data sharing and reuse, and train and educate researchers on how to share and reuse data, including for the development and use of AI.329 • NIH’s Toward an Ethical Framework for Artificial Intelligence in Biomedical and Behavioral Research: Transparency for Data and Model Reuse Workshop focused on highlighting the importance of standardizing the safe shareability of synthetic data, data sharing for general reuse, and multimodal data, which can lead to transformational product development if leveraged in AI tools.330 HHS near -term priorities: • Release draft guidelines on data-sharing principles consistent with the HHS Data Strategy, including common approaches to structuring data and metadata and clarity around what data types can be published and shared.331 • Offer secure sandboxes332 to spur collaborat ions in data sharing and standards development."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_293",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nlead to transformational product development if leveraged in AI tools.330 HHS near -term priorities: • Release draft guidelines on data-sharing principles consistent with the HHS Data Strategy, including common approaches to structuring data and metadata and clarity around what data types can be published and shared.331 • Offer secure sandboxes332 to spur collaborat ions in data sharing and standards development. • Develop open -industry standards and open -source tooling and infrastructure for registries to leverage AI to support device pre - and postmarket submission requirements, cross -standard data mapping, and de - identification to develop AI -ready datasets and tool ing. • Accelerate work with standards development organizations and industry collaborations on standards to support AI development and use across the life cycle . • Accelerate alignment of federally funded research data standards (semantic, format, and transport) with HHS -adopted standards for EHRs, healthcare providers, and payers (e.g., USCDI, USCDI+, HL7, FHIR, and CARIN). HHS long -term priorities: • As the landscape changes for public access to research results, data management, and sharing, HHS may need to build added capacity to assist key players in refining standards for both."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_294",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nfunded research data standards (semantic, format, and transport) with HHS -adopted standards for EHRs, healthcare providers, and payers (e.g., USCDI, USCDI+, HL7, FHIR, and CARIN). HHS long -term priorities: • As the landscape changes for public access to research results, data management, and sharing, HHS may need to build added capacity to assist key players in refining standards for both. 327 https://arpa -h.gov/news -and-events/arpa -h-announces -medical -imaging -data-partnership -fda 328 https://arpa -h.gov/research -and-funding/programs/arpa -h-bdf-toolbox 329 https://datascience.nih.gov/data -ecosystem/generalist -repository -ecosystem -initiative 330 https://datascience.nih.gov/sites/default/files/ai -meetings/NIH -Transparency -Workshop -Report -v6-FINAL -updated -09-16-24-508.pdf 331 https://cdo.hhs.gov/s/hhs -data-strategy 332 See Appendix A: “Glossary of terms” for the definition of “sandbox” used in this Plan 74 2.6.4 Cultivate AI -Empowered Workforces and Organization Cultures Without a sufficient supply of talent in AI to enable innovation at scale in medical products and across the medical product life cycle , widescale adoption and effective uptake may not be feasible. To that end, HHS plans to spur workforce development externally and internally to empower continued responsible, safe innovation of AI across the medical product life cycle by focusing on key themes of actions : 1. Improving training in the governance and management of AI in medical products 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_295",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nlife cycle , widescale adoption and effective uptake may not be feasible. To that end, HHS plans to spur workforce development externally and internally to empower continued responsible, safe innovation of AI across the medical product life cycle by focusing on key themes of actions : 1. Improving training in the governance and management of AI in medical products 2. Developing and retaining AI talent related to medical products Below, HHS discusses the context of this goal in more detail, corresponding actions to date, and plans to cultivate AI-empowered workforces and organizational cultures in medical products. 1. Improving training in the governance and management of AI in medical products Context: Most individuals involved in AI will be responsible for managing and using such technologies rather than developing them. Ensuring that the medical product ecosystem (including developers, clinicians, and patients) gets the most out of AI will require focusing not just on the technologies themselves but also on their implementation, workflow integration, and life cycle management. Training to enable the research workforce to responsibly manage and use such technologies will be critical to harnessing AI to a dvance medical products."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_296",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthat the medical product ecosystem (including developers, clinicians, and patients) gets the most out of AI will require focusing not just on the technologies themselves but also on their implementation, workflow integration, and life cycle management. Training to enable the research workforce to responsibly manage and use such technologies will be critical to harnessing AI to a dvance medical products. HHS actions to date (non -exhaustive): • FDA’s blog entry, “A Lifecycle Management Approach Toward Deliver ing Safe, Effective AI - Enabled Health Care,”333 provide s an overview of one potential approach to developing, validating, and managing ongoing governance of AI use in medical devices to maintain their safety and effectiveness. This approach could provide a foundation for HHS to build upon to develop further best practices for training on governance and management of AI in medical devices and during their development. HHS near -term priorities: • Explore targeting resources, training, and workshops to include governance and management of AI technologies in clinical research, including in clinical trial design and management. HHS long -term priorities: • Develop internal data science, computer science, and AI talent related to medical products through targeted internal trainings or apprenticeship programs. 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_297",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndevices and during their development. HHS near -term priorities: • Explore targeting resources, training, and workshops to include governance and management of AI technologies in clinical research, including in clinical trial design and management. HHS long -term priorities: • Develop internal data science, computer science, and AI talent related to medical products through targeted internal trainings or apprenticeship programs. 2. Developing and retaining AI talent related to medical products Context: To harness the potential of AI , the private sector industry, government, academia, non -profits, and other involved parties may need a strong pipeline for a diverse workforce capable of developing and embedding AI to enhance medical products and their development. Professionals from all backgrounds w ill need baseline knowledge to develop and apply AI safely, responsibly, and effectively. Therefore, developing and retaining AI talent related to medical products could be critical to growing and maintaining inn ovation."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_298",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nparties may need a strong pipeline for a diverse workforce capable of developing and embedding AI to enhance medical products and their development. Professionals from all backgrounds w ill need baseline knowledge to develop and apply AI safely, responsibly, and effectively. Therefore, developing and retaining AI talent related to medical products could be critical to growing and maintaining inn ovation. 333 https://www.fda.gov/medical -devices/digital -health -center -excellence/blog -lifecycle -management -approach -toward -delivering -safe-effective -ai-enabled -health -care 75 HHS actions to date: • FDA’s STEM Outreach, Education, and Engagement Program seeks to provide educational opportunities to prospective scientists, raise awareness of the FDA as a science -based agency, expose students to the broad scope of regulatory science and its impact on our lives, inspire future innovators to pursue the wide r ange of scientific careers that make up the field of regulatory science at the FDA, and recruit and hire scientists.334 Though the program is generally oriented toward the FDA, it enhances the overall talent ecosystem and can explore additional focuses related to AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_299",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nof regulatory science and its impact on our lives, inspire future innovators to pursue the wide r ange of scientific careers that make up the field of regulatory science at the FDA, and recruit and hire scientists.334 Though the program is generally oriented toward the FDA, it enhances the overall talent ecosystem and can explore additional focuses related to AI. • NIH’s Bridge2AI program creates flagship datasets based on ethical principles, associated standards and tools, and skills and workforce development to address grand challenges in biomedical and behavioral research that require AI analysis.335 • FDA’s scientific internships and fellowships offer undergraduate and graduate students the chance to explore careers related to research, regulatory science, and other STEM fields that develop potential future FDA and other technical talent in the workforce.336 Though the program is generally oriented toward the FDA, it enhances the overall talent ecosystem and can help promote the exploration of additional focuses related to AI across medical products. • HHS integrated AI into enterprise activities (see the Internal Operations chapter) and released a public tracker of all use cases.337 As of 2023, there were 164 AI use cases across HHS and its divisions, including deduplicating data, detecting adverse events, monitoring safety, managing signal detection, visualizing data, and analyzing texts."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_300",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nof additional focuses related to AI across medical products. • HHS integrated AI into enterprise activities (see the Internal Operations chapter) and released a public tracker of all use cases.337 As of 2023, there were 164 AI use cases across HHS and its divisions, including deduplicating data, detecting adverse events, monitoring safety, managing signal detection, visualizing data, and analyzing texts. For example, the FDA is exploring the use of AI in various fields, including deduplicating non -public adverse event data in the FAERS and identifying novel terms for opioid -related drugs using the Term Identification and Novel Synthetic Opioid Detection and Evaluation Analytics tool, which uses publicly available social media and forensic chemistry data to identify novel referents to drug products in social media texts.338 HHS near -term priorities: • Expand internship and apprenticeship programs to incorporate AI -specific roles related to medical products and their development. • Explore additional resourcing for existing outreach, education, and engagement programs to incorporate AI-specific content, particularly those related to medical products and their development. • Evaluate the expansion of NIH’s AIM -AHEAD Program to include recruitment and training for AI expertise in clinical research."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_301",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ninternship and apprenticeship programs to incorporate AI -specific roles related to medical products and their development. • Explore additional resourcing for existing outreach, education, and engagement programs to incorporate AI-specific content, particularly those related to medical products and their development. • Evaluate the expansion of NIH’s AIM -AHEAD Program to include recruitment and training for AI expertise in clinical research. 2.7 Conclusion AI can be a medical device, be part of a medical device, enhance the design and conduct of clinical trials, streamline manufacturing and supply chains, and bolster postmarket surveillance and monitoring of medical products, ultimately improving patient care and accessibility to innovative medical products. However, the rapid advancement of AI also presents challenges that should be addressed. HHS’s balanced approach aims to foster AI innovation while maintaining robust regulatory frameworks that ensure medi cal products remain safe, effective, and high quality."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_302",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nmanufacturing and supply chains, and bolster postmarket surveillance and monitoring of medical products, ultimately improving patient care and accessibility to innovative medical products. However, the rapid advancement of AI also presents challenges that should be addressed. HHS’s balanced approach aims to foster AI innovation while maintaining robust regulatory frameworks that ensure medi cal products remain safe, effective, and high quality. 334 https://www.fda.gov/science -research/fda -stem-outreach -education -and-engagement 335 https://commonfund.nih.gov/sites/default/files/OT2 -Data-Generation -Projects -B2AI -051321 -508.pdf 336 https://www.fda.gov/about -fda/jobs -and-training -fda/scientific -internships -fellowships -trainees -and-non-us-citizens 337 https://www.hhs.gov/sites/default/files/hhs -ai-use-cases -2023 -public -inventory.csv 338 https://www.hhs.gov/sites/default/files/hhs -ai-use-cases -2023 -public -inventory.csv 76 3 Healthcare Delivery 3.1 Introduction and Context U.S. healthcare delivery —defined here as financing, direct provision of patient care, related administrative services and research —is a large and highly complex system. National health expenditures in the U.S. (including public health) were approximately $4.5 T in 2022, representing 17% of the U.S."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_303",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-public -inventory.csv 338 https://www.hhs.gov/sites/default/files/hhs -ai-use-cases -2023 -public -inventory.csv 76 3 Healthcare Delivery 3.1 Introduction and Context U.S. healthcare delivery —defined here as financing, direct provision of patient care, related administrative services and research —is a large and highly complex system. National health expenditures in the U.S. (including public health) were approximately $4.5 T in 2022, representing 17% of the U.S. economy and contributing to the employment of approximately 9% of the nation’s workforce.339, 340 In the U.S., healthcare is delivered by licensed providers and predominately financed by payers (e.g., in 2022, 92% of patients in the U.S. had health insurance).341 A range of stakeholders —beyond patients, providers, and payers —participate in the healthcare delivery ecosystem, including entities that provide resources and technologies that enable care. Many HHS entities, including CMS, HRSA, SAMHSA, IHS, AHRQ, and oth ers, are directly involved in facilitating healthcare delivery or providing guidelines, payment and funding, training, and other operational support to delivery partners."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_304",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nhealth insurance).341 A range of stakeholders —beyond patients, providers, and payers —participate in the healthcare delivery ecosystem, including entities that provide resources and technologies that enable care. Many HHS entities, including CMS, HRSA, SAMHSA, IHS, AHRQ, and oth ers, are directly involved in facilitating healthcare delivery or providing guidelines, payment and funding, training, and other operational support to delivery partners. In healthcare delivery in particular, AI has the potential to enhance a wide range of activities , from care delivery to healthcare finance to research (e.g., health services and behavioral health).342, 343 HHS aspires to maximize the potential benefit of AI to stakeholders across the healthcare delivery system —to do so, it is essential that AI interventions be patient -centric, with transparency, safety, equity, and security at the forefront of implementation considerations .344 It is also imperative to protect the safety and security of Americans by ensuring new technology is tested, deployed, and monitored responsibly. In the following chapter, HHS outlines its four goals and actions specific to healthcare delivery: (1) to catalyze health AI innovation and adoption, (2) promote trustworthy AI development and ethical and responsible use, (3) democratize AI technologies and resources, and (4) cultivate AI-empowered workforces and organization cultures."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_305",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsecurity of Americans by ensuring new technology is tested, deployed, and monitored responsibly. In the following chapter, HHS outlines its four goals and actions specific to healthcare delivery: (1) to catalyze health AI innovation and adoption, (2) promote trustworthy AI development and ethical and responsible use, (3) democratize AI technologies and resources, and (4) cultivate AI-empowered workforces and organization cultures. 3.1.1 Action Plan Summary Later in this chapter, HHS articulates proposed actions to advance its four goals for the responsible use of AI in the sector. Below is a summary of the themes of actions within each goal. For full details of proposed actions please see section 3.6 Action Plan. 339 https://www.cms.gov/newsroom/fact -sheets/national -health -expenditures -2022 -highlights# 340 https://www.bls.gov/spotlight/2023/healthcare -occupations -in-2022/# 341 https://www.cms.gov/newsroom/fact -sheets/national -health -expenditures -2022 -highlights# 342 Health services research refers to activities in applied research settings that improve care delivery processes. 343 https://www.ahrq.gov/healthsystemsresearch/index.html 344 https://pmc.ncbi.nlm.nih.gov/articles/PMC8826344/# 77 Key goals that actions support Themes of proposed actions (not exhaustive, see 3.6 Action Plan for more details) 1."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_306",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAction Plan. 339 https://www.cms.gov/newsroom/fact -sheets/national -health -expenditures -2022 -highlights# 340 https://www.bls.gov/spotlight/2023/healthcare -occupations -in-2022/# 341 https://www.cms.gov/newsroom/fact -sheets/national -health -expenditures -2022 -highlights# 342 Health services research refers to activities in applied research settings that improve care delivery processes. 343 https://www.ahrq.gov/healthsystemsresearch/index.html 344 https://pmc.ncbi.nlm.nih.gov/articles/PMC8826344/# 77 Key goals that actions support Themes of proposed actions (not exhaustive, see 3.6 Action Plan for more details) 1. Catalyzing health AI innovation and adoption • Supporting the ability to gather evidence for effectiveness , safety, and risk mitigation of AI interventions and best practices for implementation in healthcare delivery settings • Providing guidelines and resources on oversight, medical liability, and privacy and security protections to increase confidence for organizations to develop AI • Ensuring developers and potential deployers of AI have clarity on coverage and payment determination processes to encourage development of AI 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_307",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsafety, and risk mitigation of AI interventions and best practices for implementation in healthcare delivery settings • Providing guidelines and resources on oversight, medical liability, and privacy and security protections to increase confidence for organizations to develop AI • Ensuring developers and potential deployers of AI have clarity on coverage and payment determination processes to encourage development of AI 2. Promoting trustworthy AI development and ethical and responsible use • Enhancing enforcement and clarify ing guidelines relating to existing requirements • Providing guidelines and support related to organizational governance • Promoting external evaluation, monitoring, and transparency reporting • Enhancing infrastructure to ensure patient safety 3. Democratizing AI technologies and resources • Promoting equitable access through technical support for and collaboration with delivery organizations that provide services to underserved populations • Providing support for healthcare delivery organizations to address core infrastructure and deployment challenges (i.e., technology, infrastructure, and data infrastructure) that improve AI readiness 4. Cultivating AI - empowered workforces and organization cultures • Equipping healthcare delivery professionals with access to training, resources, and research to support AI literacy and expertise in their respective health system organizations."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_308",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto underserved populations • Providing support for healthcare delivery organizations to address core infrastructure and deployment challenges (i.e., technology, infrastructure, and data infrastructure) that improve AI readiness 4. Cultivating AI - empowered workforces and organization cultures • Equipping healthcare delivery professionals with access to training, resources, and research to support AI literacy and expertise in their respective health system organizations. 3.2 Stakeholders Engaged in the Healthcare Delivery AI Value Chain Healthcare delivery is a highly complex set of activities covering the financing of healthcare through public or private health insurance and the provision of healthcare services through private and public hospitals and ambulatory facilities. Employers and individuals purchase healthcare insurance through various entitie s. Healthcare is delivered by thousands of hospitals and millions of clinicians and other healthcare professionals who offer various services and are regulated by authorities from federal and STLT government entities. Exhibit 7 shows a non -exhaustive, illustrative diagram of example flows between stakeholders and a bulleted list of stakeholders involved healthcare delivery. Please note that neither the diagram nor the list capture s all stakeholder roles and interactions. Please refer to other HHS documents for additional details on regulatory guidance and authorities."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_309",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nby authorities from federal and STLT government entities. Exhibit 7 shows a non -exhaustive, illustrative diagram of example flows between stakeholders and a bulleted list of stakeholders involved healthcare delivery. Please note that neither the diagram nor the list capture s all stakeholder roles and interactions. Please refer to other HHS documents for additional details on regulatory guidance and authorities. Roles may vary depending on healthcare delivery system or activity. 78 Exhibit 7: Healthcare Delivery Stakeholder Engagement Map • HHS divisions and example roles in healthcare delivery (non -exhaustive): o ACF: Administers more than 60 programs that provide benefits and services to support families and children, including promoting economic and social well -being. ACF’s role in the HHS AI Strategic Plan will focus on ensuring effective and equitable delivery of services to children and families that will promote optimal health . o AHRQ: Focuses on improving the quality, safety, efficiency, and effectiveness of healthcare for all Americans through research, technology assessments, and work on dissemination and implementation. AHRQ’s role in the HHS AI Strategic Plan will focus on promoting and conducting research on the safe adoption of AI that enables high -quality care, disseminating actionable, evidence -based AI knowledge, and provisioning evidence required for coverage decisions."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_310",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe quality, safety, efficiency, and effectiveness of healthcare for all Americans through research, technology assessments, and work on dissemination and implementation. AHRQ’s role in the HHS AI Strategic Plan will focus on promoting and conducting research on the safe adoption of AI that enables high -quality care, disseminating actionable, evidence -based AI knowledge, and provisioning evidence required for coverage decisions. o ARPA -H: Conducts transformative, high -impact healthcare research across focus areas, including advancing technical solutions, forging a resilient health ecosystem, and driving scalable solutions. ARPA -H’s role in the HHS AI Strategic Plan will focus on issuing aw ards to catalyze cutting -edge research that will improve healthcare delivery . o CDC: Provides guidelines and research on healthcare delivery for major diseases, supports public health program funding, and may leverage AI to inform and support delivery. CDC’s role in the HHS AI Strategic Plan will focus on researching the efficacy of AI in disease prevention and implementing AI in public health efforts. o CMS: Administers major public healthcare payer programs (e.g., Medicare and Medicaid) and can be involved in setting payment and coverage policies for specific items or services."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_311",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nleverage AI to inform and support delivery. CDC’s role in the HHS AI Strategic Plan will focus on researching the efficacy of AI in disease prevention and implementing AI in public health efforts. o CMS: Administers major public healthcare payer programs (e.g., Medicare and Medicaid) and can be involved in setting payment and coverage policies for specific items or services. CMS’ s role in the HHS AI Strategic Plan will focus on determining coverage and payment of AI -enabled healthcare services, overseeing and certifying state IT systems and data collection standards, and providing technical assistance to providers, states, and othe r stakeholders. As appropriate, CMS will look to use payment and regulat ory policy to ensure trustworthy, responsible use of AI by payers and providers. o FDA: Helps ensure that human and animal drugs, biological products, and medical devices are safe and effective for their intended uses and that electronic products that emit radiation are safe. As AI becomes a more prominent aspect of medical products and their development, manufacturing operations, and use, the FDA will play a continued role in regulating and supporting stakeholders. 79 o HRSA: Provides equitable healthcare to the nation’s highest -need communities, including through programs that support people with low incomes, people with HIV , pregnant women, children, parents, rural communities, transplant patients, and the health workforce."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_312",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\naspect of medical products and their development, manufacturing operations, and use, the FDA will play a continued role in regulating and supporting stakeholders. 79 o HRSA: Provides equitable healthcare to the nation’s highest -need communities, including through programs that support people with low incomes, people with HIV , pregnant women, children, parents, rural communities, transplant patients, and the health workforce. HRSA’s role in the HHS AI Strategic Plan will focus on ensuring the equitable use of AI to benefit underserved communities and educating and training future generations of healthcare professionals . o IHS: Provides healthcare services to American Indian and Alaska Native communities. IHS’s role in the HHS AI Strategic Plan will focus on implementing healthcare delivery within these populations and ensuring the applicability of AI guidelines to relevant STLT s. o NIH: Supports and conducts biomedical and behavioral research across the U.S. and abroad and can help educate the workforce on AI and promote innovation through its initiatives. NIH’s role in the HHS AI Strategic Plan will focus on supporting research on the impact of AI on biomedical and behavioral health, establishing standards i n these areas based on research, and unlocking funding to promote the responsible use of AI across HHS service domains."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_313",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand can help educate the workforce on AI and promote innovation through its initiatives. NIH’s role in the HHS AI Strategic Plan will focus on supporting research on the impact of AI on biomedical and behavioral health, establishing standards i n these areas based on research, and unlocking funding to promote the responsible use of AI across HHS service domains. o SAMHSA: Leads public health efforts to advance the behavioral health of the nation and improve the lives of individuals living with mental and substance use disorders, as well as their families. SAMHSA’s role in the HHS AI Strategic Plan will focus on providing grant funding and guidelines to STLT communities and collecting, analyzing, and distributing behavioral health data to evaluate programs, improve policies, and raise awarene ss of resources on prevention, harm reduction, treatment, and recovery. • Other federal agencies: HHS also works closely with many other federal departments, such as the Department of Veterans Affairs and the Department of Housing and Urban Development. • Patients, beneficiaries, and their caregivers: The primary care recipients will interact with the healthcare system as patients in some capacity; in 2020, 83.4% of adults and 94.0% of children reported that they visited a physician or other healthcare provider in the previous year.345 Caregivers, sometimes serving as guardians, also play a critical role in providing care for infants, children, adolescents, and elder family members."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_314",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncaregivers: The primary care recipients will interact with the healthcare system as patients in some capacity; in 2020, 83.4% of adults and 94.0% of children reported that they visited a physician or other healthcare provider in the previous year.345 Caregivers, sometimes serving as guardians, also play a critical role in providing care for infants, children, adolescents, and elder family members. • Providers: These are the primary vehicle for care delivery in the U.S., including: o Healthcare facilities and systems: The U.S. health system includes approximately 6,100 hospitals (from small community organizations to national systems) in addition to a range of post -acute care settings, outpatient clinics, and long -term care settings.346, 347 o Clinicians and support staff: In the U.S."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_315",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n• Providers: These are the primary vehicle for care delivery in the U.S., including: o Healthcare facilities and systems: The U.S. health system includes approximately 6,100 hospitals (from small community organizations to national systems) in addition to a range of post -acute care settings, outpatient clinics, and long -term care settings.346, 347 o Clinicians and support staff: In the U.S. in 2022, there were around 15 million clinical employees, including 933,000 active physicians, 3.4 million registered nurses, and 1.4 million personal care aids , in addition to other clinical staff (e.g., specialists, assistants, therapists, and technicians.348 o Non-clinical staff: Non-clinical staff play key roles in organizing and delivering healthcare (e.g., supply chain, maintenance, reception, HR and finance, communications, and IT) and also could engage with AI-enabled tools in administrative settings o Healthcare administration executives: Medical and health services managers help coordinate and oversee the complex operations of healthcare delivery organizations; 567,200 healthcare administration managers were employed in the U.S. in 2023.349 Additionally, senior executives, trustees, and boards of directors drive the overarching strategy of delivery organizations and make decisions on AI investments."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_316",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncould engage with AI-enabled tools in administrative settings o Healthcare administration executives: Medical and health services managers help coordinate and oversee the complex operations of healthcare delivery organizations; 567,200 healthcare administration managers were employed in the U.S. in 2023.349 Additionally, senior executives, trustees, and boards of directors drive the overarching strategy of delivery organizations and make decisions on AI investments. • Payers: These are p ublic and private organizations that finance patient care and help connect pat ients to appropriate providers and services based on their needs including: o Public payers (e.g., state Medicaid and other governmental agencies): Agencies that support implementing regulation, financing, and delivery. o Private payers: National, regional, and local payers that support financing and care. 345 https://www.ncbi.nlm.nih.gov/books/NBK587178/ 346 https://data.cms.gov/provider -data/dataset/xubh -q36u More than 5,300 hospitals are registered with Medicare with other care settings making up the balance. 347 https://www.aha.org/statistics/fast -facts-us-hospitals 348 https://www.bls.gov/spotlight/2023/healthcare -occupations -in-2022/ 349 https://www.bls.gov/ooh/management/medical -and-health -services -managers.htm 80 o Employers: Employer -sponsored healthcare , which accounts for 54% of managed care lives in the U.S. (often administered by private payers) ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_317",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand care. 345 https://www.ncbi.nlm.nih.gov/books/NBK587178/ 346 https://data.cms.gov/provider -data/dataset/xubh -q36u More than 5,300 hospitals are registered with Medicare with other care settings making up the balance. 347 https://www.aha.org/statistics/fast -facts-us-hospitals 348 https://www.bls.gov/spotlight/2023/healthcare -occupations -in-2022/ 349 https://www.bls.gov/ooh/management/medical -and-health -services -managers.htm 80 o Employers: Employer -sponsored healthcare , which accounts for 54% of managed care lives in the U.S. (often administered by private payers) . Employers have an active interest in ensuring the quality and safety of care provided to their employees.350 • STLT governments: These entities directly perform a variety of healthcare delivery activities, including providing care and financing and providing regulatory oversight of private and public sector activities. • Other entities supporting healthcare delivery: o Technology companies: A variety of technology vendors actively develop technology for healthcare settings, ranging from diversified, big -tech companies to dedicated healthcare services and technology vendors such as EHRs, revenue cycle management (RCM), and other ancillary ser vices vendors."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_318",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nproviding care and financing and providing regulatory oversight of private and public sector activities. • Other entities supporting healthcare delivery: o Technology companies: A variety of technology vendors actively develop technology for healthcare settings, ranging from diversified, big -tech companies to dedicated healthcare services and technology vendors such as EHRs, revenue cycle management (RCM), and other ancillary ser vices vendors. o Research institutions: In partnership with healthcare facilities, academic research institutions fuel discoveries that unlock new treatment modalities with the potential to transform the standard of care (e.g., enhanced patient services, new clinical innovations, mitigation of quality and safety issues, newly designed organizational workflows). o Biopharmaceutical and medical device companies: While the specifics of research and discovery on medical products including drugs, biological products, and devices are covered in other chapters of this plan, these organizations also engage in healthcare delivery via post -launch monitoring, maintenance, and surveillance of AI deployed in clinical settings. o Non-profit and CBOs: Many of these entities support the direct delivery of referral and care coordination. 3.3 Opportunities for the Application of AI in Healthcare Delivery AI has the potential to transform care delivery processes, but it also carries inherent risks that must be monitored to ensure positive patient impact and safety."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_319",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsurveillance of AI deployed in clinical settings. o Non-profit and CBOs: Many of these entities support the direct delivery of referral and care coordination. 3.3 Opportunities for the Application of AI in Healthcare Delivery AI has the potential to transform care delivery processes, but it also carries inherent risks that must be monitored to ensure positive patient impact and safety. Five ways that AI can support the healthcare system include : 1. Improv ing the quality and safety of patient care: Medical errors, including incorrect and/or delayed diagnoses, may contribute to adverse patient outcomes.351, 352 AI has the potential to accelerate diagnoses and prevent adverse events by rapidly processing expansive and disparate information, detecting patterns not always apparent to human observation, and directing clinicians to higher -likelihood diagnoses. AI can also enhance care models and health services research to develop innovations that better enable clinicians, payers, and patients. 2. Improv ing the patient experience: AI has the potential to enhance patient satisfaction through more efficient and tailored service s that better meet their needs. AI can also provide patients with tools to better understand medical information, including their own medical records and health status, and facilitate more engaged communication with both providers and payers (e.g., through sharing interpretable and relevant patient -facing information).353 3."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_320",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI has the potential to enhance patient satisfaction through more efficient and tailored service s that better meet their needs. AI can also provide patients with tools to better understand medical information, including their own medical records and health status, and facilitate more engaged communication with both providers and payers (e.g., through sharing interpretable and relevant patient -facing information).353 3. Automat ing administrative processes and reduce workforce burden and burnout: The growth in administrative complexity of healthcare delivery , coupled with shortages in the healthcare workforce, especially in primary care, exacerbates burnout in these already highly demanding work environments.354, 355, 356 AI applications in administrative contexts – including documentation, member/patient communications, and claims processing - can alleviate resources and provide organizations with more bandwidth to enhance care delivery."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_321",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand burnout: The growth in administrative complexity of healthcare delivery , coupled with shortages in the healthcare workforce, especially in primary care, exacerbates burnout in these already highly demanding work environments.354, 355, 356 AI applications in administrative contexts – including documentation, member/patient communications, and claims processing - can alleviate resources and provide organizations with more bandwidth to enhance care delivery. 350 https://www.census.gov/content/dam/Census/library/publications/2023/demo/p60 -281.pdf 351 https://jamanetwork.com/journals/jamainternalmedicine/article -abstract/2813854 352 https://patientsafetyj.com/article/116529 -patient -safety -trends -in-2023 -an-analysis -of-287-997-serious -events -and-incidents -from -the-nation -s-largest -event - reporting -database 353 https://pmc.ncbi.nlm.nih.gov/articles/PMC10734361/#section7 -20552076231220833 354 https://www.cms.gov/Outreach -and-Education/Outreach/Partnerships/Downloads/April2019PoPNewsletter.pdf ; https://www.healthit.gov/sites/default/files/page/2020 -02/BurdenReport_0.pdf 355 https://bhw.hrsa.gov/data -research/projecting -health -workforce -supply -demand 356 https://www.ahrq.gov/prevention/clinician/ahrq -works/burnout/index.html# 81 4."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_322",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nclaims processing - can alleviate resources and provide organizations with more bandwidth to enhance care delivery. 350 https://www.census.gov/content/dam/Census/library/publications/2023/demo/p60 -281.pdf 351 https://jamanetwork.com/journals/jamainternalmedicine/article -abstract/2813854 352 https://patientsafetyj.com/article/116529 -patient -safety -trends -in-2023 -an-analysis -of-287-997-serious -events -and-incidents -from -the-nation -s-largest -event - reporting -database 353 https://pmc.ncbi.nlm.nih.gov/articles/PMC10734361/#section7 -20552076231220833 354 https://www.cms.gov/Outreach -and-Education/Outreach/Partnerships/Downloads/April2019PoPNewsletter.pdf ; https://www.healthit.gov/sites/default/files/page/2020 -02/BurdenReport_0.pdf 355 https://bhw.hrsa.gov/data -research/projecting -health -workforce -supply -demand 356 https://www.ahrq.gov/prevention/clinician/ahrq -works/burnout/index.html# 81 4. Enhanc ing equity and access: Healthcare disparities are persistent within healthcare , and outcomes can vary by socioeconomic status, location, demographic factors , and more .357 There is a rapidly growing awareness of the importance of social drivers of health and health -related social needs on health outcomes.358 AI systems have the ability to incorporate SDOH and other information to inform the identification of at -risk patients, communicate in a patient’s preferred language and literacy level, surmount barriers to access for individuals with disabilities, and re commend services and resources better suited to individual circumstances.359, 360 5."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_323",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndrivers of health and health -related social needs on health outcomes.358 AI systems have the ability to incorporate SDOH and other information to inform the identification of at -risk patients, communicate in a patient’s preferred language and literacy level, surmount barriers to access for individuals with disabilities, and re commend services and resources better suited to individual circumstances.359, 360 5. Bend ing the cost curve: The U.S. remains the highest -cost healthcare system globally, which limits access to care for Americans and hinders U.S. economic productivity. In the aggregate, the adoption of AI across the healthcare delivery value chain could reduce administrative overhead, in crease asset and resource utilization, and lessen adverse events,361 which some reports estimate could reduce annual national healthcare expenditure by up to 10%.362 3.4 Trends in AI in Healthcare Delivery Current trends indicate that the innovative use of AI in healthcare delivery is rapidly evolving . However, there are still barriers to its use. Key trends include: 1. Investment in health AI is large and growing: AI accounts for 25% of all healthcare venture capital funding, totaling over $19 B since 2021. According to initial reports, r oughly two -thirds of th is investment has gone into clinical applications of AI and the other third to administrative use.363 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_324",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nstill barriers to its use. Key trends include: 1. Investment in health AI is large and growing: AI accounts for 25% of all healthcare venture capital funding, totaling over $19 B since 2021. According to initial reports, r oughly two -thirds of th is investment has gone into clinical applications of AI and the other third to administrative use.363 2. Mixed enthusiasm and concerns regarding the adoption of AI in the healthcare delivery context: A recent survey of 100 healthcare executives indicated that over 70% were already pursuing or implementing the technology.364 However, in another survey, about 40% of physicians indicated they were equally enthusiastic and concerned about using AI.365 There are concerns that AI adoption could result in a shift in the landscape of healthcare jobs and impact the patient -provider relationship.366, 367, 368, 369 Patients have similar concerns regarding AI, and results from one survey showed that approximately 60% of respondents were uncomfortable with the possibility of healthcare providers relying on AI.370, 371 Additional discussion of these risks and associated actions to mitigation can be found in this chapter’ s “Action Plan” section. 3."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_325",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\njobs and impact the patient -provider relationship.366, 367, 368, 369 Patients have similar concerns regarding AI, and results from one survey showed that approximately 60% of respondents were uncomfortable with the possibility of healthcare providers relying on AI.370, 371 Additional discussion of these risks and associated actions to mitigation can be found in this chapter’ s “Action Plan” section. 3. Variation in the adoption of AI by healthcare disciplines: In the 1990s, early uses of ML were applied to medical data to develop the first ML -based systems for diagnosis.372 AI innovations continue with today’s clinical decision support to enable it to be a critical tool for modern clinical workflows. Today, certain applications of AI and ML —particularly in radiology (e.g., reviewing types of medical images such as ECGs, MRI scans, and skin images) —have become widely accepted.373 While AI applications in radiology have matured, the adoption of AI in other disciplines, like pathology, cardiology, and primary care is 357 https://pubmed.ncbi.nlm.nih.gov/38100101/ 358 https://www.cms.gov/priorities/innovation/key -concepts/social -drivers -health -and-health -related -social -needs 359 https://pmc.ncbi.nlm.nih.gov/articles/PMC9976641/ 360 https://www.acf.hhs.gov/ai -data-research/artificial -intelligence -acf 361 It is not assumed that AI will eliminate all adverse events ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_326",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nscans, and skin images) —have become widely accepted.373 While AI applications in radiology have matured, the adoption of AI in other disciplines, like pathology, cardiology, and primary care is 357 https://pubmed.ncbi.nlm.nih.gov/38100101/ 358 https://www.cms.gov/priorities/innovation/key -concepts/social -drivers -health -and-health -related -social -needs 359 https://pmc.ncbi.nlm.nih.gov/articles/PMC9976641/ 360 https://www.acf.hhs.gov/ai -data-research/artificial -intelligence -acf 361 It is not assumed that AI will eliminate all adverse events . 362 https://www.nber.org/system/files/working_papers/w30857/w30857.pdf 363 https://www.svb.com/trends -insights/reports/artificial -intelligence -ai-in-healthcare/ 364 https://www.mckinsey.com/industries/healthcare/our -insights/generative -ai-in-healthcare -adoption -trends -and-whats -next#/ Survey where executives from 100 healthcare organizations were surveyed on their intentions to implement GenAI ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_327",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n358 https://www.cms.gov/priorities/innovation/key -concepts/social -drivers -health -and-health -related -social -needs 359 https://pmc.ncbi.nlm.nih.gov/articles/PMC9976641/ 360 https://www.acf.hhs.gov/ai -data-research/artificial -intelligence -acf 361 It is not assumed that AI will eliminate all adverse events . 362 https://www.nber.org/system/files/working_papers/w30857/w30857.pdf 363 https://www.svb.com/trends -insights/reports/artificial -intelligence -ai-in-healthcare/ 364 https://www.mckinsey.com/industries/healthcare/our -insights/generative -ai-in-healthcare -adoption -trends -and-whats -next#/ Survey where executives from 100 healthcare organizations were surveyed on their intentions to implement GenAI . 365 https://www.ama -assn.org/system/files/physician -ai-sentiment -report.pdf 366 https://hbr.org/2019/10/ai -can-outperform -doctors -so-why-dont-patients -trust-it 367 https://www.fastcompany.com/91053431/surveys -show -americans -dont-trust-ai-medical -advice -why-that-matters 368 https://insight.kellogg.northwestern.edu/article/will -ai-replace -doctors 369 https://pmc.ncbi.nlm.nih.gov/articles/PMC10811613/ 370 https://www.pewresearch.org/science/2023/02/22/60 -of-americans -would -be-uncomfortable -with-provider -relying -on-ai-in-their-own-health -care/ 371 https://hbr.org/2019/10/ai -can-outperform -doctors -so-why-dont-patients -trust-it 372 https://www.nejm.org/doi/full/10.1056/NEJM199406233302512 373 https://www.nejm.org/doi/full/10.1056/NEJMra2302038 82 growing.374, 375 Additional analyses of use cases can be found in this chapter’ s “Use Cases and Risks” section."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_328",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-ai-sentiment -report.pdf 366 https://hbr.org/2019/10/ai -can-outperform -doctors -so-why-dont-patients -trust-it 367 https://www.fastcompany.com/91053431/surveys -show -americans -dont-trust-ai-medical -advice -why-that-matters 368 https://insight.kellogg.northwestern.edu/article/will -ai-replace -doctors 369 https://pmc.ncbi.nlm.nih.gov/articles/PMC10811613/ 370 https://www.pewresearch.org/science/2023/02/22/60 -of-americans -would -be-uncomfortable -with-provider -relying -on-ai-in-their-own-health -care/ 371 https://hbr.org/2019/10/ai -can-outperform -doctors -so-why-dont-patients -trust-it 372 https://www.nejm.org/doi/full/10.1056/NEJM199406233302512 373 https://www.nejm.org/doi/full/10.1056/NEJMra2302038 82 growing.374, 375 Additional analyses of use cases can be found in this chapter’ s “Use Cases and Risks” section. 4. Increased innovation and uptake of administrative AI use: AI use in administrative tasks has advanced over the last few years , given lower development costs compared to clinical use cases and the onset of GenAI and LLM technology.376 Recent applications include “extract [ing] drug names from physicians ’ notes, reply [ing] to patient administrative questions, summariz [ing] medical dialogues, and writ [ing] histories and physical assessments. ”377 According to an American Medical Association survey, 54% of physicians are enthusiastic about using AI in their practices (particularly for administrative tasks such as documentation and charting) .378 5."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_329",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nLLM technology.376 Recent applications include “extract [ing] drug names from physicians ’ notes, reply [ing] to patient administrative questions, summariz [ing] medical dialogues, and writ [ing] histories and physical assessments. ”377 According to an American Medical Association survey, 54% of physicians are enthusiastic about using AI in their practices (particularly for administrative tasks such as documentation and charting) .378 5. Heterogeneity in organizations’ data and technology systems: The variation that exists in healthcare organizations’ access to technology and resources needed to use AI —including data management, clinical and administrative applications, and core infrastructure (e.g., cloud computing) —impacts current adoption.379 Heterogeneity in data modalities (e.g., numerical, textual, images, video, and audio) and standards across healthcare systems and EHRs create additional barriers to AI applications across the healthcare sector.380 This heterogeneity also contributes to organizations’ decision -making on which solutions to build, partner with (e.g., with AI vendors),381 or procure from others, and to what degree (e.g., AI, GenAI, or non -AI interventions).382, 383, 384 3.5 Potential Use Cases and Risks for AI in Healthcare Delivery Healthcare delivery and financing include a wide range of activities, all of which are likely to be impacted by existing and emerging AI, though some may be more impacted than others."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_330",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nvendors),381 or procure from others, and to what degree (e.g., AI, GenAI, or non -AI interventions).382, 383, 384 3.5 Potential Use Cases and Risks for AI in Healthcare Delivery Healthcare delivery and financing include a wide range of activities, all of which are likely to be impacted by existing and emerging AI, though some may be more impacted than others. The use of AI in healthcare delivery and financing —as contemplated in th is chapter —can be considered across the value chain of activities in healthcare delivery (e.g., diagnostic services, patient care delivery), financing (e.g., claims processing, provider network management), and research (see Exhibit 8) . There is variation in the type of technology and complexity across AI use cases (e.g., simpler rule -based automation versus complex LLMs), and thus, some have higher rates of adoption across the health system relative to others that are in more nascent sta ges of testing. There is also a broad range of risks posed by AI within healthcare delivery, including an impact on patient safety, deterioration of patient -provider relationships, and barriers to or inappropriate administration of care resulting from algorithmic bias. As discussed earlier in the document, HHS and its divisions (e.g., CMS) provide frameworks to both consider and mitigate risks in healthcare AI, such as FA VES."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_331",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nbroad range of risks posed by AI within healthcare delivery, including an impact on patient safety, deterioration of patient -provider relationships, and barriers to or inappropriate administration of care resulting from algorithmic bias. As discussed earlier in the document, HHS and its divisions (e.g., CMS) provide frameworks to both consider and mitigate risks in healthcare AI, such as FA VES. 374 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10487271/ 375 https://pmc.ncbi.nlm.nih.gov/articles/PMC10517477/ 376 https://www.svb.com/globalassets/trendsandinsights/reports/svb -the-ai-powered -healthcare -experience -2024.pdf 377 https://jamanetwork.com/journals/jama/fullarticle/2808296 378 https://www.ama -assn.org/system/files/physician -ai-sentiment -report.pdf 379 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8285156/ 380 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9908503/# 381 https://healthinnovation.ucsd.edu/news/11 -health -systems -leading -in-ai 382 https://pmc.ncbi.nlm.nih.gov/articles/PMC9628307/# 383 https://scopeblog.stanford.edu/2019/02/26/ai -will-not-solve -health -care-challenges -yet-but-there -are-innovative -alternatives -researcher -writes/ 384 https://www.nejm.org/doi/full/10.1056/NEJMra2204673 83 Exhibit 8: Healthcare Delivery and Financing Value Chains 3.5.1 AI in Delivery While the individual activities provided by a provider organization will vary greatly in size and focus (e.g., primary care clinics, large multispecialty groups, academic medical centers, state agencies, and federally qualified health centers), the value c hain is intended to describe the core set of healthcare delivery functions that frequently apply and the potential benefits or applications of AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_332",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nDelivery While the individual activities provided by a provider organization will vary greatly in size and focus (e.g., primary care clinics, large multispecialty groups, academic medical centers, state agencies, and federally qualified health centers), the value c hain is intended to describe the core set of healthcare delivery functions that frequently apply and the potential benefits or applications of AI. Innovation , development, and uptake of AI are inconsistent across the value chain —they are relatively more advanced in administrative functions (including those with clinical and non -clinical impact, such as operating room optimization, call -center enablement, talent management, and back -office administration) , while AI applications in diagnostics and therapeutic services are still less common outside of radiology. Overall, AI has had relatively higher levels of adoption in use cases where data is readily available (e.g., through EHRs or wearable devices), and is still nascent in application s for complex cases with limited data availability (i.e., given risks of model inaccuracy or bias toward specific populations).385, 386 Areas such as care coordination and transitions that require connecting disparate data sources (e.g., remote monitoring and hospital and home - care records) could be ripe for opportunity , but they continue to be limited in adoption , given challenges in connecting underlying data."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_333",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nwith limited data availability (i.e., given risks of model inaccuracy or bias toward specific populations).385, 386 Areas such as care coordination and transitions that require connecting disparate data sources (e.g., remote monitoring and hospital and home - care records) could be ripe for opportunity , but they continue to be limited in adoption , given challenges in connecting underlying data. Larger hospitals are further along in AI uptake, whereas smaller hospitals and physician groups are near the beginning of their AI journeys, piloting some AI use cases. However, as discussed previously, the relative value of certain AI use cases will vary based on an individual organization’s characteristics (e.g., provider size, needs, resources, existing capabilities, and service areas). In the tables below, HHS highlights a non -exhaustive list of potential benefits and risks of AI across the healthcare delivery value chain. Please note that the use cases detailed below highlight existing or potential ways that AI can be used by a variety of stakeholders in this domain. For details on how HHS and its divisions are using AI, please 385 https://pmc.ncbi.nlm.nih.gov/articles/PMC7979747/# 386 https://pmc.ncbi.nlm.nih.gov/articles/PMC7414411/# 84 reference the HHS AI Use Case Inventory 2024.387 Further, use -cases and risks related to financing and research are discussed in 3.5.2 AI in Financing and 3.5.3 AI in Care Models and Health Services Research, respectively ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_334",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nvariety of stakeholders in this domain. For details on how HHS and its divisions are using AI, please 385 https://pmc.ncbi.nlm.nih.gov/articles/PMC7979747/# 386 https://pmc.ncbi.nlm.nih.gov/articles/PMC7414411/# 84 reference the HHS AI Use Case Inventory 2024.387 Further, use -cases and risks related to financing and research are discussed in 3.5.2 AI in Financing and 3.5.3 AI in Care Models and Health Services Research, respectively . Functional component 1: Access and/or scheduling The process of scheduling patients for appointments and services Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Streamlined and automated scheduling tools to optimize efficiency E.g., predictive analytics to reduce no -shows Targeted interventions (e.g., outreach) can substantially increase show rates for patients most likely to miss appointments .388, 389 E.g., appointment scheduling optimization AI can optimize scheduling by predicting patient appointment preferences and availability, reducing wait times, and improving clinic efficiency .390 E.g., operating room scheduling optimization AI can analyze surgical schedules, patient data, and resource availability to optimize operating room usage, reducing downtime and improving surgical throughput .391 Potential to introduce bias E.g., mismatched overbooking of appointments Applying a one -size-fits-all approach to overbooking appointments based on no -show rates may disproportionately impact patients with certain characteristics (e.g., socioeconomic status, low access to transportation, and fear of doctors or hospitals) .392, 393 E.g., over-emphasis of variables that enhance disparities in scheduling AI use for procedure scheduling (e.g., operating room scheduling) could risk perpetuating disparities in access to care if algorithms trained on current resource allocation data give too much weight to certain variables (e.g., procedure profitability , coverage type).394 Functional component 2: Patient intake and support The initial stage of gathering and verifying patient information, including medical history and insurance details, to prepare for treatment and ensure smooth administrative processes Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Personalized AI -assisted patient intake processes to increase efficiency and patient satisfaction E.g., streamlined patient data collection Auto -generation and tracking of communications sent to patients to minimize duplicate data collection and patient burden395 E.g., automated AI voice technology AI-driven conversational voice technology to automate patient intake processes (e.g., through recording and transcription)396 Potential to magnify patient trust concerns E.g., overcollection of patient data The overcollection of data (or perception of data misuse, even if inaccurate) for AI models can cause patient discomfort in care delivery processes and create or enhance distrust, particularly for populations who may already have negative perceptions of th e healthcare system .397 387 https://www.healthit.gov/hhs -ai-usecases 388 https://www.healthcareitnews.com/news/fqhc -slashed -its-patient -no-show -rate-ai-3-months 389 https://pmc.ncbi.nlm.nih.gov/articles/PMC10150669/ 390 https://pmc.ncbi.nlm.nih.gov/articles/PMC10905346/# 391 https://www.nejm.org/doi/full/10.1056/NEJMra2204673 392 https://pmc.ncbi.nlm.nih.gov/articles/PMC7280239/pdf/rmhp -13-509.pdf 393 https://www.healthaffairs.org/content/forefront/discrimination -artificial -intelligence -commercial -electronic -health -record -case-study 394 https://www.healthaffairs.org/content/forefront/discrimination -artificial -intelligence -commercial -electronic -health -record -case-study 395 https://www.nber.org/system/files/working_papers/w30857/w30857.pdf 396 https://pubmed.ncbi.nlm.nih.gov/33999834/ 397 https://www.ama -assn.org/system/files/ama -patient -data-privacy -survey -results.pdf 85 Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Automated tools to reduce administrative tasks and free up staff to focus on patient care and more complex issues E.g., optimized patient request handling AI virtual agents can quickly answer simple patient requests (e.g., as one health system did during the COVID -19 pandemic by using a n NLP -driven chatbot to direct a large influx of patient calls to the appropriate system to facilitate their requests) .398 Potential to impede patient access to care E.g., incorrect decisions enabled by AI based on patient data Erroneous data collected by AI could lead to inappropriate decisions and denial of services ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_335",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe COVID -19 pandemic by using a n NLP -driven chatbot to direct a large influx of patient calls to the appropriate system to facilitate their requests) .398 Potential to impede patient access to care E.g., incorrect decisions enabled by AI based on patient data Erroneous data collected by AI could lead to inappropriate decisions and denial of services . Functional component 3: Diagnostic/therapeutic services The delivery of medical care, including diagnosis and treatment, is supported by advanced systems like EHR, clinical decision support, wearables, and telehealth tools to improve the quality and efficiency of care Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Automated documentation and summarization of patient information to increase healthcare worker efficiency399 E.g., ambient listening AI-driven ambient listening systems can capture and transcribe patient -provider interactions in real time, facilitating more accurate documentation and diagnosis and enabling providers to focus more on patient care and improving the patient experience .400, 401 Potential for inappropriate application E.g., confabulations Automated documentation systems may generate false information on a patient’s medical history and lead to inappropriate care recommendations, underscoring the importance of human -in-the-loop and robust confabulation detection methods .402 E.g., AI impacting patient -clinician relationships and trust Patients have expressed concerns that utilizing AI for clinical decision -making may deteriorate patient -provider relationships , as AI continually automates tasks typically done by humans — especially given the emotional and personal nature of experiencing medical conditions, underscoring the importance of empathetic and compassionate interactions within healthcare delivery .403, 404 398 https://www.nejm.org/doi/full/10.1056/NEJMra2204673 399 https://catalyst.nejm.org/doi/full/10.1056/CAT.23.0404 400 https://med.stanford.edu/news/all -news/2024/03/ambient -listening -notes.html 401 https://www.ama -assn.org/system/files/2019 -01/augmented -intelligence -policy -report.pdf 402 https://openreview.net/pdf?id=6eMIzKFOpJ 403 https://pmc.ncbi.nlm.nih.gov/articles/PMC10116477/# 404 https://journalofethics.ama -assn.org/article/how -will-artificial -intelligence -affect -patient -clinician -relationships/2020 -05 86 Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Automated intelligence tools to support the evaluation of diagnosis and treatment options and surface critical insights about patient conditions E.g., prediction and risk identification AI algorithms can analyze patient health indicators to predict disease outcomes (e.g., one health system used an AI algorithm to predict sepsis in patients by combining EHR data with blood pressure and heart rate measures) .405, 406 E.g., precision medicine AI can power CDS tools to help physicians consider optimal interventions and help surface critical ( and potentially challenging to trace) insights about patient conditions .407 Potential misuse or misinterpretation of health data E.g., ineffective treatment plans informed by AI Potential prioritization of testing data and analysis over patient -reported indicators and other factors in AI-generated behavioral health treatment decision support could lead to misdiagnoses and treatments that may worsen behavioral health outcomes and trust .408 E.g., health technologies may not consider nuances of individuals AI tools may not account for demographic and SDOH factors such as communication barriers, which may increase technological concerns among patients and lead to reduced patient satisfaction, trust, and effectiveness in care .409 Analy sis of patient data to develop targeted interventions or educational materials E.g., sentiment analysis through multiple data formats AI can process unstructured data (e.g., text posted on social media, user input) to generate summaries of perspectives on mental health."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_336",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nbarriers, which may increase technological concerns among patients and lead to reduced patient satisfaction, trust, and effectiveness in care .409 Analy sis of patient data to develop targeted interventions or educational materials E.g., sentiment analysis through multiple data formats AI can process unstructured data (e.g., text posted on social media, user input) to generate summaries of perspectives on mental health. These can be used to develop and disseminate personalized educational materials, guidance, strategies, and referrals .410 E.g., AI analysis to develop combined interventions AI can help create holistic treatment plans that combine multiple types of interventions (e.g., behavioral and clinical interventions) such as guided diet monitoring and AI -tailored education paired with CDS (e.g., measurement of health indicators and personalized medication plans) for diabetes patients .411 E.g., AI technology that provides reminders and measure s medicine intake AI tools such as smartphone apps can assess and encourage adherence through daily monitoring and reminders (e.g., smartphone camera to confirm ingestion of drug) .412 405 https://ai.nejm.org/doi/full/10.1056/AIp2300031 Use of GPT -4 to Diagnose Complex Clinical Cases 406 https://www.sciencedirect.com/science/article/abs/pii/S1553725020300969?via%3Dihub 407 https://www.mcpdigitalhealth.org/article/S2949 -7612(24)00041 -5/fulltext 408 https://www.aha.org/aha -center -health -innovation -market -scan/2024 -05-14-will-ai-help-address -our-behavioral -health -crisis 409 https://pmc.ncbi.nlm.nih.gov/articles/PMC8521858/# 410 https://pmc.ncbi.nlm.nih.gov/articles/PMC10982476/# 411 https://pmc.ncbi.nlm.nih.gov/articles/PMC10591058 412 https://pmc.ncbi.nlm.nih.gov/articles/PMC8521858/#s3 87 Functional component 4: Discharge and care transition Managing the process of transitioning patients from one care setting to another, ensuring continuity of care and proper follow -ups through integrated systems and patient engagement platforms Potential use cases (non-exhaustive) Potential risks (non-exhaustive) AI algorithms that analyze patient circumstances and enable more personalized and efficient care transition processes E.g., patient -facing virtual care assistant s AI can increase education and transparency by explaining a diagnosis and care management plan, giving patients a 24/7 resource that educates them and provides timely information through a virtual care assistant or chatbot .413, 414 E.g., chatbots that minimize potential engagement with clinicians AI chatbots can help encourage and deliver care for patients who may have conditions they perceive as embarrassing or stigmatizing and would prefer not to have an in -person consultation .415 Potential for inappropriate application E.g., confabulation of inappropriate recommendations AI models can make errors in data analysis, incorrectly transcribe recording s, or convey false information to clinicians .416 E.g., deterioration of key skillsets Additional introduction of AI tools may result in over-reliance o n these technologies by clinicians, potentially leading to deskilling in nuanced areas of health, particularly where human empathy and engagement play a significant role .417 Functional component 5: Care coordination and management Ongoing management of patient care across different services and providers, utilizing digital tools and analytics to enhance care coordination, patient engagement, and overall health outcomes Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Remote monitoring of patient conditions to enhance patient care effectiveness and timeliness E.g., chronic care management AI decision aids can support ongoing disease management by providing patients with tools that support reminders, predict issues, and flag care needs to providers and patients."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_337",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nanalytics to enhance care coordination, patient engagement, and overall health outcomes Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Remote monitoring of patient conditions to enhance patient care effectiveness and timeliness E.g., chronic care management AI decision aids can support ongoing disease management by providing patients with tools that support reminders, predict issues, and flag care needs to providers and patients. Additionally, they can be used in hospital settings to monitor care across disease areas (e.g., glucose changes for someone with diabetes but who is hospitalized for other ac ute needs) .418, 419, 420, 421 Potential to introduce bias E.g., incorrect risk stratification by demographic AI algorithms used in care coordination decision - making may be vulnerable to bias by assigning the same level of risk to patients despite characteristics that should be taken into consideration to determine risk (e.g., one AI algorithm used by a health sys tem reduced the number of minority patients identified for care, even though that cohort of patients was sicker and needed more care) .422, 423 413 https://pubmed.ncbi.nlm.nih.gov/37054749/ , https://pmc.ncbi.nlm.nih.gov/articles/PMC10219811/ 414 https://cdsic.ahrq.gov/sites/default/files/2024 -09/PAIGE%20Assessment%20Report_Public%20Version.pdf 415 https://www.frontiersin.org/journals/communication/articles/10.3389/fcomm.2023.1275127/full 416 https://openreview.net/pdf?id=6eMIzKFOpJ 417 https://www.sciencedirect.com/science/article/pii/S2949916X24000938# 418 https://www.jmir.org/2023/1/e42335/PDF 419 https:/pubmed.ncbi.nlm.nih.gov/38215713 Remote Monitoring and Artificial Intelligence: Outlook for 2050."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_338",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndetermine risk (e.g., one AI algorithm used by a health sys tem reduced the number of minority patients identified for care, even though that cohort of patients was sicker and needed more care) .422, 423 413 https://pubmed.ncbi.nlm.nih.gov/37054749/ , https://pmc.ncbi.nlm.nih.gov/articles/PMC10219811/ 414 https://cdsic.ahrq.gov/sites/default/files/2024 -09/PAIGE%20Assessment%20Report_Public%20Version.pdf 415 https://www.frontiersin.org/journals/communication/articles/10.3389/fcomm.2023.1275127/full 416 https://openreview.net/pdf?id=6eMIzKFOpJ 417 https://www.sciencedirect.com/science/article/pii/S2949916X24000938# 418 https://www.jmir.org/2023/1/e42335/PDF 419 https:/pubmed.ncbi.nlm.nih.gov/38215713 Remote Monitoring and Artificial Intelligence: Outlook for 2050. 420 https://wires.onlinelibrary.wiley.com/doi/epdf/10.1002/widm.1485 421 https://www.annallergy.org/article/S1081 -1206(21)01276 -X/abstract Methods to engage patients in the modern clinic. 422 https://www.nature.com/articles/s41746 -023-00858 -z# Bias in AI models for medical applications: challenges and mitigation strategies ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_339",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nneeded more care) .422, 423 413 https://pubmed.ncbi.nlm.nih.gov/37054749/ , https://pmc.ncbi.nlm.nih.gov/articles/PMC10219811/ 414 https://cdsic.ahrq.gov/sites/default/files/2024 -09/PAIGE%20Assessment%20Report_Public%20Version.pdf 415 https://www.frontiersin.org/journals/communication/articles/10.3389/fcomm.2023.1275127/full 416 https://openreview.net/pdf?id=6eMIzKFOpJ 417 https://www.sciencedirect.com/science/article/pii/S2949916X24000938# 418 https://www.jmir.org/2023/1/e42335/PDF 419 https:/pubmed.ncbi.nlm.nih.gov/38215713 Remote Monitoring and Artificial Intelligence: Outlook for 2050. 420 https://wires.onlinelibrary.wiley.com/doi/epdf/10.1002/widm.1485 421 https://www.annallergy.org/article/S1081 -1206(21)01276 -X/abstract Methods to engage patients in the modern clinic. 422 https://www.nature.com/articles/s41746 -023-00858 -z# Bias in AI models for medical applications: challenges and mitigation strategies . 423 https://www.science.org/doi/10.1126/science.aax2342 88 Functional component 6: Claims submission and billing Submitting claims for reimbursement and managing billing are often automated to ensure timely and accurate payment, reduce denials, and optimize RCM Potential benefits and example use cases (non- exhaustive) Potential risks (non-exhaustive) Tools to help measure and assist physicians in choosing and logging optimal interventions424, 425 E.g., billing code automation and analysis Automating billing codes and checking the accuracy of billing based on unstructured notes and data426, 427 Potential for increased barriers to patient care E.g., inaccurate claims submissions Inaccurate claims submissions caused by AI may occur due to model failures (e.g., poor/exposed data, analysis methodology, interpretation) and lead to increased liability for medical professionals and fines .428, 429 E.g., expanding costs due to competition in payment integrity/ revenue cycle management As providers invest in AI to optimize revenue and payers invest in AI to increase payment integrity, the potential for meaningful costs to the system increases —with the additional risk of affecting patients .430, 431, 432 424 https://www.medicaleconomics.com/view/revolutionizing -denials -management -with-artificial -intelligence 425 https://www -nejm -org.ezproxyhhs.nihlibrary.nih.gov/doi/10.1056/NEJMra2204673 426 https://www -nejm -org.ezproxyhhs.nihlibrary.nih.gov/doi/10.1056/NEJMra2204673 427 https://www.medicaleconomics.com/view/revolutionizing -denials -management -with-artificial -intelligence ; https://www -nejm - org.ezproxyhhs.nihlibrary.nih.gov/doi/10.1056/NEJMra2204673 428 https://link.springer.com/article/10.1007/s40273 -019-00777 -6# 429 https://oig.hhs.gov/compliance/physician -education/fraud -abuse -laws/# 430 https://www.hfma.org/revenue -cycle/denials -management/health -systems -start-to-fight -back-against -ai-powered -robots -driving -denial -rates-higher/ 431 https://jamanetwork.com/journals/jama/fullarticle/2812255 AI Alone Will Not Reduce the Administrative Burden of Healthcare 432 https://jamanetwork.com/journals/jama -health -forum/fullarticle/2816204 Denial —Artificial Intelligence Tools and Health Insurance Coverage Decisions."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_340",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nhttps://www -nejm -org.ezproxyhhs.nihlibrary.nih.gov/doi/10.1056/NEJMra2204673 427 https://www.medicaleconomics.com/view/revolutionizing -denials -management -with-artificial -intelligence ; https://www -nejm - org.ezproxyhhs.nihlibrary.nih.gov/doi/10.1056/NEJMra2204673 428 https://link.springer.com/article/10.1007/s40273 -019-00777 -6# 429 https://oig.hhs.gov/compliance/physician -education/fraud -abuse -laws/# 430 https://www.hfma.org/revenue -cycle/denials -management/health -systems -start-to-fight -back-against -ai-powered -robots -driving -denial -rates-higher/ 431 https://jamanetwork.com/journals/jama/fullarticle/2812255 AI Alone Will Not Reduce the Administrative Burden of Healthcare 432 https://jamanetwork.com/journals/jama -health -forum/fullarticle/2816204 Denial —Artificial Intelligence Tools and Health Insurance Coverage Decisions. 89 Functional component 7: Quality, safety, and population health Ensuring healthcare services meet established standards of quality and safety, using tools like AI -powered support, decision support systems, and continuous monitoring to improve clinical care and organizational performance Potential use cases (non-exhaustive) Potential risks (non-exhaustive) AI tools to enhance patient care and hospital quality measures E.g., adverse event and re -admission prevention AI can remotely monitor patient conditions to prevent re - admissions by identifying risks of potential deterioration and prioritizing interventions, ensuring timely and effective care .433 E.g., quality measurement Abstraction and analytics tools for more accurate and efficient hospital quality measurement434 Potential for bias E.g., underrepresentation of certain populations in training data Underlying training data may be biased due to historical disparities in access and quality of care delivery .435 3.5.2 AI in Financing The financing landscape features a wide variety of payers (e.g., Medicare, state Medicaid agencies, large national insurers, regional specialty payers, and managed care organizations)."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_341",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nhospital quality measurement434 Potential for bias E.g., underrepresentation of certain populations in training data Underlying training data may be biased due to historical disparities in access and quality of care delivery .435 3.5.2 AI in Financing The financing landscape features a wide variety of payers (e.g., Medicare, state Medicaid agencies, large national insurers, regional specialty payers, and managed care organizations). There are key variations among these organizations (e.g., populations served) and in their payment structures (e.g., value -based care, fee -for-service). Across these, there are wide range s of use cases and risks for these payers , which include the examples listed in the table below.436, 437 In financing, AI and LLMs are increasingly being used for a range of functions and tasks, including prior authorization, clinical review assessments, utilization management, and claims adjudication.438 Given the industry’s extensive data analytics and document processing, a large and expanding wave of new use cases is expected in the coming years."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_342",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ninclude the examples listed in the table below.436, 437 In financing, AI and LLMs are increasingly being used for a range of functions and tasks, including prior authorization, clinical review assessments, utilization management, and claims adjudication.438 Given the industry’s extensive data analytics and document processing, a large and expanding wave of new use cases is expected in the coming years. Expansion in this segment is not without challenges: there have been ongoing litigation and concerns from Congress regarding the use of AI and algorithms to deny prior authorization requests, particularly in how AI complies with state and federal regulations impacting payer decision -making .439 433 https://www.nejm.org/doi/full/10.1056/NEJMra2204673 434 https://ai.nejm.org/doi/full/10.1056/AIcs2400420 435 https://pmc.ncbi.nlm.nih.gov/articles/PMC10497548/#CR49 436 https://www.nejm.org/doi/full/10.1056/NEJMra2204673 437 https://www.nber.org/system/files/working_papers/w30857/w30857.pdf 438 https://www.healthaffairs.org/content/forefront/ai -and-health -insurance -prior -authorization -regulators -need -step-up-oversight 439 https://www.statnews.com/2023/11/14/unitedhealth -class -action -lawsuit -algorithm -medicare -advantage/ 90 Functional component 1: Member intake The process of enrolling individuals in a healthcare insurance plan, ensuring their information is accurately captured and maintained for future interactions Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Streamlined enrollment tools that personalize member engagement E.g., generating personalized member outreach AI can analyze member data to create tailored communication strategies (e.g., through GenAI) that address specific health needs, preferences, and engagement patterns ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_343",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nenrolling individuals in a healthcare insurance plan, ensuring their information is accurately captured and maintained for future interactions Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Streamlined enrollment tools that personalize member engagement E.g., generating personalized member outreach AI can analyze member data to create tailored communication strategies (e.g., through GenAI) that address specific health needs, preferences, and engagement patterns . Potential for privacy concerns E.g., over-personalized outreach autogenerated by AI Communications may be perceived as intrusive, and AI over -personalization could be perceived as the overcollection or overuse of member data .440 Functional component 2: Application processing and eligibility determination Reviewing and verifying applications to determine if applicants meet the criteria for coverage, ensuring that only eligible individuals receive benefits Potential use cases (non-exhaustive) Potential risks (non-exhaustive) AI to significantly reduce manual application -centric workloads E.g., application review AI can support the rapid review of applications to identify missing information, check other eligibility (e.g., secondary coverage), and support other functions ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_344",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand verifying applications to determine if applicants meet the criteria for coverage, ensuring that only eligible individuals receive benefits Potential use cases (non-exhaustive) Potential risks (non-exhaustive) AI to significantly reduce manual application -centric workloads E.g., application review AI can support the rapid review of applications to identify missing information, check other eligibility (e.g., secondary coverage), and support other functions . E.g., adaptive customer -facing chatbots AI-driven chatbots can be trained to handle a large variety of inquiries —from eligibility questions to application status updates —providing instant and accurate responses to members and reducing call center burden .441 Potential to introduce bias E.g., incorrect denial of eligibility Without proper calibration or human -in-the-loop, models risk denying eligibility —particularly to populations with historically more complicated coverage —creating significant hurdles for patients to receive necessary procedures .442 E.g., exacerbating underserved populations’ distrust of care Inaccurate responses to populations already less likely to seek care and support may further discourage care - seeking behavior .443 440 https://www.ama -assn.org/system/files/ama -patient -data-privacy -survey -results.pdf 441 https://www.ncbi.nlm.nih.gov/books/NBK602381/ 442 https://jamanetwork.com/journals/jama -health -forum/fullarticle/2816204 443 https://jamanetwork.com/journals/jama -health -forum/fullarticle/2816204 91 Functional component 3: Claims processing and remittance Handling and adjudicating claims submitted by healthcare providers, ensuring timely payment or denial based on policy terms and services rendered Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Automatic AI processing of complex claims data to streamline decision -making E.g., fast -tracking claims approvals Predictive analytics can generate summaries and rapidly assess the validity of claims to fast -track approvals.444 E.g., automated claims review AI algorithms can automate the review of claims for errors, inconsistencies, and compliance with policy terms, speeding up the process and reducing manual effort .445 Potential to exacerbate costs in the system E.g., expanding costs due to competition in payment integrity/RCM As providers invest in AI to optimize their revenues and payers invest in AI tools to increase their payment integrity capabilities , incremental costs could occur through administrative waste — this could affect patients (hospitals billing patients in case of denials by payers) .446, 447, 448 Functional component 4: Utilization, case, and disease management Monitoring and managing the use of healthcare services to ensure they are necessary and cost effective, thereby optimizing resource use and controlling costs Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Predictive analytic tools to optimize healthcare service delivery to patients E.g., patient re -admission analysis and prevention AI interventions can support case management programs by predict ing which patients are at higher risk and supporting targeted interventions to prevent future re - admissions (in one example, AI interventions reduced re - admission rates by 55%) .449 Automatic AI processing of utilization management and prior authorization E.g., prior authorization adjudication AI can streamline the prior authorization process by quickly verifying necessary medical information and automating approval workflows, reducing delays in patient care.450,451 Potential to generate inappropriate outcomes E.g., AI decision support tools used in coverage determinations AI decision support tools used to support determination of coverage for services may be inconsistent with terms of coverage , a specific patient’s circumstances , or fail to abide by applicab le federal or state law .452 444 https://pmc.ncbi.nlm.nih.gov/articles/PMC6616181/ 445 https://www.nber.org/system/files/working_papers/w30857/w30857.pdf 446 https://www.hfma.org/revenue -cycle/denials -management/health -systems -start-to-fight -back-against -ai-powered -robots -driving -denial -rates-higher/ 447 https://jamanetwork.com/journals/jama/fullarticle/2812255 AI Alone Will Not Reduce the Administrative Burden of Healthcare."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_345",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto support determination of coverage for services may be inconsistent with terms of coverage , a specific patient’s circumstances , or fail to abide by applicab le federal or state law .452 444 https://pmc.ncbi.nlm.nih.gov/articles/PMC6616181/ 445 https://www.nber.org/system/files/working_papers/w30857/w30857.pdf 446 https://www.hfma.org/revenue -cycle/denials -management/health -systems -start-to-fight -back-against -ai-powered -robots -driving -denial -rates-higher/ 447 https://jamanetwork.com/journals/jama/fullarticle/2812255 AI Alone Will Not Reduce the Administrative Burden of Healthcare. 448 https://jamanetwork.com/journals/jama -health -forum/fullarticle/2816204 Denial —Artificial Intelligence Tools and Health Insurance Coverage Decisions 449 https://www.nejm.org/doi/full/10.1056/NEJMra2204673 450 https://www.nejm.org/doi/full/10.1056/NEJMra2204673 451 https://pubmed.ncbi.nlm.nih.gov/36809561/ Could an artificial intelligence approach to prior authorization be more human?"
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_346",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nlaw .452 444 https://pmc.ncbi.nlm.nih.gov/articles/PMC6616181/ 445 https://www.nber.org/system/files/working_papers/w30857/w30857.pdf 446 https://www.hfma.org/revenue -cycle/denials -management/health -systems -start-to-fight -back-against -ai-powered -robots -driving -denial -rates-higher/ 447 https://jamanetwork.com/journals/jama/fullarticle/2812255 AI Alone Will Not Reduce the Administrative Burden of Healthcare. 448 https://jamanetwork.com/journals/jama -health -forum/fullarticle/2816204 Denial —Artificial Intelligence Tools and Health Insurance Coverage Decisions 449 https://www.nejm.org/doi/full/10.1056/NEJMra2204673 450 https://www.nejm.org/doi/full/10.1056/NEJMra2204673 451 https://pubmed.ncbi.nlm.nih.gov/36809561/ Could an artificial intelligence approach to prior authorization be more human? 452 https://www.aha.org/system/files/media/file/2024/02/faqs -related -to-coverage -criteria -and-utilization -management -requirements -in-cms-final-rule-cms-4201 -f.pdf 92 Functional component 5: Provider network management Managing relationships and contracts with healthcare providers to ensure a robust and effective network for members that facilitates access to necessary services Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Algorithms that compare quantitative network metrics (e.g., rates, credentialing compliance) to identify areas of variability and potential for standardization E.g., provider rate comparison AI can compare rates across different providers and services, helping payers and patients make informed decisions about cost -effective care options and negotiate better rates .453 Algorithms that streamline documentation processes to support expansive provider network E.g., automated provider credentialing AI can automate provider credential verification, ensuring that all necessary qualifications and certifications are up to date and reducing the administrative burden on healthcare organizations .454 Potential to exacerbate bias E.g., increased bias caused by AI algorithms Safety -net hospitals, which are typically low -margin and care for underrepresented populations, may be further disadvantaged in payer negotiations with payors using sophisticated AI algorithms to manage their network strategy .455, 456 Functional component 6: Program integrity Implementing measures, including advanced analytics, to prevent fraud, waste, and abuse within the healthcare insurance system to ensure the integrity and sustainability of the program Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Algorithms that detect and mitigate fraud to protect patients E.g., fraud detection Provider -ranking algorithms can identify fraud using a corpus of publicly and privately available data."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_347",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nintegrity Implementing measures, including advanced analytics, to prevent fraud, waste, and abuse within the healthcare insurance system to ensure the integrity and sustainability of the program Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Algorithms that detect and mitigate fraud to protect patients E.g., fraud detection Provider -ranking algorithms can identify fraud using a corpus of publicly and privately available data. CMS has launched a Fraud Prevention System that uses predictive analytics to screen claims before payment, using indicators that flag fraud and enable protective interventions .457 Potential for unintended consequences or inappropriate outcomes E.g., increased financial burden Payer investment in AI tools that increase adverse coverage decisions may financially impact patients and organizations as hospitals increase billing to offset revenue lost from increased denials .458, 459, 460 453 https://www.nber.org/system/files/working_papers/w30857/w30857.pdf 454 https://www.beckershospitalreview.com/strategy/the -role-of-ai-in-clinician -credentialing -and-enrollment -a-balanced -perspective.html 455 https://www.chcf.org/wp -content/uploads/2024/04/ExaminingAIandHealthCare.pdf 456 https://www.science.org/doi/10.1126/science.aax2342 Dissecting racial bias in an algorithm used to manage the health of populations ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_348",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nfinancial burden Payer investment in AI tools that increase adverse coverage decisions may financially impact patients and organizations as hospitals increase billing to offset revenue lost from increased denials .458, 459, 460 453 https://www.nber.org/system/files/working_papers/w30857/w30857.pdf 454 https://www.beckershospitalreview.com/strategy/the -role-of-ai-in-clinician -credentialing -and-enrollment -a-balanced -perspective.html 455 https://www.chcf.org/wp -content/uploads/2024/04/ExaminingAIandHealthCare.pdf 456 https://www.science.org/doi/10.1126/science.aax2342 Dissecting racial bias in an algorithm used to manage the health of populations . 457 https://www.cms.gov/About -CMS/Components/CPI/Widgets/Fraud_Prevention_System_2ndYear.pdf 458 https://www.hfma.org/revenue -cycle/denials -management/health -systems -start-to-fight -back-against -ai-powered -robots -driving -denial -rates-higher/ 459 https://jamanetwork.com/journals/jama/fullarticle/2812255 AI Alone Will Not Reduce the Administrative Burden of Healthcare. 460 https://jamanetwork.com/journals/jama -health -forum/fullarticle/2816204 Denial —Artificial Intelligence Tools and Health Insurance Coverage Decisions ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_349",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n455 https://www.chcf.org/wp -content/uploads/2024/04/ExaminingAIandHealthCare.pdf 456 https://www.science.org/doi/10.1126/science.aax2342 Dissecting racial bias in an algorithm used to manage the health of populations . 457 https://www.cms.gov/About -CMS/Components/CPI/Widgets/Fraud_Prevention_System_2ndYear.pdf 458 https://www.hfma.org/revenue -cycle/denials -management/health -systems -start-to-fight -back-against -ai-powered -robots -driving -denial -rates-higher/ 459 https://jamanetwork.com/journals/jama/fullarticle/2812255 AI Alone Will Not Reduce the Administrative Burden of Healthcare. 460 https://jamanetwork.com/journals/jama -health -forum/fullarticle/2816204 Denial —Artificial Intelligence Tools and Health Insurance Coverage Decisions . 93 Functional component 7: Quality, safety, and population health Ensuring that healthcare services provided to members meet established standards of quality and safety, including continuously monitoring and improving these standards Potential use cases (non-exhaustive) Potential risks (non-exhaustive) AI models that monitor patient and provider indicators (e.g., sentiment analysis) to gather feedback and improve care quality E.g., patient experience analysis AI can analyze patient feedback from surveys and other sources to identify satisfaction, trends, and areas for improvement in care, providing actionable insights to payers about quality of care within their provider network .461 Potential to introduce bias E.g., failure to identify diseases in patient populations AI algorithms trained on specific patient populations may be biased, leading to inaccurate conclusions regarding patient safety (e.g., a sepsis prediction algorithm built on a hospital’s EHR only identified the condition in 7% of the patient population, delaying care for others in need and inaccurately representing quality of patient care ).462 461 https://www.nejm.org/doi/full/10.1056/NEJMra2204673 462 https://jamanetwork.com/journals/jama -health -forum/fullarticle/2815239 94 3.5.3 AI in Care Models and Health Services Research The use of AI in care model and health services development is growing within applied research settings."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_350",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\na hospital’s EHR only identified the condition in 7% of the patient population, delaying care for others in need and inaccurately representing quality of patient care ).462 461 https://www.nejm.org/doi/full/10.1056/NEJMra2204673 462 https://jamanetwork.com/journals/jama -health -forum/fullarticle/2815239 94 3.5.3 AI in Care Models and Health Services Research The use of AI in care model and health services development is growing within applied research settings. AI also informs the development of non -device behavioral interventions (e.g., cognitive behavioral therapy , nutrition counseling ), which can lead to the generation, modification, adaptation, or refinement of existing interventions.463, 464 HHS divisions support research and innovation in these areas, including AHRQ (e.g., AI and safety NOFO ,465 guidance on mitigating algorithmic bias ),466 CMS (e.g., CMMI outcomes challenge), NIH ( e.g., Office of Behavioral and Social Sciences Research ),467 and SAMHSA (e.g., Center for Behavioral Health Statistics and Quality ).468 Care model and health services research Analyzing and optimizing healthcare delivery, workforce models, financial performance, and patient outcomes through innovative, data -driven, and value -based approaches to improve health system performance and equity . Note: This refers to AI-based research into care models , which may involve medical products but pertains primarily to the use of AI to i mprove healthcare delivery ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_351",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nhealth services research Analyzing and optimizing healthcare delivery, workforce models, financial performance, and patient outcomes through innovative, data -driven, and value -based approaches to improve health system performance and equity . Note: This refers to AI-based research into care models , which may involve medical products but pertains primarily to the use of AI to i mprove healthcare delivery . Discussion pertaining to medical product development is found in other chapters, notably Medical Product Development, Safety, and Effectiveness. Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Clinical pathway and care model optimization/generation E.g., AI -generated care pathways AI can recommend and optimize clinical care pathways, which ensure s that patient care aligns with evidence -based guidelines and reduce s variation in clinical care between practitioners .469 E.g., population -data-enhanced care models AI can synthesize large volumes of data and generate customized care models. By aligning incentives around patient outcomes, AI can help payers develop value -based care models."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_352",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncan recommend and optimize clinical care pathways, which ensure s that patient care aligns with evidence -based guidelines and reduce s variation in clinical care between practitioners .469 E.g., population -data-enhanced care models AI can synthesize large volumes of data and generate customized care models. By aligning incentives around patient outcomes, AI can help payers develop value -based care models. Predictive analytics can identify trends and help develop care models for patie nts.470, 471 E.g., digital twins to measure patient conditions AI can analyze patient data from various sources, including EHRs, wearables, medical devices, and more, to generate digital twins that help provide early detection of health risks and create proactive interventions .472, 473 Potential to introduce bias E.g., inaccurate conclusions in research on patient populations AI algorithms trained on specific patient populations may be biased, leading to misrepresentative findings from research that do not apply equally across groups or perpetuate existing biases .474, 475 463 https://www.nia.nih.gov/research/dbsr/nih -stage -model -behavioral -intervention -development 464 https://www.samhsa.gov/resource/dbhis/trauma -focused -cognitive -behavioral -therapy -tf-cbt 465 https://grants.nih.gov/grants/guide/pa -files/PA -24-261.html 466 https://www.ahrq.gov/news/newsroom/press -releases/guiding -principles.html 467 https://obssr.od.nih.gov/ 468 https://www.samhsa.gov/about -us/who -we-are/offices -centers/cbhsq 469 https://healthsciencepub.com/index.php/jaihm/article/view/88/84 470 https://bmcmededuc.biomedcentral.com/articles/10.1186/s12909 -023-04698 -z 471 https://pmc.ncbi.nlm.nih.gov/articles/PMC11269274/ 472 https://pubmed.ncbi.nlm.nih.gov/31649194/ 473 https://ai.cms.gov/assets/CMS_AI_Playbook.pdf 474 https://pmc.ncbi.nlm.nih.gov/articles/PMC6347576/ 475 https://postgraduateeducation.hms.harvard.edu/trends -medicine/confronting -mirror -reflecting -our-biases -through -ai-health -care 95 Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Predictive tools informing research into patient outcomes and care models E.g., AI -enabled smartphone applications for medication adherence An AI -enabled smartphone app can provide reminders and dosage instructions and then confirm ingestion to detect non -adherence and predict future non - adherence.476 This data and any research findings from this work can be used to inform direct care and design of care models ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_353",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npatient outcomes and care models E.g., AI -enabled smartphone applications for medication adherence An AI -enabled smartphone app can provide reminders and dosage instructions and then confirm ingestion to detect non -adherence and predict future non - adherence.476 This data and any research findings from this work can be used to inform direct care and design of care models . E.g., predictive rapid response system for in -hospital cardiac arrest AI-based algorithm for predicting events of deterioration (e.g., cardiac arrest and unexpected ICU admission) , which c ould be used to improve decision - making and design of care models .477 3.6 Action Plan In light of the evolving AI landscape in healthcare delivery, HHS has already taken multiple steps including issuance of new guidelines and rules and launch of health AI related programs to promote responsible AI. The Action Plan below follows the four goals that support HHS’s AI strategy : 1. catalyzing health AI innovation and adoption ; 2. promoting trustworthy AI development and ethical and responsible use ; 3. democratizing AI technologies and resources ; and 4. cultivating AI -empowered workforces and organization cultures. For each goal, the Action Plan provides context, an overview of HHS and relevant other federal actions to date, and specific near- and long -term priorities HHS will take."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_354",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ninnovation and adoption ; 2. promoting trustworthy AI development and ethical and responsible use ; 3. democratizing AI technologies and resources ; and 4. cultivating AI -empowered workforces and organization cultures. For each goal, the Action Plan provides context, an overview of HHS and relevant other federal actions to date, and specific near- and long -term priorities HHS will take. HHS recognizes that th is Action Plan will require revisions over time as technologies evolve and is committed to providing structure and flexibility to ensure long standing impact. 3.6.1 Catalyze Health AI Innovation and Adoption HHS has an opportunity to increase AI innovation and adoption safely through the following actions: 1. Support ing the ability to gather evidence for effectiveness , safety, and risk mitigation of AI interventions and best practices for implementation in healthcare delivery settings 2. Provid ing guidelines and resources on oversight, medical liability, and privacy and security protections to increase confidence for organizations to develop AI 3. Ensur ing developers and potential deployers of AI have clarity on coverage and payment determination processes to encourage development of AI Below, HHS discusses the context, HHS and other federal actions to date, and plans to catalyze health AI innovation and adoption in healthcare delivery. 1."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_355",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand privacy and security protections to increase confidence for organizations to develop AI 3. Ensur ing developers and potential deployers of AI have clarity on coverage and payment determination processes to encourage development of AI Below, HHS discusses the context, HHS and other federal actions to date, and plans to catalyze health AI innovation and adoption in healthcare delivery. 1. Support ing the ability to gather evidence for effectiveness , safety, and risk mitigation of AI interventions and best practices for implementation in healthcare delivery settings Context: There is variation in both confidence and understanding of AI and concerns about its potential impacts among clinicians and other leaders in delivery settings. Some disciplines, such as radiology, have a more established track record of working with AI in clinical settings. In contrast, others are less likely to see AI applications beyond administrative settings in the present state . According to an AMA survey, 56% of physicians believe 476 https://pmc.ncbi.nlm.nih.gov/articles/PMC8521858/ 477 https://pubmed.ncbi.nlm.nih.gov/32205618/ 96 the most promising AI use cases are in supporting administrative tasks.478 Further research on the application of AI in complex clinical settings could unlock innovation and incentivize adoption by providing an evidence - based foundation for the appropriate and safe use of AI ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_356",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nstate . According to an AMA survey, 56% of physicians believe 476 https://pmc.ncbi.nlm.nih.gov/articles/PMC8521858/ 477 https://pubmed.ncbi.nlm.nih.gov/32205618/ 96 the most promising AI use cases are in supporting administrative tasks.478 Further research on the application of AI in complex clinical settings could unlock innovation and incentivize adoption by providing an evidence - based foundation for the appropriate and safe use of AI . These efforts could also aim to build evidence to address clinicians’ and other stakeholders’ concerns to ensure that AI is adopted in ways most helpful to patients and those engaged in their care. Such an approach will also help sustain effective and re sponsible use of AI by building confidence in these technologies for patients, clinicians, and other stakeholders based on an informed understanding of their benefits. Given that healthcare organizations in the U.S."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_357",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nconcerns to ensure that AI is adopted in ways most helpful to patients and those engaged in their care. Such an approach will also help sustain effective and re sponsible use of AI by building confidence in these technologies for patients, clinicians, and other stakeholders based on an informed understanding of their benefits. Given that healthcare organizations in the U.S. are highly diverse regarding AI readiness and infrastructure, additional resources, guidelines, and education would also help organizations assess decisions on investing in AI.479, 480, 481 HHS and other federal actions to date ( non-exhaustive ): • ASTP LEAP in Health Information Technology cooperative agreement awards provided funding opportunities for the advanced development of AI solutions for patient care.482 • CMS AI Health Outcomes Challenge provided innovators an opportunity to showcase their AI tools that can be used to predict patient health outcomes for Medicare beneficiaries for potential use in CMS with an opportunity to showcase their AI tools that help predict patient health outcomes for Medicare beneficiaries , which could be used in CMS ’s innovative payment and service delivery models.483 • NIH COVID -19 medical imaging during the COVID -19 pandemic engaged in a multi -institutional effort utilizing medical imaging techniques screening for infected heart and lung features to assess disease severity and propose treatments.484 • National Institute of Mental Health’s (NIMH) Digital Global Mental Health Program funds research on the development, testing, implementation, and cost -effectiveness of digital mental health technology appropriate for low - and middle -income countries.485 It places emphasis on research leveraging AI and/or other novel computational and statistical approaches to improve the prevention, diagnosis, and treatment of mental health along a treatment trajectory and continuum of care."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_358",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nDigital Global Mental Health Program funds research on the development, testing, implementation, and cost -effectiveness of digital mental health technology appropriate for low - and middle -income countries.485 It places emphasis on research leveraging AI and/or other novel computational and statistical approaches to improve the prevention, diagnosis, and treatment of mental health along a treatment trajectory and continuum of care. • General Service Administration’s (GSA’s) Technology Transformation Services (TTS) and other programs support research in healthcare delivery, including through tech uplift and innovation support, and could be expanded to include AI.486 • SAMHSA Innovative Uses of Technology to Enhance Access to Services Within the Crisis Continuum publication highlights innovative uses of technology that help those in need get access to critical services, including how AI can help with disease screening and delivery (e.g., personalized self - serve mental health apps)."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_359",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nuplift and innovation support, and could be expanded to include AI.486 • SAMHSA Innovative Uses of Technology to Enhance Access to Services Within the Crisis Continuum publication highlights innovative uses of technology that help those in need get access to critical services, including how AI can help with disease screening and delivery (e.g., personalized self - serve mental health apps). • AHRQ AI and Healthcare Safety NOFO invite s grant applications that support healthcare safety by determining (1) whether and how certain breakthrough uses of AI systems can affect patient safety and (2) how AI systems can be safely implemented and used.487 478 https://www.ama -assn.org/system/files/physician -ai-sentiment -report.pdf 479 https://pmc.ncbi.nlm.nih.gov/articles/PMC9628307/# 480 https://pubmed.ncbi.nlm.nih.gov/30802901/ 481 https://www.nejm.org/doi/full/10.1056/NEJMra2204673 482 https://www.hhs.gov/about/news/2024/09/17/hhs -announces -2024 -leap-health -awardees -focused -data-quality -responsible -ai-accelerating -adoption -behavioral - health.html 483 https://www.cms.gov/priorities/innovation/innovation -models/artificial -intelligence -health -outcomes -challenge 484 https://www.nih.gov/news -events/news -releases/nih -harnesses -ai-covid -19-diagnosis -treatment -monitoring 485 https://www.nimh.nih.gov/about/organization/cgmhr/digital -global -mental -health -program 486 https://tts.gsa.gov/ 487 https://grants.nih.gov/grants/guide/pa -files/PA -24-261.html 97 • SAMHSA Neural Network Analysis utilizes an AI neural network to analyze the co -occurrence of substance use problems, anxiety disorders, and depressive orders.488 Findings show evidence that mental health clinics should provide integrated treatment plans and screen for various conditions and factors."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_360",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-ai-covid -19-diagnosis -treatment -monitoring 485 https://www.nimh.nih.gov/about/organization/cgmhr/digital -global -mental -health -program 486 https://tts.gsa.gov/ 487 https://grants.nih.gov/grants/guide/pa -files/PA -24-261.html 97 • SAMHSA Neural Network Analysis utilizes an AI neural network to analyze the co -occurrence of substance use problems, anxiety disorders, and depressive orders.488 Findings show evidence that mental health clinics should provide integrated treatment plans and screen for various conditions and factors. HHS near -term priorities : • Support health services research on best practices for procuring, deploying, and monitoring AI tools in healthcare delivery settings (e.g., AHRQ healthcare safety and AI NOFO ).489 • Build on existing “challenge” initiatives driv ing innovation in AI relevant to healthcare delivery, such as the CMS AI Health Outcomes Challenge and the NIH CRDC AI Data -Readiness (AIDR) Challenge .490, 491 • Explore opportunities to expand initiatives that promote AI innovation in healthcare delivery contexts, such as the GSA’s TTS .492 • Provide guidelines on how to test and pilot AI applications within healthcare institutions before fully implementing them in care delivery. 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_361",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nas the CMS AI Health Outcomes Challenge and the NIH CRDC AI Data -Readiness (AIDR) Challenge .490, 491 • Explore opportunities to expand initiatives that promote AI innovation in healthcare delivery contexts, such as the GSA’s TTS .492 • Provide guidelines on how to test and pilot AI applications within healthcare institutions before fully implementing them in care delivery. 2. Provid ing guidelines and resources on oversight, medical liability, and privacy and security protections to increase confidence for organizations to develop and deploy AI Context: Providers are reticent to deploy new AI interventions without knowing whether they have been “vetted” by appropriate entities or whether these entities have considered patient outcomes , safety, privacy and other factors . They are further reluctant to use new AI technologies without appropriate clarity on their potential liability from using these tools. First, on oversight of quality assurance and vetting of AI interventions, despite many regulations that address technology in healthcare (e.g., medical technologies including EHRs and RCM), there are still gaps in clarity and scope in how they may specific ally address AI use (generally and situationally). For example, some AI technologies may fall outside of existing medical device authorities. Authority over the regulation of health IT that are not medical devices belongs in part to the ASTP/ ONC ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_362",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n(e.g., medical technologies including EHRs and RCM), there are still gaps in clarity and scope in how they may specific ally address AI use (generally and situationally). For example, some AI technologies may fall outside of existing medical device authorities. Authority over the regulation of health IT that are not medical devices belongs in part to the ASTP/ ONC . As descri bed in the Medical Product Development, Safety, and Effectiveness chapter, ASTP’s HTI -1 Final Rule does not create an approval process per se but does establish policies that require transparency on the part of certain c ertified health IT (such as EHRs) regarding the AI -based technology offered in such products. Starting on January 1, 2025, regulations finalized in the final rule require the availability of specific “source attribute” information for any decision support intervention technologies certified to 45 CFR 170.315(b)(11) (including AI -based decision support interventions) offered as part of the health IT product .493 An increasing number of AI tools in health IT could fall outside of current regulation, including certain EHR -integrated AI decision support tools (e.g., appointment no -show prediction algorithms) and AI algorithms deployed by health plans and insurance is suers for utilization management and prior authorization."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_363",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI -based decision support interventions) offered as part of the health IT product .493 An increasing number of AI tools in health IT could fall outside of current regulation, including certain EHR -integrated AI decision support tools (e.g., appointment no -show prediction algorithms) and AI algorithms deployed by health plans and insurance is suers for utilization management and prior authorization. These tools that do not meet the statutory definition of “device” for FDA oversight may not currently undergo regulatory review, validation, or testing.494 Additionally, the HTI-1 Final Rule applies to A I-based technologies regardless of device definitions, use cases (e.g., clinical, administrative) , or risk categories. HHS aims to further refine its regulatory framework covering AI technologies to promote safe and trustworthy use."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_364",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndo not meet the statutory definition of “device” for FDA oversight may not currently undergo regulatory review, validation, or testing.494 Additionally, the HTI-1 Final Rule applies to A I-based technologies regardless of device definitions, use cases (e.g., clinical, administrative) , or risk categories. HHS aims to further refine its regulatory framework covering AI technologies to promote safe and trustworthy use. 488 https://www.tandfonline.com/doi/full/10.1080/15504263.2024.2357623 489 https://grants.nih.gov/grants/guide/pa -files/PA -24-261.html 490 https://www.cms.gov/priorities/innovation/innovation -models/artificial -intelligence -health -outcomes -challenge 491 https://commons.cancer.gov/news/nci -crdc-artificial -intelligence -data-readiness -aidr-challenge 492 https://tts.gsa.gov/ 493 https://www.healthit.gov/topic/laws -regulation -and-policy/health -data-technology -and-interoperability -certification -program 494 https://www.fda.gov/regulatory -information/search -fda-guidance -documents/clinical -decision -support -software 98 Additionally, regarding liability, while there is considerable experience regarding liability associated with the uses of technology in medical practice, AI (and especially GenAI such as LLMs ) “raise[s] distinctive issues that do not apply to older forms of CDS or ways of researching medical questions online.”495 The use of patient data in AI has caused concerns among both medical professionals and patients ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_365",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nwhile there is considerable experience regarding liability associated with the uses of technology in medical practice, AI (and especially GenAI such as LLMs ) “raise[s] distinctive issues that do not apply to older forms of CDS or ways of researching medical questions online.”495 The use of patient data in AI has caused concerns among both medical professionals and patients . These include how it can be used in model development, patient consent for providers and developers regarding data storage, and when patients are informed of use. Ongoing updates to model inputs and training make it difficult to establish fact patterns and/or recreate specific incidents or scenarios needed for evidentiary rules. Regarding patient data usage, HIPAA Privacy and Security Rule compliance is required when covered entities or business associates use or disclose PHI for AI development or maintenance. Uses and disclosures of PHI under HIPAA require written patient authorization unless permitted for certain specified purposes such as treatment, payment, or healthcare operations. When PHI is used for research involving AI , depending on the type of PHI being disclosed and the type of research being conducted , the HIPAA Privac y Rule may require that the individual authorizes the use or disclosure of PHI or provide a waiver or alteration of authorization by an IRB.496 Sharing PHI with AI developers may also create additional complexity."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_366",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nused for research involving AI , depending on the type of PHI being disclosed and the type of research being conducted , the HIPAA Privac y Rule may require that the individual authorizes the use or disclosure of PHI or provide a waiver or alteration of authorization by an IRB.496 Sharing PHI with AI developers may also create additional complexity. Ultimately, using or disclosing patient data, including PHI, for AI models requires case -specific assessment and management to ensure compliance with HIPAA and other privacy regulations.497 The “Promote Trustworthy AI Development and Ethical and Responsible Use” section of this action plan further discusses patient security and privacy . Ultimately, supplementing guidelines and regulations while enhancing clarity on oversight and quality assurance from HHS divisions will enhance confidence in adopting safe and appropriate AI use cases within delivery and financing. HHS near -term priorities: • Provide additional guidelines on how AI use in healthcare should adhere to privacy and security standards, including HIPAA. This will include providing guidelines on risks of re -identification in the context of HIPAA and delineating when data used for AI requires patient authorization (i.e., research). To execute this priority, HHS will collaborate with other federal agencies t o create unified standards and frameworks for privacy and security in AI applications."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_367",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nadhere to privacy and security standards, including HIPAA. This will include providing guidelines on risks of re -identification in the context of HIPAA and delineating when data used for AI requires patient authorization (i.e., research). To execute this priority, HHS will collaborate with other federal agencies t o create unified standards and frameworks for privacy and security in AI applications. • Within applicable existing HHS and division authorities, provide additional guidelines on liability considerations for clinicians and healthcare providers using AI. • Provide guidelines and frameworks for appropriate approaches and roles clinicians and support staff should have in engaging with AI (e.g., role suitability related to technology based on the risk level of the AI application). • Continue to clarify and build stakeholder awareness on applicable oversight and regulatory structures. 3."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_368",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\non liability considerations for clinicians and healthcare providers using AI. • Provide guidelines and frameworks for appropriate approaches and roles clinicians and support staff should have in engaging with AI (e.g., role suitability related to technology based on the risk level of the AI application). • Continue to clarify and build stakeholder awareness on applicable oversight and regulatory structures. 3. Ensur ing developers and potential deployers of AI have clarity on coverage and payment determination processes to encourage development of AI Context: With many providers already facing economic pressure, there is limited appetite to invest in or use new and emerging information technologies, particularly when there is no guarantee of payment for services.498 Clear 495 https://jamanetwork.com/journals/jama -health -forum/fullarticle/2805334 496 45 CFR 164.512(i)(1)(i) 497 https://www.justice.gov/opcl/privacy -act-1974 498 https://pmc.ncbi.nlm.nih.gov/articles/PMC8166111/# 99 frameworks for payment for AI -enabled services will influence the wider use of AI in medicine, as providers may be more financially incentivized to utilize such technologies.499 Increasing the clarity on frameworks for payment for AI services will require policymakers to disseminate information to technology developers, device manufacturers, clinicians, and patients."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_369",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n45 CFR 164.512(i)(1)(i) 497 https://www.justice.gov/opcl/privacy -act-1974 498 https://pmc.ncbi.nlm.nih.gov/articles/PMC8166111/# 99 frameworks for payment for AI -enabled services will influence the wider use of AI in medicine, as providers may be more financially incentivized to utilize such technologies.499 Increasing the clarity on frameworks for payment for AI services will require policymakers to disseminate information to technology developers, device manufacturers, clinicians, and patients. Clarity in payment determinations processes could support numerous priorities, including informing access to innovative technologies, reducing uncertainty for developers and manufacturers, protecting the safety of beneficiaries of federal programs, stewardship of federal funds, and encouraging evid ence development where gaps exist. HHS actions to date ( non-exhaustive ): • CMS established separate payment pathways for at least eight AI/ML-enabled devices through CPT® and new technology add -on payments (NTAP) under the Medicare Inpatient Prospective Payment System (IPPS ), as of May 2024,500 which represents less than 5% of FDA -authorized AI-based products.501, 502, 503 CMS has taken steps to ensure that Medicare coverage determination and payment pathways are clear for innovations, including those enabled by AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_370",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nleast eight AI/ML-enabled devices through CPT® and new technology add -on payments (NTAP) under the Medicare Inpatient Prospective Payment System (IPPS ), as of May 2024,500 which represents less than 5% of FDA -authorized AI-based products.501, 502, 503 CMS has taken steps to ensure that Medicare coverage determination and payment pathways are clear for innovations, including those enabled by AI. • CMS payment for Software as a Service (as referenced in the Medical Product Development, Safety, and Effectiveness chapter ) established payment pathways for hospital outpatient departments through add-on codes.504 • CMS Transitional Coverage for Emerging Technologies (TCET) (CMS -3421 -FN) (as referenced in the Medical Product Development, Safety, and Effectiveness chapter ) finalized the TCET Pathway in August 2024 to facilitate safer and more predictable access to new technologies for Medicare beneficiaries and further reduce uncertainties about coverage.505 HHS near -term priorities: • Convene key stakeholders to inform coverage process and requirements for federal insurance programs (e.g., policymakers, technology developers, device manufacturers, clinicians, and patients). • Provide guidelines and clarity on the coverage determination process for new AI products and services provided to federal beneficiaries. • Develop guidelines for AI developers regarding evidentiary standards for payment and coverage decision -making."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_371",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-term priorities: • Convene key stakeholders to inform coverage process and requirements for federal insurance programs (e.g., policymakers, technology developers, device manufacturers, clinicians, and patients). • Provide guidelines and clarity on the coverage determination process for new AI products and services provided to federal beneficiaries. • Develop guidelines for AI developers regarding evidentiary standards for payment and coverage decision -making. 3.6.2 Promote Trustworthy AI Development and Ethical and Responsible Use A primary focus of AI in care delivery is ensuring patient safety, security, and privacy. AHRQ defines patient safety as a multifaceted discipline intended to protect patients in care administration . Potential AI -related patient adverse events (resulting either from an incorrect action carried out by an AI-enabled tool or healthcare staff incorrectly using an AI -enabled tool ) must be thoroughly mitigated."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_372",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nof AI in care delivery is ensuring patient safety, security, and privacy. AHRQ defines patient safety as a multifaceted discipline intended to protect patients in care administration . Potential AI -related patient adverse events (resulting either from an incorrect action carried out by an AI-enabled tool or healthcare staff incorrectly using an AI -enabled tool ) must be thoroughly mitigated. In healthcare delivery , some methods of increasing trustworthiness and safety related to AI include e nsuring a human [is] in the loop during AI decision - making, ensuring that models and their use by providers and payers are transparent, interpretable, and explainable, 499 https://doi.org/10.1038/s41746 -022-00609 -6 Paying for artificial intelligence in medicine 500 https://www.nature.com/articles/s41746 -022-00609 -6/tables/1 501 https://www.fda.gov/medical -devices/software -medical -device -samd/artificial -intelligence -and-machine -learning -aiml-enabled -medical -devices 502 https://doi.org/10.1038/s41746 -022-00609 -6 Paying for artificial intelligence in medicine 503 As with other technologies, Medicare provides payment for AI -enabled devices on a case -by-case basis, based on applications submitted by healthcare providers, device manufacturers, or other stakeholders ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_373",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nartificial intelligence in medicine 500 https://www.nature.com/articles/s41746 -022-00609 -6/tables/1 501 https://www.fda.gov/medical -devices/software -medical -device -samd/artificial -intelligence -and-machine -learning -aiml-enabled -medical -devices 502 https://doi.org/10.1038/s41746 -022-00609 -6 Paying for artificial intelligence in medicine 503 As with other technologies, Medicare provides payment for AI -enabled devices on a case -by-case basis, based on applications submitted by healthcare providers, device manufacturers, or other stakeholders . 504 https://www.govinfo.gov/content/pkg/FR -2022 -11-23/pdf/2022 -23918.pdf# 505 https://www.cms.gov/newsroom/fact -sheets/final -notice -transitional -coverage -emerging -technologies -cms-3421 -fn 100 and clear guardrails are established for its use. Lack of explainability in AI systems can lead to skepticism, over - reliance, or rejection by clinicians.506, 507 Underpinning these principles are the following priority areas where HHS can support the safe use of AI: 1. Enhanc ing enforcement and clarify ing guidelines relating to existing requirements 2. Provid ing guidelines and support related to internal governance 3. Promot ing external evaluation, monitoring, and transparency reporting 4. Enhanc ing infrastructure to ensure patient safety Below, HHS discusses the context, its actions to date, and plans to promote trustworthy AI development and ethical and responsible use in healthcare delivery. 1."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_374",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand clarify ing guidelines relating to existing requirements 2. Provid ing guidelines and support related to internal governance 3. Promot ing external evaluation, monitoring, and transparency reporting 4. Enhanc ing infrastructure to ensure patient safety Below, HHS discusses the context, its actions to date, and plans to promote trustworthy AI development and ethical and responsible use in healthcare delivery. 1. Enhanc ing enforcement and clarify ing guidelines relating to existing requirements Context : As discussed earlier, HHS and its divisions can promote adoption and protect beneficiaries in the context of AI by clarifying existing healthcare regulations and proactively enforcing existing legal requirements that certain AI applications may violate . These efforts will provide an improved, safer patient experience in cases where questions exist about whether existing federal requirements are being properly applied. Given the rapidly expanding nature of AI risks, adding clarity to existing regulations may not always be sufficient. HHS could develop new levers, rules, and programs to ensure that healthcare organizations and AI developers adhere to best-practice risk mitigation principles at every stage of the AI life cycle , spanning design, development, deployment, maintenance , and retirement."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_375",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nbeing properly applied. Given the rapidly expanding nature of AI risks, adding clarity to existing regulations may not always be sufficient. HHS could develop new levers, rules, and programs to ensure that healthcare organizations and AI developers adhere to best-practice risk mitigation principles at every stage of the AI life cycle , spanning design, development, deployment, maintenance , and retirement. HHS actions to date ( non-exhaustive ): • AHRQ AI developed a program in healthcare safety (see subsections below for an additional dedicated discussion of patient safety ) in response to EO 14110 and as part of the Patient Safety Organizations Program to allow for the rapid development of AI patient safety -focused data, analyses, and resources. The program helps collectively track and identify situations where AI deployed in healthcare settings may ca use adverse events and provides a means of learning from such occurrences in the future. The Patient Safety and Quality Improvement Act of 2005, 42 U.S.C."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_376",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nSafety Organizations Program to allow for the rapid development of AI patient safety -focused data, analyses, and resources. The program helps collectively track and identify situations where AI deployed in healthcare settings may ca use adverse events and provides a means of learning from such occurrences in the future. The Patient Safety and Quality Improvement Act of 2005, 42 U.S.C. 299b -21 et seq., which established the PSO P rogram, also provides certain legal protections for organizations to share information on patient safety events to improve care without the fear that the information could be used against them in settings such as legal or administrative proceedings.508 • HHS Plan for Promoting Responsible Use of Artificial Intelligence in Automated and Algorithmic Systems by STLT Governments in the Administration of Public Benefits includes recommendations such as impact assessment to determine estimated benefits and risks from AI, measuring the quality and appropriateness of the data used in a system’s training, testing, and prediction, and consulting workers and providing adequate training for all staff around developing, using, enhancing, and maintaining automated and al gorithmic systems.509 • Final Rule on Nondiscrimination in Health Programs and Activities (Section 1557 of the Patient Protection and Affordable Care Act [“Section 1557 ”]) prohibits discrimination in certain health programs and activities, and, like other federal civil rights laws, Section 1557 applies to the use of AI, clinical algorithms, predictive analytics, and other tools."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_377",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand maintaining automated and al gorithmic systems.509 • Final Rule on Nondiscrimination in Health Programs and Activities (Section 1557 of the Patient Protection and Affordable Care Act [“Section 1557 ”]) prohibits discrimination in certain health programs and activities, and, like other federal civil rights laws, Section 1557 applies to the use of AI, clinical algorithms, predictive analytics, and other tools. 506 https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911 -020-01332 -6 507 https://ccforum.biomedcentral.com/articles/10.1186/s13054 -024-05005 -y# 508 https://pso.ahrq.gov/sites/default/files/wysiwyg/ai -healthcare -safety -program.pdf 509 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 101 o Section 1557 includes a provision that applies non -discrimination principles to using patient care decision support tools, including AI ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_378",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nlike other federal civil rights laws, Section 1557 applies to the use of AI, clinical algorithms, predictive analytics, and other tools. 506 https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911 -020-01332 -6 507 https://ccforum.biomedcentral.com/articles/10.1186/s13054 -024-05005 -y# 508 https://pso.ahrq.gov/sites/default/files/wysiwyg/ai -healthcare -safety -program.pdf 509 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 101 o Section 1557 includes a provision that applies non -discrimination principles to using patient care decision support tools, including AI . It requires those organizations covered by the rule — including any health program or activity that receives Federal financial assistance from HHS, including health insurance exchanges and HHS health programs and activities —to take steps to identify and mitigate the risk of discrimination that may result through the us e of AI and other forms of patient care decision support tools.510, 511 • Frequently asked questions (FAQ) related to coverage criteria and utilization management requirements in CMS final rule (CMS -4201 -F) emphasized compliance with existing coverage rules by addressing the question of whether Medicare Advantage (MA) rules on coverage criteria prohibit MA organizations from using algorithms or AI to make coverage decisions."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_379",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nother forms of patient care decision support tools.510, 511 • Frequently asked questions (FAQ) related to coverage criteria and utilization management requirements in CMS final rule (CMS -4201 -F) emphasized compliance with existing coverage rules by addressing the question of whether Medicare Advantage (MA) rules on coverage criteria prohibit MA organizations from using algorithms or AI to make coverage decisions. The FAQ response explained that while an algorithm may be used to assist in making coverage determinations, it is the responsibility of the MA organization t o ensure compliance with applicable rules for coverage determinations, such as those related to medical necessity and basing a decision on individual patient’s circumstances. o CMS released a rule on December 10, 2024, that provides additional clarifications on the topics of coverage criteria, utilization management requirements, and AI use that also clarifies and amends language in 422.112(a)(8) (Ensuring Equitable Access to Medicare Advantage (MA) Services —Guardrails for Artificial Intelligence).512, 513 • The HHS Trustworthy AI playbook details principles organizations can implement to foster additional trust in their AI development ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_380",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nDecember 10, 2024, that provides additional clarifications on the topics of coverage criteria, utilization management requirements, and AI use that also clarifies and amends language in 422.112(a)(8) (Ensuring Equitable Access to Medicare Advantage (MA) Services —Guardrails for Artificial Intelligence).512, 513 • The HHS Trustworthy AI playbook details principles organizations can implement to foster additional trust in their AI development . It captures mandates from regulations such as EO 13960, Office of Management and Budget (OMB) Memorandum M -21-06, and NIST guidelines.514 HHS near -term priorities: • Increase the oversight and enforcement of existing federal laws and regulations, such as those prohibiting denying medically necessary, covered services or discrimination in access to federal benefits. • Collaborate with other agencies outside of HHS (e.g., the Federal Trade Commission [FTC]) to strengthen and enforce consumer protections related to health data privacy and false marketing in the context of AI. This could include monitoring and addressing AI applications that compromise health data privacy or enhancing data sharing among agencies to detect and respond more rapidly to AI violations in healthcare settings. • Develop additional targeted guidelines building on existing policy frameworks that explain to regulated entities how to comply with existing requirements when AI tools or technologies are applied. 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_381",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nThis could include monitoring and addressing AI applications that compromise health data privacy or enhancing data sharing among agencies to detect and respond more rapidly to AI violations in healthcare settings. • Develop additional targeted guidelines building on existing policy frameworks that explain to regulated entities how to comply with existing requirements when AI tools or technologies are applied. 2. Provid ing guidelines and support related to the local governance of AI Context: Some healthcare delivery and financing organizations have established their governance frameworks and means of vetting, evaluating, and monitoring AI tools locally . However, in other cases, risk assessment 510 See 45 Code of Federal Regulations (CFR) 92.210. 511 These requirements will take effect on May 1, 2025 . 512 https://public -inspection.federalregister.gov/2024 -27939.pdf 513 https://www.ecfr.gov/current/title -42/chapter -IV/subchapter -B/part -422/subpart -C/section -422.112 514 https://www.hhs.gov/sites/default/files/hhs -trustworthy -ai-playbook.pdf 102 processes and clear governance structures may not be in place or may not be rigorous enough to protect patients or beneficiaries.515 HHS actions to date ( non-exhaustive ): • HHS and division playbook s provide d perspectives on risk, including the Trustworthy AI (TAI) playbook and CMS AI Playbook, which provide specific considerations to help organizations safely operationalize AI development."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_382",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nprocesses and clear governance structures may not be in place or may not be rigorous enough to protect patients or beneficiaries.515 HHS actions to date ( non-exhaustive ): • HHS and division playbook s provide d perspectives on risk, including the Trustworthy AI (TAI) playbook and CMS AI Playbook, which provide specific considerations to help organizations safely operationalize AI development. • AHRQ Guiding Principles to Address the Impact of Algorithm Bias on Racial and Ethnic Disparities in Health and Healthcare include d principles for organizations seeking to mitigate racial and ethnic disparities across every step of the AI life cycle .516 • AHRQ Digital Healthcare Equity Framework and Practical Guide for Implementation is an evidence -based guide to help organizations intentionally consider equity in developing and using digital healthcare technologies and solutions. The Guide serves as a resource to digital healthcare developers and vendors, healthcare systems, clinical providers, and payers and includes a checklist of steps and real-world examples for advancing equity across phases of the Digital Healthcare Life Cycle .517, 518 HHS near -term priorities: • Within HHS authorities, support efforts to develop targeted guidelines on risk management and internal AI governance for health organizations that build on existing policy, governance, and risk management frameworks (e.g., NIST AI Risk Management Framework and ASTP’s HTI -1 Final Rule )."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_383",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nfor advancing equity across phases of the Digital Healthcare Life Cycle .517, 518 HHS near -term priorities: • Within HHS authorities, support efforts to develop targeted guidelines on risk management and internal AI governance for health organizations that build on existing policy, governance, and risk management frameworks (e.g., NIST AI Risk Management Framework and ASTP’s HTI -1 Final Rule ). Guidelines may include standards that apply globally, by sector, or by use type and are specific enough to apply effectively to different healthcare delivery and financing subcategories . They may vary by applicable division o r framework. • Explore using federal programs and incentives, including those administered by CMS, to require or encourage internal governance mechanisms and evaluation practices for healthcare delivery and financing organizations. This could include regulations requiring the establishment of internal committees responsible for monitoring and reviewing all AI use cases across their organizations. • Explore mechanisms to ensure that healthcare delivery and financing organizations, including those administered by CMS, meet the minimum governance and evaluation standards and identify relevant authorities to enforce these requirements (e.g., via audits, corrective action plans, and enforcement in the event of continued noncompliance). • Develop recommended minimum standards for evaluating the risk of AI tools."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_384",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nacross their organizations. • Explore mechanisms to ensure that healthcare delivery and financing organizations, including those administered by CMS, meet the minimum governance and evaluation standards and identify relevant authorities to enforce these requirements (e.g., via audits, corrective action plans, and enforcement in the event of continued noncompliance). • Develop recommended minimum standards for evaluating the risk of AI tools. These could include risk stratification guidelines based on the device ’s potential impact and risk -appropriate monitoring cadence and metrics. • Develop hospital guidelines and resources to identify, manage, and mitigate AI -related safety, bias, or effectiveness concerns. HHS long -term priorities: • Continue educating the public and clinical teams on trustworthy and safe AI through publications, research, and standards to interpret AI, communicate interventions to patients, identify types of adverse events that can occur with AI, and how to report such events through e xisting systems. • Convene and/or support publicly accessible conferences and dialogue with industry experts on AI risks and appropriate risk management approaches. 515 https://ai.nejm.org/doi/abs/10.1056/AIp2300048 For example, one study found that even well -resourced academic medical centers sometimes found it difficult to identify and manage potential problems associated with predictive AI tools."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_385",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI, and how to report such events through e xisting systems. • Convene and/or support publicly accessible conferences and dialogue with industry experts on AI risks and appropriate risk management approaches. 515 https://ai.nejm.org/doi/abs/10.1056/AIp2300048 For example, one study found that even well -resourced academic medical centers sometimes found it difficult to identify and manage potential problems associated with predictive AI tools. How Academic Medical Centers Govern AI Prediction Tools in the Context of Uncertainty and Evolving Regulation. 516 https://pubmed.ncbi.nlm.nih.gov/38100101/ 517 https://digital.ahrq.gov/health -it-tools -and-resources/digital -healthcare -equity 518 https://digital.ahrq.gov/health -it-tools -and-resources/digital -healthcare -equity/digital -healthcare -equity -framework -and-guide 103 3. Promot ing external evaluation, monitoring, and transparency reporting to enhance the quality assurance of AI Context: Testing and evalua ting the effects of AI in real -world delivery settings is challenging due to the rapid expansion of AI in different clinical areas and due to common challenges inherent to clinical medical data (e.g., low prevalence of certain disease s, lack of or difficulty in obtaining ground truth data) . Furthermore, the potential of AI lies in its ability to design models that learn, update, and adapt continuously as more data becomes available or as data changes."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_386",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nof AI in different clinical areas and due to common challenges inherent to clinical medical data (e.g., low prevalence of certain disease s, lack of or difficulty in obtaining ground truth data) . Furthermore, the potential of AI lies in its ability to design models that learn, update, and adapt continuously as more data becomes available or as data changes. This ability poses unique regulatory challenges, requiring the development of suitable controls and testing methods that balance the potential benefits and risks of adopting AI within and beyond traditional clinic settings. HHS recognizes the se real-world challenges associated with establishing appropriate evaluation and monitoring processes and will balance the scope of requir ed monitoring and evaluation against the risk posed by AI in proposing regulatory guardrails. Given the large volume and diversity of anticipated AI applications needing some evaluation and the need to take local considerations into account, HHS anticipates the need for a public/private approach to quality assurance of AI used in healthcare.519 To help anchor a nationwide quality assurance approach, HHS may consider whether there are areas where rulemaking may be appropriate to enable successful governance practices and oversight of the use of AI in healthcare delivery and financing, for example , by motivating and supporting nationwide public -private approaches to validate AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_387",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\napproach to quality assurance of AI used in healthcare.519 To help anchor a nationwide quality assurance approach, HHS may consider whether there are areas where rulemaking may be appropriate to enable successful governance practices and oversight of the use of AI in healthcare delivery and financing, for example , by motivating and supporting nationwide public -private approaches to validate AI. See also the Medical Product Development, Safety, and Effectiveness chapter for further discussion of approaches to quality assurance of health AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_388",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthere are areas where rulemaking may be appropriate to enable successful governance practices and oversight of the use of AI in healthcare delivery and financing, for example , by motivating and supporting nationwide public -private approaches to validate AI. See also the Medical Product Development, Safety, and Effectiveness chapter for further discussion of approaches to quality assurance of health AI. HHS actions to date ( non-exhaustive): • HTI-1 Final Rule lays a foundation for transparency by establishing a set of requirements for certain AI supplied by EHR developers and their systems that are certified under the ONC Health IT Certification Program to ensure clinical users will be able to access a consistent, baseline set of information about the algorithms they use to support their decision -making.520 Other industry actions to date ( non-exhaustive): • Multiple organizations collaborating on initiatives to convene healthcare delivery stakeholders to address challenges and launch initiatives related to AI.521 • The Trustworthy and Responsible AI Network (TRAIN) is a collaboration of provider organizations working to operationalize responsible AI principles .522 • The Coalition for Health AI (CHAI) is a collaboration among healthcare organi zations and technology developers to promote development, evaluation, and appropriate use of AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_389",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nconvene healthcare delivery stakeholders to address challenges and launch initiatives related to AI.521 • The Trustworthy and Responsible AI Network (TRAIN) is a collaboration of provider organizations working to operationalize responsible AI principles .522 • The Coalition for Health AI (CHAI) is a collaboration among healthcare organi zations and technology developers to promote development, evaluation, and appropriate use of AI. The collaboration has developed a template “model card” aligned with ASTP’s HTI-1 AI transparency requirements.523 HHS near -term priorities: • Build on transparency requirements by working with the industry to specify consensus approaches to standardized metrics, information, and data for HTI -1’s decision support interventions’ source attribute (aka “model card”) requirements. 519 https://jamanetwork.com/journals/jama/article -abstract/2813425 A Nationwide Network of Health AI Assurance Laboratories. 520 Providers and payers have voluntarily committed to leveraging this framework to help guide their AI governance, development, and purchasing activities."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_390",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nrequirements by working with the industry to specify consensus approaches to standardized metrics, information, and data for HTI -1’s decision support interventions’ source attribute (aka “model card”) requirements. 519 https://jamanetwork.com/journals/jama/article -abstract/2813425 A Nationwide Network of Health AI Assurance Laboratories. 520 Providers and payers have voluntarily committed to leveraging this framework to help guide their AI governance, development, and purchasing activities. 521 https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000513 522 https://train4health.ai/ 523 https://chai.org/draft -chai-applied -model -card/ 104 • Support efforts to widen the accessibility of AI performance information by considering incentives to disclose healthcare providers ’ and payers ’ use of AI and related performance information that impacts access to or the quality of care."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_391",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthis framework to help guide their AI governance, development, and purchasing activities. 521 https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000513 522 https://train4health.ai/ 523 https://chai.org/draft -chai-applied -model -card/ 104 • Support efforts to widen the accessibility of AI performance information by considering incentives to disclose healthcare providers ’ and payers ’ use of AI and related performance information that impacts access to or the quality of care. • Explore the use of federal programs and incentives to encourage external accountability mechanisms for payer and provider organizations deploying AI, including: o Motivating deployers of AI to undergo independent, external algorithmic audits conducted by certified entities free from conflict of interest o Incentivizing performance transparency among other developers and deployers of AI to include a broader range of technologies (e.g., beyond EHR technologies covered by policies finalized in HTI-1)524 o Collaboration with existing and emerging validation, monitoring, and transparency efforts in the private sector, supporting when and where appropriate. 4. Enhanc ing infrastructure to ensure patient safety, security, and privacy Context: As discussed previously in this Plan, maintaining patient safety, security, and privacy is a pivotal but complex challenge compounded by the possibilities of AI to influence or administer care delivery."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_392",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nwith existing and emerging validation, monitoring, and transparency efforts in the private sector, supporting when and where appropriate. 4. Enhanc ing infrastructure to ensure patient safety, security, and privacy Context: As discussed previously in this Plan, maintaining patient safety, security, and privacy is a pivotal but complex challenge compounded by the possibilities of AI to influence or administer care delivery. A key component of ensuring patient safety is maintaining enough direct oversight by clin ical staff (including face-to-face time between doctors and patients and monitoring of insights that AI may suggest). Patients also increasingly demand transparency about decisions impacting their care , particularly if AI tools influence diagnoses or treatments. Caregivers also require clear information on their AI tools so they can communicate to patients how AI is being leveraged in care, which will empower patients to make informed decisions and provide consent. AI introduces potential new vulnerabilities concerning patient security and privacy . The types of data demanded and the number of stakeholders seeking it continue broadening, underscoring the importance of ensuring robust patient data protection as AI use expands. As discussed in “Catalyze health AI innovation and adoption” above, HHS privacy and security protections such as HIPAA provide guidelines for handling patient data."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_393",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npotential new vulnerabilities concerning patient security and privacy . The types of data demanded and the number of stakeholders seeking it continue broadening, underscoring the importance of ensuring robust patient data protection as AI use expands. As discussed in “Catalyze health AI innovation and adoption” above, HHS privacy and security protections such as HIPAA provide guidelines for handling patient data. Still, an additional opportunity exists to evolve such protections in parallel with AI technology. HHS has already taken steps to address such areas of concern for patient safety, security, and privacy in AI and will continue expanding its strategy. HHS actions to date ( non-exhaustive): • AHRQ’s AI in Healthcare Safety Program took steps to analyze and aggregate data of types of AI incidents (e.g., patients, caregivers, or others) and encourages more organizations to work with PSOs that support patient safety and quality improvement."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_394",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nconcern for patient safety, security, and privacy in AI and will continue expanding its strategy. HHS actions to date ( non-exhaustive): • AHRQ’s AI in Healthcare Safety Program took steps to analyze and aggregate data of types of AI incidents (e.g., patients, caregivers, or others) and encourages more organizations to work with PSOs that support patient safety and quality improvement. Specifically, to “establish a common framework for approaches to identifying and capturing clinical errors resulting from AI deployed in healthcare settings,” the existing common formats provide a basis for and can be enhanced to better capture such concerns.525 • AHRQ’s PSO Program —communication mechanism —engaged with the PSOs on AI and healthcare through various presentations and discussions.526 • AHRQ exploratory analyses of patient safety events , through the Network of Patient Safety Databases (NPSD), analyzed potential AI -related patient safety events to better understand the current 524 Metrics and measures that are similar to what pertain to certified EHRs would provide users basic information about algorithm s, training data, and performance metrics and provide a better foundation for evaluation ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_395",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nanalyses of patient safety events , through the Network of Patient Safety Databases (NPSD), analyzed potential AI -related patient safety events to better understand the current 524 Metrics and measures that are similar to what pertain to certified EHRs would provide users basic information about algorithm s, training data, and performance metrics and provide a better foundation for evaluation . 525 https://pso.ahrq.gov/resources/ai -healthcare -safety# 526 https://www.psoppc.org/psoppc_web/DLMS/downloadDocument?groupId=2371&pageName=welcome 105 capacity of the Common Formats and NPSD in capturing where AI deployed in the healthcare setting may cause unintended impacts.527, 528 HHS near -term priorities: • Expand the capability of PSOs to assist providers in learning from and preventing potentially AI -related adverse impacts through education , resource sharing, and development. • Explore mechanisms to encourage data submission on potentially AI -related events as part of the AI in Healthcare Safety Program. HHS long -term priorities: • Utilize the NPSD as the “central tracking repository” for patient safety incidents resulting from AI deployed in healthcare settings . The repository already includes some related information."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_396",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthrough education , resource sharing, and development. • Explore mechanisms to encourage data submission on potentially AI -related events as part of the AI in Healthcare Safety Program. HHS long -term priorities: • Utilize the NPSD as the “central tracking repository” for patient safety incidents resulting from AI deployed in healthcare settings . The repository already includes some related information. • Consider expanding AHRQ AI in Healthcare Safety Program to sustain and build upon initial program projects and advance activities that analyze the NPSD.529 • Promote AHRQ research on mitigating racial bias from algorithms530 • Consider expanding grant -making projects and NOFOs. • Continue to evaluate potential impacts that AI may have on patient -provider interactions (e.g., direct face-to-face time, gathering of patient information). 3.6.3 Democratize AI Technologies and Resources To achieve the goals for AI to accelerate access and equity in healthcare delivery, the technology and understanding around implementation must be accessible. Without the explicit consideration of biases resulting from the under -representation of certain patient populations from training data, underserved settings could find themselves experiencing less benefit from AI.531 HHS can implement actions in the areas below, with particular attention to stakeholder groups that may already be affected by the digital divide: 1."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_397",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ntechnology and understanding around implementation must be accessible. Without the explicit consideration of biases resulting from the under -representation of certain patient populations from training data, underserved settings could find themselves experiencing less benefit from AI.531 HHS can implement actions in the areas below, with particular attention to stakeholder groups that may already be affected by the digital divide: 1. Promot ing equitable access through technical support for and collaboration with delivery organizations that provide services to underserved populations 2. Provid ing support for healthcare delivery organizations to address core infrastructure and deployment challenges (i.e., technology, infrastructure, and data infrastructure) that improve AI readiness Below, HHS discusses the context, its actions to date, and plans to democratize AI technologies and resources within the healthcare sector. 1."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_398",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsupport for and collaboration with delivery organizations that provide services to underserved populations 2. Provid ing support for healthcare delivery organizations to address core infrastructure and deployment challenges (i.e., technology, infrastructure, and data infrastructure) that improve AI readiness Below, HHS discusses the context, its actions to date, and plans to democratize AI technologies and resources within the healthcare sector. 1. Promot ing equitable access through technical support for and collaboration with delivery organizations that provide services to underserved populations Context: The extent of possible AI impacts on underserved populations is still greatly unknown, especially given the complex and under -researched nuances that underserved communities may face.532 527 https://www.psoppc.org/psoppc_web/DLMS/downloadDocument?groupId=2372&pageName=welcome 528 https://pso.ahrq.gov/common -formats 529 https://pso.ahrq.gov/resources/ai -healthcare -safety# 530 https://pubmed.ncbi.nlm.nih.gov/38100101/ 531 https://pmc.ncbi.nlm.nih.gov/articles/PMC10844447/ 532 https://pmc.ncbi.nlm.nih.gov/articles/PMC8486995/ 106 Care providers in predominately underserved settings —e.g., community health centers and safety -net hospitals —may stand to benefit the most from the potential of AI (e.g., reduced costs, lower administrative burdens) while also facing the largest barriers, given a lack of AI expertise and robust capital budgets to deploy new technology."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_399",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-healthcare -safety# 530 https://pubmed.ncbi.nlm.nih.gov/38100101/ 531 https://pmc.ncbi.nlm.nih.gov/articles/PMC10844447/ 532 https://pmc.ncbi.nlm.nih.gov/articles/PMC8486995/ 106 Care providers in predominately underserved settings —e.g., community health centers and safety -net hospitals —may stand to benefit the most from the potential of AI (e.g., reduced costs, lower administrative burdens) while also facing the largest barriers, given a lack of AI expertise and robust capital budgets to deploy new technology. As discussed earlier in the “Trends” section of this chapter, additional concerns about equitable delivery of care come from the potential of AI to automate traditional interactions administered by providers. For populations in underserved settings, the re duction of patient -provider interactions poses risks to patients, especially when social factors such as literacy and culture directly impact patient experience. Additionally, there is an increased risk for such populations if care settings become less app ropriately staffed because of AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_400",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe potential of AI to automate traditional interactions administered by providers. For populations in underserved settings, the re duction of patient -provider interactions poses risks to patients, especially when social factors such as literacy and culture directly impact patient experience. Additionally, there is an increased risk for such populations if care settings become less app ropriately staffed because of AI. HHS is committed to helping organizations determine which technologies are most suitable for their contexts and collaborating with underserved populations to increase research efforts on how AI can impact care delivery and outcomes.533, 534 HHS actions to date ( non-exhaustive): • NIH ’s AIM -AHEAD Program increases diversity in AI researchers and data by providing underrepresented communities with AI access through partnerships, research, infrastructure, and data science training to expand the participation and representation of currently underrepresented populations in developing AI models.535 HHS near -term priorities: • Establish regional technical assistance centers through grants or cooperative agreements that can aid under -resourced care settings on AI applications. • Disseminate AI impact assessment templates, implementation toolkits, and technical assistance resources for health delivery organizations considering using AI by either promoting existing tools or funding the creation of new tools where gaps exist."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_401",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nmodels.535 HHS near -term priorities: • Establish regional technical assistance centers through grants or cooperative agreements that can aid under -resourced care settings on AI applications. • Disseminate AI impact assessment templates, implementation toolkits, and technical assistance resources for health delivery organizations considering using AI by either promoting existing tools or funding the creation of new tools where gaps exist. • Fund research to develop insights on best practices for adopting AI applications in under -resourced settings. This may include helping under -resourced organizations run pilots of high -potential AI. HHS long -term priorities: • Convene communities of practice across healthcare delivery to facilitate information sharing on the application of AI, particularly in underserved populations. This may include soliciting feedback and input from organizations in underserved populations tha t have adopted AI (e.g., through already available assistance from a private or non -profit entity) on addressing key challenges . • Continue to evaluate potential impacts that AI may have on patient -provider interactions (e.g., direct face-to-face time, gathering of patient information). 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_402",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nin underserved populations. This may include soliciting feedback and input from organizations in underserved populations tha t have adopted AI (e.g., through already available assistance from a private or non -profit entity) on addressing key challenges . • Continue to evaluate potential impacts that AI may have on patient -provider interactions (e.g., direct face-to-face time, gathering of patient information). 2. Provid ing support for healthcare delivery organizations to address core infrastructure and deployment challenges (i.e., technology, infrastructure, and data infrastructure) that improve AI readiness Context: Organizations need prerequisite capabilities and infrastructure including data systems to leverage AI. Healthcare delivery is a vastly complex system with various specialties and stakeholders administering care. As such, infrastructural tools and AI will not likely be generalizable to broad types of hospitals and clinical settings."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_403",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ninfrastructure and deployment challenges (i.e., technology, infrastructure, and data infrastructure) that improve AI readiness Context: Organizations need prerequisite capabilities and infrastructure including data systems to leverage AI. Healthcare delivery is a vastly complex system with various specialties and stakeholders administering care. As such, infrastructural tools and AI will not likely be generalizable to broad types of hospitals and clinical settings. For example, pediatric specialties face a distinct set of circumstances compared to adult specialties, 533 https://www.hhs.gov/guidance/sites/default/files/hhs -guidance -documents/006_Serving_Vulnerable_and_Underserved_Populations.pdf 534 https://www.politico.com/newsletters/future -pulse/2024/04/25/ai -degrades -our-work -nurses -say-00154253 535 https://datascience.nih.gov/artificial -intelligence/aim -ahead 107 underscoring the importance of children’s hospitals and pediatric units having the flexibility to configure AI to their contexts. While data quality and accuracy are necessary for training algorithms, the availability of datasets for training and tuning is an industrywide barrier to develop ing higher -quality health AI, especially for smaller and under - resourced healthcare delivery and payer organizations."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_404",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n107 underscoring the importance of children’s hospitals and pediatric units having the flexibility to configure AI to their contexts. While data quality and accuracy are necessary for training algorithms, the availability of datasets for training and tuning is an industrywide barrier to develop ing higher -quality health AI, especially for smaller and under - resourced healthcare delivery and payer organizations. Additionally, the technological infrastructure to sufficiently run AI models and store large data is not yet widely accessible to or affordab le by healthcare organizations, limiting their ability to utilize AI at scale. Hospitals and ambulatory practices that benefit from federal incentives to adopt technology such as EHRs may be better placed to adopt AI because of the availability of AI tools and third -party vendors integrating through EHR. Providers with a lower adopti on of EHR technology, such as behavioral health and long -term post-acute care entities, may find AI tools less available and usable. HHS actions to date ( non-exhaustive): • HRSA Uniform Data System (UDS) Modernization Initiative update d and improve d the UDS dataset and the technology used for data submission, collection, and analysis, providing HRSA with de - identified patient data."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_405",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nEHR technology, such as behavioral health and long -term post-acute care entities, may find AI tools less available and usable. HHS actions to date ( non-exhaustive): • HRSA Uniform Data System (UDS) Modernization Initiative update d and improve d the UDS dataset and the technology used for data submission, collection, and analysis, providing HRSA with de - identified patient data. This initiative enables HRSA to support its nearly 1,400 health centers better by implementing more effective data analysis and predictive solutions.536 • IHS Data Modernization Initiative partners with tribal and urban leaders to modernize EHR standards across the IHS system to enhance interoperability and functionality in healthcare to serve patients better .537 • ACF Data Strategy increase d its AI capabilities and support ed analysis on care delivery opportunities for children, families, and underserved populations through increased data interoperability.538, 539 HHS near -term priorities: • Work with the industry to promote open -source AI specifications for stakeholders (e.g., developers) to leverage. • Establish regional technical assistance centers through grants or cooperative agreements to support lower -resourced care settings —specifically on data and technology modernization to enhance AI readiness. • Disseminate AI -readiness assessment templates for providers considering developing AI solutions to support decision -making on data, system, and technology infrastructure gaps."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_406",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nopen -source AI specifications for stakeholders (e.g., developers) to leverage. • Establish regional technical assistance centers through grants or cooperative agreements to support lower -resourced care settings —specifically on data and technology modernization to enhance AI readiness. • Disseminate AI -readiness assessment templates for providers considering developing AI solutions to support decision -making on data, system, and technology infrastructure gaps. HHS long -term priorities: • Update internal data infrastructure to ensure sufficient and actionable information is available for underserved communities to inform support strategies HHS can implement. • Make available open de -identified data assets of administrative, clinical, quality/outcomes, and safety data to support AI development, testing, and validation. HHS has established similar resources for providers seeking to implement EHRs or undertake quality improvement or payment reform initiatives. The department can leverage the experience of implementing those initiatives, but it would likely require addition al funding to establish these additional AI deployment resources ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_407",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nassets of administrative, clinical, quality/outcomes, and safety data to support AI development, testing, and validation. HHS has established similar resources for providers seeking to implement EHRs or undertake quality improvement or payment reform initiatives. The department can leverage the experience of implementing those initiatives, but it would likely require addition al funding to establish these additional AI deployment resources . 536 https://bphc.hrsa.gov/data -reporting/uds -training -and-technical -assistance/uniform -data-system -uds-modernization -initiative# 537 https://www.ihs.gov/hit/ 538 https://www.acf.hhs.gov/ai -data-research/artificial -intelligence -acf 539 https://www.acf.hhs.gov/ai -data-research/acf -data-strategy 108 3.6.4 Cultivate AI -Empowered Workforces and Organization Cultures A workforce that is knowledgeable on AI will help accelerate innovation (e.g., identifying new use cases), manage deployment -specific risks associated with new tools, establish appropriate organizational governance structures, evaluate setting -specific tra ining data for potential biases, monitor model -drift,540 mitigate adverse impacts, and communicate with patients, families, and providers about the use of this technology. An effective health AI workforce will require cross -functional teams, including clinicians, biostatisticians, privacy/information security o fficials, analysts, acquisition staff, and IT professionals."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_408",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nassociated with new tools, establish appropriate organizational governance structures, evaluate setting -specific tra ining data for potential biases, monitor model -drift,540 mitigate adverse impacts, and communicate with patients, families, and providers about the use of this technology. An effective health AI workforce will require cross -functional teams, including clinicians, biostatisticians, privacy/information security o fficials, analysts, acquisition staff, and IT professionals. Ensuring that individuals and organizations are sufficiently prepared to use AI will be critical in safe, effective, and widespread adoption. The key opportunity HHS will focus on is equipping healthcare delivery professionals with access to training, resources, and research to support AI literacy and expertise in their respective health system organizations. Context: To date, AI is incorporated into the curriculums of most healthcare education, certification, and continuing education programs in a limited capacity, if at all. Additionally, most AI expertise is concentrated within technology organizations and/or researc h institutions (e.g., universities and large technology organizations). HHS will take steps to increase AI knowledge and expertise among healthcare professionals, ensuring foundational know -how within delivery organizations that lowers the cost of implementing new tools and ensures they are applied appropriately."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_409",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nin a limited capacity, if at all. Additionally, most AI expertise is concentrated within technology organizations and/or researc h institutions (e.g., universities and large technology organizations). HHS will take steps to increase AI knowledge and expertise among healthcare professionals, ensuring foundational know -how within delivery organizations that lowers the cost of implementing new tools and ensures they are applied appropriately. HHS actions to date ( non-exhaustive): • CMS AI Playbook include d educational materials that define AI, use cases, and trends within healthcare delivery, along with applications that CMS is considering using within its operations and their potential impact on patient care (e.g., wearables, digital twins, customer suppor t).541 • AHRQ’s intramural research programs (e.g., Health Services Research Dissertation Awards, Institutional Training Awards, Mentored Clinical Scientist Development Awards) offer ed predoctoral and post-doctoral educational, research infrastructure, and career development grants and opportunities in health services research. In addition, the AHRQ supports the development of health services research infrastructure in emerging centers of excellence and work s with Federal and academic partners to develop innovative curricula and educational models.542 540 Monitoring model drift is essential to ensuring AI models and resulting diagnostic and therapeutic decisions are based on rel evant data ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_410",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nopportunities in health services research. In addition, the AHRQ supports the development of health services research infrastructure in emerging centers of excellence and work s with Federal and academic partners to develop innovative curricula and educational models.542 540 Monitoring model drift is essential to ensuring AI models and resulting diagnostic and therapeutic decisions are based on rel evant data . 541 https://ai.cms.gov/assets/CMS_AI_Playbook.pdf 542 https://www.ahrq.gov/funding/training -grants/rsrchtng.html 109 HHS long -term priorities: • Promote AI literacy through long -term public education initiatives focused on reaching an audience of professionals (clinical and non -clinical) operating in a healthcare delivery context • Convene regular AI sessions at healthcare conferences with seminars hosted by industry experts, learning tracks, practical workshops, and recorded resources to promote collaboration, learning, and innovation. • Develop guidelines on appropriate training curricula and cadence for how AI concepts should be covered across cadres of healthcare workers (e.g., continuing medical education, degree programs). • Directly fund workforce training programs that train the existing health AI workforce and educate the next generation of medical professionals. • Share AI internal training resources on public websites for health AI professionals working in the industry to adapt or use directly in various healthcare settings."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_411",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nbe covered across cadres of healthcare workers (e.g., continuing medical education, degree programs). • Directly fund workforce training programs that train the existing health AI workforce and educate the next generation of medical professionals. • Share AI internal training resources on public websites for health AI professionals working in the industry to adapt or use directly in various healthcare settings. • Continue to evaluate the potential impacts of AI on the healthcare workforce. The interventions listed above are focused primarily on developing new programs and using public education and outreach, including to varied populations such as people with disabilities, to promote the responsible use of AI in healthcare. Looking ahead, agencies should also review existing workforce training programs and funding sources for health services research that can be leveraged to accomplish these objectives. 3.7 Conclusion Through actions in its Strategic Plan, HHS will help facilitate delivery organizations’ ability to expand access and transform patient care using AI. Given the rapid advancements in AI, HHS will continually review the actions of this plan and make efforts to extend support to stakeholders in the healthcare delivery ecosystem. 110 4 Human Services Delivery 4.1 Introduction and Context AI presents an opportunity to improve the quality, accessibility, interoperability , coordination , and overall impact of human services programs in the U.S."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_412",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nGiven the rapid advancements in AI, HHS will continually review the actions of this plan and make efforts to extend support to stakeholders in the healthcare delivery ecosystem. 110 4 Human Services Delivery 4.1 Introduction and Context AI presents an opportunity to improve the quality, accessibility, interoperability , coordination , and overall impact of human services programs in the U.S. The aging and diversifying population, complex and disparate public benefits systems, and persistent workforce shortage heighten the potential of AI in the sector. However, AI adoption in human services is nascent, reflecting critical challenges , including a lack of funding, outdated IT and data infrastructure, and concerns over technology’s impact on human services program participants .543, 544 Despite these challenges, interest in AI remains, with 83% of government leaders believing technology will become more important in supporting the human services workforce.545 HHS has released its Plan for Promoting the Responsible Use of Artificial Intelligence in Automated and Algorithmic Systems by State, Local, Tribal, and Territorial Governments in Public Benefit Administration .546 However, there is an opportunity to do more."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_413",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nchallenges, interest in AI remains, with 83% of government leaders believing technology will become more important in supporting the human services workforce.545 HHS has released its Plan for Promoting the Responsible Use of Artificial Intelligence in Automated and Algorithmic Systems by State, Local, Tribal, and Territorial Governments in Public Benefit Administration .546 However, there is an opportunity to do more. HHS aspires to maximize the opportunities of AI while protecting Americans’ safety and security by ensuring the technology is tested, deployed, and monitored responsibly.547 HHS has identified actions as part of this Plan to catalyze AI innovation and adoption, promote trustworthy AI development and ethical and responsible use, democratize AI technologies and resources, and cultivate AI -empowered workforces and organization cultures. In this chapter, HHS outlines the scope and stakeholders relevant to AI in human services delivery before providing an overview of the opportunities of AI in the sector and observed trends. The chapter then outlines potential use cases for AI in human serv ices and the risks of AI adoption. Finally, it concludes with a proposed approach to meet HHS’s departmentwide goals for AI, which considers gaps, existing initiatives, and new opportunities."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_414",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nin human services delivery before providing an overview of the opportunities of AI in the sector and observed trends. The chapter then outlines potential use cases for AI in human serv ices and the risks of AI adoption. Finally, it concludes with a proposed approach to meet HHS’s departmentwide goals for AI, which considers gaps, existing initiatives, and new opportunities. 543 https://nff.org/learn/survey 2022 survey of non -profits from the Nonprofit Finance Fund found that more than half of participating organizations felt they would be unable to meet demand for their services in the upcoming year. 544 https://pmc.ncbi.nlm.nih.gov/articles/PMC6816239/ Review of funding models for evidence -based interventions. “Every traditional pot of funding has a little bit of a question mark on it.” 545 https://www.cpsai.org/ . Cited on the home page from a survey conducted by the Center for Public Sector AI ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_415",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nfelt they would be unable to meet demand for their services in the upcoming year. 544 https://pmc.ncbi.nlm.nih.gov/articles/PMC6816239/ Review of funding models for evidence -based interventions. “Every traditional pot of funding has a little bit of a question mark on it.” 545 https://www.cpsai.org/ . Cited on the home page from a survey conducted by the Center for Public Sector AI . 546 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf Published in April 2024 (herein referred to as Plan for Promoting Responsible Use of AI in Public Benefits) 547 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf Published in April 2024 (herein referred to as Plan for Promoting Responsible Use of AI in Public Benefits) 111 4.1.1 Scope of the Human Services Delivery AI Value Chain Exhibit 92: Overview of HHS Human Services Delivery Programmatic Areas Promote health and well-being Assist populations with complex needs Support families and children Enhance community and economic development Description Access to healthcare services, preventative care, treatment for illnesses, mental health support Public health initiatives to prevent disease and promote a healthy lifestyle Aid to individuals experiencing economic hardship, homelessness, substance abuse Support for seniors, including long-term care and community services Childcare, early care and education , family support Child welfare services, foster care, adoption Community initiatives improv ing local infra structure and services Economic assistance and job training Note: other chapters including Public Health and Healthcare Delivery cover similar or interconnected services ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_416",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto individuals experiencing economic hardship, homelessness, substance abuse Support for seniors, including long-term care and community services Childcare, early care and education , family support Child welfare services, foster care, adoption Community initiatives improv ing local infra structure and services Economic assistance and job training Note: other chapters including Public Health and Healthcare Delivery cover similar or interconnected services . However, as much as possible HHS has segmented discussion of human services programs into this chapter . 4.1.2 Action Plan Summary Later in this chapter, HHS articulates proposed actions to advance its four goals for the responsible use of AI in the sector. Below is a summary of the themes of actions within each goal. For full details of proposed actions please see section 4.6 Action Plan. Key goals that actions support Themes of proposed actions (not exhaustive, see 4.6 Action Plan for more details) 1. Catalyzing health AI innovation and adoption•Unlocking resources for AI adoption and modernizing IT and tech infrastructure •Ensuring data quality and availability for AI adoption 2. Promoting trustworthy AI development and ethical and responsible use•Providing guidance to served populations on balancing risks with opportunities for AI applications and establishing participant trust 3."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_417",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nexhaustive, see 4.6 Action Plan for more details) 1. Catalyzing health AI innovation and adoption•Unlocking resources for AI adoption and modernizing IT and tech infrastructure •Ensuring data quality and availability for AI adoption 2. Promoting trustworthy AI development and ethical and responsible use•Providing guidance to served populations on balancing risks with opportunities for AI applications and establishing participant trust 3. Democratizing AI technologies and resources•Raising the floor of constituent digital literacy and digital penetration •Identifying areas of cooperation across sectors to improve AI -related economies of scale 4. Cultivating AI -empowered workforces and organization cultures•Improving human services employee digital literacy, talent, and openness to adopt new technology •Using AI to mitigate the labor workforce shortage in human services 4.2 Stakeholders Engaged in the Human Services Delivery AI Value Chain Human services programs in the U.S. benefit the most vulnerable populations , their caregivers , and their guardians. Various federal, STLT, and community stakeholders contribute to programs that serve that aim. Federal agencies fund STLT human services agencies and community organizations to deliver programs while also delivering programs themselves; STLTs fun d community organizations and directly deliver programs; and CBOs deliver programs with a combination of federal, STLT, and philanthropic funds."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_418",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n, their caregivers , and their guardians. Various federal, STLT, and community stakeholders contribute to programs that serve that aim. Federal agencies fund STLT human services agencies and community organizations to deliver programs while also delivering programs themselves; STLTs fun d community organizations and directly deliver programs; and CBOs deliver programs with a combination of federal, STLT, and philanthropic funds. Exhibit 1 0 shows a non -exhaustive diagram of example flows between stakeholders and a bulleted list of stakeholders involved in human services. Please note that neither the diagram nor the list captures all roles and interactions. For additional details on regulatory guidance and authorities, p lease refer to other HHS documents. 112 The exhibit reflects example roles and relationships, but roles may vary depending on the human services program. Exhibit 10: Human Services Delivery Stakeholder Engagement Map • HHS agencies548 o ACF: Provides services to support families and children, including promoting the economic and social well -being of children, families, and communities. o ACL: Supports programs for populations with complex needs, particularly older adults and people with disabilities. o CMS: Administers federal health insurance programs (e.g., Medicare and Medicaid), outlines conditions of participation related to these programs, and can provide reimbursements to specific devices or services."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_419",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nfamilies and children, including promoting the economic and social well -being of children, families, and communities. o ACL: Supports programs for populations with complex needs, particularly older adults and people with disabilities. o CMS: Administers federal health insurance programs (e.g., Medicare and Medicaid), outlines conditions of participation related to these programs, and can provide reimbursements to specific devices or services. o SAMHSA: Focuses on promoting health and well -being, including services related to suicide prevention and mental health and substance abuse treatment and prevention. o HRSA: Provides access to essential health services for underserved populations , focus ing on services that promote health and well -being and assist populations with complex needs. o IHS: Provides a comprehensive healthcare delivery system and ensures culturally appropriate public health and human services are available for American Indian and Alaska Native people to raise the physical, mental, social, and spiritual health of the population to the highest level. • Other federal agencies: HHS also works closely with many other federal departments, such as the Department of Agriculture and the Department of Housing and Urban Development. • STLT government human services agencies: STLT human services departments administer programs and provide public benefits."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_420",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npeople to raise the physical, mental, social, and spiritual health of the population to the highest level. • Other federal agencies: HHS also works closely with many other federal departments, such as the Department of Agriculture and the Department of Housing and Urban Development. • STLT government human services agencies: STLT human services departments administer programs and provide public benefits. These departments often administer federal programs like the Supplemental Nutrition Assistance Program (SNAP) and the Special Supplemental Nutrition Program for Women, Infants, and Children (WIC) alongside HHS programs. 548 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf See Appendix B in the Plan for Responsible Use of AI for an overview of major human services and other public benefits programs administered by HHS . 113 • CBOs, including community action agencies: These organizations directly deliver human services programs and benefits to the public. • Participants and their caregivers and guardians: In 2023, an estimated 99.1 million people (30% of the U.S. population) accessed services from various programs, including human services, collectively known as the “social safety net.”549 This figure includes one in eight adults and one in two children. • Technology companies: These include companies focused on AI infrastructure (e.g., cloud storage), large, diversified tech companies, vendors of digital solutions, and white hat hackers."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_421",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n99.1 million people (30% of the U.S. population) accessed services from various programs, including human services, collectively known as the “social safety net.”549 This figure includes one in eight adults and one in two children. • Technology companies: These include companies focused on AI infrastructure (e.g., cloud storage), large, diversified tech companies, vendors of digital solutions, and white hat hackers. These companies provide the infrastructure and services for stakeholders to adopt AI. • Research institutions: Often in partnership with federal agencies, STLTs, or CBOs, academic or other research institutions conduct trials and evaluations to understand the evidence for human services interventions and design and test potential programs. 4.3 Opportunities for the Application of AI in Human Services Delivery AI in human services can improve service experience and quality, increase the pace and quality of funds distribution, enhancing capabilities of the human services workforce , increase accessibility of services , and enhance interoperability to improve service coordination . These opportunities are driven by multiple factors, including changing population demographics, a complex public benefits ecosystem, and workforce shortages. The opportunities include : 1."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_422",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nservices can improve service experience and quality, increase the pace and quality of funds distribution, enhancing capabilities of the human services workforce , increase accessibility of services , and enhance interoperability to improve service coordination . These opportunities are driven by multiple factors, including changing population demographics, a complex public benefits ecosystem, and workforce shortages. The opportunities include : 1. Improving service experience and quality: Eligible participants face challenges accessing human services programs and consider the experience difficult .550 Public sector health and human services have lower customer satisfaction scores than other industries surveyed by the American Customer Satisfaction Index.551 AI can address challenges and improve satisfaction , including by assisting in matching participants to programs, speeding up application processes, improving benefit delivery speed, and enhancing the participant support experience. 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_423",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nservices programs and consider the experience difficult .550 Public sector health and human services have lower customer satisfaction scores than other industries surveyed by the American Customer Satisfaction Index.551 AI can address challenges and improve satisfaction , including by assisting in matching participants to programs, speeding up application processes, improving benefit delivery speed, and enhancing the participant support experience. 2. Increasing the pace and quality of funds distribution: Billions of dollars flow through HHS to STLTs, community organizations, and directly to Americans around the country.552 Often, the faster these funds can be appropriately distributed, the faster public benefits and vital services can be delivered.553 As the assistance programs launched during COVID -19 pandemic demonstrated, the ability to quickly and effectively provide funds has the potential to save lives and livelihoods.554 AI has the potential to improve the speed and accuracy of funding distribution from HHS to other stakeholders and ensure that resource distribution is equitable and linked to areas with the greatest need. 3. Enhancing capabilities of human services workforce: Human services departments face challenges in recruiting and retaining critical workforce populations, and needs are only growing. For instance, the Bureau of Labor Statistics projects an annual social worker shortage across the U.S."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_424",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nfrom HHS to other stakeholders and ensure that resource distribution is equitable and linked to areas with the greatest need. 3. Enhancing capabilities of human services workforce: Human services departments face challenges in recruiting and retaining critical workforce populations, and needs are only growing. For instance, the Bureau of Labor Statistics projects an annual social worker shortage across the U.S. of 67,300 over the nex t decade.555 Other estimates suggest the gap is closer to 100,000.556 The workforce shortage can lead to longer wait times and reduced services.557 At the same time, the American public is aging,558 and more people are 549 https://aspe.hhs.gov/sites/default/files/documents/18eff5e45b2be85fb4c350176bca5c28/how -many -people -social -safety -net.pdf 550 https://www.urban.org/research/publication/customer -service -experiences -and-enrollment -difficulties . Difficulties included trouble determining eligibility, providing documentation, navigating varied requirements, and receiving benefits when needed. 551 https://theacsi.org/news -and-resources/reports/2024/10/15/acsi -insurance -and-mortgage -lenders -study -2024/ A full industry comparison is available in the report ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_425",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAt the same time, the American public is aging,558 and more people are 549 https://aspe.hhs.gov/sites/default/files/documents/18eff5e45b2be85fb4c350176bca5c28/how -many -people -social -safety -net.pdf 550 https://www.urban.org/research/publication/customer -service -experiences -and-enrollment -difficulties . Difficulties included trouble determining eligibility, providing documentation, navigating varied requirements, and receiving benefits when needed. 551 https://theacsi.org/news -and-resources/reports/2024/10/15/acsi -insurance -and-mortgage -lenders -study -2024/ A full industry comparison is available in the report . 552 https://www.hhs.gov/sites/default/files/fy -2024 -budget -in-brief.pdf Multiple examples including the HRSA Health Center Program that proposed awarding $7.1 B to 1,400 health centers in 2024 or TANF which passed $17.3 B in funding to states in FY 2023 553 https://pmc.ncbi.nlm.nih.gov/articles/PMC6816239/ 554 https://www.cbpp.org/research/poverty -and-inequality/robust -covid -relief -achieved -historic -gains -against -poverty -and-0 555 https://www.bls.gov/ooh/community -and-social -service/social -workers.htm 556 https://www.cpsai.org/ 557 https://www.councilofnonprofits.org/nonprofit -workforce -shortage -crisis 558 https://www.census.gov/newsroom/press -releases/2023/population -estimates -characteristics.html 114 expected to access human services programs over time.559 This may strain workforce capacity, increase demand for services, and place greater emphasis on efficient benefits provisioning."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_426",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nstates in FY 2023 553 https://pmc.ncbi.nlm.nih.gov/articles/PMC6816239/ 554 https://www.cbpp.org/research/poverty -and-inequality/robust -covid -relief -achieved -historic -gains -against -poverty -and-0 555 https://www.bls.gov/ooh/community -and-social -service/social -workers.htm 556 https://www.cpsai.org/ 557 https://www.councilofnonprofits.org/nonprofit -workforce -shortage -crisis 558 https://www.census.gov/newsroom/press -releases/2023/population -estimates -characteristics.html 114 expected to access human services programs over time.559 This may strain workforce capacity, increase demand for services, and place greater emphasis on efficient benefits provisioning. AI can augment the human services workforce’s processes by automating rote tasks, processing narrative information (e.g., client notes, meetings, interviews) with NLP, and drafting documents. In one analogous setting, customer support centers, a National Bureau of Economic Research study found that using an AI -based conversational assistant improved worker productivity by 14%.560 An equivalent productivity enhancement in human services could allow staff to allocate more time to value -added tasks and participant interaction, increasing worker productivity even if staff shortages persist. HHS also acknowledges concerns related to po tential staff displacement and outlines actions below to monitor workforce and service impacts. 4."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_427",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nan AI -based conversational assistant improved worker productivity by 14%.560 An equivalent productivity enhancement in human services could allow staff to allocate more time to value -added tasks and participant interaction, increasing worker productivity even if staff shortages persist. HHS also acknowledges concerns related to po tential staff displacement and outlines actions below to monitor workforce and service impacts. 4. Increasing accessibility of services: A diverse and growing population qualifies for human services, yet many struggle to access these programs. According to the Urban Institute, four in ten adults reported enrollment difficulties in accessing public services, including Temporary Assistance fo r Needy Families (TANF) and SNAP.561 Multiple factors may drive enrollment access ibility challenges . For instance, benefits applications require advanced vocabulary, health literacy, or financial literacy.562 However, according to the American Community Survey, 26 million U.S. residents (approximately 9% of the population) have limited English proficiency.563, 564 Program access challenges can prevent eligible participants from accessing services when they are needed. For instance, during the COVID -19 pandemic, participation in WIC only grew by 2% from 2020 to 2021 despite a n increase in eligibility.565 AI can assist stakeholders in the human services delivery ecosystem by increasing access to their services and meeting their equity goals."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_428",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n564 Program access challenges can prevent eligible participants from accessing services when they are needed. For instance, during the COVID -19 pandemic, participation in WIC only grew by 2% from 2020 to 2021 despite a n increase in eligibility.565 AI can assist stakeholders in the human services delivery ecosystem by increasing access to their services and meeting their equity goals. AI applications have improved accessibility in other sectors through technologies like visual assistance and closed c aptioning. Further, advances in GenAI have improved the accuracy and cultural nuances of automated language translation.566 Human services staff may not be able to solely rely on these tools, but they can adapt translation models to target participant needs and reach communities chronically underserved due to language gaps.567, 568 5. Enhancing interoperability to improve service coordination: A significant volume of human -services - related data is collected in narrative format (e.g., case notes) or manually transcribed (e.g., in shelters).569 These records are not easily searchable and require manual review, hindering the data quality for accurate needs assessment , service delivery and care, systemwide analytics , or interoperability between agencies.570 Another challenge for interoperability is the complex and multifaceted nature of the U.S. public benefits system."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_429",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nis collected in narrative format (e.g., case notes) or manually transcribed (e.g., in shelters).569 These records are not easily searchable and require manual review, hindering the data quality for accurate needs assessment , service delivery and care, systemwide analytics , or interoperability between agencies.570 Another challenge for interoperability is the complex and multifaceted nature of the U.S. public benefits system. Those wishing to access programs must comply with varied administrative and program requirements to apply for services; however, these requirements are inconsistent across states and systems 559 https://www.healthsystemtracker.org/chart -collection/health -expenditures -vary-across -population/ , https://www.cdc.gov/pcd/issues/2024/23_0267.htm Extrapolated from healthcare spend and chronic disease trends in U.S. population 560 https://www.nber.org/papers/w31161 As measured in issues resolved per hour 561 https://www.urban.org/research/publication/customer -service -experiences -and-enrollment -difficulties 562 https://www.cbpp.org/sites/default/files/11 -18-08fa.pdf SNAP applications require an understanding of gross versus net income, and which assets count against eligibility (savings accounts) and which do not (property)."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_430",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n559 https://www.healthsystemtracker.org/chart -collection/health -expenditures -vary-across -population/ , https://www.cdc.gov/pcd/issues/2024/23_0267.htm Extrapolated from healthcare spend and chronic disease trends in U.S. population 560 https://www.nber.org/papers/w31161 As measured in issues resolved per hour 561 https://www.urban.org/research/publication/customer -service -experiences -and-enrollment -difficulties 562 https://www.cbpp.org/sites/default/files/11 -18-08fa.pdf SNAP applications require an understanding of gross versus net income, and which assets count against eligibility (savings accounts) and which do not (property). 563 https://www.census.gov/newsroom/press -releases/2017/acs -5yr.html 564 https://www.kff.org/racial -equity -and-health -policy/issue -brief/five -key-facts-about -immigrants -with-limited -english -proficiency/ 565 https://www.cbpp.org/research/food -assistance/eligible -low-income -children -missing -out-on-crucial -wic-benefits -during 566 https://www.sciencedirect.com/science/article/pii/S2772941924000012 567 https://lfaidata.foundation/blog/2024/05/21/translation -augmented -generation -breaking -language -barriers -in-llm-ecosystem/ LLM projects to improve translation from English to less widely spoken languages 568 https://www.ecfr.gov/current/title -45/subtitle -A/subchapter -A/part -92/subpart -C/section -92.201 Section 1557 requires that, if a covered entity uses machine translation , the translation must be reviewed by a qualified human translator when the underlying text is critical to the rights, benefits, or meaningful access to an individual with limited English proficiency, when accuracy is essential, or when the source documents or materials contained complex, non -literal , or technical language ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_431",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nrequires that, if a covered entity uses machine translation , the translation must be reviewed by a qualified human translator when the underlying text is critical to the rights, benefits, or meaningful access to an individual with limited English proficiency, when accuracy is essential, or when the source documents or materials contained complex, non -literal , or technical language . 569 https://controller.lacity.gov/landings/interim -housing -audit The Los Angeles Homeless Services Authority (LAHSA) released an audit in 2023 that found inaccuracies in its shelter capacity data. The system is maintained with an email -based daily census report system which is centrally copied into a master file by hand. 570 https://controller.lacity.gov/landings/interim -housing -audit The daily census reports did not meet the accuracy requirements for use by LAHSA’s bed availability system."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_432",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nHomeless Services Authority (LAHSA) released an audit in 2023 that found inaccuracies in its shelter capacity data. The system is maintained with an email -based daily census report system which is centrally copied into a master file by hand. 570 https://controller.lacity.gov/landings/interim -housing -audit The daily census reports did not meet the accuracy requirements for use by LAHSA’s bed availability system. 115 vary.571, 572 Advances in AI technologies, including optical character recognition, NLP, and LLMs, have the potential to transform data into structured formats and more easily improve service delivery and share them across agencies.573 Further, higher -quality data could allow AI applications such as integrated benefits systems to shift delivery to a person -centered design, where benefits across healthcare, housing, family assistance, and food security are coordinated and delivered toget her.574 4.4 Trends in AI in Human Services Delivery Current trends indicate that AI in human services is nascent, but interest in piloting innovative technology is growing among STLTs and community organizations: 1. STLT and community groups are interested in AI adoption . Still, they are early in the process with a focus on ideation and collaboration : Multiple non -profit organizations have established AI practices, indicating enthusiasm throughout the domain. Examples of actions in the human services ecosystem are articulated below; however, these are non -exhaustive:575 a."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_433",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nSTLTs and community organizations: 1. STLT and community groups are interested in AI adoption . Still, they are early in the process with a focus on ideation and collaboration : Multiple non -profit organizations have established AI practices, indicating enthusiasm throughout the domain. Examples of actions in the human services ecosystem are articulated below; however, these are non -exhaustive:575 a. U.S. Digital Response launched tools to help state and local governments safely use GenAI to do their jobs better and faster.576 b. Center for Public Sector AI launched Rolling Prompts that allow companies and organizations working with AI to share their ideas with state health and human services leaders on how to apply their technology in the domain.577 c. GovAI Coalition developed policy templates and other resources to support STLTs with implementing governance for responsible experimentation and use of AI. The coalition represents more than five hundred agencies, primarily from city and local governments.578 2. However, AI adoption in the human services sector remains low despite the opportunities it presents : The current adoption of AI at scale —beyond the pilot phase —is low in the human services ecosystem compared to other sectors.579 While some private sector and non -profit players have launched programs, these are often limited in scope or targeted to a specific geography or population. Examples include platforms leveraging GenAI to assist with benefits applications ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_434",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npresents : The current adoption of AI at scale —beyond the pilot phase —is low in the human services ecosystem compared to other sectors.579 While some private sector and non -profit players have launched programs, these are often limited in scope or targeted to a specific geography or population. Examples include platforms leveraging GenAI to assist with benefits applications . However, these are often limited in scope (e.g., only focused on paid leave policies) and are not integrated into states’ application processes. Other human services program delivery examples include social or assistive robots and GenAI -enabled interview simulations.580 3. Low adoption is driven in part by reliance on pro bono efforts or other non -profit collaborations : Public sector service delivery agencies leverage external support for pilots that often are for lower risk use cases to reduce administrative burden or to support research . One example is the Illinois Department of Employment Security, which partnered with U.S."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_435",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsimulations.580 3. Low adoption is driven in part by reliance on pro bono efforts or other non -profit collaborations : Public sector service delivery agencies leverage external support for pilots that often are for lower risk use cases to reduce administrative burden or to support research . One example is the Illinois Department of Employment Security, which partnered with U.S. Digital Response to improve its translation of unemployment insurance policies using ML -based translation software.581 Additionally, HHS has seen more 571 https://nj.gov/humanservices/wfnj/apply/ , https://www.mass.gov/info -details/program -verifications -what -information -you-need -to-provide For instance, TANF (or state equivalent program) asks applicants for materials including state ID, social security cards, proof of residency, pay st ubs, work hours verification, birth certificates, and marriage certificates."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_436",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nResponse to improve its translation of unemployment insurance policies using ML -based translation software.581 Additionally, HHS has seen more 571 https://nj.gov/humanservices/wfnj/apply/ , https://www.mass.gov/info -details/program -verifications -what -information -you-need -to-provide For instance, TANF (or state equivalent program) asks applicants for materials including state ID, social security cards, proof of residency, pay st ubs, work hours verification, birth certificates, and marriage certificates. 572 https://napawash.org/academy -studies/modernizing -public -benefits -delivery -how-innovation -can-deliver -results -for-eligible -households -and-taxpayers 573 https://www.iiba.org/business -analysis -blogs/how -ai-is-rewriting -the-rules -of-data-analysis/ 574 https://napawash.org/academy -studies/modernizing -public -benefits -delivery -how-innovation -can-deliver -results -for-eligible -households -and-taxpayers 575 https://initiatives.weforum.org/ai -governance -alliance/home International examples include the World Economic Forum’s AI Governance Alliance which has brought together stakeholders from 463 public, private, and social sector entities to share knowledge of AI governance best p ractices."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_437",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-can-deliver -results -for-eligible -households -and-taxpayers 573 https://www.iiba.org/business -analysis -blogs/how -ai-is-rewriting -the-rules -of-data-analysis/ 574 https://napawash.org/academy -studies/modernizing -public -benefits -delivery -how-innovation -can-deliver -results -for-eligible -households -and-taxpayers 575 https://initiatives.weforum.org/ai -governance -alliance/home International examples include the World Economic Forum’s AI Governance Alliance which has brought together stakeholders from 463 public, private, and social sector entities to share knowledge of AI governance best p ractices. 576 https://www.usdigitalresponse.org/services/public -sector -generative -ai 577 https://www.cpsai.org/ 578 https://www.sanjoseca.gov/your -government/departments -offices/information -technology/ai -reviews -algorithm -register/govai -coalition 579 https://www.acf.hhs.gov/opre/report/options -opportunities -address -mitigate -existing -potential -risks-promote -benefits . Based also on focus groups and conversations ACF has had with human service delivery agencies and industry input on AI integrations in human and health serv ices. 580 https://pmc.ncbi.nlm.nih.gov/articles/PMC10474924/ 581 https://www.usdigitalresponse.org/services/public -sector -generative -ai 116 AI-related research activity in human services fields with incentives to develop innovative approaches, such as in child welfare, to prevent the mistreatment of children.582 4."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_438",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nBased also on focus groups and conversations ACF has had with human service delivery agencies and industry input on AI integrations in human and health serv ices. 580 https://pmc.ncbi.nlm.nih.gov/articles/PMC10474924/ 581 https://www.usdigitalresponse.org/services/public -sector -generative -ai 116 AI-related research activity in human services fields with incentives to develop innovative approaches, such as in child welfare, to prevent the mistreatment of children.582 4. Concerns over potential negative impact of AI may limit adoption in human services : Stakeholders in human services are reticent to adopt AI tools without risk assessments and stringent requirements to account for potential adverse effects. These are important safeguards as data -driven bias further perpetuates existing inequities, placing served populations at risk of worsened outcomes and further exclusion.583, 584 Furthermore, as stipulated in the Plan for Responsible Use of AI in Public Benefits, there are rights - and safety -impacting risks from AI applications, such as automated denial of program applications.585 To account for these risks, stakeholders may place a higher bar on technology vendors and service partners , which , while important, may contribute to a lag in AI adoption in human services compared to other sectors ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_439",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI in Public Benefits, there are rights - and safety -impacting risks from AI applications, such as automated denial of program applications.585 To account for these risks, stakeholders may place a higher bar on technology vendors and service partners , which , while important, may contribute to a lag in AI adoption in human services compared to other sectors . Trade-offs should be considered 4.5 Potential Use Cases and Risks for AI in Human Services Delivery Value chains vary across programs and organizations in human services delivery. For example, the type and sequence of activities involved in runaway homeless youth programs, Head Start programs, refugee resettlement, and child welfare services are unique t o each program. Below is a general view of the core functions underlying human services. Exhibit 11: Human Services Delivery Value Chain 4.5.1 AI Use Cases Along the Human Services Delivery Value Chain In the tables below, HHS highlights a non -exhaustive list of potential benefits and risks of AI across the human services delivery value chain. Please note that the use cases detailed below highlight existing or potential ways that AI can be used by a variety of stakeholders in this domain."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_440",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI Use Cases Along the Human Services Delivery Value Chain In the tables below, HHS highlights a non -exhaustive list of potential benefits and risks of AI across the human services delivery value chain. Please note that the use cases detailed below highlight existing or potential ways that AI can be used by a variety of stakeholders in this domain. For details on how HHS and its divisions are using AI, please reference the HHS AI Us e Case Inventory 2024.586 HHS notes that AI is one technological tool among several for human services delivery stakeholders and that overreliance on AI may pose risks that need to be fully addressed.587 Further, many technologies (e.g., LLMs) are 582 https://www.acf.hhs.gov/opre/report/options -opportunities -address -mitigate -existing -potential -risks-promote -benefits 583 https://pmc.ncbi.nlm.nih.gov/articles/PMC9976641/ 584 https://www.rockefellerfoundation.org/insights/perspective/putting -the-needs -of-vulnerable -populations -first-collaborating -to-address -ai-bias/ 585 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 586 https://www.healthit.gov/hhs -ai-usecases 587 https://www.healthaffairs.org/content/forefront/discrimination -artificial -intelligence -commercial -electronic -health -record -case-study 117 still being evaluated for potential risks in human services settings."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_441",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npose risks that need to be fully addressed.587 Further, many technologies (e.g., LLMs) are 582 https://www.acf.hhs.gov/opre/report/options -opportunities -address -mitigate -existing -potential -risks-promote -benefits 583 https://pmc.ncbi.nlm.nih.gov/articles/PMC9976641/ 584 https://www.rockefellerfoundation.org/insights/perspective/putting -the-needs -of-vulnerable -populations -first-collaborating -to-address -ai-bias/ 585 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 586 https://www.healthit.gov/hhs -ai-usecases 587 https://www.healthaffairs.org/content/forefront/discrimination -artificial -intelligence -commercial -electronic -health -record -case-study 117 still being evaluated for potential risks in human services settings. HHS has previously addressed risk considerations related to using AI in other documents, including the HHS Trustworthy AI Playbook and the Plan for Responsible Use of AI in Public Benefits. In addition to the potential use cases, the Department has included potential risks to consider. This list is also non -exhaust ive. HHS will consider mitigation steps to address identified risks in the actions proposed later in this chapter (see Action Plan)."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_442",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndocuments, including the HHS Trustworthy AI Playbook and the Plan for Responsible Use of AI in Public Benefits. In addition to the potential use cases, the Department has included potential risks to consider. This list is also non -exhaust ive. HHS will consider mitigation steps to address identified risks in the actions proposed later in this chapter (see Action Plan). Interactions between the federal government, STLTs, and community organizations : Functional component 1: Policy setting, research, and discovery The federal government and STLTs establish policies and regulations that guide, inform, and govern all stages of the value chain Potential use cases (non -exhaustive) Potential risks (non -exhaustive) Tools that synthesize multiple, varied datasets to inform policy assessment and creation E.g., data-driven measurement analytics AI-driven insight generation from program measurement data, population statistics, and other areas to inform policy setting."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_443",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nfederal government and STLTs establish policies and regulations that guide, inform, and govern all stages of the value chain Potential use cases (non -exhaustive) Potential risks (non -exhaustive) Tools that synthesize multiple, varied datasets to inform policy assessment and creation E.g., data-driven measurement analytics AI-driven insight generation from program measurement data, population statistics, and other areas to inform policy setting. This set of tools can synthesize multiple, varied datasets to inform policy assessment and new policy -setting .588, 589 Potential for third -party risk E.g., program data breach through a third - party vendor Third -party data storage could be an access point for a data breach of sensitive population data .590 Functional component 2: Program design The federal government, STLTs, and community organizations design programs and benefit delivery from a systemic to an individual level Potential use cases (non -exhaustive) Potential risks (non -exhaustive) AI-driven measurement and data analysis tools to inform program design E.g., policy measurement analytics Leverage AI -driven insights from the policy -setting stage to inform best practices for designing and delivering programs591 E.g., resource and geospatial mapping AI can support resource mapping, geospatial analysis of population statistics and needs, and predictive modeling to inform program design and organization selection .592, 593 Potential for explainability and accountability risk E.g., directing program resources based on a black box algorithm AI applications could have flawed inputs and lack appropriate safeguards for users to understand decision -making or training data, resulting in mismatched resources for potential participants .594 588 https://www.sciencedirect.com/science/article/pii/S0740624X20300034 ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_444",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand needs, and predictive modeling to inform program design and organization selection .592, 593 Potential for explainability and accountability risk E.g., directing program resources based on a black box algorithm AI applications could have flawed inputs and lack appropriate safeguards for users to understand decision -making or training data, resulting in mismatched resources for potential participants .594 588 https://www.sciencedirect.com/science/article/pii/S0740624X20300034 . History of algorithmic models being deployed to inform government policy 589 https://www.apec.org/publications/2022/11/artificial -intelligence -in-economic -policymaking International governments are deploying AI to inform policy and measure impact. 590 See the Cybersecurity and Critical Infrastructure Protection chapter for more information on third -party and data -breach risks for the health and human services ecosystem. 591 https://www.science.org/doi/10.1126/science.aao4408 The study is related to placement, but the analogy has possible benefits."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_445",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto inform government policy 589 https://www.apec.org/publications/2022/11/artificial -intelligence -in-economic -policymaking International governments are deploying AI to inform policy and measure impact. 590 See the Cybersecurity and Critical Infrastructure Protection chapter for more information on third -party and data -breach risks for the health and human services ecosystem. 591 https://www.science.org/doi/10.1126/science.aao4408 The study is related to placement, but the analogy has possible benefits. 592 https://www.sciencedirect.com/science/article/pii/S0740624X20300034 593 https://www.apec.org/publications/2022/11/artificial -intelligence -in-economic -policymaking 594 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 118 Functional component 3: Community organization selection The federal government and STLTs select community organizations to execute programs, distribute benefits, and manage and evaluate existing partners Potential use cases (non -exhaustive) Potential risks (non -exhaustive) Evaluation tools for managing community organization networks and identifying new partners E.g., natural -language notes processing and analytics Convert narrative format and voice notes taken by caseworkers during network monitoring into digital data that can be evaluated more efficiently and assessed over time595 E.g., web-scraping for community organization benchmarking data AI-driven web search for rapid rate benchmarking, service availability search, and organization prior history to inform network selection, grant approvals, and negotiations596 Potential for misrepresentation due to incorrect interpretation of unstructured data E.g., inaccurate structuring of web- scraping data leading to errors in proposal evaluations AI-driven web -scraping may inaccurately assess data from community organization websites and public references , leading to creation of false or misleading conclusions that affect grant awards or partner evaluation ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_446",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nnetwork selection, grant approvals, and negotiations596 Potential for misrepresentation due to incorrect interpretation of unstructured data E.g., inaccurate structuring of web- scraping data leading to errors in proposal evaluations AI-driven web -scraping may inaccurately assess data from community organization websites and public references , leading to creation of false or misleading conclusions that affect grant awards or partner evaluation . Functional component 4: Funds and benefits allocation and distribution Federal and state governments distribute funds to states and community organizations for programs Potential use cases (non -exhaustive) Potential risks (non -exhaustive) Tools to evaluate grant applications and distribute resources to areas with the highest need, where funding flexibility is allowed by the programs E.g., proposal synthesis and evaluation To enable faster, more informed reading of grant applications for discretionary grants597 E.g., predictive analytics for funds shortages AI-driven assessment of where programs and organizations are under/overutilizing funding to improve the allocation of spending across the human services ecosystem598, 599 Potential for inequitable funding allocation based on incorrect output E.g., flawed AI-based algorithmic funding distribution leads to resource shortages in STLTs and CBOs AI-based algorithm distributes funding based on flawed assessment, which could lead to STLTs and CBOs receiving insufficient resources to conduct programs and distribute benefits600 Functional component 5: Program operations and service delivery The activities range from participant engagement and needs assessment to benefits change and enrollment ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_447",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nflawed AI-based algorithmic funding distribution leads to resource shortages in STLTs and CBOs AI-based algorithm distributes funding based on flawed assessment, which could lead to STLTs and CBOs receiving insufficient resources to conduct programs and distribute benefits600 Functional component 5: Program operations and service delivery The activities range from participant engagement and needs assessment to benefits change and enrollment . Detailed in Interactions with participants Potential use cases (non -exhaustive) Potential risks (non -exhaustive) Detailed in Interactions with participants functional components Detailed in Interactions with participants functional components 595 https://pubmed.ncbi.nlm.nih.gov/39396164/ . Discussion on use in Healthcare and Public Health 596 Vendor solutions available for web -scraping. 597 Commercial tools widely available (e.g., ChatGPT and Bard) with enterprise solutions to build bespoke solutions with private data. 598 https://www.sciencedirect.com/science/article/pii/S0740624X20300034 599 https://www.apec.org/publications/2022/11/artificial -intelligence -in-economic -policymaking 600 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 119 Functional component 6: Monitoring and evaluation Assess the effectiveness of individual programs and overall policies in achieving their aims."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_448",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand Public Health 596 Vendor solutions available for web -scraping. 597 Commercial tools widely available (e.g., ChatGPT and Bard) with enterprise solutions to build bespoke solutions with private data. 598 https://www.sciencedirect.com/science/article/pii/S0740624X20300034 599 https://www.apec.org/publications/2022/11/artificial -intelligence -in-economic -policymaking 600 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 119 Functional component 6: Monitoring and evaluation Assess the effectiveness of individual programs and overall policies in achieving their aims. Identify areas of improvement and recommendations in the future Potential use cases (non -exhaustive) Potential risks (non -exhaustive) Tools to support the evaluation of program effectiveness using unstructured data E.g., natural -language notes processing and analytics Convert narrative format notes taken during program delivery (e.g., paper records in homeless shelters, case notes in behavioral health consultations) into digital records for measurement and evaluation601 E.g., data-driven performance assessment and reporting AI-driven data analytics based on data collected from programs, caseworker notes, and external sources to measure program outputs and outcomes, enhancing insights beyond descriptive or leading indicators602,603 Potential for misrepresentation for incorrect output E.g., confabulation from AI -generated notes leading to errors in caseworker evaluations AI confabulation when transcribing caseworker program notes can lead to data misclassification or incorrect measurement of program performance, which can affect policy decisions .604 Functional component 7: Program integrity Ensure accurate, secure, and efficient program delivery and that stakeholders in the value chain are fulfilling their roles."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_449",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\noutput E.g., confabulation from AI -generated notes leading to errors in caseworker evaluations AI confabulation when transcribing caseworker program notes can lead to data misclassification or incorrect measurement of program performance, which can affect policy decisions .604 Functional component 7: Program integrity Ensure accurate, secure, and efficient program delivery and that stakeholders in the value chain are fulfilling their roles. Protect against potential fraud, waste, and abuse Potential use cases (non -exhaustive) Potential risks (non -exhaustive) Data -driven continuous monitoring of the human services portfolio for irregularities E.g., fraud detection and prevention Detect irregular patterns in benefits usage, contractor behavior, potential fraud, waste, and abuse using AI -driven analytics versus manual investigation605 E.g., automated reporting and insight generation Data -driven dashboards with the ability to assess program integrity and flag potential irregular activity across a full network of providers606 Potentia l for incorrect use of AI models and incorrect output E.g., improper adaptation of AI fraud detection leading to incorrect program investigation AI applications developed for one purpose (e.g., fraud detection in financial services, payment processing, or verification) used to serve similar functions in human services (e.g., program fraud detection) and leading to erroneous fraud investigations607, 608 601 https://pubmed.ncbi.nlm.nih.gov/39396164/ Discussion on use in Healthcare and Public Health."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_450",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand incorrect output E.g., improper adaptation of AI fraud detection leading to incorrect program investigation AI applications developed for one purpose (e.g., fraud detection in financial services, payment processing, or verification) used to serve similar functions in human services (e.g., program fraud detection) and leading to erroneous fraud investigations607, 608 601 https://pubmed.ncbi.nlm.nih.gov/39396164/ Discussion on use in Healthcare and Public Health. 602 https://www.sciencedirect.com/science/article/pii/S0740624X20300034 603 https://www.apec.org/publications/2022/11/artificial -intelligence -in-economic -policymaking 604 https://pubmed.ncbi.nlm.nih.gov/39405325/ 605 https://www.brookings.edu/articles/using -ai-and-machine -learning -to-reduce -government -fraud/ 606 https://learn.microsoft.com/en -us/power -bi/create -reports/sample -artificial -intelligence 607 https://www.brookings.edu/articles/using -ai-and-machine -learning -to-reduce -government -fraud/ 608 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 120 Interactions with participants : Functional component 8: Participant engagement and needs assessment Create awareness and initiate relationships with potential participants."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_451",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nin Healthcare and Public Health. 602 https://www.sciencedirect.com/science/article/pii/S0740624X20300034 603 https://www.apec.org/publications/2022/11/artificial -intelligence -in-economic -policymaking 604 https://pubmed.ncbi.nlm.nih.gov/39405325/ 605 https://www.brookings.edu/articles/using -ai-and-machine -learning -to-reduce -government -fraud/ 606 https://learn.microsoft.com/en -us/power -bi/create -reports/sample -artificial -intelligence 607 https://www.brookings.edu/articles/using -ai-and-machine -learning -to-reduce -government -fraud/ 608 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 120 Interactions with participants : Functional component 8: Participant engagement and needs assessment Create awareness and initiate relationships with potential participants. Assess the needs of individuals or populations and make a preliminary determination of potentially applicable programs Potential use cases (non -exhaustive) Potential risks (non - exhaustive) Assistance tools for the human services workforce to better predict population needs and communicate with participants E.g., predictive analytics and risk stratification Predict high -risk individuals and populations and reach out sooner for enrollment, interventions, and wraparound services (e.g., mental health crisis support)."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_452",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\na preliminary determination of potentially applicable programs Potential use cases (non -exhaustive) Potential risks (non - exhaustive) Assistance tools for the human services workforce to better predict population needs and communicate with participants E.g., predictive analytics and risk stratification Predict high -risk individuals and populations and reach out sooner for enrollment, interventions, and wraparound services (e.g., mental health crisis support). Enable caseworkers to flag specific cases for review and personalized treatment609, 610, 611 E.g., live-language and cross -cultural translation for caseworkers AI-driven live translation tools enable caseworkers to interact with participants who speak a different language or caseworkers who speak another language with non-native fluency."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_453",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand reach out sooner for enrollment, interventions, and wraparound services (e.g., mental health crisis support). Enable caseworkers to flag specific cases for review and personalized treatment609, 610, 611 E.g., live-language and cross -cultural translation for caseworkers AI-driven live translation tools enable caseworkers to interact with participants who speak a different language or caseworkers who speak another language with non-native fluency. Enhancements to translation tools may further assist in identifying cross -cultural communication barriers extending beyond language (e.g., non-verbal communicatio n and cultural practices)612 Potential for incorrect output E.g., inaccurate live translation AI-powered live translation incorrectly communicates information between participants and caseworkers, leading to critical gaps in communication, especially when discussing legal documents or care613, 614 609 https://www.medicaid.gov/state -resource -center/innovation -accelerator -program/iap -downloads/program -areas/factsheet -riskstratification.pdf 610 https://www.ajmc.com/view/improving -risk-stratification -using -ai-and-social -determinants -of-health 611 https://www.ncbi.nlm.nih.gov/books/NBK475995/ 612 Multiple vendors exist alongside publicly available solutions like Google Translate."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_454",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nfor incorrect output E.g., inaccurate live translation AI-powered live translation incorrectly communicates information between participants and caseworkers, leading to critical gaps in communication, especially when discussing legal documents or care613, 614 609 https://www.medicaid.gov/state -resource -center/innovation -accelerator -program/iap -downloads/program -areas/factsheet -riskstratification.pdf 610 https://www.ajmc.com/view/improving -risk-stratification -using -ai-and-social -determinants -of-health 611 https://www.ncbi.nlm.nih.gov/books/NBK475995/ 612 Multiple vendors exist alongside publicly available solutions like Google Translate. 613 https://www.sciencedirect.com/science/article/pii/S2772941924000012 Live translation has been shown to outperform machine translation, but performance is still not fully accurate or adaptable to nuanced cultural differences."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_455",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nwhen discussing legal documents or care613, 614 609 https://www.medicaid.gov/state -resource -center/innovation -accelerator -program/iap -downloads/program -areas/factsheet -riskstratification.pdf 610 https://www.ajmc.com/view/improving -risk-stratification -using -ai-and-social -determinants -of-health 611 https://www.ncbi.nlm.nih.gov/books/NBK475995/ 612 Multiple vendors exist alongside publicly available solutions like Google Translate. 613 https://www.sciencedirect.com/science/article/pii/S2772941924000012 Live translation has been shown to outperform machine translation, but performance is still not fully accurate or adaptable to nuanced cultural differences. 614 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 121 Functional component 9: Application processing Collect required data and documentation from other agencies (where possible), potential clients and participants, or their caregivers, and process benefits applications Potential use cases (non -exhaustive) Potential risks (non -exhaustive) Platforms to process applications more rapidly and accurately and provide plain -language information to participants E.g., predictive eligibility determination Enable people to understand what programs are available to them with a strong indication of eligibility based on a limited set of demographic and social factors."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_456",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ntheir caregivers, and process benefits applications Potential use cases (non -exhaustive) Potential risks (non -exhaustive) Platforms to process applications more rapidly and accurately and provide plain -language information to participants E.g., predictive eligibility determination Enable people to understand what programs are available to them with a strong indication of eligibility based on a limited set of demographic and social factors. Further, partially complete the application process based on simplified data and articulate ho w to finish the process with plain language615 E.g., streamlined application processing Automate application tasks where possible and use data connections from multiple sources and agencies to auto -fill applications and accelerate decision -making."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_457",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nindication of eligibility based on a limited set of demographic and social factors. Further, partially complete the application process based on simplified data and articulate ho w to finish the process with plain language615 E.g., streamlined application processing Automate application tasks where possible and use data connections from multiple sources and agencies to auto -fill applications and accelerate decision -making. Further, enables interoperability to process multiple programs with similar or the same streamlined program616 Potential for algorithmic bias in decision -making E.g., generating misrepresentative benefit determinations for similarly situated people If AI is applied to aspects of human services delivery, including program eligibility determination, fraud detection, or risk -stratification, there is a risk that those programs will misclassify populations and individuals based on historical misrepresenta tion in underlying data, and influence decisions in prejudicial ways .617, 618 Functional component 10: Eligibility determination Determine whether a person is eligible for the program or benefits they have applied for and for what level of support Potential use cases (non -exhaustive) Potential risks (non - exhaustive) Connect across multiple disparate human services systems to improve benefit selection and speed up service delivery E.g., outcomes and follow -on services prediction Predict the likelihood that individuals enrolling in one program will likely be eligible for and could use another (e.g., X% of enrollees in SNAP are likely to require other cash assistance) and recommend those services using plain language at the time of enrollment619, 620 E.g., integrated benefits delivery systems AI-driven integration of data, applications, eligibility determination, and service delivery across programs in multiple agencies (e.g., across healthcare, human services, housing, and food security) 621 See risks outlined in Functional component 8: Application processing 615 https://www.thomsonreuters.com/en -us/posts/corporates/ai -family -leave -law/ 616 https://europepmc.org/article/pmc/pmc10114030 Efforts to streamline or automate the prior authorization process could be applied in other health and human services areas like public benefits."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_458",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\napplications, eligibility determination, and service delivery across programs in multiple agencies (e.g., across healthcare, human services, housing, and food security) 621 See risks outlined in Functional component 8: Application processing 615 https://www.thomsonreuters.com/en -us/posts/corporates/ai -family -leave -law/ 616 https://europepmc.org/article/pmc/pmc10114030 Efforts to streamline or automate the prior authorization process could be applied in other health and human services areas like public benefits. 617 https://jswve.org/volume -20/issue -2/item -05/ 618 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 619 https://pmc.ncbi.nlm.nih.gov/articles/PMC7125114/ Studies done in healthcare settings to predict outcomes or need for follow -on service (e.g., re -admission). 620 https://pmc.ncbi.nlm.nih.gov/articles/PMC11161909/ Recently published survey of studies on the use of AI to predict outcomes. 621 https://pmc.ncbi.nlm.nih.gov/articles/PMC9723913/ 122 Functional component 11: Service delivery and payments Provide services or payment to participants based on their eligibility."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_459",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-2/item -05/ 618 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 619 https://pmc.ncbi.nlm.nih.gov/articles/PMC7125114/ Studies done in healthcare settings to predict outcomes or need for follow -on service (e.g., re -admission). 620 https://pmc.ncbi.nlm.nih.gov/articles/PMC11161909/ Recently published survey of studies on the use of AI to predict outcomes. 621 https://pmc.ncbi.nlm.nih.gov/articles/PMC9723913/ 122 Functional component 11: Service delivery and payments Provide services or payment to participants based on their eligibility. This part of the value chain may include multiple steps and services but is simplified here Potential use cases (non -exhaustive) Potential risks (non -exhaustive) AI-generated service content and AI -supported platforms to increase the reach and effectiveness of programs E.g., AI -generated service content Guidance for and promotion of AI -supported platforms that fulfill the goals of HHS agencies (e.g., social isolation games for the elderly population, digital therapeutic interventions like chatbots for cognitive behavioral therapy, conversational agents fo r mental health programs) 622 E.g., AI -enabled robotics in elderly or disability care Social robots can help treat isolation or dementia in elderly populations."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_460",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nGuidance for and promotion of AI -supported platforms that fulfill the goals of HHS agencies (e.g., social isolation games for the elderly population, digital therapeutic interventions like chatbots for cognitive behavioral therapy, conversational agents fo r mental health programs) 622 E.g., AI -enabled robotics in elderly or disability care Social robots can help treat isolation or dementia in elderly populations. Assistive robots can help with daily tasks, including personal hygiene and mobility .623 Potential for bias or incorrect output E.g., improper assessment of program participant suitability for an education program Biased data or flawed algorithms are used to determine eligibility or conditions for workforce training programs, leading to incorrect placement or program offers .624 E.g., misaligned assignment of caseworkers Flawed AI -driven assessment of case complexity could exacerbate workforce challenges through misallocated resources .625 Functional component 12: Benefits change and disenrollment Renew and update recipient benefits or disenroll participants when they no longer meet assistance criteria Potential use cases (non -exhaustive) Potential risks (non -exhaustive) Proactive enrollee management to ensure accurate re -enrollment and benefit changes E.g., enrollee address and information verification Use AI to confirm enrollee information and assist with confirming eligibility, disenrolling, or reenrolling."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_461",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n12: Benefits change and disenrollment Renew and update recipient benefits or disenroll participants when they no longer meet assistance criteria Potential use cases (non -exhaustive) Potential risks (non -exhaustive) Proactive enrollee management to ensure accurate re -enrollment and benefit changes E.g., enrollee address and information verification Use AI to confirm enrollee information and assist with confirming eligibility, disenrolling, or reenrolling. Tool relevant during determination windows and when the participant may have had a change in life event626 E.g., proactive eligibility change notification Use of data integrated across multiple agencies to predict when participant eligibility (e.g., benefits cliffs) will change and proactively notify using plain language627 Potential to magnify participant trust concerns and AI skepticism E.g., overcollection of data The overcollection of data (or perception of overcollection or misuse ) for an AI model predicting benefits change ( e.g., loss of benefits) may enhance distrust, particularly for underrepresented populations who may already have negative perceptions of human services programs .628 622 Private mental health technology companies are using AI to generate content for mental health programs."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_462",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\novercollection of data The overcollection of data (or perception of overcollection or misuse ) for an AI model predicting benefits change ( e.g., loss of benefits) may enhance distrust, particularly for underrepresented populations who may already have negative perceptions of human services programs .628 622 Private mental health technology companies are using AI to generate content for mental health programs. 623 https://pmc.ncbi.nlm.nih.gov/articles/PMC10474924/ 624 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 625 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 626 Multiple vendor solutions across other sectors (e.g., financial services) exist."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_463",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n( e.g., loss of benefits) may enhance distrust, particularly for underrepresented populations who may already have negative perceptions of human services programs .628 622 Private mental health technology companies are using AI to generate content for mental health programs. 623 https://pmc.ncbi.nlm.nih.gov/articles/PMC10474924/ 624 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 625 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 626 Multiple vendor solutions across other sectors (e.g., financial services) exist. 627 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 628 https://www.ama -assn.org/system/files/ama -patient -data-privacy -survey -results.pdf 123 Cross -cutting parts of the value chain: Functional component 13: Customer service/experience Provide customer support and information to people as they navigate the process from needs assessment to service delivery and benefits change Potential use cases (non -exhaustive) Potential risks (non - exhaustive) Customer support tools to improve interactions of human services staff and more simply and accurately offer support to participants E.g., enhanced external chatbot or virtual assistant Create GenAI -enabled chatbots or virtual assistants that can answer questions for participants or potential applicants in plain language in multiple languages."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_464",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nbenefits change Potential use cases (non -exhaustive) Potential risks (non - exhaustive) Customer support tools to improve interactions of human services staff and more simply and accurately offer support to participants E.g., enhanced external chatbot or virtual assistant Create GenAI -enabled chatbots or virtual assistants that can answer questions for participants or potential applicants in plain language in multiple languages. Assist with basic eligibility prediction and integration into application processing629 E.g., synthesized participant feedback tool Use GenAI and connection to unstructured caseworker notes and call center feedback to conduct sentiment analysis and identify trends and common themes from participant inquiries and calls to human services call centers630 E.g., community organization and STLT -facing chatbot or virtual assistant GenAI -enabled chatbot or virtual assistant for community organizations and STLTs to understand grant and award requirements, answer questions related to new policies , and receive direction related to programmatic questions631 E.g., back -end call center optimization AI-driven analytics to understand what service channels, times, and other circumstances require differing capacity and optimizing workforce to accommodate demand632 Potentia l for incorrect output E.g., internal staff chatbot or external facing chatbot providing false information Internal AI -powered chatbots used by support staff to interact with participants could provide human services staff with incorrect information to provide to participants, potentially reducing benefits access.633 A similar public -facing chatbot could similarly create risks if it provides incorrect information, creates barriers to program access, or leads participants to believe they are ineligible for programs ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_465",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nfalse information Internal AI -powered chatbots used by support staff to interact with participants could provide human services staff with incorrect information to provide to participants, potentially reducing benefits access.633 A similar public -facing chatbot could similarly create risks if it provides incorrect information, creates barriers to program access, or leads participants to believe they are ineligible for programs . 4.6 Action Plan In light of the evolving AI landscape in human services delivery , HHS has taken multiple steps across issuing new guidelines for STLT use of AI in public benefits, practice sharing through public -private partnerships, and provision of grant funding to promote responsible AI. The Action Plan below follows the four goals that support HHS’s AI strategy : 1. catalyzing health AI innovation and adoption; 2. promoting trustworthy AI development and ethical and responsible use; 3. democratizing AI technologies and resources; and 4. cultivating AI -empowered workforces and organization cultures. For each goal, the Action Plan provides context, an overview of HHS and relevant other federal actions to date, and specific near- and long -term priorities HHS will take. HHS recognizes that this Action Plan will require revisions over time as technologies evolve and is committed to providing structure and flexibility to ensure longstanding impact ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_466",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nworkforces and organization cultures. For each goal, the Action Plan provides context, an overview of HHS and relevant other federal actions to date, and specific near- and long -term priorities HHS will take. HHS recognizes that this Action Plan will require revisions over time as technologies evolve and is committed to providing structure and flexibility to ensure longstanding impact . 629 https://www.frontiersin.org/journals/communication/articles/10.3389/fcomm.2023.1275127/full 630 Companies developing GPTs and LLMs offer enterprise solutions to tailor their GenAI tool to specific organizational needs. 631 https://journals.sagepub.com/doi/10.1177/02750740231200522 632 https://www.nber.org/papers/w31161 The paper assesses the impact of AI in customer support roles in general. 633 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 124 4.6.1 Catalyze AI Innovation and Adoption HHS could promote AI innovation and adoption through opportunities related to the following areas: 1. Unlocking resources for AI adoption and modernizing IT and tech infrastructure 2. Ensuring data quality and availability for AI adoption Below, the Department discusses context, HHS actions to date, HHS near -term priorities, and potential long -term actions. 1."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_467",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n4.6.1 Catalyze AI Innovation and Adoption HHS could promote AI innovation and adoption through opportunities related to the following areas: 1. Unlocking resources for AI adoption and modernizing IT and tech infrastructure 2. Ensuring data quality and availability for AI adoption Below, the Department discusses context, HHS actions to date, HHS near -term priorities, and potential long -term actions. 1. Unlocking resources for AI adoption and modernizing IT and tech infrastructure Context: Grants and contracts in human services do not tend to allocate funds for AI -related investments, nor do they require demonstrated IT capabilities as conditions for awards. Overall, the sector faces funding and workforce shortage s that leave many stakeholders feeling unable to meet demand for their services over a year.634 STLTs and community organizations may lack funding that can be directed toward investments in AI or improving tech infrastructure.635 As a result of this persistent funding shortage, non -profits spend less on IT infrastructure than the private sector, even though more technologically advanced non -profits are more likely to fulfill their missions.636 This lack of investment has led to outdated IT infrastructure in agencies and community organizations or overreliance on analog and paper record keeping. Organizations may require leapfrogging several IT maturation stages to incorporate AI into their oper ations."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_468",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nless on IT infrastructure than the private sector, even though more technologically advanced non -profits are more likely to fulfill their missions.636 This lack of investment has led to outdated IT infrastructure in agencies and community organizations or overreliance on analog and paper record keeping. Organizations may require leapfrogging several IT maturation stages to incorporate AI into their oper ations. STLTs and CBOs seeking to make transformational investments in IT without a proper technological foundation may face additional challenges, including reduced service quality due to the need to troubleshoot AI use. Greater resources for AI adoption would enable multiple opportunities, including enhancing interoperability, increasing the pace and quality of funds distribution as well as improving service quality and experience. 634 https://nff.org/learn/survey A 2022 survey of non -profits from the Nonprofit Finance Fund found that more than half of participating organizations felt they would be unable to meet the demand for their services in the upcoming year . 635 https://pmc.ncbi.nlm.nih.gov/articles/PMC6816239/ 636 https://ssir.org/articles/entry/taking_on_tech_governance# 125 HHS actions to date (non -exhaustive): • HHS’ s Plan for the Responsible Use of AI in Public Benefits: o Outlined additional areas of support for STLTs about promoting AI use in public benefits, including providing information on funding available to STLTs."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_469",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nunable to meet the demand for their services in the upcoming year . 635 https://pmc.ncbi.nlm.nih.gov/articles/PMC6816239/ 636 https://ssir.org/articles/entry/taking_on_tech_governance# 125 HHS actions to date (non -exhaustive): • HHS’ s Plan for the Responsible Use of AI in Public Benefits: o Outlined additional areas of support for STLTs about promoting AI use in public benefits, including providing information on funding available to STLTs. o Recommended specific enablers for the effective adoption of AI in public benefits administration among STLTs and vendors. These enablers include improved IT infrastructure, high -quality data, and appropriate safeguards. o Explored providing technical assistance to STLTs attempting to implement responsible AI in public benefits to increase their capacity to utilize AI appropriately and root out and mitigate risks. • Leveraged existing partnerships and developed new relationships to coordinate the promotion and adoption of AI. HHS has existing partnerships with coalitions, advisory committees, and other organizations and is creating new relationships to help share best practices and lessons, including mistakes , across jurisdictions. This information sharing can shorten the learning curve for newer adopters and provide hands -on, tactical guidelines, including templates for policies, governance, and the procurement of AI tools. • Provided grant funding to CBOs , improving service quality through AI applications."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_470",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nother organizations and is creating new relationships to help share best practices and lessons, including mistakes , across jurisdictions. This information sharing can shorten the learning curve for newer adopters and provide hands -on, tactical guidelines, including templates for policies, governance, and the procurement of AI tools. • Provided grant funding to CBOs , improving service quality through AI applications. ACF and ACL are funding organizations using AI to improve their operations or program delivery in multiple ways, including using robotics in assisted living facilities or launching AI -enabled chatbots.637, 638 Other federal actions to date (non -exhaustive) • USDA released the Framework for STLT Use of Artificial Intelligence in Public Benefits in April 2024 (referred to as the “USDA’s Framework for STLT Use of AI”).639 Mirroring HHS’s Plan for Responsible Use of AI in Public Benefits, the Department of Agriculture’s plan provides guidelines for STLT’s use of AI, including determining the benefits and goals of AI adoption, interactions with vendors, and the responsible u se of data and IT system design. HHS near -term priorities: • Identify funding opportunities available to lower -resourced STLTs and community organizations for AI adoption in human services, including IT modernization, data quality improvement, or other investment - type grant programs."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_471",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nof AI, including determining the benefits and goals of AI adoption, interactions with vendors, and the responsible u se of data and IT system design. HHS near -term priorities: • Identify funding opportunities available to lower -resourced STLTs and community organizations for AI adoption in human services, including IT modernization, data quality improvement, or other investment - type grant programs. • Explore private sector collaborations that could provide technical assistance to HHS, STLTs, and community organizations interested in adopting AI applications and modernizing IT for their human services programs. • Compile and make available best practice implementations of IT modernization, including for those categories outlined in the Plan for Responsible Use of AI in Public Benefits (e.g., IT readiness, and best practices interoperability) in the human services delivery ecosystem . • Explore expanding the procurement guide for STLTs (above what was provided in the Plan for Responsible Use of AI in Public Benefits ) to use as they evaluate AI tools in their information systems that help administer public benefit programs."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_472",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nof AI in Public Benefits (e.g., IT readiness, and best practices interoperability) in the human services delivery ecosystem . • Explore expanding the procurement guide for STLTs (above what was provided in the Plan for Responsible Use of AI in Public Benefits ) to use as they evaluate AI tools in their information systems that help administer public benefit programs. 637 https://acl.gov/news -and-events/announcements/acl -awards -20-field-initiated -projects -program -grants 638 https://acl.gov/news -and-events/announcements/new -funding -opportunity -small -business -innovation -research -program -4 639 https://www.fns.usda.gov/framework -artificial -intelligence -public -benefit 126 HHS long -term priorities: • Explore resources for government, non -profit, and research collaborations working in the human services ecosystem to adopt AI for improving their programs and benefits. • Identify best -practice open -source AI and infrastructure tools for human services organizations to leverage mapping tools to specific high -value use cases. • Evaluate opportunities to modernize HHS’s IT infrastructure to support greater AI adoption in the human services ecosystem."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_473",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand research collaborations working in the human services ecosystem to adopt AI for improving their programs and benefits. • Identify best -practice open -source AI and infrastructure tools for human services organizations to leverage mapping tools to specific high -value use cases. • Evaluate opportunities to modernize HHS’s IT infrastructure to support greater AI adoption in the human services ecosystem. • Integrate resource and technical assistance opportunities into mechanisms such as block grants, advanced planning documents, challenge grants, and federal contracts for AI applications that address human services programs dependent on resourcing and where most appropriate and feasible (e.g., promote health and well -being). • Consider designing “moonshot” competitions such as those used by CMMI, GSA, and Defense Advanced Research Projects Agency (DARPA) for system -level human service delivery solutions and providing resources and assistance for promising solutions to scale. 2. Ensuring data quality and availability for AI adoption Context: Owing in part to legacy IT, program requirements, concerns over participant privacy, and employee/client digital literacy (among other factors), many human services agencies record data in unstructured, non - standardized formats. These data are difficult to incorporate into AI -driven applications."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_474",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nproviding resources and assistance for promising solutions to scale. 2. Ensuring data quality and availability for AI adoption Context: Owing in part to legacy IT, program requirements, concerns over participant privacy, and employee/client digital literacy (among other factors), many human services agencies record data in unstructured, non - standardized formats. These data are difficult to incorporate into AI -driven applications. With improved data quality, governance, and interoperability, HHS could drive greater adoption of AI use cases that require accessible data. Additionally, AI itself can improve data availability through better inte rpretation of unstructured information. Data quality and availability improvements may enhance interoperability for service coordination and move the Department closer to its goal of a human -centered approach that seamlessly connects participants’ platforms to programs across human services, healthcare, and other public benefits. HHS actions to date (non -exhaustive): • The Plan for Responsible Use of AI in Public Benefits (HHS) recommended enablers for the effective adoption of AI among STLTs, including improving data quality and access. HHS near -term priorities: • Continue to issue guidelines and establish interoperability standards where authorized for sharing data across programs, departments, levels of government, and community organizations."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_475",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nactions to date (non -exhaustive): • The Plan for Responsible Use of AI in Public Benefits (HHS) recommended enablers for the effective adoption of AI among STLTs, including improving data quality and access. HHS near -term priorities: • Continue to issue guidelines and establish interoperability standards where authorized for sharing data across programs, departments, levels of government, and community organizations. • Identify, with STLT and community organization input, priority areas of human services delivery with gaps in data quality and collection (e.g., translations for less widely spoken languages) and align on a path forward for improvement. • Promote data quality standards, governance, and access to best practices observed in the human services ecosystem or adjacent areas with adaptations to human services , including best-practice for AI use to improve data -processing and structuring. • Explore private sector collaborations that could provide technical assistance to HHS, STLTs, and community organizations interested in improving data quality. HHS long -term priorities: • Consider implementing shared sandbox environments to accelerate piloting use cases and reduce the cost of understanding the return on investment in AI applications. • Review HHS -owned datasets for quality and applicability to AI use cases and create improvement plans where necessary."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_476",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ntechnical assistance to HHS, STLTs, and community organizations interested in improving data quality. HHS long -term priorities: • Consider implementing shared sandbox environments to accelerate piloting use cases and reduce the cost of understanding the return on investment in AI applications. • Review HHS -owned datasets for quality and applicability to AI use cases and create improvement plans where necessary. 127 4.6.2 Promote Trustworthy AI Development and Ethical and Responsible Use HHS could ensure that AI use remains trustworthy and safe by: 1. Providing guidelines on balancing risks to served populations and establishing participant trust with opportunities for AI applications. Below, the Department discusses the context, HHS actions to date, HHS near -term priorities, and potential long - term actions. 1. Providing guidance to served populations on balancing risks with opportunities for AI applications and establishing participant trust Context: Many stakeholders are vocal and active in ensuring that the populations that HHS serves are directly involved in developing AI applications and determining data used in AI models.640 Tailoring AI in human services to match the needs and cultural context of participants could improve service quality and accessibility of services."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_477",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nwith opportunities for AI applications and establishing participant trust Context: Many stakeholders are vocal and active in ensuring that the populations that HHS serves are directly involved in developing AI applications and determining data used in AI models.640 Tailoring AI in human services to match the needs and cultural context of participants could improve service quality and accessibility of services. This is especially important for populations that have historically been under - or misrepresented in data (e.g., refugees, tribal communities, and people with disabilities) and for AI applications that could affect peoples’ rights and safety (e.g., benefit eligibility determination).641 Initial research on AI indicates that cultural context and background impact preferences for using AI.642 However, more time and investment would be required to fully allay concerns about misrepresenting served groups in AI applications. Further, concerns for participant data privacy and safety may inhibit technology adoption . For instance, among AI vendors, there is broad awareness of federal AI risk frameworks and support for guardrails; however, many offerings do not provide the level of transparency required to assuage human service stakeholder concerns. Human services agen cies attempting to address data bias and privacy concerns without sufficient guidelines may disqualify AI solution vendors unwilling to offer additional transparency on their training data."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_478",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nvendors, there is broad awareness of federal AI risk frameworks and support for guardrails; however, many offerings do not provide the level of transparency required to assuage human service stakeholder concerns. Human services agen cies attempting to address data bias and privacy concerns without sufficient guidelines may disqualify AI solution vendors unwilling to offer additional transparency on their training data. Finally, HHS’s existing authority enforcing the use of AI in human services delivery is limited . It lacks a robust approach to AI oversight, including certifications, privacy and security controls, and third -party evaluations. Clear risk assessment and mitigation standards for organizations that develop and deploy AI in human services settings could mitigate the risk of inappropriate use. 640 https://datasociety.net/library/democratizing -ai-principles -for-meaningful -public -participation/ , https://www.upwardlyglobal.org/ai -for-impact -report/ 641 https://www.ncbi.nlm.nih.gov/books/NBK584407/ 642 https://hai.stanford.edu/news/how -culture -shapes -what -people -want -ai 128 HHS actions to date (non -exhaustive): • ACF Policy on Generative AI Tools from July 2024643 provided principles to encourage the appropriate and responsible use of GenAI to support its workforce and improve service delivery."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_479",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nrisk of inappropriate use. 640 https://datasociety.net/library/democratizing -ai-principles -for-meaningful -public -participation/ , https://www.upwardlyglobal.org/ai -for-impact -report/ 641 https://www.ncbi.nlm.nih.gov/books/NBK584407/ 642 https://hai.stanford.edu/news/how -culture -shapes -what -people -want -ai 128 HHS actions to date (non -exhaustive): • ACF Policy on Generative AI Tools from July 2024643 provided principles to encourage the appropriate and responsible use of GenAI to support its workforce and improve service delivery. These requirements for ACF staff and contractors include understanding the tool’s purpose and limitations, understanding how to securely use and protect participant data, reviewing and fact -checking the output, and being transparent with use. • Plan for Responsible Use of AI in Public Benefits (HHS): o Provided recommendations for Managing Risks for the Use of Automated Algorithmic Systems , including those focused on managing the highest risk AI use cases, ensuring safety and security, sustaining human judgment, allowing participant opt -outs, protecting recipient interests, and safeguarding civil liberties. o Recommended establishing effective governance mechanisms for AI risks consistent with the six principles outlined in the NIST AI Risk Management Framework."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_480",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nRisks for the Use of Automated Algorithmic Systems , including those focused on managing the highest risk AI use cases, ensuring safety and security, sustaining human judgment, allowing participant opt -outs, protecting recipient interests, and safeguarding civil liberties. o Recommended establishing effective governance mechanisms for AI risks consistent with the six principles outlined in the NIST AI Risk Management Framework. Additional recommendations include maintaining an inventory of automated and algorithm -based technol ogies, creating a formalized process to evaluate risks in AI use, and educating vendors about their AI governance practices. • HHS Trustworthy AI Playbook (2021) outlined guidelines for the internal use of AI applications at HHS .644 It provides guidelines to ensure that AI applications internal to HHS are developed and deployed ethically, effectively, and securely, aligned with federal standards, and promote public trust throughout the AI life cycle . However, these guidelines have not been tailored specifically to human services programs and are mostly limited to guidelines on internal use cases rather than promoting external adoption."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_481",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nIt provides guidelines to ensure that AI applications internal to HHS are developed and deployed ethically, effectively, and securely, aligned with federal standards, and promote public trust throughout the AI life cycle . However, these guidelines have not been tailored specifically to human services programs and are mostly limited to guidelines on internal use cases rather than promoting external adoption. • Joint Statement on Enforcement of Civil Rights, Fair Competition, Consumer Protection, and Equal Opportunity Laws in Automated Systems (April 2024)645 clarified the ability to use enforcement action for violations from automated systems and that it can use that authority to enforce rules related to equity, including enforcing Civil Rights, Fair Competition, and Consumer Protection. • Published internal governance documents for external reference. ACF has published its AI Activation Toolkit.646 Other federal actions (non -exhaustive) : • USDA’s Framework for STLT Use of AI includes most risk management and governance recommendations from the HHS Plan for Responsible Use of AI in Public Benefits. This reflects the overlapping responsibility of many STLT human services departments to administer a mix of HHS and USDA programs (e.g., TANF and SNAP)."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_482",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI Activation Toolkit.646 Other federal actions (non -exhaustive) : • USDA’s Framework for STLT Use of AI includes most risk management and governance recommendations from the HHS Plan for Responsible Use of AI in Public Benefits. This reflects the overlapping responsibility of many STLT human services departments to administer a mix of HHS and USDA programs (e.g., TANF and SNAP). HHS near -term priorities: • Issue new guidelines and recommendations as outlined in the Plan for Responsible Use of AI in Public Benefits, including clarifying principles for roles of human intervention in automated systems, customer support, and GenAI use. • Consider issuing guidelines on best -practice interactions with participants to explain and establish trust in using AI in human services programs. • Research effective methods for using AI in human services while adopting best -practice safety standards (e.g., bias mitigation and maintaining human -in-the-loop). • Define applicable regulatory authorities for using AI in human services delivery (e.g., for AI -enabled devices in assisted and community living) and clarify HHS’s role in enforcement regarding the trustworthiness and safety of AI use."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_483",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nprograms. • Research effective methods for using AI in human services while adopting best -practice safety standards (e.g., bias mitigation and maintaining human -in-the-loop). • Define applicable regulatory authorities for using AI in human services delivery (e.g., for AI -enabled devices in assisted and community living) and clarify HHS’s role in enforcement regarding the trustworthiness and safety of AI use. 643 https://www.acf.hhs.gov/sites/default/files/documents/main/ACF -Generative -AI-Policy -June-2024.pdf 644 https://www.hhs.gov/sites/default/files/hhs -trustworthy -ai-playbook.pdf 645 https://www.justice.gov/crt/media/1346821/dl?inline 646 https://www.acf.hhs.gov/ai -data-research/artificial -intelligence -acf 129 HHS long -term priorities: • Integrate AI safety and transparency requirements into HHS funding mechanisms by complying with best-practice guidelines for block grant conditions, state plans, advanced planning documents, challenge grants, and federal contracts in coordination with relevant federal partners. • Explore direct resource support opportunities for HHS, STLTs, and community organizations to monitor AI applications and use risks . 4.6.3 Democratize access to AI technologies and resources across the U.S., including for underrepresented populations HHS could ensure equitable access to AI through actions related to several opportunities, including: 1. Raising the floor of constituent digital literacy and digital penetration 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_484",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nExplore direct resource support opportunities for HHS, STLTs, and community organizations to monitor AI applications and use risks . 4.6.3 Democratize access to AI technologies and resources across the U.S., including for underrepresented populations HHS could ensure equitable access to AI through actions related to several opportunities, including: 1. Raising the floor of constituent digital literacy and digital penetration 2. Identifying areas of cooperation across sectors to improve AI -related economies of scale Below, the Department discusses the context, HHS actions to date, HHS near -term priorities, and potential long - term actions. 1. Raising the floor of constituent digital literacy and digital penetration Context: In some programs, the population likely to access human services programs is older and less likely to speak English proficiently. Historically, these populations have lower digital literacy, internet access, and smartphone penetration rates.647 Further, 24 million Americans, some of whom overlap with human services populations, lack access to broadband internet.648 This “digital divide” limits the effectiveness and solution space for client -facing AI applications in human services. AI applications could mitigate these challenges; however, it requires a baseline digital literacy and capability that some parts of the human services ecosystem may not have. One additional consequence of the digital divide concerns data access and consent."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_485",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nlack access to broadband internet.648 This “digital divide” limits the effectiveness and solution space for client -facing AI applications in human services. AI applications could mitigate these challenges; however, it requires a baseline digital literacy and capability that some parts of the human services ecosystem may not have. One additional consequence of the digital divide concerns data access and consent. An agency or community organization may be unable to obtain data for populations with limited digital access or who cannot or will not consent to sharing their data. Data ga ps can exacerbate data quality issues and hinder the deployment of equitable and contextualized predictive analytics and the development of better AI tools. Increasing the connectivity and digital experience of potential participants could increase their a ccess to services that otherwise required technology participants did not previously have or understand. HHS actions to date (non -exhaustive): • The Plan for the Responsible Use of AI in Public Benefits engaged with the public to collect broad feedback on the use of AI in public benefits. These engagements included listening sessions, advisory committees, tribal consultations, webinars, workshops, and other activities intended to include more voices in H HS AI -related policy development."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_486",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nHHS actions to date (non -exhaustive): • The Plan for the Responsible Use of AI in Public Benefits engaged with the public to collect broad feedback on the use of AI in public benefits. These engagements included listening sessions, advisory committees, tribal consultations, webinars, workshops, and other activities intended to include more voices in H HS AI -related policy development. Other federal actions (non -exhaustive): • The USDA Framework for STLT Use of AI closely mirrors recommendations from HHS’s plan for ensuring equitable access and protecting against bias in using AI in public systems. 647 https://www.ntia.gov/blog/2022/switched -why-are-one-five-us-households -not-online 648 https://www.ntia.gov/blog/2022/switched -why-are-one-five-us-households -not-online 130 HHS near -term priorities: • Establish ongoing consultation channels with the inclusion of various partners, such as IT/AI collaboratives, community -based groups, AI subject matter experts, research organizations, frontline staff, and participants and representatives across different populations (e.g., urban/rural, children/adults, older adults, people with disabilities) and backgrounds (e.g., race, sexual orientation, ethnicities, and language) to identify paths to improve AI accessibility in human services."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_487",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n• Establish ongoing consultation channels with the inclusion of various partners, such as IT/AI collaboratives, community -based groups, AI subject matter experts, research organizations, frontline staff, and participants and representatives across different populations (e.g., urban/rural, children/adults, older adults, people with disabilities) and backgrounds (e.g., race, sexual orientation, ethnicities, and language) to identify paths to improve AI accessibility in human services. • Develop guidelines for how STLTs and community organizations can address inequities in digital literacy in populations they serve, including guidelines for identifying the historical, contemporary, and structural contributors to the inequities that drive d isparities in AI adoption. • Share information on HHS -implemented AI use cases to model opportunities for human services organizations. • Compile and research potential AI use cases to mitigate or address inequities. HHS long -term priorities: • Consider establishing grant or assistance programs where authorized and resourced to address inequities in access to impactful AI in the human services ecosystem (e.g., awards for populations with a high digital divide)."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_488",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI use cases to model opportunities for human services organizations. • Compile and research potential AI use cases to mitigate or address inequities. HHS long -term priorities: • Consider establishing grant or assistance programs where authorized and resourced to address inequities in access to impactful AI in the human services ecosystem (e.g., awards for populations with a high digital divide). • In coordination with appropriate entities, explore developing and implementing education campaigns for at-risk demographic groups focused on the harms of AI -enabled scams (e.g., deepfake -supported scams like impersonation of family members, government officials, and financial institutions) that are intended to defraud individuals of money and resources. • Continue to evaluate and support methods to ensure underserved populations may access and benefit from AI. 2. Identifying areas of cooperation across sectors to improve AI -related economies of scale Context: Even where agencies and organizations find they have funds to invest in AI applications for their own organization , they may face two additional accessibility barriers. First, a smaller organization may find it challenging to capture the benefits of AI at scale without broader sector wide investment beyond its means.649 For instance , a use-case like fraud detection or program measurement analytics may require data or technical capabilities from across multiple organizations."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_489",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI applications for their own organization , they may face two additional accessibility barriers. First, a smaller organization may find it challenging to capture the benefits of AI at scale without broader sector wide investment beyond its means.649 For instance , a use-case like fraud detection or program measurement analytics may require data or technical capabilities from across multiple organizations. Second, a small organization may lack an in -house workforce with enough technical expertise to evaluate vendor options and integrate new solutions ( for further details on opportunities related to the workforce , please see the next section on “Cultivating AI -Empowered Workforces and Organizational Cultures”).650 Thus, the size and makeup of these organizations may hinder access even where investment exists. Addressing challenges with scale would improve service experience and quality through greater access to program -enhancing AI . Likewise, it could increase accessibility of services where under -resourced STLTs and community organizations are able to reach more people through AI -enabled platforms that they otherwise lacked the scale to adopt. HHS near -term priorities: • Identify use cases or IT investments that are the most promising for the human services delivery ecosystem but require scale beyond community organizations or STLTs (e.g., fraud detection capabilities)."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_490",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nservices where under -resourced STLTs and community organizations are able to reach more people through AI -enabled platforms that they otherwise lacked the scale to adopt. HHS near -term priorities: • Identify use cases or IT investments that are the most promising for the human services delivery ecosystem but require scale beyond community organizations or STLTs (e.g., fraud detection capabilities). • Consider grant and technical assistance opportunities for deploying use cases requiring coordinated activity or larger scale. 649 https://hbr.org/2022/03/how -to-scale -ai-in-your-organization 650 https://www.salesforce.com/news/stories/public -sector -ai-statistics/ 131 HHS long -term priorities: • Explore creating an “AI for human services” toolkit with critical resources on AI adoption in human services and making it open source to STLTs and community action organizations. • Consider convening an HHS AI center of excellence team that provides technical expertise and capabilities to HHS, STLTs, and community organizations and develops their capabilities for the Plan’s goals. 4.6.4 Cultivating AI -Empowered Workforces and Organizational Cultures HHS could cultivate AI -empowered workforces and organizational cultures through actions related to several opportunities, including: 1. Improving human services employee digital literacy, talent, and openness to adopting technology 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_491",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nexcellence team that provides technical expertise and capabilities to HHS, STLTs, and community organizations and develops their capabilities for the Plan’s goals. 4.6.4 Cultivating AI -Empowered Workforces and Organizational Cultures HHS could cultivate AI -empowered workforces and organizational cultures through actions related to several opportunities, including: 1. Improving human services employee digital literacy, talent, and openness to adopting technology 2. Using AI to mitigate the labor workforce shortage in human services Below, the Department discusses the context, HHS actions to date, HHS near -term priorities, and potential long - term actions. 1. Improving human services employee’s digital literacy, talent, and openness to adopting technologies Context: Through informal conversations with human services stakeholders, HHS has heard both concerns about the effects of AI on their workforce and requests for assistance in educating the workforce on AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_492",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe context, HHS actions to date, HHS near -term priorities, and potential long - term actions. 1. Improving human services employee’s digital literacy, talent, and openness to adopting technologies Context: Through informal conversations with human services stakeholders, HHS has heard both concerns about the effects of AI on their workforce and requests for assistance in educating the workforce on AI. These concerns correspond to an overall shortage of AI expertise in the public sector that could impede adoption.651 Additionally , in response to an HHS RFI on AI in human and health services delivery, AI developers and implementers frequently cited organizational readiness (human capacity, technical infrastructure, data quality, change management) as a critical barrier to the succe ssful use of AI.652 Additionally, vendors require guidelines from AI -informed experts in human services on mission -driven use case identification and prioritization; however, these experts are scarce in many agencies and community organizations. Further, limited in -house digital talent among stakeholders impedes the adoption and enthusiasm for new tools."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_493",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nquality, change management) as a critical barrier to the succe ssful use of AI.652 Additionally, vendors require guidelines from AI -informed experts in human services on mission -driven use case identification and prioritization; however, these experts are scarce in many agencies and community organizations. Further, limited in -house digital talent among stakeholders impedes the adoption and enthusiasm for new tools. This gap extends to the m ost senior roles in non -profits engaged in human service delivery, where boards often lack a member with deep tech experience.653 Finally, even where agencies or CBOs potentially make large - scale investments in IT, a lack of training on AI tools could leave staff unprepared to use new technologies effectively and potentially reduce service quality . Where human services stakeholders are open to adopting new technologies, they can use AI to enhance the capabilities of their workforce , potentially freeing capacity to serve the growing population who access human services programs. HHS actions to date (non -exhaustive): • The Plan for the Responsible Use of AI in Public Benefits recommended actions for STLTs to support the workforce in responsibly using AI, including training them on developing and using automated and algorithmic systems, sustaining staff judgment when using AI, and exercising control over algorithmic systems whe n engaging third -party vendors. USDA’s Framework for STLT Use of AI closely mirrors these recommendations."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_494",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe Responsible Use of AI in Public Benefits recommended actions for STLTs to support the workforce in responsibly using AI, including training them on developing and using automated and algorithmic systems, sustaining staff judgment when using AI, and exercising control over algorithmic systems whe n engaging third -party vendors. USDA’s Framework for STLT Use of AI closely mirrors these recommendations. • HHS AI Trustworthy AI Playbook (2021) provided education on AI concerning internal HHS systems. Information included benefits , drawbacks , and potential application s of AI in the Department. The 651 https://www.salesforce.com/news/stories/public -sector -ai-statistics/ 652 Informal conversations between HHS working group and vendors . 653 https://ssir.org/articles/entry/taking_on_tech_governance# 132 Playbook also provides guidelines on incorporating trustworthy AI principles into work routines and overseeing AI -related projects. HHS near -term priorities: • Explore direct grant or technical assistance opportunities for workforce training and technical assistance within HHS, among STLTs, and in community organizations. • Develop best practice guidelines for how federal and state agencies and community organizations can improve AI readiness of their workforces. • Establish digital literacy and AI literacy training for HHS staff working in human services."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_495",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-term priorities: • Explore direct grant or technical assistance opportunities for workforce training and technical assistance within HHS, among STLTs, and in community organizations. • Develop best practice guidelines for how federal and state agencies and community organizations can improve AI readiness of their workforces. • Establish digital literacy and AI literacy training for HHS staff working in human services. • Support or initiate partnerships between the human services ecosystem and private sector leaders in AI and digital transformation to facilitate information sharing. • To the extent desired by tribal nations and where resources are available, support tribal nations working to regulate and implement oversight of AI in human services. HHS long -term priorities: • Make HHS -internal digital and AI literacy training publicly available for STLTs and community organizations. • Convene regular AI in human services conferences with learning tracks, practical workshops, and recorded resources. 2. Using AI to mitigate the labor workforce shortage in human services Context: As previously noted, the Bureau of Labor Statistics projects a 67,300 -person social worker shortage across the U.S. annually over the next decade.654 A more digital, AI -enabled workforce could identify and deploy use cases that enhance the capabilities of the human services workforce and focus staff on value -added activities and on participant interactions."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_496",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nshortage in human services Context: As previously noted, the Bureau of Labor Statistics projects a 67,300 -person social worker shortage across the U.S. annually over the next decade.654 A more digital, AI -enabled workforce could identify and deploy use cases that enhance the capabilities of the human services workforce and focus staff on value -added activities and on participant interactions. This could alleviate elements of the job driving low satisfaction and high turnover. However, there are concerns about using AI to augment the human services workforce. First, there are concerns that AI adoption may result in workforce displacement655 without improving productivity or service quality.656 Second, overreliance on AI to increase workforce capacity may remove the human element from human services programs for participants. HHS is considering ways to balance these concerns alongside the opportunity for AI in the human services workforce. Other federal activities (non -exhaustive): • The Department of Labor released comprehensive AI Practices (October 2024) that provide strategies for how AI can benefit workers and businesses while focusing on workers’ rights, job quality, well-being, privacy, and economic security. HHS near -term priorities: • Share best practices from the human services delivery ecosystem for expanding the workforce’s AI capacity."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_497",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nworkforce. Other federal activities (non -exhaustive): • The Department of Labor released comprehensive AI Practices (October 2024) that provide strategies for how AI can benefit workers and businesses while focusing on workers’ rights, job quality, well-being, privacy, and economic security. HHS near -term priorities: • Share best practices from the human services delivery ecosystem for expanding the workforce’s AI capacity. • Explore additional areas to issue guidelines specific to human services for responsibly adopting AI aligned with Department of Labor AI Practices and participants’ desires to maintain human interaction. 654 https://www.bls.gov/ooh/community -and-social -service/social -workers.htm 655 https://www.goldmansachs.com/insights/articles/generative -ai-could -raise -global -gdp-by-7-percent.html 656 https://www.healthaffairs.org/content/forefront/discrimination -artificial -intelligence -commercial -electronic -health -record -case-study AI tool for predicting no -shows can have adverse effect of reducing service quality if biased algorithms incorrectly predict no -show probability, increasing chances that set of individuals are double -booked for appointments. 133 HHS long -term priorities: • Review existing guidelines for program delivery and interoperability provided to STLTs to identify areas where AI can alleviate workforce capacity constraints."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_498",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI tool for predicting no -shows can have adverse effect of reducing service quality if biased algorithms incorrectly predict no -show probability, increasing chances that set of individuals are double -booked for appointments. 133 HHS long -term priorities: • Review existing guidelines for program delivery and interoperability provided to STLTs to identify areas where AI can alleviate workforce capacity constraints. 4.7 Conclusion AI has the potential to address underlying challenges in the human services ecosystem, from persistent workforce shortages to low participant satisfaction with programs. Eventually, AI applications may improve human services programs for those who participate in them. However, fundamental challenges have impeded adoption, including a lack of funding and concerns over rights and safety. Despite the challenges, HHS believes that AI can improve program quality, increase access, reduce administrative burden, an d enhance interoperability of public benefits systems. Further, HHS is well positioned to help the human services ecosystem overcome its challenges and realize the benefits of AI. At the same time, it can establish standards and educate the public on the risks inherent in AI, ensuring that AI applications are trustworthy and safe. It can also function as a convener to elevate best practices from the broader ecosystem and highlight lived experiences with AI and its effects on served populations and historically misrepresented groups."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_499",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nbenefits of AI. At the same time, it can establish standards and educate the public on the risks inherent in AI, ensuring that AI applications are trustworthy and safe. It can also function as a convener to elevate best practices from the broader ecosystem and highlight lived experiences with AI and its effects on served populations and historically misrepresented groups. This Plan will evolve as the AI landscape changes, but HHS believes that the actions outlined in this Plan will materially advance HHS and the U.S.’s strategic interest in AI. 134 5 Public Health 5.1 Introduction and Context For this Strategic Plan, public health is defined as “the science and art of preventing disease, prolonging life, and promoting health through the organized efforts and informed choices of society, organizations, public and private communities, and individ uals.” 657 U.S. public health covers a diverse range of issues like infectious diseases, substance use disorders, non -communicable diseases, environmental health and climate adaptation, and mental and behavioral health. Public health challenges and their underlying disease processes are complex and often involve interactions across biological, social, economic, and other dynamics, requiring collaboration across high - level actors, both public and private. The COVID -19 pandemic and its aftereffects highlighted severe challenges and gaps in the U.S."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_500",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nnon -communicable diseases, environmental health and climate adaptation, and mental and behavioral health. Public health challenges and their underlying disease processes are complex and often involve interactions across biological, social, economic, and other dynamics, requiring collaboration across high - level actors, both public and private. The COVID -19 pandemic and its aftereffects highlighted severe challenges and gaps in the U.S. public health ecosystem, including (1) difficulty rapidly collecting, sharing, and analyzing information, (2) rising health inequity and public distrust of science, and (3) longstanding resourcing and staffing strains.658 AI can help find new solutions to these challenges . For instance, AI can help by automating processes across the data life cycle (e.g., data cleaning, validation, and aggregation) and analyzing vast amounts of data to identify patterns and generate insights, thereby improving public health decisions, interventions, and programs and ensuring resources are allocated where they are ne eded most. The integration of AI into public health has the potential to significantly enhance disease monitoring and interventi on design (e.g., through automated outbreak detection and rapid analysis of large datasets and non -traditional data sources for non -communicable diseases). Additionally, AI can help improve diagnostic accuracy, better engage diverse populations, and optimi ze the use of public health’s often limited resources."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_501",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nintegration of AI into public health has the potential to significantly enhance disease monitoring and interventi on design (e.g., through automated outbreak detection and rapid analysis of large datasets and non -traditional data sources for non -communicable diseases). Additionally, AI can help improve diagnostic accuracy, better engage diverse populations, and optimi ze the use of public health’s often limited resources. Strategic focus and resourcing from HHS agencies, including CDC, NIH, and ASPR, will be critical to driving this transformational change in the public sector. HHS has a unique challenge and opportunity to drive innovation in public health, and by extension private sector healthcare. Federal activities related to data modernization and AI adoption efforts have been ongoing for nearly a decade across the public health ecosystem. Examples include E.O. 13994 , E.O. 13960, and ASTP rules HTI -1 and HTI - 2. Activities also include initiatives to increase the availability and quality of data, agency -specific implementation efforts, and federal rules and policies related to a data -driven response to COVID -19 and response readine ss for future events. These efforts, while not intended solely for the quick uptake of AI , directly connect and support public health agencies’ efforts to be able to deploy AI . The U.S."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_502",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\navailability and quality of data, agency -specific implementation efforts, and federal rules and policies related to a data -driven response to COVID -19 and response readine ss for future events. These efforts, while not intended solely for the quick uptake of AI , directly connect and support public health agencies’ efforts to be able to deploy AI . The U.S. public health ecosystem is only as strong as its weakest link; without data modernization and interoperability, isolated health entities will not have the means to contribute to and benefit from shared data and AI use. This prevents the entire e cosystem from building the comprehensive data view necessary to effectively detect, understand, and address public health issues. The foundation is be ing laid to break down silos and encourage the use of AI, and there is an opportunity for CDC and the rest of HHS to be a lighthouse for others in the ecosystem. AI innovation and usage have also been discussed in almost every global health forum over the last few years and there is opportunity for AI to improve health globally ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_503",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nbreak down silos and encourage the use of AI, and there is an opportunity for CDC and the rest of HHS to be a lighthouse for others in the ecosystem. AI innovation and usage have also been discussed in almost every global health forum over the last few years and there is opportunity for AI to improve health globally . Multiple HHS actions related to global health have already been launched (e.g., the ARPA -H program on AI antibiotics to combat anti -microbial resistance).659 However, as HHS representatives stated at the G7 conference, the effectiveness of AI is determined in large part by the strength 657 https://www.cdc.gov/training -publichealth101/media/pdfs/introduction -to-public -health.pdf 658 https://www.cdc.gov/workforce/php/about/index.html 659 https://arpa -h.gov/news -and-events/arpa -h-award -aims-combat -antimicrobial -resistance 135 of a country’s enabling environment —one that is trustworthy, accessible, and free of bias. Countries around the world, including the U.S., are looking at how best to use AI to improve healthcare systems and protect against major health threats wherever they arise. In addition to its many opportunities, AI use is accompanied by serious risks related to privacy, ethics, and equity, many of which can be further addressed by HHS actions. To maximize the benefits of AI in public health, existing efforts will have to be a ccelerated and integrated into a cohesive strategy that balances innovation with safety and security."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_504",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\narise. In addition to its many opportunities, AI use is accompanied by serious risks related to privacy, ethics, and equity, many of which can be further addressed by HHS actions. To maximize the benefits of AI in public health, existing efforts will have to be a ccelerated and integrated into a cohesive strategy that balances innovation with safety and security. To that end, later in this document , HHS has outlined a set of strategic priorities to catalyze health AI innovation and adoption, ensure AI use is trustw orthy and safe, democratize access to AI technologies and knowledge, and support the cultivation of AI -empowered workforces and organizational cultures. 5.1.1 Action Plan Summary Later in this chapter, HHS articulates proposed actions to advance its four goals for the responsible use of AI in the sector. Below is a summary of the themes of actions within each goal. For full details of proposed actions please see section 5.6 Action Plan. Key goals that actions support Themes of proposed actions (not exhaustive, see 5.6 Action Plan for more details) 1. Catalyzing health AI innovation and adoption • Encouraging research, development of guidelines, and identification of resources to support evidence generation and scale of AI in public health • Modernizing infrastructure necessary to implement AI and support adoption 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_505",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n5.6 Action Plan. Key goals that actions support Themes of proposed actions (not exhaustive, see 5.6 Action Plan for more details) 1. Catalyzing health AI innovation and adoption • Encouraging research, development of guidelines, and identification of resources to support evidence generation and scale of AI in public health • Modernizing infrastructure necessary to implement AI and support adoption 2. Promoting trustworthy AI development and ethical and responsible use • Establishing guardrails to help ensure data quality and accuracy • Standardizing data security policies across the public health ecosystem • Advancing AI tools and techniques that consider and assess health equity from end to end 3. Democratizing AI technologies and resources • Creating an environment that enables data sharing across the public health ecosystem • Supporting AI adoption, development, and collaboration , especially for STLTs and community organizations who may have limited resources • Developing user -friendly, customizable, and open -source AI tools to broaden access and accommodate a diversity of users 4. Cultivating AI - empowered workforces and organization cultures • Augmenting and supporting the public health workforce to address burnout and attrition • Promoting AI education and community -based AI approaches tailored to each community’s unique need 5.2 Stakeholders Engaged in the Public Health AI Value Chain The U.S."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_506",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI tools to broaden access and accommodate a diversity of users 4. Cultivating AI - empowered workforces and organization cultures • Augmenting and supporting the public health workforce to address burnout and attrition • Promoting AI education and community -based AI approaches tailored to each community’s unique need 5.2 Stakeholders Engaged in the Public Health AI Value Chain The U.S. public health ecosystem is anchored on the coordination and support of the federal government and STLTs and relies on the collaboration of a wide range of stakeholders, from providers, health systems, private partners, and researchers to non -profi ts and the general public to enact positive societal change. To illustrate the diversity of public health actors, below is a non -exhaustive , illustrative diagram of example flows between stakeholders (Exhibit 1 2) and a bulleted list of stakeholders involve d.660 Please note that neither the diagram nor the list captures all stakeholder roles and interactions. Please refer to other HHS documents for additional details on regulatory guidance and authorities. 660 Descriptions are illustrative and do not capture the full range of each entity’s roles and responsibilities 136 Exhibit 12: The U.S."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_507",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n2) and a bulleted list of stakeholders involve d.660 Please note that neither the diagram nor the list captures all stakeholder roles and interactions. Please refer to other HHS documents for additional details on regulatory guidance and authorities. 660 Descriptions are illustrative and do not capture the full range of each entity’s roles and responsibilities 136 Exhibit 12: The U.S. Public Health Ecosystem661 • HHS agencies: Public health is supported through the efforts of the operating divisions of HHS, such as: o ACF: Provides benefits and services to support the well -being of families and children, many of which are related to public health (e.g., behavioral health and abuse prevention). o ACL: Supports programs for populations with complex needs, particularly older adults and people with disabilities, including nutrition services, medical care, and elder support services. o AHRQ: Focuses on improving the quality, safety, efficiency, and effectiveness of healthcare for all Americans through research . o ASPR: Leads national preparedness, response, and recovery from disasters and public health emergencies. o Agency for Toxic Substances and Disease Registry (ATSDR): Prevents exposure to hazardous substances (e.g., chemicals, pesticides, heavy metals) and mitigates associated health risks. ATSDR conducts risk assessments and health consultations and supports health education ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_508",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand effectiveness of healthcare for all Americans through research . o ASPR: Leads national preparedness, response, and recovery from disasters and public health emergencies. o Agency for Toxic Substances and Disease Registry (ATSDR): Prevents exposure to hazardous substances (e.g., chemicals, pesticides, heavy metals) and mitigates associated health risks. ATSDR conducts risk assessments and health consultations and supports health education . o CDC: Actively detects, surveils, defines, prevents, and responds to disease outbreaks, administers national health programs, and supports policymaking by providing technical assistance and information. o CMS: Administers major public healthcare payer programs (e.g., Medicare and Medicaid), outlines conditions of participation related to these programs for healthcare providers contingent on sharing critical public health data (e.g., related to healthcare -associ ated infections), and could provide payment for specific devices or services. o FDA: Acts as a core regulator to ensure the safety and ef fectiveness of medical products and the security of medical devices, including AI -enabled medical devices. o IHS: Provides a comprehensive healthcare delivery system and ensures culturally appropriate public health and human services are available for American Indian and Alaska Native people to raise the physical, mental, social, and spiritual health of the population to the highest level."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_509",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsafety and ef fectiveness of medical products and the security of medical devices, including AI -enabled medical devices. o IHS: Provides a comprehensive healthcare delivery system and ensures culturally appropriate public health and human services are available for American Indian and Alaska Native people to raise the physical, mental, social, and spiritual health of the population to the highest level. 661 https://www.cdc.gov/public -health -data-strategy/php/about/public -health -ecosystem -data-goals -sources -and-modernization.html 137 o HRSA: Aims to improve access to healthcare for populations who are uninsured, isolated, or at high risk. o NIH: Acts as the steward of biomedical and behavioral research across the U.S. and supports public health efforts through the maintenance of health data repositories (e.g., NLM digital sequence information) and public outreach to promote informed health decisions. o SAMHSA: Leads public health efforts to advance the behavioral health of the nation and improve the lives of individuals living with mental and substance use disorders, as well as their families. • The public: The general population plays a crucial role in public health through participation in preventive measures and other actions, which include vaccination, hygiene, personal health and lifestyle, and disease and symptom reporting. This includes individuals th at are beneficiaries of services and their caregivers."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_510",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nof individuals living with mental and substance use disorders, as well as their families. • The public: The general population plays a crucial role in public health through participation in preventive measures and other actions, which include vaccination, hygiene, personal health and lifestyle, and disease and symptom reporting. This includes individuals th at are beneficiaries of services and their caregivers. • Other f ederal agencies : Federal agencies external to HHS , such as the E nvironmental Protection Agency (EPA) and Department of Education (E D), are critical partners and data providers to support public health actions. This includes information provided through public benefit programs, population data, environmental data, and job and economic data. • Public Health Service Commissioned Corps: The cross -agency work and value across federal agencies is exemplified throughout the U.S. Public Health Service Commissioned Corps. Commissioned Corps officers serve 21 federal agencies, demonstrating the important strategic role all agencies have in responsible AI adoption to support public health. • STLTs: STLTs and freely associated state health departments are the backbone of the public health ecosystem and are key partners to HHS in public health work."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_511",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nis exemplified throughout the U.S. Public Health Service Commissioned Corps. Commissioned Corps officers serve 21 federal agencies, demonstrating the important strategic role all agencies have in responsible AI adoption to support public health. • STLTs: STLTs and freely associated state health departments are the backbone of the public health ecosystem and are key partners to HHS in public health work. STLTs are responsible for the health and wellness of their communities and critically manage datasets t hat are shared with federal health agencies and support prevention and interventions within their communities (e.g., vaccine distribution) as well as issue guidelines to various local stakeholders and organizations. • Public education and outreach organizations: Communication and public education campaigns are a critical component of the public health value chain, including the promotion of immunization campaigns. There are several entities (e.g., the Medicare PACE program) which represent the Surgeon General and the U.S. Public Health Service Commissioned Corps, whose mission is to perform public health education and outreach, such as promoting immunization campaigns. These organizations may receive federal funding tied directly to specific campaigns, funding from private partners, or funding from healthcare organizatio ns in local areas. Providers, payers, and CBOs also play critical roles."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_512",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nwhich represent the Surgeon General and the U.S. Public Health Service Commissioned Corps, whose mission is to perform public health education and outreach, such as promoting immunization campaigns. These organizations may receive federal funding tied directly to specific campaigns, funding from private partners, or funding from healthcare organizatio ns in local areas. Providers, payers, and CBOs also play critical roles. • Academia and research institutions: Academic and research organizations, including associated hospitals, labs, and research institutions, are key producers of scientific research . They provide training for the next generation of public health staff and serve as a critical hub for innovation across the field, particularly related to AI use cases. • Healthcare systems, providers, and labs: Healthcare systems are critical for the successful delivery of ongoing and emergency public health programs, and serve as producers of data through health registries, surveillance systems, and research databases, which inform policy. • Pharmaceutical, biotechnology, and medical device industry: Private life sciences organizations support public health efforts through the provision and distribution of drugs , biological products, and medical devices at scale. They also include researchers and subject matter experts involved in medical research and discovery and are major source s of AI innovation."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_513",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsurveillance systems, and research databases, which inform policy. • Pharmaceutical, biotechnology, and medical device industry: Private life sciences organizations support public health efforts through the provision and distribution of drugs , biological products, and medical devices at scale. They also include researchers and subject matter experts involved in medical research and discovery and are major source s of AI innovation. • Global partners: Global partners, including multilateral organizations, bilateral organizations, NGOs, foreign governments, and others collaborate with U.S. public health agencies to address health challenges that transcend borders. Their collective actions help facilitate the sharing of knowledge and data, support the early mitigation of infectious diseases, prevent public health emergencies, support capacity building in healthcare systems, and help ensure equitabl e access to healthcare services and interventions across regions. • Non-profit and CBOs: National public health collaborative organizations, whose membership typically consist s of people and entities dedicated to a particular public health function (e.g., epidemiologists) or purpose (e.g., strengthening public health laboratories) play an important role as partners, conduits, and implementation intermediaries to federal and STLT public health agencies."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_514",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ne access to healthcare services and interventions across regions. • Non-profit and CBOs: National public health collaborative organizations, whose membership typically consist s of people and entities dedicated to a particular public health function (e.g., epidemiologists) or purpose (e.g., strengthening public health laboratories) play an important role as partners, conduits, and implementation intermediaries to federal and STLT public health agencies. Additionally, NGOs embedde d 138 in communities support the delivery of health and wellness services to ensure that public health programs reach vulnerable populations effectively. • Foundations and private funders: Foundations may support public health by providing funding for clinical trials and research in areas such as SDOH , or direct ly deliver ing public health services. Additionally, other funders may invest in organizations , such as technology companies, in the value chain. • Technology companies: These include companies focused on AI infrastructure (e.g., cloud storage), large, diversified tech companies, vendors of digital solutions, and white hat hackers. These companies provide the infrastructure and services for stakeholders to adopt AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_515",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndirect ly deliver ing public health services. Additionally, other funders may invest in organizations , such as technology companies, in the value chain. • Technology companies: These include companies focused on AI infrastructure (e.g., cloud storage), large, diversified tech companies, vendors of digital solutions, and white hat hackers. These companies provide the infrastructure and services for stakeholders to adopt AI. Several HHS divisions (e.g., ASTP, OGA, NIH, and others) advance global health AI efforts through bilateral and multilateral collaboration, conferences, and multi -national organizations, such as the Global Digital Health Partnership, a collaboration betwee n WHO and country governments to support the executive implementation of worldwide digital health services. Additionally subject matter experts from across the Department act as delegates to provide policy input and feedback to multinational organizations such as the Group of Seven (G7), Group of Twenty (G20), and the Organi sation for Economic Co -operation and Development (OECD). The data value chain The stakeholders above play many pivotal roles in public health, including data collection. As discussed earlier, without high -quality data, proper data collection, and standardization, the ability of AI to drive insights may be limited."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_516",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nas the Group of Seven (G7), Group of Twenty (G20), and the Organi sation for Economic Co -operation and Development (OECD). The data value chain The stakeholders above play many pivotal roles in public health, including data collection. As discussed earlier, without high -quality data, proper data collection, and standardization, the ability of AI to drive insights may be limited. The section s below outline the data value chain in public health, existing data improvement efforts from the CDC, and additional actions to strengthen the public health data ecosystem. As a central player across the public health data flow (Exhibit 1 3), the CDC has already begun making significant headway through its Data Modernization Initiative ( DMI ), an effort focused on improving the accessibility, timeliness, and comprehensiveness of data for day -to-day public health responses. The DMI seeks to address public health functions like improved data-sharing speed (e.g., through language and terms for data protection and use), increased ability for STLTs to exchange data with CDC (e.g., th rough automatic pipelines), and enabling near-real-time public reporting of diseases (e.g., through a centralized data dissemination platform). Many of these investments to create a unified approach to data management at all levels of public health can lay the foundation to support additional AI use c ases."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_517",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nprotection and use), increased ability for STLTs to exchange data with CDC (e.g., th rough automatic pipelines), and enabling near-real-time public reporting of diseases (e.g., through a centralized data dissemination platform). Many of these investments to create a unified approach to data management at all levels of public health can lay the foundation to support additional AI use c ases. Exhibit 13: CDC DMI data flow662 662 https://www.cdc.gov/ophdst/public -health -data-strategy/public_health_data_strategy -final-p.pdf 139 Notable recent DMI accomplishments include: • Connecting public health and healthcare systems by aligning current data infrastructure with requirements to exchange information through TEFCA ™, supporting adoption of interoperability standards like the USCDI and the USDCI+ initiative, and using intermediaries to reduce point -to-point connections (Exhibit 1 3). For example, in 2023, CDC helped connect 90% of Epidemiology and Laboratory Capacity recipients to the Association of Public Health Laboratories Informatics Services, ReportStream, or health informa tion exchanges for lab data.663 • Automating and improving data access by supporting the implementation of automated bidirectional electronic reporting feeds like electronic case reporting (eCR), electronic laboratory reporting, and admission -discharge -transfer feeds to reduce manual reporting."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_518",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nhelped connect 90% of Epidemiology and Laboratory Capacity recipients to the Association of Public Health Laboratories Informatics Services, ReportStream, or health informa tion exchanges for lab data.663 • Automating and improving data access by supporting the implementation of automated bidirectional electronic reporting feeds like electronic case reporting (eCR), electronic laboratory reporting, and admission -discharge -transfer feeds to reduce manual reporting. In 2023, the CDC helped 34 jurisdictions implement eCR data to improve case monitoring.664 • Streamlining data collection and processing to help ensure data is collected once and reused across public health entities, reducing duplication and improving integration. CDC is migrating toward an integrated cloud -computing data platform665 and using AI use cases for key data systems (e.g., modernizing the National Vital Statistics System to automatically code multiple causes of death).666 • Implementing a core data use agreement (DUA) to unify and enhance data exchanges nationally across jurisdictions.667 Continuing these efforts , with additional integration across public health, healthc are (particularly primary care), and community organizations , could further build resilience and improve healthcare services in both emergency response and everyday contexts (e.g., through automated data exchange across healthcare system EHRs and local demographic data from CBOs)."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_519",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nagreement (DUA) to unify and enhance data exchanges nationally across jurisdictions.667 Continuing these efforts , with additional integration across public health, healthc are (particularly primary care), and community organizations , could further build resilience and improve healthcare services in both emergency response and everyday contexts (e.g., through automated data exchange across healthcare system EHRs and local demographic data from CBOs). There is a bold opportunity to build on CDC ’s and others’ efforts to further integrate data, which could both be supported by AI and enable AI use to advance public health priorities. 5.3 Opportunities for the Application of AI in Public Health As AI technologies become more widespread, HHS will work to ensure AI is integrated within public health organizations and missions in an ethical, dependable, and equitable manner by public health partners. There are multiple opportunity areas where AI can support public health priorities and infrastructure: 1. Improving threat detection, data -driven decision -making , and the effectiveness of interventions: There is an opportunity to use AI in aggregating and analyzing larger, more complex, or unstructured health datasets, including healthcare delivery data (e.g., claims or EHR data) —in addition to non -health datasets (e.g., migration patterns and climate) —that could support more timely and effective interventions."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_520",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n1. Improving threat detection, data -driven decision -making , and the effectiveness of interventions: There is an opportunity to use AI in aggregating and analyzing larger, more complex, or unstructured health datasets, including healthcare delivery data (e.g., claims or EHR data) —in addition to non -health datasets (e.g., migration patterns and climate) —that could support more timely and effective interventions. One example of this is the integration of secondary data into surveillance systems to better predict and respond to emerging public health threats.668 Another example of this is integrating SDOH and other datasets to better understand underlying risk factors and disease processes for non -communicable diseases, such as diabetes and cardiovascular diseases, to inform effective intervention design. Lastly, a broader application (e.g., data exploration) could be used to accelerate guideline development by supporting the initial synthesis of research across disease areas, provided there is appropriate human oversight and transparency."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_521",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nSDOH and other datasets to better understand underlying risk factors and disease processes for non -communicable diseases, such as diabetes and cardiovascular diseases, to inform effective intervention design. Lastly, a broader application (e.g., data exploration) could be used to accelerate guideline development by supporting the initial synthesis of research across disease areas, provided there is appropriate human oversight and transparency. While these 663 https://www.cdc.gov/public -health -data-strategy/php/about/phds -progress -in-2023.html 664 https://www.cdc.gov/public -health -data-strategy/php/about/phds -progress -in-2023.html 665 https://www.cdc.gov/data -modernization/php/technologies/edav.html 666 https://www.cdc.gov/surveillance/data -modernization/technologies/ai -ml.html 667 https://www.cdc.gov/data -interoperability/php/use -agreement/index.html 668 https://www.ncbi.nlm.nih.gov/books/NBK11770/ . As defined by the authors of this book, “Public health surveillance is the ongoing systematic collection, analysis, and interpretation of data, closely integrated with the timely dissemination of these data to those responsible for preventin g and control ling disease and injury” and does not constitute any other forms of surveillance. 140 are just examples, the deployment of AI in public health requires the development and adoption of guidelines to address the associated ethical and safety implications.669 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_522",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ninterpretation of data, closely integrated with the timely dissemination of these data to those responsible for preventin g and control ling disease and injury” and does not constitute any other forms of surveillance. 140 are just examples, the deployment of AI in public health requires the development and adoption of guidelines to address the associated ethical and safety implications.669 2. Optimizing the allocation of limited resources, especially during public health emergencies: Resourcing has long been a challenge for the U.S. public health system, where funding may be siloed and sometimes inconsistent.670 To best prioritize efforts that maximize health outcomes and equity, AI can be used to identify high -risk areas where existing interventions can have the most impact —ensuring the right resources reach the right communities at the right time."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_523",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nemergencies: Resourcing has long been a challenge for the U.S. public health system, where funding may be siloed and sometimes inconsistent.670 To best prioritize efforts that maximize health outcomes and equity, AI can be used to identify high -risk areas where existing interventions can have the most impact —ensuring the right resources reach the right communities at the right time. During the CO VID-19 pandemic, many countries, including the U .S., prioritized vaccine distribution to high -risk populations like frontline workers and the elderly, an effort that was supported, in some cases, by predictive analytics.671 Emergency response can be further enabled through AI in various ways, such as predictive modeling of supply chains and mapping of vaccine acceptability.672, 673 Recently, CDC has been using AI to help inform interventions and accelerate response s to outbreaks.674 AI can support resource optimization, both during public health emergencies and in ongoing programs addressing other areas, such as non -communicable diseases. 3."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_524",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nbe further enabled through AI in various ways, such as predictive modeling of supply chains and mapping of vaccine acceptability.672, 673 Recently, CDC has been using AI to help inform interventions and accelerate response s to outbreaks.674 AI can support resource optimization, both during public health emergencies and in ongoing programs addressing other areas, such as non -communicable diseases. 3. Improving efficiency of public health operations and supporting public health workers to better serve their communities: Responsible, safe, and strategic adoption of AI across the public health ecosystem could greatly reduce the operational burden on a healthcare system and public health authorities that are challenged by burnout and excessive workload (e.g., in 2022, 46% o f health workers reported feeling burned out often or very often).675 For example, AI can be leveraged to automate processes related to grant writing and review to reduce costs or time -consuming activities like data entry and compliance reporting, provided there is sufficient human oversight. The a dministrative burden in public benefits programs is estimated to range from 15% to 30% of total healthcare spending, half of which includes routine or repetitive tasks that could be automated.676 Current AI tools are not always fit for purpose for these specific tasks and will require additional development to ensure they balance eff ectiveness with safety and accuracy."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_525",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nThe a dministrative burden in public benefits programs is estimated to range from 15% to 30% of total healthcare spending, half of which includes routine or repetitive tasks that could be automated.676 Current AI tools are not always fit for purpose for these specific tasks and will require additional development to ensure they balance eff ectiveness with safety and accuracy. Additionally, in order to use these tools, public health professionals will need upskilling and training opportunities on the safe and effective use of AI. 4. Enhanc ing health equity and access to care for underserved populations : AI applications, GenAI in particular, offer unique potential to transform the way public health decisions and programs are implemented, particularly for traditionally underserved populations, provided potential biases are adequately prevented."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_526",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npublic health professionals will need upskilling and training opportunities on the safe and effective use of AI. 4. Enhanc ing health equity and access to care for underserved populations : AI applications, GenAI in particular, offer unique potential to transform the way public health decisions and programs are implemented, particularly for traditionally underserved populations, provided potential biases are adequately prevented. AI can advan ce health equity and improve access to care through the elimination of human bias in decision -making, more targeted outreach (e.g., identification and outreach to high -risk, high -need populations), and evidence -based personalized messaging (e.g., based on language needs, health literacy, and local community context) that can increase public awareness and acceptance of public health guidelines and programs.677, 678 For example, the CDC launched the Coronavirus Self -Checker Chatbot in 2020 to help individuals decide whether to seek care or manage their symptoms at home.679 Additionally, through automatic capabilities like translation, transcription, and personalization, AI can rapidly generate content that meets the health literacy, language, and local contexts of diverse populations. AI could also be used to support traini ng and guidelines that support the public health workforce or service recipients."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_527",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto help individuals decide whether to seek care or manage their symptoms at home.679 Additionally, through automatic capabilities like translation, transcription, and personalization, AI can rapidly generate content that meets the health literacy, language, and local contexts of diverse populations. AI could also be used to support traini ng and guidelines that support the public health workforce or service recipients. 669 http:/dx.doi.org/10.5888/pcd21.240245 670 https://www.milbank.org/quarterly/articles/covid -19-and-underinvestment -in-the-public -health -infrastructure -of-the-united -states/ . Maani, et al. “COVID -19 and Underinvestment in the Public Health Infrastructure of the United States,” Milbank Quarterly (May 2020) 671 https://pmc.ncbi.nlm.nih.gov/articles/PMC8036633/ . Jain et al., “A Rapid Review of COVID -19 Vaccine Prioritization in the US: Alignment between Federal Guidance and State Practice,” International Journal of Environmental Research and Public Health,” (March 2021) 672 https://www.sciencedirect.com/science/article/abs/pii/S0141813024074518 673 https://www.nature.com/articles/s41598 -024-76891 -z 674 https://www.cdc.gov/surveillance/data -modernization/technologies/ai -ml.html 675 https://www.cdc.gov/vitalsigns/health -worker -mental -health/index.html 676 https://academic.oup.com/healthaffairsscholar/article/2/2/qxae008/7591560 677 Fisher, S., Rosella, L.C."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_528",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nMilbank Quarterly (May 2020) 671 https://pmc.ncbi.nlm.nih.gov/articles/PMC8036633/ . Jain et al., “A Rapid Review of COVID -19 Vaccine Prioritization in the US: Alignment between Federal Guidance and State Practice,” International Journal of Environmental Research and Public Health,” (March 2021) 672 https://www.sciencedirect.com/science/article/abs/pii/S0141813024074518 673 https://www.nature.com/articles/s41598 -024-76891 -z 674 https://www.cdc.gov/surveillance/data -modernization/technologies/ai -ml.html 675 https://www.cdc.gov/vitalsigns/health -worker -mental -health/index.html 676 https://academic.oup.com/healthaffairsscholar/article/2/2/qxae008/7591560 677 Fisher, S., Rosella, L.C. Priorities for successful use of artificial intelligence by public health organizations: a literature review. BMC Public Health 22, 2146 (2022). https://doi.org/10.1186/s12889 -022-14422 -z 678 Chen , Y., Clayton , E. W., Novak , L. L., Anders , S., Malin , B. Human -Centered Design to Address Biases in Artificial Intelligence. J Med Internet Res 25, 43251 (2023). https://doi.org/ 10.2196/43251 679 https://time.com/5807914/cdc -bot-coronavirus/ 141 5.4 Trends in AI in Public Health Technological and scientific advancements have accelerated public health improvements throughout history, a phenomenon that was brought to the global forefront most recently with the COVID -19 pandemic."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_529",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nS., Malin , B. Human -Centered Design to Address Biases in Artificial Intelligence. J Med Internet Res 25, 43251 (2023). https://doi.org/ 10.2196/43251 679 https://time.com/5807914/cdc -bot-coronavirus/ 141 5.4 Trends in AI in Public Health Technological and scientific advancements have accelerated public health improvements throughout history, a phenomenon that was brought to the global forefront most recently with the COVID -19 pandemic. The global public health ecosystem delivered a safe an d effective COVID -19 vaccine and achieved greater than 70% coverage worldwide by August 2024.680, 681 Despite this success, the pandemic brought to light the multiple challenges (e.g., outdated systems and limited resources) and opportunities for innovation in the U .S. public health system. AI technologies show promise for mitigating future public health crises and strengthening the public health system. Notabl e emerging trends include, non -exhaustively: 1. Enthusiasm and concerns accompany AI adoption in public health: There is growing excitement about using AI in healthcare and public health, but there are also concerns among the American public and health officials about its potential impacts."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_530",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ntechnologies show promise for mitigating future public health crises and strengthening the public health system. Notabl e emerging trends include, non -exhaustively: 1. Enthusiasm and concerns accompany AI adoption in public health: There is growing excitement about using AI in healthcare and public health, but there are also concerns among the American public and health officials about its potential impacts. Some public health stakeholders are rapidly adopting AI and referencing it frequently, and are excited to continue provided that concerns with respect to equity and ethics are addressed .682 For instance, as early as February 2022, there were already more than 4,500 scientific papers referenced the use of AI and ML in response to the pandemic, including 239 on surveillance and 219 on forecasting.683 In contrast, over half of adults in a recent nationwide survey were unsure of the impact of AI on those seeking health information online, and another 23% felt AI was doing more harm than good.684 Both AI excitement and concerns will need to be addressed in the future. 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_531",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto the pandemic, including 239 on surveillance and 219 on forecasting.683 In contrast, over half of adults in a recent nationwide survey were unsure of the impact of AI on those seeking health information online, and another 23% felt AI was doing more harm than good.684 Both AI excitement and concerns will need to be addressed in the future. 2. Predictive analytics are enabling early disease detection and can accelerate public health response s: The nowcasting and forecasting capabilities of AI are revolutionizing epidemiology by providing real -time surveillance and predictive modeling that inform proactive public health responses .685 AI extends the library of diverse data types that can be used to predict and track public health threats.686 Potential examples include image recognition to aid in the early detection of diseases from medical scans, audio analysis for monitoring mental health through voice patterns ,687 and NLP insights from textual health records and social media to track disease spread and public sentiment. There has been strong momentum in the use of AI in these areas. 3. Implementation of AI in public health is often limited due to resource constraints, infrastructure deficiencies, lack of technological knowledge, and data paucity: Limited resources in traditionally underserved populations and more fragile environments can contribute to data paucity and difficulty establishing the necessary technical infrastructure that AI relies on."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_532",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nbeen strong momentum in the use of AI in these areas. 3. Implementation of AI in public health is often limited due to resource constraints, infrastructure deficiencies, lack of technological knowledge, and data paucity: Limited resources in traditionally underserved populations and more fragile environments can contribute to data paucity and difficulty establishing the necessary technical infrastructure that AI relies on. Outdated data infrastructure may also limit the a bility to use AI, although initiatives like CDC’s DMI and grants to STLTs are helping improve core infrastructure.688 In addition, public health entities often face challenges attracting, retaining, and training high -quality technical talent ; this challenge was exacerbated by the COVID -19 pandemic.689 4. Adoption and use of AI in public health is inconsistent: Public sector domains, including public health, have unevenly leveraged AI and have varying levels of AI awareness and expertise.690 Much of this is driven by the availability of high -quality data, differing domain needs, planned and ongoing collaboration efforts, and the availability of modernized data platforms and funding. As discussed above, the diverse potential of AI merits great er investment in widespread implementation. 680 Vaccine coverage defined as the share of the population that received at least 1 dose of the COVID -19 vaccine . 681 https://ourworldindata.org/covid -vaccinations . Accessed December 2024."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_533",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndomain needs, planned and ongoing collaboration efforts, and the availability of modernized data platforms and funding. As discussed above, the diverse potential of AI merits great er investment in widespread implementation. 680 Vaccine coverage defined as the share of the population that received at least 1 dose of the COVID -19 vaccine . 681 https://ourworldindata.org/covid -vaccinations . Accessed December 2024. 682 https://www.healthaffairs.org/doi/10.1377/hlthaff.2024.00050 683 https://blogs.cdc.gov/genomics/2022/03/01/artificial -intelligence -2/ 684 https://www.kff.org/health -misinformation -and-trust/poll -finding/kff -health -misinformation -tracking -poll-artificial -intelligence -and-health -information/ 685 https://blogs.cdc.gov/genomics/2022/03/01/artificial -intelligence -2/ 686 https://www.cdc.gov/surveillance/data -modernization/technologies/ai -ml.html 687 https://pmc.ncbi.nlm.nih.gov/articles/PMC11179519/ 688 https://www.cdc.gov/surveillance/surveillance -data-strategies/dmi -investments.html 689 https://www.healthaffairs.org/doi/full/10.1377/hlthaff.2024.00020 690 https://www.tandfonline.com/doi/full/10.1080/14719037.2023.2231950 142 5.5 Potential Use Cases and Risks for AI in Public Healt h The below value chain , while non -exhaustive, highlights core public health operations and program areas, with a particular emphasis on preparedness and response during acute public health emergencies."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_534",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n685 https://blogs.cdc.gov/genomics/2022/03/01/artificial -intelligence -2/ 686 https://www.cdc.gov/surveillance/data -modernization/technologies/ai -ml.html 687 https://pmc.ncbi.nlm.nih.gov/articles/PMC11179519/ 688 https://www.cdc.gov/surveillance/surveillance -data-strategies/dmi -investments.html 689 https://www.healthaffairs.org/doi/full/10.1377/hlthaff.2024.00020 690 https://www.tandfonline.com/doi/full/10.1080/14719037.2023.2231950 142 5.5 Potential Use Cases and Risks for AI in Public Healt h The below value chain , while non -exhaustive, highlights core public health operations and program areas, with a particular emphasis on preparedness and response during acute public health emergencies. For further details on related topics, in particular refer to the following chapters: Medical Research and Discovery and Medical Product Development, Safety, and Effectiveness for the product development life cycle , which public health informs; Healthcare Delivery for the delivery of healthcare, which is inext ricably linked to public health; and Human Services for the delivery of programs that often address SDOH. This framewor k is an illustra tive representation of the diversity of public health AI applications and should be adapted to the specific contexts that organizations operate in , including areas such as infectious disease contr ol, chronic disease prevention an d management , and more."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_535",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npublic health; and Human Services for the delivery of programs that often address SDOH. This framewor k is an illustra tive representation of the diversity of public health AI applications and should be adapted to the specific contexts that organizations operate in , including areas such as infectious disease contr ol, chronic disease prevention an d management , and more. Exhibit 14: Public Health Value Chain Every step in the public health value chain represents opportunities for AI to improve the work of public health in the form of increased efficiency, greater analytical power and complexity, improved healthcare and information access, and broader awareness of public health priorities. At the same time, AI is accompanied by risks, many of which are found across multiple use cases. In public health applications, some common risks include bias (intentional or unintentional discrimination of certain groups due to flaws or underrepresentatio n in training data),691 confabulation (fabrication of sources or information),692 poor interpretability (difficulty explaining AI results due to large datasets and multiple parameters), parasocial relationships (user interpretation of socialization due to “lifelike” interactions with AI models), 693 and unauthorized disclosure of confidential information. Additionally, without comprehensive guardrails, AI may be adopted over traditional techniques for cost savings, even if AI is less effective."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_536",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndata),691 confabulation (fabrication of sources or information),692 poor interpretability (difficulty explaining AI results due to large datasets and multiple parameters), parasocial relationships (user interpretation of socialization due to “lifelike” interactions with AI models), 693 and unauthorized disclosure of confidential information. Additionally, without comprehensive guardrails, AI may be adopted over traditional techniques for cost savings, even if AI is less effective. 691 https://www.cdc.gov/pcd/issues/2024/24_0245.htm 692 https://www.cnn.com/2023/08/29/tech/ai -chatbot -hallucinations/index.html 693 https://www.cambridge.org/core/journals/behavioral -and-brain -sciences/article/how -deep -is-ais-love-understanding -relational - ai/77364078496FCE70F71C7A9F293AC322 Gillath, O., Abumusab, S., Ai, T., et al. How deep is AI’s love? Understanding relational AI. Behavioral and Brain Sciences ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_537",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndisclosure of confidential information. Additionally, without comprehensive guardrails, AI may be adopted over traditional techniques for cost savings, even if AI is less effective. 691 https://www.cdc.gov/pcd/issues/2024/24_0245.htm 692 https://www.cnn.com/2023/08/29/tech/ai -chatbot -hallucinations/index.html 693 https://www.cambridge.org/core/journals/behavioral -and-brain -sciences/article/how -deep -is-ais-love-understanding -relational - ai/77364078496FCE70F71C7A9F293AC322 Gillath, O., Abumusab, S., Ai, T., et al. How deep is AI’s love? Understanding relational AI. Behavioral and Brain Sciences . 2023 143 An AI risk that is particularly challenging for public health is misinformation and disinformation; as the COVID - 19 pandemic showed, “information that is false, inaccurate, or misleading according to the best available evidence at the time ” is now able to spread at never -before -seen speed and scale (e.g., through social media and search engines) and can lead to serious public health consequences like harassment and violence against health workers, insufficient adherence to quarantine guideli nes, and the promotion of unproven medical treatments.694 In addition, given that GenAI is built on neural networks with multitudes of parameters, it is difficult to explain how insights and recommendations are generated —sometimes referred to as the “black box problem.” 695 Combined with the potential for false responses and simulated deepfakes (realistic -looking fake images, audio, or video), AI may impact national trust and ultimately reduce the eff ectiveness of public health programs."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_538",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nbuilt on neural networks with multitudes of parameters, it is difficult to explain how insights and recommendations are generated —sometimes referred to as the “black box problem.” 695 Combined with the potential for false responses and simulated deepfakes (realistic -looking fake images, audio, or video), AI may impact national trust and ultimately reduce the eff ectiveness of public health programs. Some of the risks are further considered below; HHS will continue to support mitigation against these risks, in alignment with the action plan discussed later in this document. In the tables below, HHS highlights a non -exhaustive list of potential benefits and risks of AI across the public health value chain. Please note that the use cases detailed below highlight existing or potential ways that AI can be used by a variety of stakeholders in this domain."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_539",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nin alignment with the action plan discussed later in this document. In the tables below, HHS highlights a non -exhaustive list of potential benefits and risks of AI across the public health value chain. Please note that the use cases detailed below highlight existing or potential ways that AI can be used by a variety of stakeholders in this domain. For details on how HHS and its divisions are using AI, please referenc e the HHS AI Use Case Inventory 2024.696 Functional component 1: Public health research to inform decisions and programming Research and analytics efforts to understand and improve the health of populations and inform future programs and decisions Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Deriving novel insights through rapid analysis of large, complex, and often unstructured datasets to inform programming AI can enable greater data capture and analysis of previously unused or underutilized data beyond traditional tabular and numeric formats (e.g., audio files and images) to inform more effective interventions ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_540",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand inform future programs and decisions Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Deriving novel insights through rapid analysis of large, complex, and often unstructured datasets to inform programming AI can enable greater data capture and analysis of previously unused or underutilized data beyond traditional tabular and numeric formats (e.g., audio files and images) to inform more effective interventions . E.g., NLP of health records AI algorithms can extract clinical insights from unstructured EHRs and conduct prediction and classification tasks that would be challenging to do using traditional methods; this can inform public health interventions and population studies .697 Potential to introduce bias and discrimination E.g., exclusion of underrepresented groups AI is often trained on historical data, which often focuses on specific demographic groups more than others, leading to misrepresentative findings that do not apply equally across groups and perpetuation of existing biases .698, 699 694 https://www.hhs.gov/surgeongeneral/priorities/health -misinformation/index.html 695 https://doi.org/10.1016/S2589 -7500(21)00208 -9 696 https://www.healthit.gov/hhs -ai-usecases 697 https://pubmed.ncbi.nlm.nih.gov/36805219/ 698 https://postgraduateeducation.hms.harvard.edu/trends -medicine/confronting -mirror -reflecting -our-biases -through -ai-health -care 699 https://pmc.ncbi.nlm.nih.gov/articles/PMC6347576/ 144 Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Integrating multiple data types and secondary data in existing public health models to inform research and effective interventions Integrating health datasets (e.g., case data and wastewater data) and non -health data (e.g., migration patterns, travel and sales patterns, and search engine data) can inform forecasting and surveillance of ongoing public health priorities and emerging thr eats."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_541",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n(non-exhaustive) Potential risks (non-exhaustive) Integrating multiple data types and secondary data in existing public health models to inform research and effective interventions Integrating health datasets (e.g., case data and wastewater data) and non -health data (e.g., migration patterns, travel and sales patterns, and search engine data) can inform forecasting and surveillance of ongoing public health priorities and emerging thr eats. E.g., integration of non -health and individual healthcare data with public health data in non -communicable disease and other disease contexts AI can help generate interpretable insights on how previously unaccounted -for factors (e.g., SDOH, environmental and digital) influence disease risk and analyses that can be further improved by the integration of existing healthcare (e.g., claims data) and public health datasets (e.g., epidemiological data) . Potential to reduce validity or interpretability E.g., unclear conclusions due to multifactorial data Large datasets that include multiple variables may inaccurately find associations where no true connection exists . Potential to overuse synthetic data E.g., degradation of model integrity and diverse representation as synthetic data is iterated on Using synthetic data, even with positive intent to increase diversity, can erode model quality as it is analyzed, re - analyzed to produce additional synthetic data, and so on."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_542",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nmultiple variables may inaccurately find associations where no true connection exists . Potential to overuse synthetic data E.g., degradation of model integrity and diverse representation as synthetic data is iterated on Using synthetic data, even with positive intent to increase diversity, can erode model quality as it is analyzed, re - analyzed to produce additional synthetic data, and so on. This could jeopardize the accuracy and validity of results and ultimately not ach ieve the potential goals of representing diverse populations and/or reducing bias . Using synthetic data and data linkage techniques to advance research and preserve privacy Synthetic data, which is artificially generated to mimic patient or population data without containing any actual personal information, allows researchers to conduct studies and test algorithms without the risk of exposing personally identifiable information (PII) or PHI. PPRL techniques further enhance this capability as it allows f or the matching of records corresponding to the same entity across different databases ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_543",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndata, which is artificially generated to mimic patient or population data without containing any actual personal information, allows researchers to conduct studies and test algorithms without the risk of exposing personally identifiable information (PII) or PHI. PPRL techniques further enhance this capability as it allows f or the matching of records corresponding to the same entity across different databases . E.g., digital twins and scenario modeling Virtual replicas of physical systems or processes, like personalized patient models, can be used to simulate different scenarios (e.g., public health scenario modeling and clinical trials) to optimize public health interventions or treatment plans and improve outcomes .700 Functional component 2: Detection, epidemiology, and surveillance Data and models used to analyze disease trends, identify outbreaks, and study the distribution and determinants of health events in populations For more information see the Healthcare Delivery and Medical Product Development, Safety, and Effectiveness chapters Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Leveraging AI -powered infectious disease surveillance and prediction AI models can be leveraged to process high volumes of health and secondary non-health datasets to signal potential hotspots or outbreaks as well as monitor ongoing disease spread and changes ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_544",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nmore information see the Healthcare Delivery and Medical Product Development, Safety, and Effectiveness chapters Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Leveraging AI -powered infectious disease surveillance and prediction AI models can be leveraged to process high volumes of health and secondary non-health datasets to signal potential hotspots or outbreaks as well as monitor ongoing disease spread and changes . E.g., AI-enabled syndromic surveillance In parallel with traditional statistical approaches, AI methods can be used to analyze data to detect emerging health threats .701 Potential to reduce interpretability E.g., false identification of disease trends AI models that are overly sensitive to small disturbances may falsely report variations as public health events, 700 https://www.nature.com/articles/s41746 -023-00927 -3 701 https://pmc.ncbi.nlm.nih.gov/articles/PMC7484813/ 145 Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Developing intelligent disease diagnostic tools to improve clinical decision - making AI and ML algorithms can be harnessed to improve clinical decision -making and diagnostics from imaging systems to advance detection of non- communicable diseases and ongoing public health priorities (e.g., AI -powered detection of cardiac heart failure) ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_545",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-3 701 https://pmc.ncbi.nlm.nih.gov/articles/PMC7484813/ 145 Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Developing intelligent disease diagnostic tools to improve clinical decision - making AI and ML algorithms can be harnessed to improve clinical decision -making and diagnostics from imaging systems to advance detection of non- communicable diseases and ongoing public health priorities (e.g., AI -powered detection of cardiac heart failure) . E.g., AI -powered image processing and diagnostics AI can be used to accurately analyze images (e.g., mammograms) and diagnose diseases to support clinical decision -making or accelerate public health screening campaign .702, 703 inappropriately directing public health efforts . Potential to disclose confidential information E.g., unauthorized disclosure of PHI Detection algorithms with access to PHI may inadvertently reveal PHI or other identifying information in outputs or be subject to cybersecurity threats . Advancing precision public health to optimize resources Integrating precision medicine (e.g., genomics and metabolomics) with population -based strategies can help provide “the right intervention to the right population at the right time .”704 E.g., identification of high -risk geographies or populations Precision public health can identify vulnerable communities, enabling public health entities to take proactive action ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_546",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncybersecurity threats . Advancing precision public health to optimize resources Integrating precision medicine (e.g., genomics and metabolomics) with population -based strategies can help provide “the right intervention to the right population at the right time .”704 E.g., identification of high -risk geographies or populations Precision public health can identify vulnerable communities, enabling public health entities to take proactive action . 702 https://www.thelancet.com/journals/landig/article/PIIS2589 -7500(20)30160 -6/fulltext 703 https://www.ahajournals.org/doi/10.1161/CIRCULATIONAHA.122.060137 704 https://www.ajpmonline.org/article/S0749 -3797(15)00522 -X/abstract 146 Functional component 3: Public health program design and guideline development The creation of strategies and interventions to improve population health outcomes and prevent disease and persistent health issues (e.g., cancer and diabetes)."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_547",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npopulations Precision public health can identify vulnerable communities, enabling public health entities to take proactive action . 702 https://www.thelancet.com/journals/landig/article/PIIS2589 -7500(20)30160 -6/fulltext 703 https://www.ahajournals.org/doi/10.1161/CIRCULATIONAHA.122.060137 704 https://www.ajpmonline.org/article/S0749 -3797(15)00522 -X/abstract 146 Functional component 3: Public health program design and guideline development The creation of strategies and interventions to improve population health outcomes and prevent disease and persistent health issues (e.g., cancer and diabetes). Also includes the development of public health guidelines (e.g., vaccine recommendations and po stmarket monitoring of medical products) Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Designing hyper -local public health programming to optimize resources AI can be leveraged to aggregate and analyze local health data to better understand targeted needs (e.g., prevalence of disease by neighborhood), risks (e.g., environmental and socioeconomic factors), and/or infrastructure capacity (e.g., healthcare worker availability, access to PPE, access to testing and access to nutrition) to create targeted programs that optimize resource usage ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_548",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npublic health programming to optimize resources AI can be leveraged to aggregate and analyze local health data to better understand targeted needs (e.g., prevalence of disease by neighborhood), risks (e.g., environmental and socioeconomic factors), and/or infrastructure capacity (e.g., healthcare worker availability, access to PPE, access to testing and access to nutrition) to create targeted programs that optimize resource usage . E.g., crowd -sourced air quality analytics and advocacy Using AI to integrate community input and various data sources (e.g., civilian reports and photographs and emission data) enables research that not only advances science but also drives social change (e.g., identification of practical actions with immediate effects based on dat a on local pollution patterns and their health effects) .705 Potential to divulge confidential information E.g., unauthorized disclosure of PHI Algorithms with access to PHI may inadvertently reveal PHI or other identifying information in outputs or be subject to cybersecurity threats . Potential to design impractical interventions E.g., increasingly narrow design not applicable to broad populations AI models focusing on population subset analysis may narrow program design leading to the creation of highly specific interventions that cannot be scaled across communities, an impractical outcome in public health where issues are widespread ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_549",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ninformation in outputs or be subject to cybersecurity threats . Potential to design impractical interventions E.g., increasingly narrow design not applicable to broad populations AI models focusing on population subset analysis may narrow program design leading to the creation of highly specific interventions that cannot be scaled across communities, an impractical outcome in public health where issues are widespread . Automating grant and Request for Proposal (RFP) writing or reviewing processes to improve efficiency Enabled by human oversight and transparency, AI can automate select manual steps in the grant and RFP writing or reviewing processes (e.g., aggregating data, proofreading to ensure accuracy and compliance with submission requirements) enabling substantial efficiencies for government entities and non - profits . E.g., grant writing assistant apps Based on user inputs like length of response, conciseness, and context, grant writing assistants can enable supporting initial drafts with appropriate oversight and transparency . E.g., grant reviewing tools AI tools can rapidly sort through RFP responses or proposals to synthesize key trends or gaps in the applications, supporting the human -led review process ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_550",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nE.g., grant writing assistant apps Based on user inputs like length of response, conciseness, and context, grant writing assistants can enable supporting initial drafts with appropriate oversight and transparency . E.g., grant reviewing tools AI tools can rapidly sort through RFP responses or proposals to synthesize key trends or gaps in the applications, supporting the human -led review process . Potential to misunderstand or mischaracterize grant applications E.g., federal due process concerns Mistakes by AI that violate federal regulations governing grant approval or continuation can lead to due process concerns for grant applicants and concerns about the proper allocation of government resources, potentially leading to litigation. 705 https://airquality.lacity.gov/ 147 Functional component 4: Program delivery Implementation and administration of public health programs Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Personalizing program delivery to enhance access and equity Public -facing AI tools can be used to efficiently dispense personalized health advice or programming across broad populations and diseases ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_551",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nproper allocation of government resources, potentially leading to litigation. 705 https://airquality.lacity.gov/ 147 Functional component 4: Program delivery Implementation and administration of public health programs Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Personalizing program delivery to enhance access and equity Public -facing AI tools can be used to efficiently dispense personalized health advice or programming across broad populations and diseases . E.g., AI chatbots Chatbot apps and interfaces can conduct conversations and generate a wide range of non -scripted, conversational responses based on user text or voice input (e.g., CDC’s COVID -19 chatbot and WHO’s S.A.R.A.H GenAI tool delivers tailored messages on well -being topics like nutrition and stress management based on user video or text inputs) .706 (see Functional component 6: Ongoing public education and community engagement for further details) Potential to confuse users or provide inaccurate recommendations E.g., misidentification of AI as human Users may confuse AI chatbots with human interaction, developing emotional attachments or other parasocial relationships with adverse mental health effects .707 Potential to disenfranchise the workforce E.g., belief that public health staff are being replaced Public health experts may perceive the role of AI in program delivery as replacing their roles ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_552",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ninaccurate recommendations E.g., misidentification of AI as human Users may confuse AI chatbots with human interaction, developing emotional attachments or other parasocial relationships with adverse mental health effects .707 Potential to disenfranchise the workforce E.g., belief that public health staff are being replaced Public health experts may perceive the role of AI in program delivery as replacing their roles . Potential to reduce staff skillset E.g., declining skills for community health workers (CHWs) or others Decreasing interactions between CHWs and the people they serve prevents the close understanding and connection necessary for CHWs to serve as liaisons between health/social services and communities . Improving program delivery speed and reach AI tools can be used to accelerate program delivery through faster performance of manual tasks and broader reach (e.g., virtually instead of in person) . E.g., food product sampling While food sampling for safety and quality is traditionally performed manually, AI can be used to automatically conduct sampling with improved accuracy and repeatability."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_553",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n. Improving program delivery speed and reach AI tools can be used to accelerate program delivery through faster performance of manual tasks and broader reach (e.g., virtually instead of in person) . E.g., food product sampling While food sampling for safety and quality is traditionally performed manually, AI can be used to automatically conduct sampling with improved accuracy and repeatability. This would enable faster detection of potential outbreaks, reducing the spread of disease .708 E.g., supporting public health campaign delivery Using AI to predict areas or populations in need of additional resourcing given changing factors (e.g., rapid processing of healthcare usage, disease prevalence, and resource availability data) to make dynamic changes to resource prioritization and allocation or campaigns .709 706 https://www.who.int/campaigns/s -a-r-a-h 707 https://www.cambridge.org/core/journals/behavioral -and-brain -sciences/article/how -deep -is-ais-love-understanding -relational - ai/77364078496FCE70F71C7A9F293AC322 Gillath, O., Abumusab, S., Ai, T., et al. How deep is AI’s love? Understanding relational AI. Behavioral and Brain Sciences ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_554",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ngiven changing factors (e.g., rapid processing of healthcare usage, disease prevalence, and resource availability data) to make dynamic changes to resource prioritization and allocation or campaigns .709 706 https://www.who.int/campaigns/s -a-r-a-h 707 https://www.cambridge.org/core/journals/behavioral -and-brain -sciences/article/how -deep -is-ais-love-understanding -relational - ai/77364078496FCE70F71C7A9F293AC322 Gillath, O., Abumusab, S., Ai, T., et al. How deep is AI’s love? Understanding relational AI. Behavioral and Brain Sciences . 2023 708 https://www.fda.gov/food/new -era-smarter -food-safety/new -era-smarter -food-safety -blueprint 709 https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2780137 148 Functional component 5: Program monitoring Tracking and assessing the progress, compliance, and effectiveness of public health programs Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Improving detection of data issues and abnormalities to enhance program effectiveness and efficiency AI-based program monitoring can continuously and proactively identify data anomalies or outliers in data that may indicate potential health issues or errors . E.g., detection of data abnormalities AI models can be used to detect unexpected program results, which can facilitate the detection of adverse events (e.g., malfunctioning device) or anomalies (e.g., unusual results , potential fraud ) that merit further investigation or adjustment ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_555",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand proactively identify data anomalies or outliers in data that may indicate potential health issues or errors . E.g., detection of data abnormalities AI models can be used to detect unexpected program results, which can facilitate the detection of adverse events (e.g., malfunctioning device) or anomalies (e.g., unusual results , potential fraud ) that merit further investigation or adjustment . Potential for incomplete or incorre ct analysi s E.g. limited integration of local context or participant feedback AI-driven program analytics might not appropriately consider qualitative participant feedback or contextual factors that influence program performance (e.g., cultural , economic, o r social conditi ons), leading to less effective decision -making . Functional component 6: Ongoing public education and community engagement Two-way, continuous efforts to inform, engage, and collaborate with communities and individuals to improve health education outcomes and program sustainability Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Personalizing public health messaging and education to increase access and improve equity AI can be leveraged to curate messages specifically for different demographics and scale outreach to a broader audience at low cost (e.g., 24/7 availability, automatic content moderation) ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_556",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncollaborate with communities and individuals to improve health education outcomes and program sustainability Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Personalizing public health messaging and education to increase access and improve equity AI can be leveraged to curate messages specifically for different demographics and scale outreach to a broader audience at low cost (e.g., 24/7 availability, automatic content moderation) . E.g., content generation tools AI tools can assist organizations in tasks like drafting email campaigns, creating appealing webpages, and personalizing content that appeals to specific populations .710 Potential to produce inaccurate messaging E.g., delivery of inappropriate messaging to specific populations AI used for content creation may misinterpret audiences and deliver either inappropriate content (e.g., culturally insensitive recommendations) or inappropriate tone (e.g., medical terminology to the general public) . E.g., spread of misinformation and/or disinformation Especially in uncertain or evolving situations, misinformation and/or disinformation can be enabled by AI deepfakes and other false content and spread rapidly over the internet, stoking public uncertainty and mistrust of prevailing public health guidelines ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_557",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\neither inappropriate content (e.g., culturally insensitive recommendations) or inappropriate tone (e.g., medical terminology to the general public) . E.g., spread of misinformation and/or disinformation Especially in uncertain or evolving situations, misinformation and/or disinformation can be enabled by AI deepfakes and other false content and spread rapidly over the internet, stoking public uncertainty and mistrust of prevailing public health guidelines . Fostering inclusive communication to improve access and increase equity AI-based translation technologies can help bridge linguistic and / or cultural gaps, enabling organizations to reach a diverse audience at scale . E.g., real-time translation apps Advanced translation tools can enable live interactions adapted to specific languages, dialects, or jargon, which can help build trust , advance equi ty, and increase engagement .711 710 https://www.cdc.gov/health -communication/media/pdfs/2024/10/AI -for-Good_Listen -Up_S2E5_Transcript.pdf 711 https://pubmed.ncbi.nlm.nih.gov/37904073/ Bakdash, L., Abid, A., Gourisankar, A., Henry, T. L . Chatting Beyond ChatGPT: Advancing Equity Through AI -Driven Language Interpretation."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_558",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nscale . E.g., real-time translation apps Advanced translation tools can enable live interactions adapted to specific languages, dialects, or jargon, which can help build trust , advance equi ty, and increase engagement .711 710 https://www.cdc.gov/health -communication/media/pdfs/2024/10/AI -for-Good_Listen -Up_S2E5_Transcript.pdf 711 https://pubmed.ncbi.nlm.nih.gov/37904073/ Bakdash, L., Abid, A., Gourisankar, A., Henry, T. L . Chatting Beyond ChatGPT: Advancing Equity Through AI -Driven Language Interpretation. J GEN INTERN MED 39, 492 –495 (2024) 149 Functional component 7: Emergency preparedness, response, and medical countermeasure development and deployment Design, coordination, and implementation of strategies and interventions to prevent, detect, and respond to acute health threats Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Supporting public health emergency personnel to increase the efficiency and effectiveness of their response During public health emergency and response situations, AI can be used to reduce the immediate burden faced by staff, increase the efficiency of training and onboarding programs (e.g., tailored healthcare worker programs based on local context), and support rapid response (e.g., resource allocation) .712 E.g., self-learning rescue robots AI-based robotic systems can offer support in disaster prevention and response (e.g., scouting an unknown situation, identifying hazards, and conducting rescue operations in life -hostile environments) ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_559",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nburden faced by staff, increase the efficiency of training and onboarding programs (e.g., tailored healthcare worker programs based on local context), and support rapid response (e.g., resource allocation) .712 E.g., self-learning rescue robots AI-based robotic systems can offer support in disaster prevention and response (e.g., scouting an unknown situation, identifying hazards, and conducting rescue operations in life -hostile environments) . Potential to misdirect staff E.g., inappropriate directions provided to emergency support staff AI tools leveraged in emergency situations may misinterpret emergency hazards (e.g., fires and flooding) and recommend actions with the potential to cause harm if inaccurate or misinterpreted . Disseminating real -time public health guidelines to improve access AI systems can be used to rapidly integrate data sources, generate alerts, and target the distribution of emergency messages . E.g., weather advisory messages SAI models can analyze geographic, weather, and user data to generate relevant and informative alerts (e.g., different winter weather advisories depending on location and whether the user is driving) . Developing medical countermeasures AI has the potential to empower more informed decisions on where investments should be directed (e.g., molecules or vaccine R&D pipeline), along with better monitoring of medical countermeasure effectiveness in real - time."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_560",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand user data to generate relevant and informative alerts (e.g., different winter weather advisories depending on location and whether the user is driving) . Developing medical countermeasures AI has the potential to empower more informed decisions on where investments should be directed (e.g., molecules or vaccine R&D pipeline), along with better monitoring of medical countermeasure effectiveness in real - time. E.g., identification of potential drug targets These target discovery methods can help uncover novel targets and pathways underlying diseases, enabling faster development of interventions .713 Note: Medical countermeasure development is particularly cross -cutting with life sciences and is primarily discussed within the Medical Research and Discovery and Medical Product Development, Safety, and Effectiveness chapters of this Strategic Plan. Potential to misdirect resources E.g., inappropriate identification of drug targets Inaccurate conclusions drawn by AI models (e.g., ineffective drug targets) may falsely build confidence in interventions ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_561",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nNote: Medical countermeasure development is particularly cross -cutting with life sciences and is primarily discussed within the Medical Research and Discovery and Medical Product Development, Safety, and Effectiveness chapters of this Strategic Plan. Potential to misdirect resources E.g., inappropriate identification of drug targets Inaccurate conclusions drawn by AI models (e.g., ineffective drug targets) may falsely build confidence in interventions . 712 https://www.noaa.gov/news -release/biden -harris -administration -invests -250k -to-develop -powerful -artificial -intelligence -tool 713 https://www.fda.gov/media/167973/download 150 Potential use cases (non-exhaustive) Potential risks (non-exhaustive) Evaluating and learning from past emergency response efforts to improve the effectiveness of interventions AI tools can be harnessed to analyze data from past public health responses to identify trends, successes, and opportunities for improvement (e.g., the impact of various state -specific COVID -19 policies to inform future public health decisions) . E.g., AI -enabled after -action reviews An AI -enabled review process can analyze an organization’s response to an emergency or disaster, compare it to a vast library of previous records to identify areas for improvement and develop targeted recommendations and programs (e.g., simulations) ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_562",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe impact of various state -specific COVID -19 policies to inform future public health decisions) . E.g., AI -enabled after -action reviews An AI -enabled review process can analyze an organization’s response to an emergency or disaster, compare it to a vast library of previous records to identify areas for improvement and develop targeted recommendations and programs (e.g., simulations) . Functional component 8: Public health enabler functions (e.g., operations, finance, IT, and data) Infrastructure and administrative processes necessary to support public health service delivery and management Potential benefits and example use cases (non-exhaustive) Potential risks (non-exhaustive) Automating administrative and operational tasks to improve efficiency Like many other organizations, AI offers significant opportunities for public health agencies to achieve operational efficiencies and reduce human errors, particularly in the realm of labor -intensive administrative tasks, when combined with human oversight .714 E.g., data entry Smarter data entry facilitated by AI can help transcribe information from various formats into centralized databases and enhance the overall quality of data with predictive text fields and real -time error -checking algorithms .715 Potential to disenfranchise workforce E.g., belief that administrative and operational staff are being replaced Individuals whose roles involve tasks that can be automated may perceive the role of AI as replacing their positions and responsibilities ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_563",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nfrom various formats into centralized databases and enhance the overall quality of data with predictive text fields and real -time error -checking algorithms .715 Potential to disenfranchise workforce E.g., belief that administrative and operational staff are being replaced Individuals whose roles involve tasks that can be automated may perceive the role of AI as replacing their positions and responsibilities . 5.6 Action Plan In light of the evolving AI landscape in public health , HHS has taken multiple steps to launch ecosystem -wide infrastructure updates and create guidelines that promote responsible AI. The Action Plan below follows the four goals that support HHS’s AI strategy : 1. catalyzing health AI innovation and adoption; 2. promoting trustworthy AI development and ethical and responsible use; 3. democratizing AI technologies and resources; and 4. cultivating AI -empowered workforces and organization cultures. For each goal, the Action Plan provides context, an overview of HHS and relevant other federal actions to date, and specific near - and long -term priorities HHS will take."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_564",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nhealth AI innovation and adoption; 2. promoting trustworthy AI development and ethical and responsible use; 3. democratizing AI technologies and resources; and 4. cultivating AI -empowered workforces and organization cultures. For each goal, the Action Plan provides context, an overview of HHS and relevant other federal actions to date, and specific near - and long -term priorities HHS will take. HHS recognizes that this Action Plan will require revisions over time as technologies evolve and is committed to providing structure and flexibility to ensure longstanding impact 5.6.1 Catalyze Health AI Innovation and Adoption The adoption and implementation of AI have the potential to revolutionize public health and protect the public against emerging and ongoing threats, for example, through enhanced disease forecasting. Unlike healthcare 714 https://www.science.org/doi/10.1126/science.adh2586 715 https://www.healthit.gov/hhs -ai-usecases/ai -assisted -data-entry 151 delivery or R&D, where the private sector is heavily involved in AI innovation and investment, private sector engagement in public health is more limited. Therefore, HHS will play an even more crucial role in allocating resources, aligning incentives, and guiding AI implementation and adoption across the public health ecosystem. As such, HHS can address current challenges and barriers to innovation through: 1."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_565",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nR&D, where the private sector is heavily involved in AI innovation and investment, private sector engagement in public health is more limited. Therefore, HHS will play an even more crucial role in allocating resources, aligning incentives, and guiding AI implementation and adoption across the public health ecosystem. As such, HHS can address current challenges and barriers to innovation through: 1. Encouraging r esearch, development of guidelines, and identification of resources to support evidence generation and scale of AI in public health 2. Modernizing infrastructure necessary to implement AI and support adoption Below, we discuss context, HHS actions to date, and plans to catalyze health AI innovation and adoption. 1. Encouraging r esearch, development of guidelines, and identification of resources to support evidence generation and scale of AI in public health Context: As AI advances, its full impact remains uncertain, highlighting the need for cross -disciplinary research to encourage widespread innovation and adoption with responsible use. As such, targeted research on the potential of AI for impact across core public health objectives (e.g., health equity , patient privacy) and diverse public health domains (e.g., immunization outreach , emerging disease research ) can provide evidence of the effectiveness and cross -domain applicability of AI ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_566",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncross -disciplinary research to encourage widespread innovation and adoption with responsible use. As such, targeted research on the potential of AI for impact across core public health objectives (e.g., health equity , patient privacy) and diverse public health domains (e.g., immunization outreach , emerging disease research ) can provide evidence of the effectiveness and cross -domain applicability of AI . HHS and its divisions can lea d by example by identifying and prioritizing scalable high -impact AI use cases that address the most pressing public health challenges, from improving disease surveillance and emergency response to addressing limited resourcing and workforce shortages, to advancing health equity and access to care. HHS will continue to create programs , guidelines, and resources to support AI innovation , and share its findings with the broader public health ecosystem to encourage further innovation . HHS actions to date ( non-exhaustive ): • CDC Data Modernization Initiative (DMI) is investing in tools and technologies (e.g., advanced disease surveillance systems , real -time data analytics platforms ) to get better, faster, actionable insights for decision -making at all levels of public health (see above for additional details).716 • CDC AI Accelerator Initiative (AIX) focused on operationalizing and scaling four high -impact public health use cases."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_567",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nData Modernization Initiative (DMI) is investing in tools and technologies (e.g., advanced disease surveillance systems , real -time data analytics platforms ) to get better, faster, actionable insights for decision -making at all levels of public health (see above for additional details).716 • CDC AI Accelerator Initiative (AIX) focused on operationalizing and scaling four high -impact public health use cases. • CDC staff chatbot is an internal AI chatbot to provide guidelines on interacting with GenAI, enabling staff to innovate safely and responsibly. • Public Health Data Strategy AI plan milestone 2.05 outlin ed a plan for how the agency will leverage AI and launch pilots."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_568",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nInitiative (AIX) focused on operationalizing and scaling four high -impact public health use cases. • CDC staff chatbot is an internal AI chatbot to provide guidelines on interacting with GenAI, enabling staff to innovate safely and responsibly. • Public Health Data Strategy AI plan milestone 2.05 outlin ed a plan for how the agency will leverage AI and launch pilots. CDC hopes to encourage safe and responsible AI use and improve public health efficiency, response readiness, and outcomes through the completion of this milestone.717 • NIH grants and other resourcing programs like NSF 23 -610: National AI Research Institutes or NIH’s Bridge2AI provide d resources to advance AI use in biomedical and scientific applications.718, 719 • FDA explored the use of AI internally , including but not limited to: deduplicating non -public adverse event data in the FAERS ; identifying novel terms for opioid -related drugs using the Term Identification and Novel Synthetic Opioid Detection and Evaluation Analytics tool , which uses publicly available social media and forensic chemistry data to identify novel referents to drug products 716 https://www.cdc.gov/surveillance/data -modernization/index.html 717 https://www.cdc.gov/public -health -data-strategy/php/about/milestones -for-2024 -and-2025.html 718 https://new.nsf.gov/funding/opportunities/national -artificial -intelligence -research -institutes/nsf23 -610/solicitation 719 https://commonfund.nih.gov/bridge2ai 152 in social media text; and searching and indexing tobacco authorization applications using ASSIST4Tobacco , an AI -based NLP tool."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_569",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand Evaluation Analytics tool , which uses publicly available social media and forensic chemistry data to identify novel referents to drug products 716 https://www.cdc.gov/surveillance/data -modernization/index.html 717 https://www.cdc.gov/public -health -data-strategy/php/about/milestones -for-2024 -and-2025.html 718 https://new.nsf.gov/funding/opportunities/national -artificial -intelligence -research -institutes/nsf23 -610/solicitation 719 https://commonfund.nih.gov/bridge2ai 152 in social media text; and searching and indexing tobacco authorization applications using ASSIST4Tobacco , an AI -based NLP tool. 720, 721 HHS near -term priorities: • Update the Public Health Data Strategy to explicitly support AI development and life cycle management.722 • Ensure grants related to research through NIH continue to allow for the use of AI and the study of its impacts on public health domains. • Continue piloting the use of AI to enhance the forecasting of contagious outbreaks, chronic conditions, and addictive substances. • Continue piloting the use of AI for evidence -based public health messaging to providers and patients tailored to language, literacy, and local context. • Develop implementation guidelines and playbooks for public health partners on the use of AI models and AI systems used by public health officials to support existing operations using tools commonly available within their systems."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_570",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsubstances. • Continue piloting the use of AI for evidence -based public health messaging to providers and patients tailored to language, literacy, and local context. • Develop implementation guidelines and playbooks for public health partners on the use of AI models and AI systems used by public health officials to support existing operations using tools commonly available within their systems. • Partner with nonprofit organizations and others to use AI in health outreach campaigns. HHS long -term priorities: • Share findings and impacts of AI on public health, including operational impacts, internal risks, benefits, and other findings to inform future actions and support the broader community. • Support funding and grants for AI use in public health through existing mechanisms and new opportunities where applicable. • Consider conducting a strategic review and supporting the scaling up of high -impact investments aligned with division goals. Also, support the alignment of public health partners in these areas. • Consider supporting guidelines to other stakeholders on how and where to scale and where there may be an investment case. 2. Modernizing infrastructure necessary to implement AI and support adoption Context: Many public health entities lack the modern technology infrastructure needed to support AI implementation."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_571",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nwith division goals. Also, support the alignment of public health partners in these areas. • Consider supporting guidelines to other stakeholders on how and where to scale and where there may be an investment case. 2. Modernizing infrastructure necessary to implement AI and support adoption Context: Many public health entities lack the modern technology infrastructure needed to support AI implementation. As discussed previously, effective public health action relies on integrating diverse data sources (e.g., through public -private data sharing and lin kage of existing individual health data with public health data) to enable more holistic patient care. However, current public health data systems are siloed, vary in modernization, and often run on outdated technology, leading to different levels of AI re adiness.723 Additionally, the diversity of data formats and the multitude of data standards limits interoperability and seamless data sharing —for example, CDC currently maintains over 100 separate disease surveillance systems that are not fully integrated.724 Public health officials may be hesitant to adopt AI solutions due to these technological and resource challenges, which affect the entire public ecosystem’s ability to function and communicate effectively. HHS, including CDC and others, has started to lay the foundation for modernizing data systems (e.g., DMI) and is investing significant resources today."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_572",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndisease surveillance systems that are not fully integrated.724 Public health officials may be hesitant to adopt AI solutions due to these technological and resource challenges, which affect the entire public ecosystem’s ability to function and communicate effectively. HHS, including CDC and others, has started to lay the foundation for modernizing data systems (e.g., DMI) and is investing significant resources today. However, there are additional actions HHS can and will continue to take. 720 https://www.hhs.gov/sites/default/files/hhs -ai-use-cases -inventory.pdf 721 https://www.hhs.gov/sites/default/files/hhs -ai-use-cases -2023 -public -inventory.csv 722 https://www.cdc.gov/public -health -data-strategy/php/index.html 723 https://jamanetwork.com/journals/jama/fullarticle/2782635 724 https://pmc.ncbi.nlm.nih.gov/articles/PMC10126962/ 153 HHS actions to date (non -exhaustive): • CDC DMI provided direct funding and technical assistance to STLTs to support eCR (automated data feed) implementation , modernize data infrastructure, and connect public health data systems, among other things • Public health infrastructure grants , as of September 2024, had allocated or distributed $611M in funding to support public health data modernization.725 This is part of the $4.2B public health infrastructure grant awarded to health departments around the country to support their most pressing needs, from workforce development to laboratory information systems."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_573",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npublic health data systems, among other things • Public health infrastructure grants , as of September 2024, had allocated or distributed $611M in funding to support public health data modernization.725 This is part of the $4.2B public health infrastructure grant awarded to health departments around the country to support their most pressing needs, from workforce development to laboratory information systems. • CDC and ASTP f ederal interoperability initiative established TEFCA ™, adopted FHIR -based standards for implementing API in certain certified health IT applications and USCDI+ data elements. HHS near -term priorities: • Advance HHS Data Strategy to enable cross -agency data sharing to support AI development for public health. • Pilot use of AI to assist integration and mapping of heterogeneous structured and unstructured public health data streams and public -health -relevant data (e.g., environmental, social media, retail, and over - the-counter medication sales). • Pilot aggregation of multijurisdictional data for AI development, validation, and risk monitoring. • Create a strategy for developing AI to support the integration of public health functions into EHR systems. • Convene regular forums for public health partners to collaborate on data modernization efforts. HHS long -term priorities: • Provide additional opportunities based upon available funding and support for grants for data modernization and AI -readiness initiatives."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_574",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndevelopment, validation, and risk monitoring. • Create a strategy for developing AI to support the integration of public health functions into EHR systems. • Convene regular forums for public health partners to collaborate on data modernization efforts. HHS long -term priorities: • Provide additional opportunities based upon available funding and support for grants for data modernization and AI -readiness initiatives. • Continue implementing data standards across the core public health data systems (e.g., expand the use of USCDI+ data elements and standardize definitions of common data metrics/variables such as population) to improve the quality and completeness of data a nd maximize AI accuracy and effectiveness. • Continue current efforts to simplify the technology landscape and help public health entities better integrate and process data (e.g., by implementing key integrated enterprise -wide data platforms of CDC and helping jurisdictions migrate and onboard cloud -based solutions). • Continue working toward interoperability standards so that AI data systems “speak the same language,” including standardized implementation of TEFCA ™. • Continue funding for internal operational capabilities and data modernization for existing core data systems such as Vital Records to increase the processing speed and insights such as identifying trends in opioid -related deaths, drug overdoses, and other pathways."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_575",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n• Continue working toward interoperability standards so that AI data systems “speak the same language,” including standardized implementation of TEFCA ™. • Continue funding for internal operational capabilities and data modernization for existing core data systems such as Vital Records to increase the processing speed and insights such as identifying trends in opioid -related deaths, drug overdoses, and other pathways. • Consider additional ways to integrate public health and healthcare data systems or provide opportunities with “sandboxes” for piloting. • Strategically explore additional ways that AI can both improve the current modernization efforts and where the current modernization efforts could be used as a platform to encourage AI tool use by others. 5.6.2 Promote Trustworthy AI Development and Ethical and Responsible Use Context: AI has transformative potential to change the way the public, patients, and providers interact with the healthcare system. This includes increasing the tailoring of health information by language, geography, and 725 https://www.cdc.gov/infrastructure -phig/php/data -research/profiles/index.html 154 background through the use of AI chatbots, AI -enabled translation tools, and other services.726 However, for these technologies to be powerful, stakeholders will need to be strongly convinced of their power, trust in the way their data is managed, and be educated on best practices for use."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_576",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ntailoring of health information by language, geography, and 725 https://www.cdc.gov/infrastructure -phig/php/data -research/profiles/index.html 154 background through the use of AI chatbots, AI -enabled translation tools, and other services.726 However, for these technologies to be powerful, stakeholders will need to be strongly convinced of their power, trust in the way their data is managed, and be educated on best practices for use. HHS will continue to aim to support innovation in AI use whi le ensuring safety and privacy. There are several areas where HHS can have an outsize impact to enable responsible AI use, including: 1. Establish ing guardrails to help ensure data quality and accuracy 2. Standardiz ing data security policies across the public health ecosystem 3. Advancing AI tools and techniques that consider and assess health equity from end to end Below, we discuss context, HHS actions to date, and plans to promote trustworthy AI development and ethical and responsible use. 1. Establish ing guardrails to help ensure data quality and accuracy Context: AI models can face issues with data quality and precision, particularly in public health, where inaccuracies can endanger individuals and communities. Both models developed by public health entities and those without public health expertise (e.g., some technology companies) must be trained on appropriate data and parameters to be accurate, reliable, and able to resist misuse to be widely trusted."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_577",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nContext: AI models can face issues with data quality and precision, particularly in public health, where inaccuracies can endanger individuals and communities. Both models developed by public health entities and those without public health expertise (e.g., some technology companies) must be trained on appropriate data and parameters to be accurate, reliable, and able to resist misuse to be widely trusted. All models can benefit from robust safeguards to ensure quality and control shared information, such as filters removing explicit content and verifying health data, and continuous monitoring to detect anomalies in real -time. Organizations can also inadvertently or maliciously create biased models or use incorrect data to spread misinformation and mistrust, negative outcomes which are difficult to identify and mitigate. Outside the U.S., there has been recent guidance from public health institutions including the World Health Organization’s (WHO) report, and the European Union’s AI Act to address some of these challen ges.727, 728 HHS is actively exploring this area and will continue to develop mechanisms, build consensus, and support partnerships to establish and monitor AI standards in collaboration with other authorities."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_578",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe U.S., there has been recent guidance from public health institutions including the World Health Organization’s (WHO) report, and the European Union’s AI Act to address some of these challen ges.727, 728 HHS is actively exploring this area and will continue to develop mechanisms, build consensus, and support partnerships to establish and monitor AI standards in collaboration with other authorities. 726 https://pmc.ncbi.nlm.nih.gov/articles/PMC10637620/ 727 https ://www.who.int/publications/i/item/9789240029200 728 https://digital -strategy.ec.europa.eu/en/policies/regulatory -framework -ai 155 HHS actions to date ( non-exhaustive ): • CDC AI Use Guidelines laid out principles and practices for responsible use, development, and procurement of GenAI use in early 2024, including for public health contexts. • HHS Plan for the Responsible Use of AI in Public Benefits outlined responsible use of AI in automated and algorithmic systems by STLTs in the administration of public benefits such as health screenings.729 • NIH Office of Extramural Research published NOT -OD-23-149, “The Use of Generative Artificial Intelligence Technologies is Prohibited for the NIH Peer Review Process ” in June 2023 ,730 which prohibit ed NIH scientific peer reviewers from using NLP, LLMs , or other GenAI technologies to analyze or formulate peer review critiques for grant applications and R&D contract proposals."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_579",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nscreenings.729 • NIH Office of Extramural Research published NOT -OD-23-149, “The Use of Generative Artificial Intelligence Technologies is Prohibited for the NIH Peer Review Process ” in June 2023 ,730 which prohibit ed NIH scientific peer reviewers from using NLP, LLMs , or other GenAI technologies to analyze or formulate peer review critiques for grant applications and R&D contract proposals. • CDC Morbidity and Mortality Weekly Report Instructions for Authors (MMWR) published in June 2023 provide d guidelines on AI use in research reporting, including in healthcare and public health contexts.731 HHS near -term priorities: • Promote transparency on the use of data and AI for public health to combat public mistrust in key areas, including the use of data for disease detection and surveillance and the spread of medical misinformation and disinformation. • Promote innovation sharing and dissemination of best practices through publications on AI -system information, model cards, training information, and open -source system publications. • Support the safe and responsible use of GenAI with plain language public health outreach and communication efforts such as CDC’s Clean Slate project , which can highlight the risks of improper usage and outline best practices. • Develop standards and guidelines on transparency for scientific research and public health communication on the role AI systems will play in its adoption."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_580",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nSupport the safe and responsible use of GenAI with plain language public health outreach and communication efforts such as CDC’s Clean Slate project , which can highlight the risks of improper usage and outline best practices. • Develop standards and guidelines on transparency for scientific research and public health communication on the role AI systems will play in its adoption. • Develop standards and guidelines to ensure public health providers comply with existing federal civil rights laws when using AI . HHS long -term priorities: • Design a mechanism to partner with AI -system designers to ensure pre -training of AI models is not based on medical misinformation or disinformation that could threaten public health. This includes ensuring AI -system outputs include the appropriate context and infor mation to share with any medical information. This could be accomplished through partnership with AI -training organizations in the private sector to support broader adoption. • Continue to partner with organizations to identify and mitigate misinformation in public health; support collaborative partnerships where appropriate. • Consider ways to implement continuous monitoring and evaluation of AI applications to detect and address potential issues (e.g., models created by malicious actors), partnering with other organizations where appropriate."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_581",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI -training organizations in the private sector to support broader adoption. • Continue to partner with organizations to identify and mitigate misinformation in public health; support collaborative partnerships where appropriate. • Consider ways to implement continuous monitoring and evaluation of AI applications to detect and address potential issues (e.g., models created by malicious actors), partnering with other organizations where appropriate. • Update and monitor existing public health data and AI governance structures and guidelines applicable across the public health data ecosystem based upon new capabilities, federal AI policy, and STLT AI policy. 729 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 730 https://grants.nih.gov/grants/guide/notice -files/NOT -OD-23-149.html 731 https://www.cdc.gov/mmwr/author_guide.html 156 2. Standardiz ing data security policies across the public health ecosystem Context: Many existing data policies and guidelines established at the federal and STLT levels were not originally developed with AI technologies in mind. As AI models are often trained or weighted using PII or PHI data, the AI use without sufficient data protectio n and security policies can pose significant risks to patient privacy and safety."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_582",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe public health ecosystem Context: Many existing data policies and guidelines established at the federal and STLT levels were not originally developed with AI technologies in mind. As AI models are often trained or weighted using PII or PHI data, the AI use without sufficient data protectio n and security policies can pose significant risks to patient privacy and safety. The lack of standardized policies across the ecosystem can also lead to inconsistencies in how sensitive data is managed and protected from entity to entity, increasing the p otential for data breaches and potentially leading to reputational loss and legal or financial consequences. Additional guidelines could build on existing HHS work, such as the HHS Cybersecurity Program or the HIPAA Security Rule and be tailored for use in public health.732, 733 HHS actions to date (non -exhaustive): • HHS common DUA structure policy support ed securely and ethically sharing data from HHS to federal agencies or external organizations.734 • HHS Healthcare and Public Health (HPH) Cybersecurity Goals included best practices for healthcare organizations and healthcare delivery organizations. HHS near -term priorities: • Create ethical guidelines for AI use in the public health ecosystem to help safeguard individual rights and safety. • Promote guidelines on secure open -source software and data security practices in AI systems within the public health ecosystem."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_583",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nHealthcare and Public Health (HPH) Cybersecurity Goals included best practices for healthcare organizations and healthcare delivery organizations. HHS near -term priorities: • Create ethical guidelines for AI use in the public health ecosystem to help safeguard individual rights and safety. • Promote guidelines on secure open -source software and data security practices in AI systems within the public health ecosystem. HHS long -term priorities: • Continue existing efforts to modernize data infrastructure, including the standardization of core public health data sources and increased privacy protection of individual data through security measures (e.g., implementation of PPRL and PII reduction techn ologies to prevent the sharing of sensitive information). 3."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_584",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand data security practices in AI systems within the public health ecosystem. HHS long -term priorities: • Continue existing efforts to modernize data infrastructure, including the standardization of core public health data sources and increased privacy protection of individual data through security measures (e.g., implementation of PPRL and PII reduction techn ologies to prevent the sharing of sensitive information). 3. Advancing AI tools and techniques that consider and assess health equity from end to end Context: AI has the potential to advance health equity by improving healthcare provision, mitigating bias in human decisions, and identifying changeable root “drivers” (e.g., neighborhood conditions) that influence health outcomes rather than relying only on demogr aphic data like race and gender.735 However, it is crucial to continually investigate and address ways in which AI may inadvertently introduce or amplify health disparities (e.g., biases in data can lead to skewed algorithms that disproportionately affect certain populations).736 Particularly in underserved communities, where prior incidents or improper data usage may have already eroded trust, there may be skepticism regarding the development and use of AI.737 HHS will continue to strive to promote the use of AI in a manner that advances health equity."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_585",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndisparities (e.g., biases in data can lead to skewed algorithms that disproportionately affect certain populations).736 Particularly in underserved communities, where prior incidents or improper data usage may have already eroded trust, there may be skepticism regarding the development and use of AI.737 HHS will continue to strive to promote the use of AI in a manner that advances health equity. 732 https://www.hhs.gov/about/agencies/asa/ocio/cybersecurity/information -security -privacy -program/index.html 733 https://www.hhs.gov/hipaa/for -professionals/security/index.html 734 https://www.hhs.gov/web/governance/digital -strategy/it -policy -archive/hhs -policy -common -data-use-agreement -structure -repository.html 735 https:/www.cdc.gov/health -equity/core/index.html . 736 https://www.science.org/doi/10.1126/science.aax2342 . Obermeyer , Z., Powers , B., V ogeli , C., Mullainathan , S. Dissecting racial bias in an algorithm used to manage the health of populations. Science."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_586",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI in a manner that advances health equity. 732 https://www.hhs.gov/about/agencies/asa/ocio/cybersecurity/information -security -privacy -program/index.html 733 https://www.hhs.gov/hipaa/for -professionals/security/index.html 734 https://www.hhs.gov/web/governance/digital -strategy/it -policy -archive/hhs -policy -common -data-use-agreement -structure -repository.html 735 https:/www.cdc.gov/health -equity/core/index.html . 736 https://www.science.org/doi/10.1126/science.aax2342 . Obermeyer , Z., Powers , B., V ogeli , C., Mullainathan , S. Dissecting racial bias in an algorithm used to manage the health of populations. Science. 2019 Oct 25;366(6464):447 -453 737 https://www.healthaffairs.org/doi/10.1377/hlthaff.2021.01466 157 HHS actions to date (non -exhaustive): • CDC -Georgia Tech Research Institute (GTRI) partnership convenes CDC’s Office of Science and experts from the GTRI to develop guidelines and training resources for public health researchers to navigate health equity challenges related to AI use.738 • NIH ’s AIM -AHEAD Program sought to develop a diverse workforce of researchers proficient in AI and address unmet needs in underrepresented communities .739 • For more information, see CDC AI Use Guidelines above . HHS near -term priorities: • Gather resources and conduct an educational public event to share mitigation actions against potential harm associated with synthetic AI -generated content intended to defraud at -risk populations of resources."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_587",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndiverse workforce of researchers proficient in AI and address unmet needs in underrepresented communities .739 • For more information, see CDC AI Use Guidelines above . HHS near -term priorities: • Gather resources and conduct an educational public event to share mitigation actions against potential harm associated with synthetic AI -generated content intended to defraud at -risk populations of resources. • Develop model card and system card standards for public health partners and external partners to use for documenting AI systems, including key fields such as intended use, known limitations, potential model biases, and others based upon industry best pract ices.740, 741 HHS long -term priorities: • Develop guidelines and best practices in conjunction with partners in the different domains of public health to protect health, save lives, and mitigate harms caused by AI specific to each domain. • In coordination with the appropriate entities, develop and implement education campaigns and outreach efforts to educate at -risk populations on the potential harms of deepfakes and AI -associated misinformation campaigns to public health (e.g., breaching he alth data through impersonation of providers, disseminating false images and video that appear to be from a trustworthy public health entity) ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_588",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndomain. • In coordination with the appropriate entities, develop and implement education campaigns and outreach efforts to educate at -risk populations on the potential harms of deepfakes and AI -associated misinformation campaigns to public health (e.g., breaching he alth data through impersonation of providers, disseminating false images and video that appear to be from a trustworthy public health entity) . • Conduct public education and community engagement on AI, which includes actively involving families, communities, and other stakeholders in the development and implementation of public health events. This includes providing resources contingent on the leve l of need within communities and fostering a two -way relationship that builds trust, shares power and collaborates to support all parties involved. 5.6.3 Democratize AI Technologies and Resources: Context: AI represents an outsized opportunity for underserved populations and under -resourced healthcare systems and agencies, as it can help improve cost structures, address resource and staffing gaps, and improve overall resource allocation and use. More so than in fields like human services, global data sharing is essential for public health. Disease knows no borders; only with transparent communication and collaboration can outbreaks and pathogens be rapidly identified and contained. Equitable access t o AI can yield substantial benefits and a high return on investment, amplifying its impact across multiple domains."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_589",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nresource allocation and use. More so than in fields like human services, global data sharing is essential for public health. Disease knows no borders; only with transparent communication and collaboration can outbreaks and pathogens be rapidly identified and contained. Equitable access t o AI can yield substantial benefits and a high return on investment, amplifying its impact across multiple domains. HHS can address current challenges through: 1. Creating an environment that enables data sharing across the public health ecosystem 2. Supporting AI adoption, development, and collaboration , especially for STLTs and community organizations who may have limited resources 3. Developing user -friendly, customizable, and open -source AI tools to broaden access and accommodate a diversity of users Below, we discuss context, HHS actions to date, and plans to democratize AI technologies and resources. 738 https://www.cdc.gov/surveillance/data -modernization/snapshot/2022 -snapshot/stories/ai -impact -health -equity.html 739 https://datascience.nih.gov/artificial -intelligence/aim -ahead 740 https://arxiv.org/abs/1810.03993 741 https://www.xd.gov/blog/creating -a-client -side-model -card-generator/ 158 1."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_590",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nwho may have limited resources 3. Developing user -friendly, customizable, and open -source AI tools to broaden access and accommodate a diversity of users Below, we discuss context, HHS actions to date, and plans to democratize AI technologies and resources. 738 https://www.cdc.gov/surveillance/data -modernization/snapshot/2022 -snapshot/stories/ai -impact -health -equity.html 739 https://datascience.nih.gov/artificial -intelligence/aim -ahead 740 https://arxiv.org/abs/1810.03993 741 https://www.xd.gov/blog/creating -a-client -side-model -card-generator/ 158 1. Creat ing an environment that enables data sharing across the public health ecosystem Context: As of 2023, CDC maintains a highly complex data infrastructure with over 1,000 data systems, increasing the challenges related to the modernization of capabilities, implementing AI infrastructure, and ensuring minimum data entry. This figure does not include local systems owned and operated by STLT agencies, which are critical to conducting on -the-ground public health activities and conducting outbreak response. State and local public health officials collect and analyze data, make recommendations to local and state leaders based on these data, and aggregate this data to aid in federal decision -making."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_591",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndata entry. This figure does not include local systems owned and operated by STLT agencies, which are critical to conducting on -the-ground public health activities and conducting outbreak response. State and local public health officials collect and analyze data, make recommendations to local and state leaders based on these data, and aggregate this data to aid in federal decision -making. Effective data -sharing agreements can enable swift, accurate, bidirectional data sharing across the ecosystem, from STLTs and community organizations to federal agencies, enabling all parties to have a reliable understanding of the current state of health across various parts of the nation. HHS will continue to support effective data sharing that can also support AI use. HHS actions to date (non -exhaustive): • In 2023, ASTP published TEFCA ™, a nationwide framework for health data exchange managed by ONC, to help create a reliable national common operating framework. Over 50 public health jurisdictions across the country use TEFCA ™ exchange to support eCR. • USCDI+ for Public Health is a collab oration between CDC and ASTP to develop standardized public health data elements building on USCDI. • ASTP’s HTI-2 Proposed Rule included the adoption of a Public Health API and other public health - focused capabilities as certification criteria to which EHR could be certified."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_592",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncountry use TEFCA ™ exchange to support eCR. • USCDI+ for Public Health is a collab oration between CDC and ASTP to develop standardized public health data elements building on USCDI. • ASTP’s HTI-2 Proposed Rule included the adoption of a Public Health API and other public health - focused capabilities as certification criteria to which EHR could be certified. Additionally, HTI -2 Proposed Rule proposes to expand ONC Health IT Certification Program certification criteria to include criteria applicable to public health IT systems. HHS near -term priorities: • Continue federal support of TEFCA ™ framework for health data exchange to streamline public health information sharing between healthcare delivery and public health agencies and between public health agencies. • Continue USCDI+ for Public Health initiatives to enhance nationwide public health data standards. HHS long -term priorities: • Coordinate with standards development organizations on standards for AI technologies in public health. 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_593",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsupport of TEFCA ™ framework for health data exchange to streamline public health information sharing between healthcare delivery and public health agencies and between public health agencies. • Continue USCDI+ for Public Health initiatives to enhance nationwide public health data standards. HHS long -term priorities: • Coordinate with standards development organizations on standards for AI technologies in public health. 2. Support ing AI adoption, development, and collaboration, particularly among STLTs and community organizations who may have limited resources Context: Currently, the creation of AI tools can require significant capital, data, and technical expertise, all of which can present barriers to entry that limit AI providers primarily to the private sector or academia.742 Federal funding for data modernization and supporting systems, prompted in response to the COVID -19 pandemic, has enabled organizations to begin updating data systems, enhance efficiencies in existing systems, and streamline operations.743 However, these tasks take time and significant investment, resources which are more readily available in the private sector.744, 745 In contrast, public health stakeholders, especially STLTs and non - profit organizations, dedicate most of their resources to maintaining essential operations and activities."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_594",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-19 pandemic, has enabled organizations to begin updating data systems, enhance efficiencies in existing systems, and streamline operations.743 However, these tasks take time and significant investment, resources which are more readily available in the private sector.744, 745 In contrast, public health stakeholders, especially STLTs and non - profit organizations, dedicate most of their resources to maintaining essential operations and activities. They 742 https://www.omfif.org/2024/07/how -the-global -south -may-pay-the-cost-of-ai-development/ 743 https://www.cdc.gov/budget/fact -sheets/covid -19/index.html 744 https://ourworldindata.org/grapher/private -investment -in-artificial -intelligence 745 https://hbr.org/2022/12/what -companies -need-to-know -before -investing -in-ai 159 may have limited ability to invest in long -term needs like AI integration and may have a low -risk appetite due to potential negative impacts. HHS has the scale and ability to support AI adoption in smaller jurisdictions and organizations through resourcing , the creation of shared centralized systems and standards, and strategic advice on how to encourage innovation and AI use. HHS actions to date (non -exhaustive): • HHS Plan for Responsible Use of AI in Public Benefits outline d additional areas of support for STLTs pertaining to promoting AI use in public benefits, including providing information on funding available to STLTs.746 • For more information, see CDC’s DMI above."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_595",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand strategic advice on how to encourage innovation and AI use. HHS actions to date (non -exhaustive): • HHS Plan for Responsible Use of AI in Public Benefits outline d additional areas of support for STLTs pertaining to promoting AI use in public benefits, including providing information on funding available to STLTs.746 • For more information, see CDC’s DMI above. HHS near -term priorities: • Develop enterprise communication systems with AI -augmented capabilities for local organizations to use to support public health outreach campaigns. • Develop a plan for providing tools, appropriately controlled data, sandboxes, and infrastructure to STLTs for AI development and experimentation leveraging the CDC One Common Data Platform. • Convene public health communities of practice with STLTs to identify opportunities, surface enablers, and barriers, identify opportunities for knowledge and resource sharing, and share best practices and lessons learned (e.g., through a professional associ ation). • Share tactical guidelines on how STLTs and community organizations can engage in low -cost, low -risk “safe innovation” (e.g., suggestions on how to set up an AI working group of existing staff and test simple AI use cases that leverage existing or easy -to-access technology and data). • Encourage and provide guidelines for STLTs to use existing data platforms and available AI systems and tools whenever possible."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_596",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncommunity organizations can engage in low -cost, low -risk “safe innovation” (e.g., suggestions on how to set up an AI working group of existing staff and test simple AI use cases that leverage existing or easy -to-access technology and data). • Encourage and provide guidelines for STLTs to use existing data platforms and available AI systems and tools whenever possible. HHS long -term priorities: • Continue initiatives to develop internal operational capabilities and modernize existing core data systems such as Vital Records , including developing and maturing associated AI infrastructure capabilities. This investment can improve processing speeds and provide insights, such as identifying trends and disease pathways in opioid -related deaths and drug overdoses. • Support enhanced system capabilities across the vital statistics operation chain to enhance insights and NLP capabilities with open -text fields and International Classification of Diseases, 11th Revision (ICD - 11) collaboration. • Provide additional opportunities, based on available funding and support, for grants for data modernization and AI -readiness initiatives. • Continue the implementation of data standards across the core public health data systems, especially in STLTs and community organizations (e.g., expand the use of USCDI+ and standardize definitions of common data metrics/variables, such as population)."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_597",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nRevision (ICD - 11) collaboration. • Provide additional opportunities, based on available funding and support, for grants for data modernization and AI -readiness initiatives. • Continue the implementation of data standards across the core public health data systems, especially in STLTs and community organizations (e.g., expand the use of USCDI+ and standardize definitions of common data metrics/variables, such as population). • Continue working toward ecosystem wide interoperability standards so that data systems “speak the same language,” including the standardized implementation of AI. • Implement a series of high -value, scalable AI projects aimed at improving specific domains of public health. These projects aim to provide immediate, real impact previously unattainable without AI technologies, augmenting efforts to solve existing and emer ging public health problems (e.g., using AI to identify cooling towers from satellite images can help better direct response efforts during Legionnaires’ disease outbreaks) .747 746 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 747 https://www.thelancet.com/journals/landig/article/PIIS2589 -7500(24)00094 -3/fulltext 160 3."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_598",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nspecific domains of public health. These projects aim to provide immediate, real impact previously unattainable without AI technologies, augmenting efforts to solve existing and emer ging public health problems (e.g., using AI to identify cooling towers from satellite images can help better direct response efforts during Legionnaires’ disease outbreaks) .747 746 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 747 https://www.thelancet.com/journals/landig/article/PIIS2589 -7500(24)00094 -3/fulltext 160 3. Develop ing user-friendly, customizable, and open -source AI tools to broaden access and accommodate a diversity of users Context: The use of AI in diverse public health settings, especially under -resourced settings, requires the customizability of AI models and increased access to technology like high -speed internet and intuitively designed AI tools. Increasing the availability of lo w-code or no -code AI platforms, available to the public at low cost, could enable health entities like STLTs and community organizations to develop sophisticated models that meet their communities’ unique needs."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_599",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nunder -resourced settings, requires the customizability of AI models and increased access to technology like high -speed internet and intuitively designed AI tools. Increasing the availability of lo w-code or no -code AI platforms, available to the public at low cost, could enable health entities like STLTs and community organizations to develop sophisticated models that meet their communities’ unique needs. Recent resources for AI in public health inc lude ASTP’s LEAP in Health IT, which provides funding to address emerging challenges that inhibit the development, use and/or advancement of well -designed, interoperable health IT.748 Going forward, HHS can consider advancing these and other efforts to support the development of open -source AI tools, particularly where they could be most impactful and where there could be shared platforms. HHS actions to date (non -exhaustive): • ASTP’s LEAP in Health IT provide s funding for health IT innovations that further the development, use, and/or advancement of well -designed, interoperable health IT. • CDC ’s AI Acceleration Initiative (AIX) is developing high -impact public health AI pilots focused on tools that are both broadly reusable and address common public health challenges. HHS near -term priorities: • Encourage STLTs to utilize existing data platforms and open -source AI systems available through local government programs."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_600",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nuse, and/or advancement of well -designed, interoperable health IT. • CDC ’s AI Acceleration Initiative (AIX) is developing high -impact public health AI pilots focused on tools that are both broadly reusable and address common public health challenges. HHS near -term priorities: • Encourage STLTs to utilize existing data platforms and open -source AI systems available through local government programs. By leveraging state data platforms for AI access, STLTs can reduce maintenance costs and enhance AI capabilities across their partner s, who may have varying levels of expertise. HHS long -term priorities: • Develop shared analytic zones and tools to promote high -value AI use cases across federal and STLT public health partners; identify common public health challenges and data platforms where this approach could have the greatest impact. • Implement scalable GenAI -powered chatbots and make them easily available and modifiable to STLTs and other public health partners. • Develop and acquire open -source AI -powered, along with accompanying training materials, to augment existing public health operations and workforce capabilities. 5.6.4 Cultivate AI -Empowered Workforces and Organization Cultures Context: Public health departments, though critical for community health awareness, prevention, and interventions, often struggle with resource limitations. AI could reduce the burden on the public health workforce provided integration is mindful of community needs ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_601",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI -powered, along with accompanying training materials, to augment existing public health operations and workforce capabilities. 5.6.4 Cultivate AI -Empowered Workforces and Organization Cultures Context: Public health departments, though critical for community health awareness, prevention, and interventions, often struggle with resource limitations. AI could reduce the burden on the public health workforce provided integration is mindful of community needs . To integrate AI in public health operations and foster a learning and innovative environment while addressing community needs, HHS can support the development of use cases, training programs, and pipelines, both formal and informal, that equip public hea lth workers with the skills needed to effectively use AI tools. HHS can address current challenges by: 748 https://www.healthit.gov/topic/onc -funding -opportunities/leading -edge -acceleration -projects -leap-health -information 161 1. Augmenting and supporting the public health workforce to address burnout and attrition while improving efficiency and productivity 2. Promoting AI education and community -based AI approaches tailored to each community’s unique needs Below, we discuss context, HHS actions to date, and plans for AI -empowered workforces and organization cultures. 1."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_602",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nhttps://www.healthit.gov/topic/onc -funding -opportunities/leading -edge -acceleration -projects -leap-health -information 161 1. Augmenting and supporting the public health workforce to address burnout and attrition while improving efficiency and productivity 2. Promoting AI education and community -based AI approaches tailored to each community’s unique needs Below, we discuss context, HHS actions to date, and plans for AI -empowered workforces and organization cultures. 1. Augmenting and supporting the public health workforce to address burnout and attrition while improving efficiency and productivity Context: As previously discussed, while the public health workforce faced challenges prior to COVID -19, the COVID - 19 pandemic exacerbated workforce issues, accelerating burnout and attrition.749 One of the greatest concerns about AI adoption is its potential to replace or reduce existing jobs and workers; however, public health currently faces a severe workforce shortage.750 Nearly half of all state and local public health professionals left their positions between 2017 and 2021, an attrition rate that, if it continues, could leave the public unprepared for future outbreaks and health threats.751 Although AI cannot replace the cross -jurisdictional and cross -functional collaboration central to public health knowledge sharing and disease response, there is enormous potential to use it to improve efficiency and support the understaffed public health workforce."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_603",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npositions between 2017 and 2021, an attrition rate that, if it continues, could leave the public unprepared for future outbreaks and health threats.751 Although AI cannot replace the cross -jurisdictional and cross -functional collaboration central to public health knowledge sharing and disease response, there is enormous potential to use it to improve efficiency and support the understaffed public health workforce. For example, AI can automate time -consuming or repetitive tasks, allowing workers to focus on more strategic or person -centered work. At the same time, a “human in the loop” approach can ensure oversight and intervention should errors occur.752, 753 HHS can continue to identify and develop AI use cases that will streamline processes and boost the productivity of existing public health workers. This not only helps alleviate burnout but also encourages further understanding and adoption of AI across th e public health ecosystem. HHS actions –to date (non -exhaustive): • CMS AI Playbook included educational materials that define AI use cases and trends within healthcare delivery, along with applications CMS is currently and is considering using within its own operations and their potential impact on patient care (e.g., wearables, digital twins and customer support).754 HHS near -term priorities: • Create GenAI tools with image/audio editing functions to augment staff capabilities for education and outreach efforts."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_604",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nmaterials that define AI use cases and trends within healthcare delivery, along with applications CMS is currently and is considering using within its own operations and their potential impact on patient care (e.g., wearables, digital twins and customer support).754 HHS near -term priorities: • Create GenAI tools with image/audio editing functions to augment staff capabilities for education and outreach efforts. HHS long -term priorities: • Identify opportunities where AI can improve efficiency by automating routine and repetitive tasks like reporting and data entry. • Invest in training and change -management initiatives to improve AI adoption, highlighting the impact AI can have on improving workforce efficiency and health outcomes, especially with respect to automating routine and time -consuming tasks . • Consider reviewing holistically the potential impact of AI on the workforce and ways operations may shift within public health (e.g., impact on staff’s sense of connection and purpose) . 749 https://www.healthaffairs.org/doi/full/10.1377/hlthaff.2024.00020 750 https://www.bbc.com/worklife/article/20230418 -ai-anxiety -artificial -intelligence -replace -jobs 751 https://www.healthaffairs.org/doi/full/10.1377/hlthaff.2022.01251 752 https://cloud.google.com/discover/human -in-the-loop#benefits -of-human -in-the-loop-hitl 753 https://doi.org/10.1007/s10462 -022-10246 -w 754 https://ai.cms.gov/assets/CMS_AI_Playbook.pdf 162 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_605",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nroutine and time -consuming tasks . • Consider reviewing holistically the potential impact of AI on the workforce and ways operations may shift within public health (e.g., impact on staff’s sense of connection and purpose) . 749 https://www.healthaffairs.org/doi/full/10.1377/hlthaff.2024.00020 750 https://www.bbc.com/worklife/article/20230418 -ai-anxiety -artificial -intelligence -replace -jobs 751 https://www.healthaffairs.org/doi/full/10.1377/hlthaff.2022.01251 752 https://cloud.google.com/discover/human -in-the-loop#benefits -of-human -in-the-loop-hitl 753 https://doi.org/10.1007/s10462 -022-10246 -w 754 https://ai.cms.gov/assets/CMS_AI_Playbook.pdf 162 2. Promoting AI education and community -based AI approaches tailored to each community’s unique needs Context: Community -based and human -centered approaches are widely used in public health, where community members are engaged from research question selection to program delivery and invited to use their lived experiences to identify and implement appropriate interv entions.755 These programs are better able to address the underlying risk factors that cause health issues, empower community members and increase program engagement, and can often reduce the cost of care through multifactorial approaches that address non -medical challenges like food insecurity and lack of transportation.756 Alongside system upgrades and funding programs, an AI -empowered workforce that understands how and when to use AI (and when not to) and how to engage the community will be needed to ensure AI is used responsibly and effectively."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_606",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\noften reduce the cost of care through multifactorial approaches that address non -medical challenges like food insecurity and lack of transportation.756 Alongside system upgrades and funding programs, an AI -empowered workforce that understands how and when to use AI (and when not to) and how to engage the community will be needed to ensure AI is used responsibly and effectively. HHS actions to date (non -exhaustive): • See information on NIH ’s AIM -AHEAD Program above HHS near -term priorities: • Define HHS’s strategic priorities for promoting awareness and building trust in public health AI. • Coordinate with academia and schools of public health to ensure students gain skills in implementing responsible and ethical AI efforts through their coursework, degree programs, and other education opportunities. • Partner with public health collaboratives and professional organizations to integrate core AI skills into communications, competencies, and certifications. • Develop AI programs and tools that use a community needs approach to incorporate community voices throughout the public health program design and implementation process. HHS long -term priorities: • Expand existing education pathways to include opportunities for STLT and federal staff to upskill in operational AI and advanced data science capabilities."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_607",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncore AI skills into communications, competencies, and certifications. • Develop AI programs and tools that use a community needs approach to incorporate community voices throughout the public health program design and implementation process. HHS long -term priorities: • Expand existing education pathways to include opportunities for STLT and federal staff to upskill in operational AI and advanced data science capabilities. 5.7 Conclusion AI technologies offer a unique opportunity to accelerate the operational efficiencies of public health agencies, advance data gathering, forecasting, and analytics, and improve outreach and communication efforts in a manner that advances equity and improve s health outcomes. However, with the many benefits of AI adoption come risks like the potential for AI -enabled misinformation campaigns through deepfakes sharing harmful health advice. Over the coming years, HHS can build upon the foundation of data modern ization and innovation laid through the COVID -19 pandemic response efforts and (1) catalyze investment and innovation in high -impact, scalable AI use cases, (2) promote ethical, responsible, and trustworthy AI development and use, (3) democratize access to AI technology and resources and (4) expand w orkforce AI capacity and capabilities."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_608",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nHHS can build upon the foundation of data modern ization and innovation laid through the COVID -19 pandemic response efforts and (1) catalyze investment and innovation in high -impact, scalable AI use cases, (2) promote ethical, responsible, and trustworthy AI development and use, (3) democratize access to AI technology and resources and (4) expand w orkforce AI capacity and capabilities. Through partnerships with stakeholders across the public health ecosystem, HHS can work toward a future where cutting -edge technologies such as GenAI -enabled chatbots to share basic health information and precision public health through deep - learning genomic algorithms help all Americans attain their highest level of health. HHS is committed to evolving its AI strategy as technologies and use cases continuously change in order to best improve the publi c’s health. 755 https://www.nimhd.nih.gov/programs/extramural/community -based -participatory.html 756 https://www.cdcfoundation.org/community -based -organizations 163 6 Cybersecurity and Critical Infrastructure Protection 6.1 Introduction and Context Securing digital systems from cyber threats is crucial for realizing the benefits and minimizing the risks of emerging technologies like AI. Without effective risk management, AI systems could put patient, participant, and public safety at risk, expose PII , and erode public trust in healthcare and public health systems."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_609",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n163 6 Cybersecurity and Critical Infrastructure Protection 6.1 Introduction and Context Securing digital systems from cyber threats is crucial for realizing the benefits and minimizing the risks of emerging technologies like AI. Without effective risk management, AI systems could put patient, participant, and public safety at risk, expose PII , and erode public trust in healthcare and public health systems. However, with appropriate controls, the possible benefits of AI to the nation’s health and human services ecosystems are immense. Furthermore, addressing cybersecurity risks is essential to comply with E.O. 14410: Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence, which calls on HHS and the federal government to promote the safe and secure design, development, and deployment of AI models across critical infrastructu re sectors. In response to the executive order and the National Cybersecurity Strategy ,757 HHS released its Cybersecurity Strategy758 in December 2023, outlining actions to improve cybersecurity in health and human services. This document builds on HHS’s Cybersecurity Strategy to highlight new actions the Department has taken since the Strategy’s release and outline additional prioritie s. The threat of cyber -incidents on the U.S. healthcare system is real and growing. Healthcare accounts for $4.5T (17%) of U.S. GDP and 9% of U.S. employment.759 These factors contribute to making healthcare a large target."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_610",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nThis document builds on HHS’s Cybersecurity Strategy to highlight new actions the Department has taken since the Strategy’s release and outline additional prioritie s. The threat of cyber -incidents on the U.S. healthcare system is real and growing. Healthcare accounts for $4.5T (17%) of U.S. GDP and 9% of U.S. employment.759 These factors contribute to making healthcare a large target. According to one survey, 92% of healthcare organizations experienced at least one cyber -incident in the past 12 months760, and the HHS OCR reported a 264% increase in large data breaches involving ransomware from 2018 to 2022.761 In health and human services, cybersecurity incidents can impact multiple stakeholders. Previous incidents have led to delays in patient care and operational and financial disruptions for providers,762 payers,763, 764 and state public health departments.765 Furthermore, the introduction of AI widens the threat landscape, as AI applications are increasingly used as tools for cyber attackers, exploitable vulnerabilities in digital systems, but also as new defensive tools. As AI adoption scales across the healt hcare and public health ecosystem, cybersecurity protections must scale with it. In this chapter, HHS outlines the current and expected trends in cybersecurity risks, how AI is impacting and creating these risks, and their implications for healthcare, public health, and human services."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_611",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nexploitable vulnerabilities in digital systems, but also as new defensive tools. As AI adoption scales across the healt hcare and public health ecosystem, cybersecurity protections must scale with it. In this chapter, HHS outlines the current and expected trends in cybersecurity risks, how AI is impacting and creating these risks, and their implications for healthcare, public health, and human services. The Department then outlines the opportunities for actions to better enable organizations to address these threats, ongoing actions HHS has taken, and additional actions that could further bolster the health and human services ecosystem’s cybersecurity capabilities."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_612",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand expected trends in cybersecurity risks, how AI is impacting and creating these risks, and their implications for healthcare, public health, and human services. The Department then outlines the opportunities for actions to better enable organizations to address these threats, ongoing actions HHS has taken, and additional actions that could further bolster the health and human services ecosystem’s cybersecurity capabilities. 757 https://www.whitehouse.gov/oncd/national -cybersecurity -strategy/ 758 https://www.hhs.gov/about/news/2023/12/06/hhs -announces -next-steps -ongoing -work -enhance -cybersecurity -health -care-public -health -sectors.html 759 https://www.cms.gov/newsroom/fact -sheets/national -health -expenditures -2022 -highlights https://www.bls.gov/spotlight/2023/healthcare -occupations -in-2022/ 760 https://www.hipaajournal.com/92pc -us-healthcare -organizations -cyberattack -past-year/ 761 https://www.hhs.gov/about/news/2024/09/26/hhs -office -civil-rights -settles -ransomware -cybersecurity -investigation -under -hipaa -security -rule-250-000.html 762 https://www.ucsf.edu/news/2020/06/417911/update -it-security -incident -ucsf 763 https://www.hipaajournal.com/change -healthcare -responding -to-cyberattack/ 764 https://pmc.ncbi.nlm.nih.gov/articles/PMC7349636/ HIPAA journal is a US -based journal that provides comprehensive coverage of data breaches, guidelines for HIPAA compliance, and practical guidelines for data breach avoidance."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_613",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-2022 -highlights https://www.bls.gov/spotlight/2023/healthcare -occupations -in-2022/ 760 https://www.hipaajournal.com/92pc -us-healthcare -organizations -cyberattack -past-year/ 761 https://www.hhs.gov/about/news/2024/09/26/hhs -office -civil-rights -settles -ransomware -cybersecurity -investigation -under -hipaa -security -rule-250-000.html 762 https://www.ucsf.edu/news/2020/06/417911/update -it-security -incident -ucsf 763 https://www.hipaajournal.com/change -healthcare -responding -to-cyberattack/ 764 https://pmc.ncbi.nlm.nih.gov/articles/PMC7349636/ HIPAA journal is a US -based journal that provides comprehensive coverage of data breaches, guidelines for HIPAA compliance, and practical guidelines for data breach avoidance. 765 https://ocrportal.hhs.gov/ocr/breach/breach_report.jsf 164 6.1.1 Action Plan Summary Later in this chapter, HHS articulates proposed actions improve the sector’s ability to manage its cybersecurity requirements. Below are the broad themes of these actions. For full details of proposed actions please see section 6.4 Action Plan. Themes of actions: 1. Addressing the shortage of appropriately skilled cybersecurity workers to fill roles in health and human services 2. Supporting the standardization and alignment on best practices, especially in cybersecurity governance 3. Reducing and managing complexity in implementing new cybersecurity capabilities 4."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_614",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthemes of these actions. For full details of proposed actions please see section 6.4 Action Plan. Themes of actions: 1. Addressing the shortage of appropriately skilled cybersecurity workers to fill roles in health and human services 2. Supporting the standardization and alignment on best practices, especially in cybersecurity governance 3. Reducing and managing complexity in implementing new cybersecurity capabilities 4. Clarifying approach to navigate acute tensions between privacy and fairness and privacy and safety in health 6.2 Stakeholders Engaged in the Cybersecurity and Critical Infrastructure in the Health and Human Services Ecosystem HHS plays a dual role in promoting cybersecurity: first, by serving as a partner to the sector through information sharing and best practice development, and second, as a regulator, enforcing cybersecurity and preparedness rules. Alongside HHS, the rest of the federal government, STLTs, providers, payers, community organizations, and other non-government stakeholders are responsible for defending against cyber -threats and maintaining their organization’s cybersecurity capabilities. Multiple divisions and groups within HHS play a part in cybersecurity. These include the Health Sector Coordinating Council (HSCC) and HHS 405(d) Task Force, two public -private partnerships that aid in developing and sharing AI guidelines to healthcare, pu blic health, and human services sector."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_615",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nnon-government stakeholders are responsible for defending against cyber -threats and maintaining their organization’s cybersecurity capabilities. Multiple divisions and groups within HHS play a part in cybersecurity. These include the Health Sector Coordinating Council (HSCC) and HHS 405(d) Task Force, two public -private partnerships that aid in developing and sharing AI guidelines to healthcare, pu blic health, and human services sector. ASPR coordinates Sector Risk Management Agency activities on behalf of HHS for the Healthcare and Public Health sector, coordinating cybersecurity preparedness and response activities within HHS, across the federal a gencies, and with industry partners. Exhibit 1 5 shows a non -exhaustive, illustrative diagram of example flows between stakeholders involved cybersecurity and critical infrastructure protection. Please note that the diagram does not capture all stakeholder roles and interactions. Please refer to other HHS documents for additional details on regulatory guidance and authorities. Roles may vary depending on domain or part of healthcare , public health, or human services ecosystem . 165 Exhibit 15: Interaction of Stakeholders in the Cybersecurity and Critical Infrastructure Protection Healthcare, Public Health, and Human Services Ecosystem. 6.3 Trends in Cybersecurity and Critical Infrastructure Protection 1."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_616",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nrefer to other HHS documents for additional details on regulatory guidance and authorities. Roles may vary depending on domain or part of healthcare , public health, or human services ecosystem . 165 Exhibit 15: Interaction of Stakeholders in the Cybersecurity and Critical Infrastructure Protection Healthcare, Public Health, and Human Services Ecosystem. 6.3 Trends in Cybersecurity and Critical Infrastructure Protection 1. Cyber -incidents are on the rise in the healthcare industry and globally, and the costs related to cybercrime are growing : As companies, agencies, and organizations transform and modernize, the number and types of cyber threats grow each year. One analysis estimates a 589% increase in security vulnerabilities from 2023 to 2024 across industries.766 Furthermore, the cost of cyber -incidents reached an estimated $8 T in 2023 and continues to grow.767 Health and human services organizations are also facing increased cybersecurity threats, including ransomware, phishing attacks, third -party breaches, data breaches, and social engineering attacks.768 Accelerating digitization in healthcare (e.g., EHRs) has made healthcare a high-priority target for cyber -threats and magnified the complexity of establishing effective defensive measures."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_617",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-incidents reached an estimated $8 T in 2023 and continues to grow.767 Health and human services organizations are also facing increased cybersecurity threats, including ransomware, phishing attacks, third -party breaches, data breaches, and social engineering attacks.768 Accelerating digitization in healthcare (e.g., EHRs) has made healthcare a high-priority target for cyber -threats and magnified the complexity of establishing effective defensive measures. The health and public health sector saw a 42% increase in ransomwa re incidents between 2021 and 2022, and the frequency of cyber -incidents affecting health systems has doubled since 2016.769 These incidents can cause system outages and endanger patient safety, among other consequences. 2. The cybercrime industry is large and mature, with the capability to launch increasingly sophisticated attacks against health and human services organizations : Cybercrime is a multi -billion -dollar, sophisticated industry replete with R&D functions that continuously improve their capabilities. Attackers are using new tools, including AI, to expedite the end -to-end attack life cycle from weeks to days or even hours. In recent years, attackers have used public health crises to demonstrate the power of their ars enal."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_618",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nhuman services organizations : Cybercrime is a multi -billion -dollar, sophisticated industry replete with R&D functions that continuously improve their capabilities. Attackers are using new tools, including AI, to expedite the end -to-end attack life cycle from weeks to days or even hours. In recent years, attackers have used public health crises to demonstrate the power of their ars enal. For instance, during the COVID -19 pandemic ransomware and phishing attacks spiked globally due to a 766 https://info.jupiterone.com/scar -2023 767 https://www.usaid.gov/digital -development/cybersecurity/economic -growth -briefer 768 https://www.aha.org/h -isac-white -reports/2024 -02-21-h-isac-tlp-white -announcement -h-isac-aha-executive -summary -cisos -current -and-emerging 769 https://aspr.hhs.gov/cyber/Pages/default.aspx 166 combination of increased threat activity and increased vulnerability due to the shift to work -from -home models.770, 771 3. The use of AI, particularly GenAI, is expected to increase the number of cyber threats, vulnerabilities, and potential for errors and accidents : The Federal Bureau of Investigation has warned that cybercriminals are increasingly leveraging AI tools with greater frequency to orchestrate targeted phishing campaigns.772 For instance, AI -driven social engineering attacks, where AI impersonates a human using LLMs, are becoming increasingly successful.773 In the first two months of 2023 alone, novel phishing attacks spiked 135%."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_619",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand potential for errors and accidents : The Federal Bureau of Investigation has warned that cybercriminals are increasingly leveraging AI tools with greater frequency to orchestrate targeted phishing campaigns.772 For instance, AI -driven social engineering attacks, where AI impersonates a human using LLMs, are becoming increasingly successful.773 In the first two months of 2023 alone, novel phishing attacks spiked 135%. Additionally, new malware is emerging that can evade traditional cybersecurity tools like endpoint detection and response (EDR) technology.774, 775 For healthcare organizations, AI -driven phishing attacks are among the most used attack vectors in U.S. healthcare cyber threats.776 In public health, AI-generated deepfakes can be used to spread misinformation, which can reduce people’s willingness to seek treatment or simply undermine trust in public health institutions.777, 778 Furthermore, AI -powered systems could also be used to de -anonymize sensitive health information, leading to costly ransomware attacks.779 This is particularly troubling given the wide range of anonymized datasets available in healthcare and public health for clinical trials, precision medicine, and medical research. Other healthcare specific threats could include vectors like adversarial at tacks on medical imaging780 or data poisoning ,781 while threats affecting federal agencies or STLTs include automated social engineering attacks782 or disinformation campaigns."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_620",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nransomware attacks.779 This is particularly troubling given the wide range of anonymized datasets available in healthcare and public health for clinical trials, precision medicine, and medical research. Other healthcare specific threats could include vectors like adversarial at tacks on medical imaging780 or data poisoning ,781 while threats affecting federal agencies or STLTs include automated social engineering attacks782 or disinformation campaigns. A broad range of other adversarial AI techniques exist in various stages of development and sophistication.783 4. The increasing need for and access to large datasets in health and human services is also leading to a greater risk of data breaches : While healthcare lags other sectors in adopting cloud storage, the increase in online patient platforms, AI adoption, and EHR use led to more health data being stored in the cloud.784 Healthcare, public health, and human services organizations manage large, sensitive datasets, including PHI, and many stakeholders have access. As data increasingly migrates to cloud storage, all organizations must take cybersecurity precautions to safegua rd sensitive data. Furthermore, relying on third -party cloud storage can magnify vulnerabilities. In fact, 35% of healthcare data breaches involve third -party vendors.785 The ramifications of data breaches in healthcare are immense."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_621",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\norganizations manage large, sensitive datasets, including PHI, and many stakeholders have access. As data increasingly migrates to cloud storage, all organizations must take cybersecurity precautions to safegua rd sensitive data. Furthermore, relying on third -party cloud storage can magnify vulnerabilities. In fact, 35% of healthcare data breaches involve third -party vendors.785 The ramifications of data breaches in healthcare are immense. For example, one ransomware attack in February exposed the private health information of 100 million individuals and may have resulted in a financial impact exceeding $2.5B.786, 787 Healthcare data breaches are increasingly costly due to losses from business 770 https://pmc.ncbi.nlm.nih.gov/articles/PMC9212240/ 771 https://pmc.ncbi.nlm.nih.gov/articles/PMC9755115/ 772 https://www.fbi.gov/contact -us/field -offices/sanfrancisco/news/fbi -warns -of-increasing -threat -of-cyber -criminals -utilizing -artificial -intelligence 773 https://www.fbi.gov/contact -us/field -offices/sanfrancisco/news/fbi -warns -of-increasing -threat -of-cyber -criminals -utilizing -artificial -intelligence 774 https://www.hhs.gov/sites/default/files/ai -cybersecurity -health -sector -tlpclear.pdf 775 https://www.hyas.com/blog/blackmamba -using -ai-to-generate -polymorphic -malware . An example of this is the Black Mamba polymorphic malware which dynamically modifies its behavior to avoid detection ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_622",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n770 https://pmc.ncbi.nlm.nih.gov/articles/PMC9212240/ 771 https://pmc.ncbi.nlm.nih.gov/articles/PMC9755115/ 772 https://www.fbi.gov/contact -us/field -offices/sanfrancisco/news/fbi -warns -of-increasing -threat -of-cyber -criminals -utilizing -artificial -intelligence 773 https://www.fbi.gov/contact -us/field -offices/sanfrancisco/news/fbi -warns -of-increasing -threat -of-cyber -criminals -utilizing -artificial -intelligence 774 https://www.hhs.gov/sites/default/files/ai -cybersecurity -health -sector -tlpclear.pdf 775 https://www.hyas.com/blog/blackmamba -using -ai-to-generate -polymorphic -malware . An example of this is the Black Mamba polymorphic malware which dynamically modifies its behavior to avoid detection . 776 https://www.hipaajournal.com/healthcare -data-breaches -due-to-phishing/ 777 https://www.nyu.edu/life/information -technology/safe -computing/protect -against -cybercrime/ai -assisted -cyberattacks -and-scams.html 778 https://www.hhs.gov/sites/default/files/surgeon -general -misinformation -advisory.pdf 779 https://www.hipaajournal.com/managed -care-of-north -america -hacking -incident -impacts -8-9-million -individuals/ 780 https://pmc.ncbi.nlm.nih.gov/articles/PMC10487122/ Manipulate medical images in a way that deceives diagnostic systems, leading to misdiagnosis or incorrect treatment decisions ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_623",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nBlack Mamba polymorphic malware which dynamically modifies its behavior to avoid detection . 776 https://www.hipaajournal.com/healthcare -data-breaches -due-to-phishing/ 777 https://www.nyu.edu/life/information -technology/safe -computing/protect -against -cybercrime/ai -assisted -cyberattacks -and-scams.html 778 https://www.hhs.gov/sites/default/files/surgeon -general -misinformation -advisory.pdf 779 https://www.hipaajournal.com/managed -care-of-north -america -hacking -incident -impacts -8-9-million -individuals/ 780 https://pmc.ncbi.nlm.nih.gov/articles/PMC10487122/ Manipulate medical images in a way that deceives diagnostic systems, leading to misdiagnosis or incorrect treatment decisions . 781 https://pmc.ncbi.nlm.nih.gov/articles/PMC10984073/ Attackers manipulate training data in an AI model by injecting false data, leading to biased models or inaccurate output . 782 https://www.weforum.org/stories/2024/10/ai -agents -in-cybersecurity -the-augmented -risks -we-all-need-to-know -about/ Using personalized messages to convince someone to divulge sensitive information or click a malicious link . 783 Other AI -enabled cyber -attacks include generating deceptive AI (e.g., deepfake attacks, morphing attacks), attacks on AI systems (e.g., data poisoni ng, evasion attacks, model extraction), emerging technologies (e.g., quantum computing, false biometric data ), and dual -use AI capabilities (e.g., computer vision, NLP, audio recognition ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_624",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nconvince someone to divulge sensitive information or click a malicious link . 783 Other AI -enabled cyber -attacks include generating deceptive AI (e.g., deepfake attacks, morphing attacks), attacks on AI systems (e.g., data poisoni ng, evasion attacks, model extraction), emerging technologies (e.g., quantum computing, false biometric data ), and dual -use AI capabilities (e.g., computer vision, NLP, audio recognition . 784 https://www.hipaajournal.com/healthcare -cloud -usage -grows -but-protecting -phi-can-be-a-challenge/ 785 https://www.hipaajournal.com/healthcare -highest -third -party -breaches/ 786 https://ocrportal.hhs.gov/ocr/breach/breach_report.jsf Incident logged on July 19, 2024. 787 https://www.hipaajournal.com/change -healthcare -responding -to-cyberattack/ 167 disruption, customer support, and remediation. The average cost of a healthcare data breach for an organization is now $10M.788, 789 5. Traditional tools for combatting cyber -threats are still effective, but cyber risks are outpacing capabilities in organizations due to several challenges : Although AI -enabled cyber threats can be more devastating, they often have vectors that resemble traditional cybersecurity attacks. Recent data shows that 84% of critical infrastructure incidents involve , “an initial access vector that could have been mitigated with best practices and security fundamentals, such as asset and patch management, credential hardening, and the principle of least privilege."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_625",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nchallenges : Although AI -enabled cyber threats can be more devastating, they often have vectors that resemble traditional cybersecurity attacks. Recent data shows that 84% of critical infrastructure incidents involve , “an initial access vector that could have been mitigated with best practices and security fundamentals, such as asset and patch management, credential hardening, and the principle of least privilege. ”790 Traditional cybersecurity practices can still help thwart these threats. However, organizations are struggling to implement even traditional tools for combatting cyber -threats due to challenges such as a mismatch of skillsets in cybersecurity workforce, lack of standardization of best practices, implementation complexity, and other barr iers. In the next section, HHS provides additional context to those challenges and outlines opportunities for the Department to take action to enhance the sector’s cybersecurity and critical infrastructure protection. 6.4 Action Plan Health and human services organizations are investing more in their cybersecurity capabilities."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_626",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nskillsets in cybersecurity workforce, lack of standardization of best practices, implementation complexity, and other barr iers. In the next section, HHS provides additional context to those challenges and outlines opportunities for the Department to take action to enhance the sector’s cybersecurity and critical infrastructure protection. 6.4 Action Plan Health and human services organizations are investing more in their cybersecurity capabilities. One estimate suggests that the global healthcare industry will spend $125 B on cyber products and services from 2020 -2025, representing 15% annual growth.791 and a 2023 survey of healthcare cybersecurity professionals found that over half had seen increases in their cybersecurity budgets in the past year.792 Despite increased attention and investment, healthcare organizations are struggling to keep up with escalating threats. For instance, ransomware attacks on the healthcare sector nearly doubled from 2022 to 2023.793 Moreover, the focus of cybersecurity spending has shifted; from 2016 to 2022, the share dedicated to preventing incidents decreased from 60% to 30%, with more resources now allocated to managing ongoing incidents.794 Below, HHS outlines several opportunities for actions to improve the sector’s ability to manage its cybersecurity requirements. These opportunities are: 1. Addressing the shortage of appropriately skilled cybersecurity workers to fill roles in health and human services 2."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_627",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto 2022, the share dedicated to preventing incidents decreased from 60% to 30%, with more resources now allocated to managing ongoing incidents.794 Below, HHS outlines several opportunities for actions to improve the sector’s ability to manage its cybersecurity requirements. These opportunities are: 1. Addressing the shortage of appropriately skilled cybersecurity workers to fill roles in health and human services 2. Supporting the standardization and alignment on best practices, especially in cybersecurity governance 3. Reducing and managing c omplexity in implementing new cybersecurity capabilities 4. Clarifying approach to navigate a cute tensions between privacy and fairness and privacy and safety in health and human services For each of these opportunities , HHS has added context and highlighted where it has taken mitigating actions and where it is considering future action. 788 https://aspr.hhs.gov/cyber/Pages/default.aspx 789 https://www.ibm.com/reports/data -breach Global average cost for a data breach is $4.88 million, for comparison . 790 https://www.ibm.com/downloads/documents/us -en/107a02e952c8fe80 791 https://www.hipaajournal.com/healthcare -cybersecurity/ 792 https://www.chiefhealthcareexecutive.com/view/healthcare -cybersecurity -budgets -are-rising -but-workers -are-hard-to-find."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_628",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nhealth and human services For each of these opportunities , HHS has added context and highlighted where it has taken mitigating actions and where it is considering future action. 788 https://aspr.hhs.gov/cyber/Pages/default.aspx 789 https://www.ibm.com/reports/data -breach Global average cost for a data breach is $4.88 million, for comparison . 790 https://www.ibm.com/downloads/documents/us -en/107a02e952c8fe80 791 https://www.hipaajournal.com/healthcare -cybersecurity/ 792 https://www.chiefhealthcareexecutive.com/view/healthcare -cybersecurity -budgets -are-rising -but-workers -are-hard-to-find. 793 https://www.dni.gov/files/CTIIC/documents/products/Ransomware_Attacks_Surge_in_2023.pdf 794 https://www.mckinsey.com/capabilities/risk -and-resilience/our -insights/cybersecurity/cybersecurity -trends -looking -over-the-horizon 168 1. Addressing the s hortage of appropriately skilled cybersecurity workers to fill roles in health and human services. Context: Many organizations lack the cybersecurity talent, knowledge, and expertise required to defend against the latest threats and are struggling to fill essential roles. Across the U.S., the gap in skilled cybersecurity workers is widening faster than new hiring can keep up.795, 796 This shortage may stem from a mismatch in skillsets rather than a lack of job -seeking cyber professionals."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_629",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nMany organizations lack the cybersecurity talent, knowledge, and expertise required to defend against the latest threats and are struggling to fill essential roles. Across the U.S., the gap in skilled cybersecurity workers is widening faster than new hiring can keep up.795, 796 This shortage may stem from a mismatch in skillsets rather than a lack of job -seeking cyber professionals. More traditional cyber professionals do not have the required expertise in areas like cloud services, AI and GenAI data and analytics, or health and human services IT. Increasingly, leaders outside of cybersecurity teams are also searching for cybersecurity talent. However, leaders often lack the basic understanding of cybersecurity needed to evaluate candidates or meet their hiring needs effectively. In the healthcare sector, one survey by CDW revealed that only 14% of healthcare IT leaders reported having fully staffed security teams.797 HHS has taken actions to improve cybersecurity workforce capabilities and , as outlined below, will look to develop trainings and explore resourcing to bring more appropriately skilled talent into the sector. HHS actions to date ( non-exhaustive ): • Increasing capabilities for under -resourced STLTs through active monitoring, data sharing, and collaboration."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_630",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nIT leaders reported having fully staffed security teams.797 HHS has taken actions to improve cybersecurity workforce capabilities and , as outlined below, will look to develop trainings and explore resourcing to bring more appropriately skilled talent into the sector. HHS actions to date ( non-exhaustive ): • Increasing capabilities for under -resourced STLTs through active monitoring, data sharing, and collaboration. HHS continues to monitor and share data, including for AI threats, to increase the capabilities of under -resourced STLTs and work with its government partners to develop and share draft guidelines on essential cybersecurity practices to protect AI models and continue providing tools and resources to help under -resourced entities implement robust cybersecurity practices. • ARPA -H is developing new tools that automatically detect and fix cyber vulnerabilities , reducing the cybersecurity burden on hospitals and healthcare organizations. These steps include: o Launching AI Cyber Challenge in collaboration with DARPA to leverage AI to create usable, automatic tools for vulnerability identification and remediation that can be deployed across the Nation ’s open -source software supply chain."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_631",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-H is developing new tools that automatically detect and fix cyber vulnerabilities , reducing the cybersecurity burden on hospitals and healthcare organizations. These steps include: o Launching AI Cyber Challenge in collaboration with DARPA to leverage AI to create usable, automatic tools for vulnerability identification and remediation that can be deployed across the Nation ’s open -source software supply chain. o Creating Universal Patching and Remediation for Autonomous Defense program, which intends to develop an autonomous cyber -threat solution that enables proactive, scalable, and synchronized security updates, reducing the uncertainty and manual effort necessary to secure hospitals. HHS near -term priorities: • Develop additional health - and human -services -sector -specific cybersecurity training geared toward organizational leadership and hiring managers outside cyber teams. • Assess opportunities to support cybersecurity workforce development for under -resourced healthcare and public health organizations. • Support adoption of technologies in HHS, STLTs, and CBOs that support secure data sharing. HHS long -term priorities: • Integrate new cybersecurity requirements in HHS grants, contracts, and cooperative agreements. • Explore incorporating AI -enabled threats into HHS Priority Intelligence Requirements to increase existing sharing of cyber threat intelligence across HHS and healthcare, public health, and human services sectors."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_632",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n• Support adoption of technologies in HHS, STLTs, and CBOs that support secure data sharing. HHS long -term priorities: • Integrate new cybersecurity requirements in HHS grants, contracts, and cooperative agreements. • Explore incorporating AI -enabled threats into HHS Priority Intelligence Requirements to increase existing sharing of cyber threat intelligence across HHS and healthcare, public health, and human services sectors. 795 https://www.weforum.org/stories/2024/04/cybersecurity -industry -talent -shortage -new-report/ 796 https://www.whitehouse.gov/oncd/briefing -room/2024/09/04/service -for-america -cyber -is-serving -your-country/ 797 https://www.hipaajournal.com/healthcare -cybersecurity/ 169 2. Supporting the standardization and alignment on best practices, especially in cybersecurity governance Context: Cybersecurity comprises a complex set of capabilities from strategy to data protection to resilience and recovery. Each organization values and prioritizes its cyber capabilities differently. As a result, there are no accepted standards for when and how to use trusted architecture techniques."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_633",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n797 https://www.hipaajournal.com/healthcare -cybersecurity/ 169 2. Supporting the standardization and alignment on best practices, especially in cybersecurity governance Context: Cybersecurity comprises a complex set of capabilities from strategy to data protection to resilience and recovery. Each organization values and prioritizes its cyber capabilities differently. As a result, there are no accepted standards for when and how to use trusted architecture techniques. In the health sector, these challenges could extend to cyber -related risk governance, where, sometimes, there are poorly defined roles and responsibilities for addressing failures in AI systems, a lack of understanding of liability when AI systems are used for decision -making, and an inability to validate model outputs.798 In many organizations, this can lead to an ad hoc approach to cyber management. Often the responsible cybersecurity team, normally the Chief Information Security Officer (CISO) for IT -related threats, is not consistently provided with the resources they n eed to protect their organization effectively. Additionally, they might not be involved early enough to assess cyber risks for new programs or may only be brought in when a breach occurs. Furthermore, this can lead to a gap in cyber capabilities, including asset management, vulnerability management, impactful metrics and reporting, identity and access, and data protection."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_634",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe resources they n eed to protect their organization effectively. Additionally, they might not be involved early enough to assess cyber risks for new programs or may only be brought in when a breach occurs. Furthermore, this can lead to a gap in cyber capabilities, including asset management, vulnerability management, impactful metrics and reporting, identity and access, and data protection. HHS has taken action to adopt and publish best-practice standards and will continue to develop and update guidelines as cybersecurity practices evolve. HHS actions to date ( non-exhaustive ): • Adopted the NIST AI Risk Management Framework:799 integrated AI-risk-management practices into planning for cybersecurity, emergency management, clinical operations, medical devices, legal, workforce management, supply chain, and procurement.800 • Released HHS’s Cybersecurity Strategy (December 2023)801 recommend ed implementing basic, traditional cybersecurity measures and is geared toward helping all organizations elevate their security floor with the proper tools and measures to manage the risks of AI in their organization. • Released its HPH Cybersecurity Performance Goals (CPGs)802 help organizations prioritize the implementation of high -impact cybersecurity practices and are adapted from CISA’s own CPGs803 and from best practices in the industry to fit the healthcare context."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_635",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ntoward helping all organizations elevate their security floor with the proper tools and measures to manage the risks of AI in their organization. • Released its HPH Cybersecurity Performance Goals (CPGs)802 help organizations prioritize the implementation of high -impact cybersecurity practices and are adapted from CISA’s own CPGs803 and from best practices in the industry to fit the healthcare context. • Released proposed measures to strengthen cybersecurity in healthcare under HIPAA (December 2024) by requiring health plans, healthcare clearing houses, and most health providers and their business associates to better protect individuals ’ electronic PHI against both external and internal threats. • Collaborate s with government partners to develop and share draft guidelines on essential cybersecurity practices to protect AI models. HHS near -term priorities • Develop guidelines on maintaining operations after a system deploying AI is compromised. Users should have policies, tools, and training in place to understand when AI systems are producing incorrect outputs, and resiliency plans for when AI systems are co mpromised."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_636",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npartners to develop and share draft guidelines on essential cybersecurity practices to protect AI models. HHS near -term priorities • Develop guidelines on maintaining operations after a system deploying AI is compromised. Users should have policies, tools, and training in place to understand when AI systems are producing incorrect outputs, and resiliency plans for when AI systems are co mpromised. • Update existing regulations and guidelines on adoption to include best practices for maintaining cybersecurity, including for maintaining secure means of data transfer and sharing 798 https://healthsectorcouncil.org/health -industry -cybersecurity -artificial -intelligence -machine -learning/ 799 https://www.nist.gov/system/files/documents/2022/08/18/AI_RMF_2nd_draft.pdf 800 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 801 https://www.hhs.gov/about/news/2023/12/06/hhs -announces -next-steps -ongoing -work -enhance -cybersecurity -health -care-public -health -sectors.html 802 https://hhscyber.hhs.gov/performance -goals.html 803 https://www.cisa.gov/cybersecurity -performance -goals 170 3. Reducing and managing c omplexity in implementing for new cybersecurity capabilities Context: Threats described above point to the need for stronger data security and access controls at each stage of AI application development."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_637",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n799 https://www.nist.gov/system/files/documents/2022/08/18/AI_RMF_2nd_draft.pdf 800 https://www.hhs.gov/sites/default/files/public -benefits -and-ai.pdf 801 https://www.hhs.gov/about/news/2023/12/06/hhs -announces -next-steps -ongoing -work -enhance -cybersecurity -health -care-public -health -sectors.html 802 https://hhscyber.hhs.gov/performance -goals.html 803 https://www.cisa.gov/cybersecurity -performance -goals 170 3. Reducing and managing c omplexity in implementing for new cybersecurity capabilities Context: Threats described above point to the need for stronger data security and access controls at each stage of AI application development. Secure design and training can help prevent AI confabulation, data breaches, and data exfiltration, which can be particularly important for institutions conducting sensitive research on biotechnology, new pathogens, and more. Developers of AI models must implement robust security controls into each facet of their operations, and users of those solutions (e.g., healthcare stakeholders) need training to understand and safely integrate t hose solutions.804 However, given persistent staffing shortages, a lack of standardization, and an increasingly complex technology landscape, organizations struggle to coordinate with solution providers, shift their organizational norms to comply with new deployments or dep loy and scale solutions across the entirety of their enterprises."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_638",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nusers of those solutions (e.g., healthcare stakeholders) need training to understand and safely integrate t hose solutions.804 However, given persistent staffing shortages, a lack of standardization, and an increasingly complex technology landscape, organizations struggle to coordinate with solution providers, shift their organizational norms to comply with new deployments or dep loy and scale solutions across the entirety of their enterprises. The De partment will identify ways to reduce the complexity through potential actions outlined below such as enhancements to HHS healthcare IT certification s. HHS actions to date ( non-exhaustive ): • Issued guidelines to enhance software transparency. Section 524B(b)(3) of the FD&C Act requires that medical device manufacturers of “cyber devices” provide a software transparency mechanism called a “Software Bill of Materials” (SBOM) as part of their premarket submissions. The SBOMs serve as one part of FDA’s evaluation of device security, postmarket vulnerability, and incident response. FDA will continue to monitor device AI cybersecurity considerations in premarket submissions and postmarket issues to a ssess whether additional policy is necessary to safeguard patient safety."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_639",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsoftware transparency mechanism called a “Software Bill of Materials” (SBOM) as part of their premarket submissions. The SBOMs serve as one part of FDA’s evaluation of device security, postmarket vulnerability, and incident response. FDA will continue to monitor device AI cybersecurity considerations in premarket submissions and postmarket issues to a ssess whether additional policy is necessary to safeguard patient safety. • The Digital Health Security (DIGIHEALS) Program is working with AI and cybersecurity experts to strengthen our electronic health ecosystem by adapting proven technologies developed for national security so those technologies can be used in civilian health systems, clinical care facilities, and even personal health devices. HHS near -term priorities: • Encourage Health IT developers to implement privacy and security by design in their products, including building cyber controls into products or offering service APIs to integrate cyber controls into other systems. This can be achieved by: o Enhancing cybersecurity certification criteria in ASTP’s ONC Health IT Certification Program . o Broadening ASTP’s ONC Health IT Certification Program’s scope to include additional health IT systems (e.g., laboratory systems, telemedicine —patient health records, exchange, or access systems, clinician -led clinical data registries, electronic prior authorization systems, and clearinghouse processing systems) ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_640",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nother systems. This can be achieved by: o Enhancing cybersecurity certification criteria in ASTP’s ONC Health IT Certification Program . o Broadening ASTP’s ONC Health IT Certification Program’s scope to include additional health IT systems (e.g., laboratory systems, telemedicine —patient health records, exchange, or access systems, clinician -led clinical data registries, electronic prior authorization systems, and clearinghouse processing systems) . • Partner with healthcare stakeholders to develop guidelines and resources for organizations looking to assess the risks of AI to their organization. This can include acquisitions and procurement guidelines to help small/under -resourced organizations assess the security impact of different AI tools and solutions, train staff on best practices, or for assessing risk for data transfer and data-sharing tools that are considered secure. • Map security risks across HHS value chains of AI systems for security and privacy risks to help address third -party concerns, including corrupt libraries, unvetted data, or label errors.805 • Provide funding to research the impact of cybersecurity on clinical settings. HHS long -term priorities: • Consider partnership with industry and other government agencies to develop Key Risk Indicators and performance thresholds that enhance software transparency. 804 https://www.rand.org/pubs/research_reports/RRA2849 -1.html 805 https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.600 -1.pdf 171 4."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_641",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nrisks to help address third -party concerns, including corrupt libraries, unvetted data, or label errors.805 • Provide funding to research the impact of cybersecurity on clinical settings. HHS long -term priorities: • Consider partnership with industry and other government agencies to develop Key Risk Indicators and performance thresholds that enhance software transparency. 804 https://www.rand.org/pubs/research_reports/RRA2849 -1.html 805 https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.600 -1.pdf 171 4. Clarifying approach to navigate a cute tensions between privacy and fairness and privacy and safety in health and human services. Context: Cybersecurity teams in health and human services contexts need to balance the desire for privacy and data protection with broader goals that are sometimes in contradiction. For instance, an organization may want to enforce strict data privacy and data -sharing restrictions while also aiming for broad data inclusion in AI models to mitigate potential bias or monitor population health. In practice, without standards or guidelines, these conflicting priorities can lead to delayed implementation decisions or sub -optimal design choices that neither sufficiently protect privacy nor lead to broader health -related goals. HHS will work to try to clarify and frame cybersecurity trade -offs to assist stakeholders in making decisions."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_642",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nAI models to mitigate potential bias or monitor population health. In practice, without standards or guidelines, these conflicting priorities can lead to delayed implementation decisions or sub -optimal design choices that neither sufficiently protect privacy nor lead to broader health -related goals. HHS will work to try to clarify and frame cybersecurity trade -offs to assist stakeholders in making decisions. HHS near -term priorities: • Provide guidelines on how organizations can navigate questions of cybersecurity trade -offs and where to focus most on protecting cybersecurity and privacy. 6.5 Conclusion In healthcare, public health, and human services, disruptions from cyber threats directly impact lives. It is crucial for HHS and its broader ecosystem to recognize the growth of cyber threats and take steps to ensure their organizations are protected. Cybersecurity is a fundamental capability for any organization in the broader HHS ecosystem that is looking to expand its use of AI applications responsibly and effectively. However, as noted above, despite widespread awareness of the threat and increased f ocus on cybersecurity, organizations are struggling to keep pace with potential attackers."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_643",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand take steps to ensure their organizations are protected. Cybersecurity is a fundamental capability for any organization in the broader HHS ecosystem that is looking to expand its use of AI applications responsibly and effectively. However, as noted above, despite widespread awareness of the threat and increased f ocus on cybersecurity, organizations are struggling to keep pace with potential attackers. There remains significant opportunity to improve skillsets of cybersecurity talent, establish and promote standards for best practices and governance, reduce the complexity of implementing new capabilities, and assist organizations in balancing questions of cybersecurity and privacy. HHS’s Cybersecurity and Infrastructure Protection strategy will continue to evolve as the threat landscape changes. HHS is committed to assisting its agencies and the broader HHS stakeholders in improving their cybersecurity capabilities and has taken seve ral steps to do so. The Department will continue to consider additional actions to lift the security floor for the healthcare system and to make it easier and safer for organizations to adopt AI applications that positively impact the American people. 172 7 Internal Operations 7.1 Introduction and Context AI presents wide -ranging opportunities for the Department. HHS operating and staff divisions have already been using AI to advance their missions to improve internal operations and enhance the execution of public -facing services."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_644",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto make it easier and safer for organizations to adopt AI applications that positively impact the American people. 172 7 Internal Operations 7.1 Introduction and Context AI presents wide -ranging opportunities for the Department. HHS operating and staff divisions have already been using AI to advance their missions to improve internal operations and enhance the execution of public -facing services. The scale at which AI is used across HHS requires a formal, departmentwide approach. The Department’s approach to AI must also focus on change management and adaptability, as AI implementation and use can transform existing processes. By optimizing Department processes, policies, a nd structures for procuring, testing, deploying, and securely managing AI solutions internally, HHS aims to accelerate knowledge sharing and coordinate support of AI investments. This will ensure greater consistency across the Department while also allowing for appropriate agency -level flexibility to drive innovation. In alignment with E.O. 13859, E.O. 14110 , and OMB Memoranda M -24-10 and M -24-18, HHS’s Office of the Chief Artificial Intelligence Officer (OCAIO) will lead three focal areas needed to deploy high -value, trustworthy AI within HHS, both at the Department level and within HHS’s divisions: 1. Governance 2. Internal process improvement and innovation 3."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_645",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto drive innovation. In alignment with E.O. 13859, E.O. 14110 , and OMB Memoranda M -24-10 and M -24-18, HHS’s Office of the Chief Artificial Intelligence Officer (OCAIO) will lead three focal areas needed to deploy high -value, trustworthy AI within HHS, both at the Department level and within HHS’s divisions: 1. Governance 2. Internal process improvement and innovation 3. Workforce and talent To create a cohesive strategy, these focal areas must be integrated into the major internal operations of HHS divisions and implemented at all departmental levels. This approach will help appropriately balance centralized coordination from the OCAIO with the necessary flexibility needed by HHS divisions to achieve their respective mission goals. Additionally, the Department’s AI Strategy will align with existing policies, frameworks, and statutory responsibilities for IT infrastructure review and deployment. 7.2 Opportunities and Risks Opportunities: Increasing AI adoption and use within the Department’s internal operations presents significant opportunities. These include: 173 1."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_646",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncoordination from the OCAIO with the necessary flexibility needed by HHS divisions to achieve their respective mission goals. Additionally, the Department’s AI Strategy will align with existing policies, frameworks, and statutory responsibilities for IT infrastructure review and deployment. 7.2 Opportunities and Risks Opportunities: Increasing AI adoption and use within the Department’s internal operations presents significant opportunities. These include: 173 1. Improv ing quality, experience, and safety of public -facing programs and services: AI can enable HHS to more effectively deliver health and human services to hundreds of millions of individuals each year by deploying use cases that have been appropriately validated in the private or public sector.806 For example, HHS agencies involved in the direct provision of patient care can leverage technologies for more accurate patient monitoring, and agencies involved in the delivery of human services can use AI to connect beneficiaries with best -fit services i n a more efficient way.807 2. Inform ing policy, guidelines, and processes that support innovation and safe use of AI within HHS: HHS will need to keep pace with a rapidly evolving technology ecosystem to successfully execute its mission."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_647",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nmonitoring, and agencies involved in the delivery of human services can use AI to connect beneficiaries with best -fit services i n a more efficient way.807 2. Inform ing policy, guidelines, and processes that support innovation and safe use of AI within HHS: HHS will need to keep pace with a rapidly evolving technology ecosystem to successfully execute its mission. Piloting and deploying use cases that assist in setting effective guidelines and improving processes will enable HHS to operate more effectively, which in turn enables the Department to best provide oversight and delivery of health and human services in the U .S. 3. Build ing knowledge and capabilities to inform public -facing policy and guidelines for HHS domains: Internal adoption of AI for HHS operations will increase the department's AI knowledge and capabilities. This, in turn, allows HHS to provide more informed policy, guidelines, and oversight of these technologies in HHS’s domains (e.g., healthcare delivery and R&D). 4. Improv ing workforce efficiencies: AI has the potential to automate current manual processes that require direct human staff and contractor time. Leveraging AI to facilitate tasks that can be augmented through technology will allow HHS staff to spend more time performing high -impact activit ies (e.g., review, coordination, enforcement, and direct provision of care where applicable). Risks: The use of AI to support HHS’s mission increases some existing risks while introducing new risks."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_648",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthat require direct human staff and contractor time. Leveraging AI to facilitate tasks that can be augmented through technology will allow HHS staff to spend more time performing high -impact activit ies (e.g., review, coordination, enforcement, and direct provision of care where applicable). Risks: The use of AI to support HHS’s mission increases some existing risks while introducing new risks. Examples of such internal risks include: • Data privacy and security: As HHS divisions gain experience with AI solutions, it is possible that future use cases may use sensitive patient -, participant -, or community -level information to train internal models or produce outputs. These types of uses will need to be managed with the same vigilance as non -AI use cases and may potentially require additional controls or adoption of other technologies depending on the context and data source to ensure that AI use is not creating new vulnerabilities. • Execution risk: Overly strict internal guidelines on exactly when AI may or may not be used risks disincentivizing innovative approaches that could create a positive impact. Research demonstrates that preconceptions about AI and its impact (e.g., on careers or on program participants) can hinder the successful deployment of new AI technologies in the workplace.808, 809 Poor communication with staff at HHS about AI progress and challenges may further exacerbate this risk."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_649",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nor may not be used risks disincentivizing innovative approaches that could create a positive impact. Research demonstrates that preconceptions about AI and its impact (e.g., on careers or on program participants) can hinder the successful deployment of new AI technologies in the workplace.808, 809 Poor communication with staff at HHS about AI progress and challenges may further exacerbate this risk. • Impact on workforce training and skills: Integrating AI into the technical and workforce workflows of HHS divisions opens the door to risks, such as a skills gap if individuals no longer perform tasks that were once part of their scope. This may not be a risk for rote tasks (e.g., calculation, b asic arithmetic, scheduling) but may pose challenges for skills like customer support or other human interaction. Additionally, the use of AI may lead to overreliance, where the staff responsible for overseeing the f unctions supported by AI fail to exercise sufficient oversight. These risks will be considered as part of the proposed actions in Planned HHS Activities below. Successful execution of this Strategic Plan faces additional risks if not appropriately managed. In addressing these or other risks posed by the development and or use of AI, HHS will additionally tailor risk management strategies to the anticipated level of risk associated with a specific model, tool, or use case."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_650",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npart of the proposed actions in Planned HHS Activities below. Successful execution of this Strategic Plan faces additional risks if not appropriately managed. In addressing these or other risks posed by the development and or use of AI, HHS will additionally tailor risk management strategies to the anticipated level of risk associated with a specific model, tool, or use case. Systems incorporating AI should apply 806 https://ftp.cdc.gov/pub/Health_Statistics/NCHS/Dataset_Documentation/NHAMCS/doc21 -ed-508.pdf 807 https://www.nejm.org/doi/full/10.1056/NEJMra2204673 808 https://pubmed.ncbi.nlm.nih.gov/37927664/ 809 https://english.rekenkamer.nl/publications/reports/2024/10/16/focus -on-ai-in-central -government An international example from Netherlands Audit on use of AI in government finding comprehensive AI assessments created significant cost or time requirements disincentivizing use and deploy ment . 174 risk management practices to identify, address, and monitor potentially negative impacts through all phases of relevant processes and system frameworks. 7.3 Governance Context: Effective AI governance throughout the entire solution life cycle —from conceptualization of an AI intervention to execution and decommissioning of the tool —is essential to facilitate appropriate adoption and risk management."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_651",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nuse and deploy ment . 174 risk management practices to identify, address, and monitor potentially negative impacts through all phases of relevant processes and system frameworks. 7.3 Governance Context: Effective AI governance throughout the entire solution life cycle —from conceptualization of an AI intervention to execution and decommissioning of the tool —is essential to facilitate appropriate adoption and risk management. Just as HHS and its divisions have built significant infrastructure around IT to ensure responsible use and minimize risks from improper data sharing, HHS has and will continue to put into place necessary safeguards around AI. AI governance pra ctices will leverage existing HHS and/or division -level governing bodies and processes where possible to ensure strategic alignment and avoid undue burden on HHS divisions. AI governance will take a tailored approach to each division’s unique structures an d needs to promote innovation while minimizing the potential impacts of AI -related risks. Exhibit 1 6 shows the interaction of the OCAIO and HHS agencies and defines at a high level the OCAIO role within HHS. Governance mechanisms illustrated in the Exhibit are further detailed below. Exhibit 16: Interaction of OCAIO and HHS agencies HHS actions to date (non -exhaustive): HHS has already created foundational governance structures to support the use of AI, including: • Hired a permanent CAIO consistent with M -24-10’s requirements ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_652",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand defines at a high level the OCAIO role within HHS. Governance mechanisms illustrated in the Exhibit are further detailed below. Exhibit 16: Interaction of OCAIO and HHS agencies HHS actions to date (non -exhaustive): HHS has already created foundational governance structures to support the use of AI, including: • Hired a permanent CAIO consistent with M -24-10’s requirements . The OCAIO will ensure that all strategic and Department policies, requirements, and guidelines are consistent with government policy and reduce barriers to the responsible use of AI. While the OCAIO holds primary responsibility for the governance of AI so lutions across HHS, the OCAIO will consult and collaborate with other offices in the Department to ensure their broad applicability to HHS divisions. • Created the HHS AI Governance Board to serve as the principal governance body responsible for guiding HHS’s AI policies, programs, and technology uses and ensuring that these policies are aligned to FA VES principles. It provide s recommendations, advice, and monitoring on key issues surrounding AI 175 use. The Board first met in May 2024, is chaired by the Deputy Secretary , co-chaired by CAIO , and is comprised of senior leaders from HHS divisions. It is responsible for supporting AI governance, developing strategic AI priorities across the enterprise, and overseeing strategic execution. The Board will also monitor progress toward HHS’s implementation of this Strategic Plan."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_653",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n175 use. The Board first met in May 2024, is chaired by the Deputy Secretary , co-chaired by CAIO , and is comprised of senior leaders from HHS divisions. It is responsible for supporting AI governance, developing strategic AI priorities across the enterprise, and overseeing strategic execution. The Board will also monitor progress toward HHS’s implementation of this Strategic Plan. • Created the HHS AI Community of Practice (CoP) run by the OCAIO that includes AI -interested staff from across HHS. The goals of the CoP are to provide an opportunity for ongoing learning and collaboration across the Department, surface priority issues for HHS -level and cross -agency coordination by the OCAIO and help i dentify key issues for consideration by the HHS AI Governance Board. The HHS AI CoP also supports workgroups in key topic areas like AI policymaking and AI talent and workforce development. HHS near -term priorities: While HHS has developed the governance approach outlined above, it will take time to refine and implement the more comprehensive structures and processes needed to accelerate the adoption of use cases and ensure organizational readiness for AI -driven missi on enhancements. To further develop these governance practices, the HHS OCAIO will: • Strengthen and formalize a comprehensive governance structure: HHS will expand upon the foundational elements detailed above to support the responsible use of AI within the organization."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_654",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nmore comprehensive structures and processes needed to accelerate the adoption of use cases and ensure organizational readiness for AI -driven missi on enhancements. To further develop these governance practices, the HHS OCAIO will: • Strengthen and formalize a comprehensive governance structure: HHS will expand upon the foundational elements detailed above to support the responsible use of AI within the organization. This will include articulating and documenting roles, responsibilities, and decision rights across key governance bodies. • Provide guidelines to HHS divisions on governance to implement AI within their scope: These guidelines will support the development of any division -specific governance policies needed to execute each agency’s unique missions and will consider the existing structures they have established. • Enrich the Community of Practice by stewarding AI working groups: These groups will share real - time insights on the use of AI across the Department, including shared learning, best practices, and additional avenues for confirming emerging issues. HHS will additionally continue to explore ways to expand the CoP over time to suit the Department’s needs. • Establish a regular cadence for reviewing and revising AI governance structures: The HHS AI Governance Board will establish a process for regularly reviewing HHS AI structures and guidelines (e.g., annually)."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_655",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nshared learning, best practices, and additional avenues for confirming emerging issues. HHS will additionally continue to explore ways to expand the CoP over time to suit the Department’s needs. • Establish a regular cadence for reviewing and revising AI governance structures: The HHS AI Governance Board will establish a process for regularly reviewing HHS AI structures and guidelines (e.g., annually). 7.4 Internal Process Improvement and Innovation Context: HHS must ensure that its processes are set up in a way that facilitates the safe and effective use and development of AI. This spans multiple types of workflows, including acquisitions and procurement (e.g., procurement of AI solutions, use of AI in selecting bespoke tools), prototyping, piloting, and deployment (e.g., creation of analytics engines for disease prevalence monitoring), maintenance and operations (e.g., ensuring ongoing quality and compliance), and security (e.g., avoiding m isuse of sensitive data). Similarly, HHS must align its internal processes for grant -making, grant oversight, and program evaluation as needed to align to best practices for adoption of AI where applicable and maintain programmatic and scientific integrity and sustainability . HHS already has multiple policies guiding each of these areas, and AI uses will need to remain aligned with existing approaches."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_656",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsensitive data). Similarly, HHS must align its internal processes for grant -making, grant oversight, and program evaluation as needed to align to best practices for adoption of AI where applicable and maintain programmatic and scientific integrity and sustainability . HHS already has multiple policies guiding each of these areas, and AI uses will need to remain aligned with existing approaches. For example, sensitive data storage must still be held to the same high bar whether AI is used or not.810, 811 In developing its approach, HHS will evaluate whether to update existing policies (e.g., Authority to 810 https://uscode.house.gov/view.xhtml?path=/prelim@title44/chapter35/subchapter2&edition=prelim 44 U.S.C. §§ 3551 et seq (FISMA) 811 https://www.whitehouse.gov/omb/management/ofcio/m -24-15-modernizing -the-federal -risk-and-authorization -management -program -fedramp/ OMB M -24-04, OMB M -24-15 176 Operate frameworks) to ensure they support the use and development of AI. These policies will also follow OMB M-24-10 and M -24-18 and will include relevant additional steps to identify and mitigate risks, such as when an AI solution has been deemed “rights impacting” or “safety impacting.” HHS actions to date (non -exhaustive): HHS has already set the foundation for the use of AI, including: • Compil ed the AI Use Case Inventory , in accordance with EO 13960, and provided a public inventory of non -classified and non -sensitive current and planned AI use cases."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_657",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nan AI solution has been deemed “rights impacting” or “safety impacting.” HHS actions to date (non -exhaustive): HHS has already set the foundation for the use of AI, including: • Compil ed the AI Use Case Inventory , in accordance with EO 13960, and provided a public inventory of non -classified and non -sensitive current and planned AI use cases. This inventory details ways in which HHS can leverage AI and includes oversight methodologies and benefits. In 202 4, the AI Use Case Inventory included 271 use cases across 13 agencies. EO 13960 initiated this use case library , which EO 141110 later endorsed and enhanced. HHS will update the inventory annually, consistent with the new requirements expressed in OMB Memo M -24-10. HHS near -term priorities: In addition to cataloging the Department’s AI use cases, HHS intends to build the necessary internal processes and support structures to enable the adoption of responsible AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_658",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthis use case library , which EO 141110 later endorsed and enhanced. HHS will update the inventory annually, consistent with the new requirements expressed in OMB Memo M -24-10. HHS near -term priorities: In addition to cataloging the Department’s AI use cases, HHS intends to build the necessary internal processes and support structures to enable the adoption of responsible AI. To this end, the HHS OCAIO will: • Coordinate the development of enterprise AI procurement approaches and toolkits: This work will provide guidelines at the HHS level to promote a standardized approach to procuring AI tools, technologies, and subject matter expertise and will be designed in close collaboration with HHS divisions to ensure it provides sufficient guidelin es across HHS and remains aligned to Federal Information Technology Acquisition Reform Act requirements .812 The HHS OCAIO will additionally explore the inclusion of AI -specific language into the HHS Acquisition Regulations813 and other relevant policies.814 • Support responsible prototyping and piloting: This support will include establishing, co -leading, and funding pilots at both the Department and division levels to address enterprise solutions applicable to numerous HHS divisions and unique mission -specific uses."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_659",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nrequirements .812 The HHS OCAIO will additionally explore the inclusion of AI -specific language into the HHS Acquisition Regulations813 and other relevant policies.814 • Support responsible prototyping and piloting: This support will include establishing, co -leading, and funding pilots at both the Department and division levels to address enterprise solutions applicable to numerous HHS divisions and unique mission -specific uses. The HHS OCAIO intends to help facilita te the establishment and use of “AI sandboxes” for rapid prototyping and solution evaluation (e.g., testing whether an algorithm leads to the desired result), and security assessments (e.g., will deployment of algorithm exacerbate or create new cybersecurity risks for HHS) prior to cross -department deployment. • Ensure oversight for AI quality monitoring: Ultimately, HHS and divisions will be responsible for ensuring the compliance of AI with applicable standards. The HHS OCAIO will implement monitoring systems for AI solutions at the department level (including accuracy, reliability, and traceability) and will advance and support capabilities for monitoring AI tools. The OCAIO will additionally issue, as applicable, guidelines to HHS divisions for establishing division -specific monitoring systems for t heir agency use."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_660",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nfor ensuring the compliance of AI with applicable standards. The HHS OCAIO will implement monitoring systems for AI solutions at the department level (including accuracy, reliability, and traceability) and will advance and support capabilities for monitoring AI tools. The OCAIO will additionally issue, as applicable, guidelines to HHS divisions for establishing division -specific monitoring systems for t heir agency use. • Ensure oversight and update processes to promote AI security: Distinct from the quality monitoring above, the HHS OCAIO will work with the Office of the Chief Information Officer (OCIO) to ensure AI use cases meet applicable security requirements. Consistent with its responsibilities, OCIO will follow its processes t o ensure that IT utilizing AI is properly secured and will update security processes as needed to reflect the changing AI landscape. The OCAIO and OCIO will collaborate with other HHS stakeholde rs to ensure these processes can be applied across HHS divisions. • Issue guidelines on use of AI: The HHS OCAIO will provide guidelines to help HHS divisions determine when and under what circumstances it makes the most sense to use AI solutions."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_661",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nneeded to reflect the changing AI landscape. The OCAIO and OCIO will collaborate with other HHS stakeholde rs to ensure these processes can be applied across HHS divisions. • Issue guidelines on use of AI: The HHS OCAIO will provide guidelines to help HHS divisions determine when and under what circumstances it makes the most sense to use AI solutions. The 812 https://www.cio.gov/handbook/it -laws/fitara -2014/ 813 https://www.hhs.gov/grants -contracts/contracts/contract -policies -regulations/hhsar/index.html 814 https://www.hhs.gov/grants -contracts/contracts/contract -policies -regulations/hhsar/index.html 177 guidelines will also include the specific steps that must be taken for rights —and safety -impacting AI use cases and other AI -use cases as needed815 consistent with EOs, OMB M -24-10, and other guidelines. 7.5 Workforce and Talent Context: The goal of an AI -enabled workforce is to allow individuals to perform their duties safely and effectively, leveraging AI tools where reasonable to assist in their workflows. HHS will continue to evaluate opportunities to leverage AI in daily workflows and aims to be responsive to a dynamically changing technological landscape in the Department. In certain scenarios, AI can optimally allow individuals to reallocate their time to the highest - impact areas, for example, by minimizing time spent on manual data analysis and spending more time on decision - making and program improvement."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_662",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nopportunities to leverage AI in daily workflows and aims to be responsive to a dynamically changing technological landscape in the Department. In certain scenarios, AI can optimally allow individuals to reallocate their time to the highest - impact areas, for example, by minimizing time spent on manual data analysis and spending more time on decision - making and program improvement. Existing federal actions: Other federal agencies have already prioritized enabling workforce and talent using AI, namely by: • Developed the Office of Personnel Management’s (OPM) “Workforce of the Future” playbook in February 2024 which details workforce strategy and offers guidelines for federal agencies on the integration of AI. In particular, the playbook includes several calls to action for federal agencies, including leveraging appropriate AI capabilities into HR processes, understa nding how AI will impact the workforce, upskilling teams with appropriate competencies, and training the workforce on AI use cases.816 • Included AI roles within OPM’s Direct Hire Authority (DHA) framework in December 2023 which allow ed federal agencies to bypass specific hiring processes for high -demand fields. This strategic decision enables agencies to attract and hire skilled AI specialists who can meet complex agency requirements without traditional hiring procedures that may otherw ise deter them from joining government agencies."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_663",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n• Included AI roles within OPM’s Direct Hire Authority (DHA) framework in December 2023 which allow ed federal agencies to bypass specific hiring processes for high -demand fields. This strategic decision enables agencies to attract and hire skilled AI specialists who can meet complex agency requirements without traditional hiring procedures that may otherw ise deter them from joining government agencies. Building on this authority, HHS has developed standard AI Position Descriptions to increase hiring speed using the DHA across the Department. • Piloted GenAI to enable workforce to automate previously manual data analysis that informs decision -making and program improvement . ASTP’s CAIO and Office of Policy are exploring how GenAI can streamline the end -to-end process of managing, analyzing, and incorporating public comments during federal rulemaking. The focus is on using engineered prompts to produce usable comment summaries for the Office of Policy’s rulemaking activities. HHS near -term priorities: To establish an AI -enabled workforce, the HHS OCAIO will: • Collaborate with governmentwide leaders to develop an AI hiring strategy: The HHS OCAIO will collaborate with other government stakeholders (including the OPM and Office of Management and Budget) to develop a strategy for hiring skilled AI specialists."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_664",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsummaries for the Office of Policy’s rulemaking activities. HHS near -term priorities: To establish an AI -enabled workforce, the HHS OCAIO will: • Collaborate with governmentwide leaders to develop an AI hiring strategy: The HHS OCAIO will collaborate with other government stakeholders (including the OPM and Office of Management and Budget) to develop a strategy for hiring skilled AI specialists. This strategy could include identifying AI needs at the Department level, evaluat ing pay scales for AI roles, and establishing shared resources to be used across federal entities (e.g., AI -related position descriptions). • Collaborate with HHS leaders to perform a gap assessment of AI skills: The HHS OCAIO will collaborate with the HHS Chief Human Capital Officer and other division workforce leaders to perform a gap assessment of the Department’s current workforce AI capabilities. This will identify areas for targeted intervention, which may includ e upskilling current talent or recruiting new talent (either within 815 Controls should be in place even where AI is not rights/safety impacting, for example, individual data protection controls, I P rights controls, contractual compliance, records management, and protection of CUI/procurement sensitive/trade secrets/other non -individual data, among other considerations . 816 https://www.opm.gov/workforce -of-the-future/wof -playbook.pdf 178 the federal government or externally) with these skills."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_665",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ntalent or recruiting new talent (either within 815 Controls should be in place even where AI is not rights/safety impacting, for example, individual data protection controls, I P rights controls, contractual compliance, records management, and protection of CUI/procurement sensitive/trade secrets/other non -individual data, among other considerations . 816 https://www.opm.gov/workforce -of-the-future/wof -playbook.pdf 178 the federal government or externally) with these skills. The gap assessment’s output will additionally inform a funding plan for closing identified gaps. • Improve AI literacy for all HHS staff: In addition to the gap analysis, the HHS OCAIO will facilitate the delivery of foundational AI literacy training to help all HHS staff and contractors become more comfortable with AI and share an understanding of the potential benefits, limitations, and r isks of AI technologies. 7.6 Conclusion In this chapter, HHS outlined the steps the Department has taken and will continue to take in the future to realize the benefits of AI in its internal operations and stay nimble and current with the rapidly evolving AI landscape. HHS recognizes that the transformative potential for AI extends to its own internal operations and not just to the work of its divisions and of the many stakeholder s of the health and human services ecosystem."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_666",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nin the future to realize the benefits of AI in its internal operations and stay nimble and current with the rapidly evolving AI landscape. HHS recognizes that the transformative potential for AI extends to its own internal operations and not just to the work of its divisions and of the many stakeholder s of the health and human services ecosystem. HHS sees significant opportunity for AI to improve its public -facing programs and services, improve processes that support innovation at HHS, inform policy and guidelines, and improve workforce efficiencies. Th ese opportunities, if responsibly undertaken, could enable the Department to better fulfill its mission of improving the health and well - being of the American people. 179 Conclusion HHS aims to be a global leader in innovating and adopting responsible AI to achieve unparalleled advances in the health and well -being of all Americans. This Strategic Plan outlines the ways in which HHS intends to achieve that goal. The use of AI in medical research and discovery, medical product development, safety, and effectiveness, healthcare delivery, human service s delivery, public health, cybersecurity, and HHS’s operations is no longer a speculative future but a present reality, driven by rapid technological advancements. In recent years, AI has become part of everyday life, including within the health , human services , and public health ecosystem."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_667",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nin medical research and discovery, medical product development, safety, and effectiveness, healthcare delivery, human service s delivery, public health, cybersecurity, and HHS’s operations is no longer a speculative future but a present reality, driven by rapid technological advancements. In recent years, AI has become part of everyday life, including within the health , human services , and public health ecosystem. This evolution is evident in the ability of AI to serve as a tool that supports d elivering high -quality care, streamlining drug development, speeding and improving health and human services communications, and more.817 Moreover, AI can enhance health equity, for example through providing real -time, automated translation services for individuals facing language barriers or supporting individuals with disabilities through optimized speech patterns and fluent conversation.818 The use of AI brings the se and many additional promising benefits discussed throughout the chapters of this Strategic Plan , yet come s with a wide range of risks such as the potential for AI to propagate biases, misclassify patient needs, or breach confidentiality. HHS is dedicated to not only fostering the adoption of AI to achieve enhanced outcomes but also protecting patients, caregivers, and all stakeholders from these and other potential pitfalls discussed in each chapter of the Strategic Plan."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_668",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncome s with a wide range of risks such as the potential for AI to propagate biases, misclassify patient needs, or breach confidentiality. HHS is dedicated to not only fostering the adoption of AI to achieve enhanced outcomes but also protecting patients, caregivers, and all stakeholders from these and other potential pitfalls discussed in each chapter of the Strategic Plan. This commitment i nvolves implementing robust measures to address these challenges while promoting the transformative potential of AI . As AI continues to evolve rapidly, HHS will adopt an equally dynamic approach, iterating on this Plan and overall AI efforts to stay ahead of developments and address emerging challenges. This proactive stance will involve continuous benefit and risk assessment, stakeholder engagement, and the implementation of robust safeguards to ensure ethical and equitable AI use. HHS will also continue to identify bold opportunities and collaborations within and across domains that have potential to improve people’s li ves. HHS divisions will continue to play crucial roles by issuing guidelines and policies, allocating resources, conducting outreach and education programs, and cultivating workforces. HHS encourages community partners, STLT governments, and other public and private sector partners to responsibly pioneer development and use of AI that improves health and human services for Americans."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_669",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthat have potential to improve people’s li ves. HHS divisions will continue to play crucial roles by issuing guidelines and policies, allocating resources, conducting outreach and education programs, and cultivating workforces. HHS encourages community partners, STLT governments, and other public and private sector partners to responsibly pioneer development and use of AI that improves health and human services for Americans. HHS is committed to collaborating with stakeholders to build on the actions detailed throughout this Strategic Plan and address problems faced in health , human services, and public health, all while ensuring safe and responsible use through the guardrails discussed. HHS will continue to support engagement and transparency with partners to foster creating human -centered solutions with meaningful impact. As HHS aims to continue its leadership at the forefront of health , human services , and public health innovation to meet the dynamic needs of the American people, this Plan is just one foundational step supporting the Department’s ability to address the challenges of tomorrow. HHS is committed to supporting AI that enhances the health and well -being of al l Americans."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_670",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nto continue its leadership at the forefront of health , human services , and public health innovation to meet the dynamic needs of the American people, this Plan is just one foundational step supporting the Department’s ability to address the challenges of tomorrow. HHS is committed to supporting AI that enhances the health and well -being of al l Americans. 817 https://www.whitehouse.gov/briefing -room/blog/2023/12/14/delivering -on-the-promise -of-ai-to-improve -health -outcomes/ 818 https://www.forbes.com/councils/forbesbusinesscouncil/2023/06/16/empowering -individuals -with-disabilities -through -ai-technology/ 180 Appendix A: Glossary of Terms Table 1: Glossary of Key Terms819 Term Definition Accountability in AI The principle that AI systems’ creators should be responsible for the outcomes of AI systems, including making amends for any harm caused. AI ethics The branch of ethics that examines the moral implications and societal impacts of artificial intelligence. AI-enabled medical device, AI -enabled device, and/or AI device In this Plan, t he terms “AI/ML -enabled medical device,” “AI -enabled device” and “AI device” may be used interchangeably to refer to one or both of (1) AI software that can perform a medical device purpose ( e.g., diagnose, cure, mitigate, treat, prevent) without being a part of a traditional hardware medical device; and (2) AI software that is part of or integral to a medical device."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_671",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nmedical device,” “AI -enabled device” and “AI device” may be used interchangeably to refer to one or both of (1) AI software that can perform a medical device purpose ( e.g., diagnose, cure, mitigate, treat, prevent) without being a part of a traditional hardware medical device; and (2) AI software that is part of or integral to a medical device. Artificial intelligence (AI) Per Executive Order 14110, section 3(b), and 15 U.S.C. 9401(3), AI is a machine -based system that can, for a given set of human -defined objectives, make predictions, recommendations, or decisions influencing real or virtual environments. Artificial intelligence systems use machine - and human -based inputs to perceive real and virtual environments; abstract such perceptions into models through analysis in an automated manner; and use model inference to formulate options for information or action. Artificial intelligence performance monitoring (AI performance monitoring) Refers to the process of regularly collecting and analyzing data on the use of a deployed AI system to evaluate its performance in accomplishing its intended tasks in real -world settings. The assessment of an AI model’s performance involves various perform ance metrics and criteria depending on the specific application."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_672",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ninformation or action. Artificial intelligence performance monitoring (AI performance monitoring) Refers to the process of regularly collecting and analyzing data on the use of a deployed AI system to evaluate its performance in accomplishing its intended tasks in real -world settings. The assessment of an AI model’s performance involves various perform ance metrics and criteria depending on the specific application. This monitoring typically aims to assess the performance of these AI systems in practice, detect performance degradation or changes (e.g., due to data drift), identify instances of misuse, an d address any safety or usability concerns. Artificial intelligence system (AI system) Any data system, software, hardware, application, tool, or utility that operates in whole or in part using AI. Assistive artificial intelligence ( assistive AI) AI-enabled products designed to assist human decision -making. The AI only provides suggestions, information, or data that helps users make more informed decisions. Assistive AI and Autonomous AI exist on a spectrum. Examples of Assistive AI might include a wearable device that monitors a patient’s vital signs and alerts the user or a healthcare provider when certain metrics are out of the normal range or a product that assists radiologists by showing the location of a potential abnormality."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_673",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nusers make more informed decisions. Assistive AI and Autonomous AI exist on a spectrum. Examples of Assistive AI might include a wearable device that monitors a patient’s vital signs and alerts the user or a healthcare provider when certain metrics are out of the normal range or a product that assists radiologists by showing the location of a potential abnormality. Autonomous artificial intelligence (autonomous AI) AI-enabled products that can perform tasks, operate independently, and make decisions without human intervention, such as AI agents. The level of autonomy can vary based on the product. Assistive AI and Autonomous AI exist on a spectrum. An example of Autonomous AI could be a product that autonomously identifies normal X -rays and creates reports without the need for radiologist intervention. Bias in AI The introduction of prejudiced assumptions and preferences into AI algorithms and datasets, which can lead to unfair outcomes or decisions. 819 Definitions sourced from FDA Digital Health and AI Glossary , CMS AI Playbook , and other resources (e.g., government publications or articles) ."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_674",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nidentifies normal X -rays and creates reports without the need for radiologist intervention. Bias in AI The introduction of prejudiced assumptions and preferences into AI algorithms and datasets, which can lead to unfair outcomes or decisions. 819 Definitions sourced from FDA Digital Health and AI Glossary , CMS AI Playbook , and other resources (e.g., government publications or articles) . 181 Term Definition Biological product Per the Public Health Service Act,820 the term \"biological product\" means a virus, therapeutic serum, toxin, antitoxin, vaccine, blood, blood component or derivative, allergenic product, protein, or analogous product, or arsphenamine or derivative of arsphenamine (or any other trivalent organ ic arsenic compound), applicable to the prevention, treatment, or cure of a disease or condition of human beings. Chatbot A program that enables communication between the LLM and the human through text or voice commands in a way that mimics human -to-human conversation."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_675",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nallergenic product, protein, or analogous product, or arsphenamine or derivative of arsphenamine (or any other trivalent organ ic arsenic compound), applicable to the prevention, treatment, or cure of a disease or condition of human beings. Chatbot A program that enables communication between the LLM and the human through text or voice commands in a way that mimics human -to-human conversation. Clinical decision support (CDS) software Software that is intended to provide decision support for the diagnosis, treatment, prevention, cure, or mitigation of diseases or other conditions Cloud computing A model for enabling ubiquitous, convenient, on -demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or ser vice provider interaction Confabulation in AI A phenomenon where AI models generate false or misleading information despite being presented with accurate data. Continual machine learning The ability of a model to adapt its performance by incorporating new data or experiences over time while retaining prior knowledge/information. The model changes are implemented such that for a given set of inputs, the output may be different before and after the changes are implemented. These changes are typically implemented and validated through a well -defined process that aims at improving performance based on analysis of new data."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_676",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nby incorporating new data or experiences over time while retaining prior knowledge/information. The model changes are implemented such that for a given set of inputs, the output may be different before and after the changes are implemented. These changes are typically implemented and validated through a well -defined process that aims at improving performance based on analysis of new data. In contrast to a locked model, a continual machine learning model has a defined learning process to change its behavior. Convolutional neural network (CNN) A specialized deep neural network architecture that consists of one or more convolution layers that is suited for processing grid -like data, such as images. In a convolution layer, a “filter” (window or template) slides over regions of the input image to i dentify low -level patterns (e.g., edges) by applying convolution (a mathematical dot operation applied to the input data). Different filters can be applied to extract different features, such as edges, textures, or curves in images. Additionally, CNNs can include pooling layers, whose function is to reduce the feature dimensionality while retaining relevant features. These convolution and pooling layers get stacked on top of each other to enable this network to build up a hierarchical understanding of patte rns and makes CNNs effective at tasks like image recognition and computer vision."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_677",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ntextures, or curves in images. Additionally, CNNs can include pooling layers, whose function is to reduce the feature dimensionality while retaining relevant features. These convolution and pooling layers get stacked on top of each other to enable this network to build up a hierarchical understanding of patte rns and makes CNNs effective at tasks like image recognition and computer vision. An important aspect of this network is its ability to conserve spatial information of the original input while still performing the feature extraction. Data card A structured report of relevant characteristics of datasets needed by stakeholders for AI development and evaluation. It contains a descriptive section including descriptive information such as number of samples, collection protocols and associated metadata, and a scorecard section, a quantitative analysis reporting dataset characteristics using relevant criteria and metrics. Data drift Refers to the change in the input data distribution a deployed model receives over time, which can cause the model's performance to degrade. This occurs when the properties of the underlying data change. Data drift can affect the accuracy and reliability o f predictive models."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_678",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nscorecard section, a quantitative analysis reporting dataset characteristics using relevant criteria and metrics. Data drift Refers to the change in the input data distribution a deployed model receives over time, which can cause the model's performance to degrade. This occurs when the properties of the underlying data change. Data drift can affect the accuracy and reliability o f predictive models. For example, medical AI -enabled products can experience data drift due to, statistical differences between the data used for model development and data used in clinical operation due to variations between medical practices or context o f use between training and clinical use, and changes in patient demographics, disease trends, and data collection methods over time. 820 https://uscode.house.gov/view.xhtml?req=(title:42%20section:262%20edition:prelim) 182 Term Definition Data governance The process of managing the availability, usability, integrity, and security of the data in enterprise systems, based on internal data standards and policies that also control data usage. Data privacy The aspect of information technology that deals with an organizations or individual’s ability to determine what data in a computer system can be shared with third parties. Data standard A type of standard, which is an agreed upon approach to allow for consistent measurement, qualification or exchange of an object, process, or unit of information."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_679",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncontrol data usage. Data privacy The aspect of information technology that deals with an organizations or individual’s ability to determine what data in a computer system can be shared with third parties. Data standard A type of standard, which is an agreed upon approach to allow for consistent measurement, qualification or exchange of an object, process, or unit of information. Data standards refer to methods of organizing, documenting, and formatting data to aid in data aggregation, sharing and reuse. Data use agreement (DUA) A legal contract between the entity that owns access to a data source, typically a dataset or database , and a secondary entity that will receive the data, or a subset of it, for reuse. A DUA outlines terms and limitations on how the shared data can be used, and the secondary entity may need to meet certain criteria, such as their affiliated institution, th eir faculty status, and IRB approval for their research study. Examples of limitations include restricting access to the shared data, requiring that any r esearch dissemination include citation of the data and its originating entity, requiring that data files are destroyed at the completion of research period, and restrictions on data use for commercial purposes. DUAs are frequently required for access to data that contain protected health information (PHI). Data -driven AI AI that emphasizes the importance of data in enhancing technology's ability to learn from and augment human intelligence."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_680",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndata and its originating entity, requiring that data files are destroyed at the completion of research period, and restrictions on data use for commercial purposes. DUAs are frequently required for access to data that contain protected health information (PHI). Data -driven AI AI that emphasizes the importance of data in enhancing technology's ability to learn from and augment human intelligence. It involves effective data understanding, governance, and a mindset that extends the value of data toward augmenting business processe s through AI. Deep learning A specialized branch of ML that involves training neural networks with multiple intermediary (hidden) layers that operate between an input layer that receives data and an output layer that presents the final network output. Each layer learns to transform i ts input data into a slightly more abstract and composite representation and produces an output that serves as an input for the next layer. As data propagates through successive layers, these models can learn hierarchical feature representations from the i nput data. For example, in healthcare, deep learning models can be used to identify tumors or suspicious lesions in medical images to support physicians and radiologists in the evaluation of disease. Deepfake A video, photo, or audio recording that seems real but has been manipulated with artificial intelligence technologies."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_681",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nlayers, these models can learn hierarchical feature representations from the i nput data. For example, in healthcare, deep learning models can be used to identify tumors or suspicious lesions in medical images to support physicians and radiologists in the evaluation of disease. Deepfake A video, photo, or audio recording that seems real but has been manipulated with artificial intelligence technologies. The underlying technology can replace faces, manipulate facial expressions, synthesize faces, and synthesize speech. Deepfakes can depict someone appearing to say or do something that they in fact never said or did. Digital health technology (DHT) A system that uses computing platforms, connectivity, software, and/or sensors for healthcare and related uses. These technologies span a wide range of uses, from applications in general wellness to applications as a medical device. They include technologies intended for use as a medical product, in a medical product, or as an adjunct to other medical products (devices, drugs, and biologics). They may also be used to develop or stu dy medical products. Digital twin A set of information constructs that mimics the structure, context, and behavior of a physical asset, is dynamically updated with data from its physical twin throughout its life cycle and informs decisions. The bidirectional interaction between the virtual and the physical is central to the digital twin. Digital twins can enable personalized medicine applications."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_682",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nstu dy medical products. Digital twin A set of information constructs that mimics the structure, context, and behavior of a physical asset, is dynamically updated with data from its physical twin throughout its life cycle and informs decisions. The bidirectional interaction between the virtual and the physical is central to the digital twin. Digital twins can enable personalized medicine applications. For example, the digital twin of a patient could inform clinical decisio ns, such as treatment options and clinical assessments. In addition, digital twins can play a role in assembling large, diverse virtual population cohorts for in silico clinical trials, and in quality assessment and process optimization of drug manufacturi ng processes. 183 Term Definition Drug Per the FD&C Act,821 the term \"drug\" means (A) articles recognized in the official United States Pharmacopoeia, official Homoeopathic Pharmacopoeia of the United States, or official National Formulary, or any supplement to any of them; and (B) articles intended for use in the diagnosis, cure, mitigation, treatment, or prevention of disease in man or other animals; and (C) articles (other than food) intended to affect the structure or any function of the body of man or other animals; and (D) articles intended for use as a compo nent of any article specified in clause (A), (B), or (C)."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_683",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nintended for use in the diagnosis, cure, mitigation, treatment, or prevention of disease in man or other animals; and (C) articles (other than food) intended to affect the structure or any function of the body of man or other animals; and (D) articles intended for use as a compo nent of any article specified in clause (A), (B), or (C). Ensemble methods ML techniques that combine multiple models to improve the overall predictive performance compared to using a single model. This involves training a set of base models, such as neural networks, and then aggregating their predictions to make the final prediction. Some common ensemble methods include bagging (i.e., training multiple models on different subsets of the training data and averaging their predictions), boosting (i.e., training models sequentially where each new model focuses on correcting the errors of the previous model), and stacking (i.e., using the predictions of multiple base models as input features for a higher -level “meta -model” that learns how to best combine them). Explainability \"Refers to a representation of the mechanisms underlying AI systems’ operation.\" (Source: NIST). Explainability may help overcome the opaqueness of black -box systems (i.e., systems where the internal workings and decision -making processes are not transpare nt or readily understandable)."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_684",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nmultiple base models as input features for a higher -level “meta -model” that learns how to best combine them). Explainability \"Refers to a representation of the mechanisms underlying AI systems’ operation.\" (Source: NIST). Explainability may help overcome the opaqueness of black -box systems (i.e., systems where the internal workings and decision -making processes are not transpare nt or readily understandable). These explanations can take various forms, including free -text explanations, saliency maps, Shapley Additive Explanations (SHAP), or relevant input examples from data. The primary intent is to answer the question \"Why\" an AI system made a particular decision. Appropriate Explainable AI (XAI) methods may enable the development of more accurate, fair, interpretable, and transparent AI systems to safely augment human decision -making in healthcare. Exploratory data analysis (EDA) An approach to analyzing datasets to summarize their main characteristics, often with visual methods, before making further assumptions or testing hypotheses. Feature engineering A ML process where attributes from raw data that best represent the underlying patterns are identified for use in training a specific ML model. It involves selecting, transforming, or creating relevant input variables (known as features) to enhance the per formance of ML models. Domain knowledge and data analysis techniques can be used to craft features that capture the inherent relationships in the data."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_685",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nattributes from raw data that best represent the underlying patterns are identified for use in training a specific ML model. It involves selecting, transforming, or creating relevant input variables (known as features) to enhance the per formance of ML models. Domain knowledge and data analysis techniques can be used to craft features that capture the inherent relationships in the data. For example, for a model that can predict heart failure, feature engineering on patient data may involve creating a “risk score” by combining relevant features such as age, blood pressure, cholesterol levels, and a history of cardiovascular disease. Federated learning A decentralized approach to training ML models. Models are trained by each site on data that are kept locally, and model updates are sent to a central server, whereby the central server aggregates these updates to improve a global model. This method is des igned to preserve data privacy, as raw data remain at the local sites and are not centralized. For example, federated learning can allow hospitals to collaborate on a heart disease prediction model without sharing patient data. The model is sent to be trai ned locally at each hospital, and only the model updates from each hospital, not raw data, are sent back and aggregated. This way, individual patient information remains localized, addressing privacy concerns while still benefiting from a collectively impr oved model."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_686",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nhospitals to collaborate on a heart disease prediction model without sharing patient data. The model is sent to be trai ned locally at each hospital, and only the model updates from each hospital, not raw data, are sent back and aggregated. This way, individual patient information remains localized, addressing privacy concerns while still benefiting from a collectively impr oved model. 821 https://uscode.house.gov/view.xhtml?req=(title:21%20section:321%20edition:prelim) 184 Term Definition Foundation models AI models trained using large, typically unlabeled datasets and significant computational resources, that are applicable across a wide range of contexts, including some that the models were not specifically developed and trained for (i.e., emergent capabil ities). These models can serve as a foundation upon which further models can be built and adapted for specific uses through further training (i.e., fine -tuning). These models can perform a range of general tasks, such as text synthesis, image manipulation, and audio generation. These models are based on deep learning architectures like transformers and can use either unimodal or multimodal input data. Generative Adversarial Network (GAN) A deep learning -based model architecture that normally consists of two competing neural networks, a generator, and a discriminator."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_687",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nThese models can perform a range of general tasks, such as text synthesis, image manipulation, and audio generation. These models are based on deep learning architectures like transformers and can use either unimodal or multimodal input data. Generative Adversarial Network (GAN) A deep learning -based model architecture that normally consists of two competing neural networks, a generator, and a discriminator. The goal of the “generator” is to synthesize fake data to fool the “discriminator”, while the “discriminator” tries to discr iminate between the synthesized examples (generator’s output) and the original training data distribution. The goal of the training is to find a point of equilibrium between the two competing networks, and after the training process, the generator learns t o generate new data with the same distribution as the training set. This approach can be used to generate synthetic images. Generative artificial intelligence (GenAI) “The class of AI models that emulate the structure and characteristics of input data to generate derived synthetic content. This can include images, videos, audio, text, and other digital content (Source: E.O. 14110). This is usually done by approximating the statistical distribution of the input data. For example, in healthcare, GenAI can be used to generate annotations on synthetic medical data (e.g., image features, text labels) to help expand datasets for training algorithms."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_688",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndata to generate derived synthetic content. This can include images, videos, audio, text, and other digital content (Source: E.O. 14110). This is usually done by approximating the statistical distribution of the input data. For example, in healthcare, GenAI can be used to generate annotations on synthetic medical data (e.g., image features, text labels) to help expand datasets for training algorithms. Health information exchange (HIE) Health Information Exchange allows healthcare professionals and patients to appropriately access and securely share a patient’s medical information electronically. There are many healthcare delivery scenarios driving the technology behind the different forms of health information exchange available today. Human -in-the-loop machine learning An approach where humans interact with ML models to enhance accuracy and end -user trust in the machine. In human in the loop ML, human interaction is iterative and can lead to continuous performance improvement over time. This interaction is especially rel evant in scenarios where the model might be uncertain about its predictions and needs human guidance for verification. Unlike human in the loop ML, supervised machine learning primarily involves human input during the data labeling phase, after which the a lgorithm trains independently. Labeling or annotation is the process of attaching descriptive information to data. Data itself are unchanged in the annotation process."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_689",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nwhere the model might be uncertain about its predictions and needs human guidance for verification. Unlike human in the loop ML, supervised machine learning primarily involves human input during the data labeling phase, after which the a lgorithm trains independently. Labeling or annotation is the process of attaching descriptive information to data. Data itself are unchanged in the annotation process. Human -centric AI (HCAI) AI that emphasizes the impact of AI technologies on individuals and society, prioritizing human well-being, needs, and goals. Interoperability The ability to communicate and exchange data accurately, effectively, securely, and consistently with different information technology systems, software applications, and networks in various settings, and exchange data such that clinical or operational pur pose and meaning of the data are preserved and unaltered. Key performance indicator (KPI) A measurable value that demonstrates how effectively an organization is achieving key business objectives. 185 Term Definition Large language model (LLM) A type of AI model trained on large text datasets to learn the relationships between words in natural language. These models can apply these learned patterns to predict and generate natural language responses to a wide range of inputs or prompts they recei ve, to conduct tasks like translation, summarization, and question answering."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_690",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n185 Term Definition Large language model (LLM) A type of AI model trained on large text datasets to learn the relationships between words in natural language. These models can apply these learned patterns to predict and generate natural language responses to a wide range of inputs or prompts they recei ve, to conduct tasks like translation, summarization, and question answering. These models are characterized by a vast number of model parameters (i.e., internal learned variables within a trained model). LLMs build on foundational AI models by developing more comprehensive language understanding beyond basic linguistic patterns. For example, in the context of LLMs, chatbot is a program that enables communication between the LLM and the human through text or voice commands in a way that mimics human -to-huma n conversation. Locked model A model that provides the same output each time the same input is applied to it and does not change with use, as its parameters or configuration cannot be updated. In case of AI -enabled medical products, locked models can help ensure consistent performance . Machine learning (ML) A set of techniques that can be used to train AI algorithms to improve performance at a task based on data. Machine learning algorithm (ML algorithm) Step-by-step procedures or set of instructions followed for performing a task or solving a problem. For example, in ML, algorithms are used to train models using data to solve a specific problem."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_691",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nlearning (ML) A set of techniques that can be used to train AI algorithms to improve performance at a task based on data. Machine learning algorithm (ML algorithm) Step-by-step procedures or set of instructions followed for performing a task or solving a problem. For example, in ML, algorithms are used to train models using data to solve a specific problem. Machine learning algorithmic bias (ML algorithmic bias) The term “bias” is used in various contexts in different fields and industries. In the context of AI, bias refers to the systematic deviation in model predictions or outcomes for certain data points or groups compared to others. Here we are focusing on, al gorithmic bias, where such deviations can stem from various sources, such as the characteristics of the training dataset, choices made during model development, data processing irregularities, or biases introduced during data collection or from human decis ions. Algorithmic bias can lead to a systematic difference or error in treatment of certain objects, people, or groups in comparison to others, or prediction failures that can result in other risks, where treatment is any kind of action, including percepti on, observation, representation, prediction, or decision. Machine learning model (ML model) A mathematical construct that generates an inference or prediction for input data. This model is the result of an ML algorithm learning from data."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_692",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\npeople, or groups in comparison to others, or prediction failures that can result in other risks, where treatment is any kind of action, including percepti on, observation, representation, prediction, or decision. Machine learning model (ML model) A mathematical construct that generates an inference or prediction for input data. This model is the result of an ML algorithm learning from data. Models are trained by algorithms, which are step-by-step procedures used to process data and derive results. AI systems (e.g., AI -enabled medical devices) employ one or more models to achieve their intended purpose. 186 Term Definition Medical device Per the FD&C Act,822 \"device\" means an instrument, apparatus, implement, machine, contrivance, implant, in vitro reagent, or other similar or related article, including any component, part, or accessory, which is (A) recognized in the official National Formulary, or the Unite d States Pharmacopeia, or any supplement to them, (B) intended for use in the diagnosis of disease or other conditions, or in the cure, mitigation, treatment, or prevention of disease, in man or other animals, or (C) intended to affect the structure or any function of the body of man or other animals, and which does not achieve its primary intended purposes through chemical action within or on the body of man or other animals and which is not dependent upon being metabolized for the achievement of its prima ry intended purposes."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_693",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nor other animals, or (C) intended to affect the structure or any function of the body of man or other animals, and which does not achieve its primary intended purposes through chemical action within or on the body of man or other animals and which is not dependent upon being metabolized for the achievement of its prima ry intended purposes. The term “device” does not include software functions pursuant to section 520(o). Note that some software -based behavioral interventions are medical devices under FDA’s statute, whereas others, such as those software functions that are “intended for maintaining or encouraging a healthy lifestyle” and are “unrelated to the diagnosis, cure, mitigation, preventio n, or treatment of a disease or condition,” are not. See sections 201(h) and 520(o)(1)(B) of the FD&C Act.823 Medical products In this Plan, the term “medical products” refers collectively to drugs, biological products, and medical devices (including some software -based behavioral interventions) as defined in this glossary. Metrics Quantitative measures used to track and assess the status of specific processes, projects, or activities. Model calibration The process of adjusting predicted probabilities generated by an ML model to ensure that they accurately reflect the observed frequencies of events or outcomes in the real world."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_694",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand medical devices (including some software -based behavioral interventions) as defined in this glossary. Metrics Quantitative measures used to track and assess the status of specific processes, projects, or activities. Model calibration The process of adjusting predicted probabilities generated by an ML model to ensure that they accurately reflect the observed frequencies of events or outcomes in the real world. For example, if a model is well calibrated and predicts 20% probability of breast cancer for a patient, then the observed frequency of breast cancer should be approximately 20 out of 100 patients that were given such a prediction by the model. Model card A structured report of relevant technical characteristics of an AI model and benchmark evaluation results in a variety of conditions, such as across different cultural, demographic, or phenotypic groups and intersectional groups that are relevant to the in tended application domains. Model cards also provide information about the context in which models are intended to be used and details of how their performance was assessed. Model deployment The process of integrating a machine learning model into an existing production environment to make practical and actionable predictions. Model fitting The process of training an ML model to capture underlying patterns in the data by adjusting the training parameters to make the model’s predictions as close as possible to the target values in the training data."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_695",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nassessed. Model deployment The process of integrating a machine learning model into an existing production environment to make practical and actionable predictions. Model fitting The process of training an ML model to capture underlying patterns in the data by adjusting the training parameters to make the model’s predictions as close as possible to the target values in the training data. This adjustment of the parameters enables th e model to generalize its understanding of the data, making it useful for making predictions on new, unseen data. A well - fit model does not overfit or underfit but performs well both on the training data and on new, unseen data, due to correctly capturing the relationships between the input and target variables. 822 https://uscode.house.gov/view.xhtml?req=(title:21%20section:321%20edition:prelim) 823 https://uscode.house.gov/view.xhtml?req=(title:21%20section:321%20edition:prelim) 187 Term Definition Model robustness The ability of an ML model to maintain its target or specified level of performance under different circumstances. These circumstances can include noisy data (e.g., data containing errors, inconsistencies, and missing values), unseen data or data drift, or adversarial attacks that manipulate the data to deceive the model."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_696",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand target variables. 822 https://uscode.house.gov/view.xhtml?req=(title:21%20section:321%20edition:prelim) 823 https://uscode.house.gov/view.xhtml?req=(title:21%20section:321%20edition:prelim) 187 Term Definition Model robustness The ability of an ML model to maintain its target or specified level of performance under different circumstances. These circumstances can include noisy data (e.g., data containing errors, inconsistencies, and missing values), unseen data or data drift, or adversarial attacks that manipulate the data to deceive the model. For example, in healthcare, challenges in model robustness can arise in medical image classification, where variations in imaging conditions like lighting or resolution, can affect the per formance of a tumor classification model trained on standardized images. Model weight A numerical parameter within an AI model that helps determine the model’s outputs in response to inputs. Multimodal An approach for processing and integrating multiple different data types, aiming to capture and leverage the relationships between them for a better understanding of the input information or improved prediction performance. These data types may include text, images, audio, video, genomics, sensor data, etc."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_697",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nparameter within an AI model that helps determine the model’s outputs in response to inputs. Multimodal An approach for processing and integrating multiple different data types, aiming to capture and leverage the relationships between them for a better understanding of the input information or improved prediction performance. These data types may include text, images, audio, video, genomics, sensor data, etc. These different data types may be processed using a sing le multimodal network (e.g., based on neural network, or other architectures) or through separate unimodal networks (e.g., LLMs for text and CNNs for images) where the unimodal outputs are combined. For example, in healthcare, data from electronic health r ecords and wearable biosensors can be combined to enable remote monitoring of patients. National Vital Statistics System (NVSS) The National Vital Statistics System is the oldest and most successful example of inter - governmental data sharing in Public Health and the shared relationships, standards, and procedures form the mechanism by which NCHS collects and disseminates the Nation ’s official vital statistics. These data are provided through contracts between NCHS and vital registration systems operated in the various jurisdictions legally responsible for the registration of vital events —births, deaths, marriages, divorces, and feta l deaths."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_698",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ndata sharing in Public Health and the shared relationships, standards, and procedures form the mechanism by which NCHS collects and disseminates the Nation ’s official vital statistics. These data are provided through contracts between NCHS and vital registration systems operated in the various jurisdictions legally responsible for the registration of vital events —births, deaths, marriages, divorces, and feta l deaths. Natural language processing (NLP) A subfield of AI and linguistics that enables computers to understand, process, interpret, and generate human language. NLP systems can perform tasks such as text classification, sentiment analysis, and translation, using techniques from computational linguistics and ML to process and analyze natural language data. Natural La nguage Generation is one application of NLP, which involves using AI systems to produce human -readable text outputs like summaries, reports, stories, or responses. Neural network A computational model inspired by the structure of the human brain. It is composed of interconnected nodes, or “neurons” organized into layers: an input layer that receives data, one or more hidden layers that process and identify patterns in the data, and an output layer that presents the final network output. Overfitting In ML, overfitting occurs when a model learns the training data too thoroughly, capturing not just the fundamental patterns, but also noise or random fluctuations."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_699",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nor “neurons” organized into layers: an input layer that receives data, one or more hidden layers that process and identify patterns in the data, and an output layer that presents the final network output. Overfitting In ML, overfitting occurs when a model learns the training data too thoroughly, capturing not just the fundamental patterns, but also noise or random fluctuations. Such a model might excel on the training data, but struggles to generalize to new, unseen da ta. Performance metrics In the context of AI quantitative or qualitative measures that can be used to assess the ability of a model to produce the desired output for a given task. The choice of the metrics depends on the specific task and the model objectives. Examples of quantit ative metrics include accuracy, precision, sensitivity (recall), specificity, F1 -score, and Area under the Receiver Operating Characteristic curve (AUC -ROC). Qualitative measures may involve heatmap evaluations or visual interpretations. These metrics enab le systematic evaluation, comparison, and refinement of models, and aid in the assessment of whether the model meets its intended objectives."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_700",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand the model objectives. Examples of quantit ative metrics include accuracy, precision, sensitivity (recall), specificity, F1 -score, and Area under the Receiver Operating Characteristic curve (AUC -ROC). Qualitative measures may involve heatmap evaluations or visual interpretations. These metrics enab le systematic evaluation, comparison, and refinement of models, and aid in the assessment of whether the model meets its intended objectives. 188 Term Definition Personally identifiable information (PII) Any information about an individual maintained by an agency, including (1) any information that can be used to distinguish or trace an individual’s identity, such as name, social security number, date and place of birth, mother‘s maiden name, or biometric records; and (2) any other information that is linked or linkable to an individual, such as medical, educational, financial, and employment information. Pharmacovigilance Per FDA’s Guidance for Industry: Good Pharmacovigilance Practices and Pharmacoepidemiologic Assessment,824 which applies to activities with respect to drugs and biological products (excluding blood and blood components), the term “pharmacovigilance” refers to “all scientific and data gathering activities relating to the detection, assessment, and understanding of adverse events. This includes the use of pharmacoepidemiologic studies."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_701",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nfinancial, and employment information. Pharmacovigilance Per FDA’s Guidance for Industry: Good Pharmacovigilance Practices and Pharmacoepidemiologic Assessment,824 which applies to activities with respect to drugs and biological products (excluding blood and blood components), the term “pharmacovigilance” refers to “all scientific and data gathering activities relating to the detection, assessment, and understanding of adverse events. This includes the use of pharmacoepidemiologic studies. These activities are undertaken with the goal of identifying adverse events and understanding, to the extent possible, their nature, frequency, and potential risk factors.” Predictive analytics The use of data, statistical algorithms, and ML techniques to identify the likelihood of future outcomes based on historical data. Privacy in AI The protection of personal data and information in the development and application of AI systems, ensuring data is used ethically and with consent. Privacy -enhancing technology Any software or hardware solution, technical process, technique, or other technological means of mitigating privacy risks arising from data processing, including by enhancing predictability, manageability, disassociability, storage, security, and confident iality. These technological means may include secure multiparty computation, homomorphic encryption, zero -knowledge proofs, federated learning, secure enclaves, differential privacy, and synthetic -data-generation tools."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_702",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand with consent. Privacy -enhancing technology Any software or hardware solution, technical process, technique, or other technological means of mitigating privacy risks arising from data processing, including by enhancing predictability, manageability, disassociability, storage, security, and confident iality. These technological means may include secure multiparty computation, homomorphic encryption, zero -knowledge proofs, federated learning, secure enclaves, differential privacy, and synthetic -data-generation tools. Proof of concept (PoC) An early stage of project development that demonstrates the feasibility of an idea or technology to prove its potential application in solving a particular problem. Protected health information (PHI) Individually identifiable health information transmitted or maintained by a covered entity or its business associates in any form or medium (45 CFR 160.103). The definition exempts a small number of categories of individually identifiable health information, such as individually identifiable health information found in employment records held by a covered entity in its role as an employer. Reading comprehension and generation (RAG) An AI technique used to enhance the understanding and generation of text by providing a data pool for reference, aiming to avoid issues like hallucination in language models."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_703",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncategories of individually identifiable health information, such as individually identifiable health information found in employment records held by a covered entity in its role as an employer. Reading comprehension and generation (RAG) An AI technique used to enhance the understanding and generation of text by providing a data pool for reference, aiming to avoid issues like hallucination in language models. Reference standard (in artificial intelligence) The best available method for establishing or measuring the true state or property of the phenomenon being examined, often represented in the form of labeled data in AI. It serves as a benchmark against which the outputs of a model are evaluated. In clinical settings and medical research, a reference standard is a diagnostic measure or method that is the gold standard clinically and is used to validate the results. For instance, a reference standard can indicate the presence, extent, and location of diseases or abnormalities. Labeling or annotation is the process of attaching descriptive information to data. Data itself are unchanged in the annotation process. 824 https://www.fda.gov/media/71546/download 189 Term Definition Reinforcement learning A ML approach where a model (or agent) learns by taking actions and getting rewards or penalties through its interactions with an environment."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_704",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nindicate the presence, extent, and location of diseases or abnormalities. Labeling or annotation is the process of attaching descriptive information to data. Data itself are unchanged in the annotation process. 824 https://www.fda.gov/media/71546/download 189 Term Definition Reinforcement learning A ML approach where a model (or agent) learns by taking actions and getting rewards or penalties through its interactions with an environment. The model learns from the consequences of its actions, rather than from being explicitly taught, and selects its actions based on its past experiences (exploitation) and by making new choices (exploration), which is essentially trial and error learning. For example, in healthcare, reinforcement learning can be used for recommending personalized treatment plans for pa tients with chronic diseases. The model is given patient data, including their medical history, current health status, and treatment responses, and then suggests a treatment plan. The key is the feedback loop: as patient data is continually updated with in formation on how well they are responding to the treatment, the model adjusts its recommendations accordingly. This process involves a lot of trial and error, as the model learns from each patient interaction. Over time, through many such interactions, the model becomes more adept at predicting and recommending the most effective treatment plans for individual patients."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_705",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\ncontinually updated with in formation on how well they are responding to the treatment, the model adjusts its recommendations accordingly. This process involves a lot of trial and error, as the model learns from each patient interaction. Over time, through many such interactions, the model becomes more adept at predicting and recommending the most effective treatment plans for individual patients. Reliability in AI The ability of AI systems to operate consistently under specific conditions, delivering accurate and dependable outcomes. Responsible AI (RAI) AI practices that uphold society’s moral values, ensuring AI systems function fairly, as intended, and are accountable for their results. This includes adherence to principles like fairness, transparency, accountability, safety, privacy, and reliability. Robustness in AI The strength of an AI system to maintain its performance in the face of changing conditions or when dealing with unexpected or adversarial inputs. Sandbox A safe, controlled, restricted environment that allows for testing products, regulatory approaches, and other technologies without being subject to specific regulations that otherwise (i.e., outside the safe, controlled, restricted sandbox environment) wou ldn't be allowed by law. Scalable and interoperable AI AI that ensures adoption within an organization is efficient, adaptable, and harmonious with existing workstreams, enabling AI-based solutions to grow and operate in sync with the agency’s goals."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_706",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nproducts, regulatory approaches, and other technologies without being subject to specific regulations that otherwise (i.e., outside the safe, controlled, restricted sandbox environment) wou ldn't be allowed by law. Scalable and interoperable AI AI that ensures adoption within an organization is efficient, adaptable, and harmonious with existing workstreams, enabling AI-based solutions to grow and operate in sync with the agency’s goals. Self-supervised machine learning ML algorithms that generate their own labels from the available unlabeled data. Unlike supervised learning, where labeled data are provided, and unsupervised learning, which uncovers hidden patterns without labels, self -supervised learning leverages the in herent structure within the data to create its own labels. This approach is useful when labeled data are limited or unavailable. Semi -supervised machine learning ML algorithms that leverage both unsupervised and supervised techniques. Supervised learning techniques are trained using labeled data, while unsupervised learning techniques are trained using unlabeled data. Labeling or annotation is the process of attach ing descriptive information to data. Data itself are unchanged in the annotation process. For example, consider the task of diagnosing lung diseases from chest X -rays."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_707",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nML algorithms that leverage both unsupervised and supervised techniques. Supervised learning techniques are trained using labeled data, while unsupervised learning techniques are trained using unlabeled data. Labeling or annotation is the process of attach ing descriptive information to data. Data itself are unchanged in the annotation process. For example, consider the task of diagnosing lung diseases from chest X -rays. A semi -supervised learning model would initially be trained on a small set of labeled X -ray images, where each image has been marked by radiologists as showing signs of specific lung conditions or being normal. The model then uses this knowledge to start making predictions on a larger set of unlabeled images. Supervised machine learning ML algorithms where labeled data is provided, and algorithms are trained using the labeled data. Labeling or annotation is the process of attaching descriptive information to data. Data itself is unchanged in the annotation process. 190 Term Definition Synthetic data Data that have been created artificially (e.g., through statistical modeling, computer simulation) so that new values and/or data elements are generated. Generally, synthetic data are intended to represent the structure, properties and relationships seen i n actual patient data, except that they do not contain any real or specific information about individuals."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_708",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe annotation process. 190 Term Definition Synthetic data Data that have been created artificially (e.g., through statistical modeling, computer simulation) so that new values and/or data elements are generated. Generally, synthetic data are intended to represent the structure, properties and relationships seen i n actual patient data, except that they do not contain any real or specific information about individuals. For example, in healthcare, synthetic data are artificial data that are intended to mimic the properties and relationships seen in real patient data. Synthetic data are examples that have been partially or fully generated using computational techniques rather than acquired from a human subject by a physical system. Test data These data are used to characterize the performance of an AI system. These data are never shown to the algorithm during training and are used to estimate the AI model’s performance after training. Testing is conducted to generate evidence to establish the performance of an AI system before the system is deployed or marketed. For AI -enabled medical products, test data should be independent of data used for training and tuning. Testbed A facility or mechanism equipped for conducting rigorous, transparent, and replicable testing of tools and technologies, including AI and privacy -enhancing technologies, to help evaluate the functionality, usability, and performance of those tools or techn ologies."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_709",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nthe system is deployed or marketed. For AI -enabled medical products, test data should be independent of data used for training and tuning. Testbed A facility or mechanism equipped for conducting rigorous, transparent, and replicable testing of tools and technologies, including AI and privacy -enhancing technologies, to help evaluate the functionality, usability, and performance of those tools or techn ologies. Training data These data are used by the manufacturer of an AI system in procedures and training algorithms to build an AI model, including to define model weights, connections, and components. Transfer learning A strategic approach within ML wherein a model developed for a particular task is adapted for a second task. This approach leverages the knowledge and patterns acquired from a previously solved problem (source task) to boost the performance and learning efficiency of a model on a subsequent, often similar, problem (target task). For example, in healthcare, a model trained to identify tumors in lung X -ray images might leverage the learned patterns to improve the identification of abnormalities in liver ultrasound images. Transparency and explainability in AI The ability of AI systems to be understood and the processes and outcomes explained in human terms. Tuning data This data is typically used by the manufacturer of an AI system to evaluate a small number of trained models."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_710",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nimages might leverage the learned patterns to improve the identification of abnormalities in liver ultrasound images. Transparency and explainability in AI The ability of AI systems to be understood and the processes and outcomes explained in human terms. Tuning data This data is typically used by the manufacturer of an AI system to evaluate a small number of trained models. This process involves exploring various aspects, including different architectures or hyperparameters (i.e., parameters used to tune the model for the task). T he tuning phase happens before the testing phase of the AI system and is part of the training process. While the AI and ML communities sometimes use the term “validation” to refer to the tuning data and phase, the FDA will not typically use th e word “validation” in this context due to its specific regulatory definition (see 21 CFR 820.3(z)). Underfitting In ML, underfitting happens when a model does not capture the patterns and complexity of the training data, leading to poor performance on both the training and new, unseen data. Unsupervised machine learning ML algorithms that only make use of unlabeled data during training. Unsupervised learning seeks to uncover hidden patterns or structures within the data. User experience (UX) design The process of designing products, systems, or services with a focus on the quality and efficiency of the user's interaction with and experience of the product."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_711",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand new, unseen data. Unsupervised machine learning ML algorithms that only make use of unlabeled data during training. Unsupervised learning seeks to uncover hidden patterns or structures within the data. User experience (UX) design The process of designing products, systems, or services with a focus on the quality and efficiency of the user's interaction with and experience of the product. User research Research conducted to understand the behaviors, needs, and motivations of users through observation techniques, task analysis, and other feedback methodologies. Watermarking The act of embedding information, which is typically difficult to remove, into outputs created by AI—including into outputs such as photos, videos, audio clips, or text —for the purposes of verifying the authenticity of the output or the identity or charact eristics of its provenance, modifications, or conveyance."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_712",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nof users through observation techniques, task analysis, and other feedback methodologies. Watermarking The act of embedding information, which is typically difficult to remove, into outputs created by AI—including into outputs such as photos, videos, audio clips, or text —for the purposes of verifying the authenticity of the output or the identity or charact eristics of its provenance, modifications, or conveyance. 191 Table 2: Acronyms Term Full Form Text ACF Administration for Children and Families ACL Administration for Community Living AHRQ Agency for Healthcare Research and Quality AI Artificial intelligence AIDR AI data readiness ARPA -H Advanced Research Projects Agency for Health ASPR Administration for Strategic Preparedness and Response ASTP/ONC Assistant Secretary for Technology Policy/Office of the National Coordinator for Health Information Technology ATSDR Agency for Toxic Substances and Disease Registry CAIO Chief AI Officer CBER Center for Biologics Evaluation and Research CDC Centers for Disease Control and Prevention CDER Center for Drug Evaluation and Research CDRH Center for Devices and Radiological Health CDS Clinical Decision Support CGMP Current Good Manufacturing Practices CMS Centers for Medicare & Medicaid Services CPT® Current Procedural Terminology CRDC Cancer Research Data Commons DMI Data Modernization Initiative DOE Department of Energy ECG Electrocardiogram EHR Electronic health record FDA Food and Drug Administration FTC Federal Trade Commission GSA General Services Administration HHS Department of Health and Human Services HIPAA Health Insurance Portability and Accountability Act HRSA Health Resources and Services Administration 192 Term Full Form Text IDE Investigational Device Exemption IHS Indian Health Service IND Investigational New Drug IRB Institutional Review Board LEAP Leading Edge Acceleration Project LLM Large language model ML Machine learning MoA Mechanism of Action MRI Magnetic Resonance Imagine NCHS National Center for Health Statistics NIH National Institutes of Health NIST National Institute of Standards and Technology NLP Natural language processing NOFO Notice of Funding Opportunity NPSD Network of Patient Safety Database s NTAP New Technology Add -on Payment OCAIO Office of the Chief Artificial Intelligence Officer OMB Office of Management and Budget PDSI Predictive Decision Support Interventions PHI Protected health information PI Predictive intelligence PII Personally identifiable information PoC Proof of concept PSO Patient Safety Organizations RCM Revenue cycle management SAMHSA Substance Abuse and Mental Health Services Administration SaMD Software as a medical device SDOH Social determinants of health TA Therapeutic area TPLC Total product life cycle 193 Term Full Form Text TTS Technology Transformation Services UDS Uniform Design System XAI Explainable AI 194 Appendix B: Select Federal Policies and Regulations Table 3: Non -exhaustive federal policies and regulations that support responsible use of AI Policy focus and goals Specific regulation, policy, or guidance Brief description Overarching legislative and executive actions on AI: Lay out coordinated federal approaches on AI broadly, including its implications in the federal government itself, that can improve AI in the U.S."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_713",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nSelect Federal Policies and Regulations Table 3: Non -exhaustive federal policies and regulations that support responsible use of AI Policy focus and goals Specific regulation, policy, or guidance Brief description Overarching legislative and executive actions on AI: Lay out coordinated federal approaches on AI broadly, including its implications in the federal government itself, that can improve AI in the U.S. and ensure its continued safe and responsible use. Executive Orde r 14110825 (Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence) Highlights the importance of enabling continued safe adoption of AI and requires several federal agencies, including HHS, to develop AI strategies. Blueprint for the AI Bill of Rights826 Identifies five principles that should guide the design, use, and deployment of automated systems to protect the American public in the age of artificial intelligence: safe and effective systems; algorithmic discrimination protections; data privacy; notice and explanation; and human alternatives, consideration, and fallback. National AI Initiative Act of 2020827 Calls for a coordinated program across the entire Federal government to accelerate AI research and application for the Nation’s economic prosperity and national security."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_714",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nsystems to protect the American public in the age of artificial intelligence: safe and effective systems; algorithmic discrimination protections; data privacy; notice and explanation; and human alternatives, consideration, and fallback. National AI Initiative Act of 2020827 Calls for a coordinated program across the entire Federal government to accelerate AI research and application for the Nation’s economic prosperity and national security. Executive Order 13859828 (Maintaining American Leadership in AI) Defines a coordinated Federal Government AI strategy focused on driving technological breakthroughs, developing appropriate AI standards, training current and future workforces, fostering public trust and confidence, and promoting an international environm ent that supports American AI research. Executive Order 13960829 (Promoting the Use of Trustworthy Artificial Intelligence in the Federal Government) Establishes principles for trustworthy AI use in and by federal government agencies."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_715",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nFederal Government AI strategy focused on driving technological breakthroughs, developing appropriate AI standards, training current and future workforces, fostering public trust and confidence, and promoting an international environm ent that supports American AI research. Executive Order 13960829 (Promoting the Use of Trustworthy Artificial Intelligence in the Federal Government) Establishes principles for trustworthy AI use in and by federal government agencies. 825 https:/www.whitehouse.gov/briefing -room/presidential -actions/2023/10/30/executive -order -on-the-safe-secure -and-trustworthy -development -and-use-of-artificial - intelligence 826 https://www.whitehouse.gov/ostp/ai -bill-of-rights/ 827 https://www.congress.gov/bill/116th -congress/house -bill/6216 828 https://www.govinfo.gov/content/pkg/FR -2019 -02-14/pdf/2019 -02544.pdf 829 https://www.hhs.gov/programs/topic -sites/ai/statutes/index.html 195 Policy focus and goals Specific regulation, policy, or guidance Brief description OMB M -21-06830 (Guidance for Regulation of Artificial Intelligence Applications) Provides guidance to all Federal agencies to inform the development of regulatory and non -regulatory approaches regarding technologies and industrial sectors that are empowered or enabled by artificial intelligence (AI) and consider ways to reduce barriers to the development and adoption of AI technologies."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_716",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nregulation, policy, or guidance Brief description OMB M -21-06830 (Guidance for Regulation of Artificial Intelligence Applications) Provides guidance to all Federal agencies to inform the development of regulatory and non -regulatory approaches regarding technologies and industrial sectors that are empowered or enabled by artificial intelligence (AI) and consider ways to reduce barriers to the development and adoption of AI technologies. HHS responded to this OMB831 with the statutory authorities that authorize HHS to issue regulations on the development and use of AI applications in the private sector, among additional topics. Section 1557 92.210 Nondiscrimination in the use of patient care decision support tools832 Protects against discrimination based on race, color, national origin, sex, age or disability in health program s or activities through use of patient decision support tools. Research Participant Protections: Establish expectations and best practices for protecting the welfare, privacy, and autonomy of research participants. The ethical considerations embedded in these policies, regulations, and best practices (e.g., privacy) address key issues relevant to the development and use of AI in research. In adhering to them, investigators can mitigate potential harms a nd inequities arising from the use and development of AI."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_717",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nexpectations and best practices for protecting the welfare, privacy, and autonomy of research participants. The ethical considerations embedded in these policies, regulations, and best practices (e.g., privacy) address key issues relevant to the development and use of AI in research. In adhering to them, investigators can mitigate potential harms a nd inequities arising from the use and development of AI. Protection of Human Subjects (45 CFR 46)833 Outlines basic provisions for IRBs , informed consent, and assurance of compliance for HHS -supported research involving human participants and their data, including considerations of risks & benefits. Protection of Human Subjects (21 CFR 50)834 and Institutional Review Boards (21 CFR 56)835 Provisions for compliance and IRBs for clinical investigations that are also regulated by FDA . Certificates of Confidentiality836 Prohibits the disclosure of identifiable, sensitive research information to anyone not connected to the research except when the participant consents or in a few other specific situations. NIH Informed Consent for Secondary Research with Data and Biospecimens837 Provides points to consider, instructions for use, and optional sample language that is designed for informed consent documents for research studies that include plans to store and share collected data and biospecimens for future use. Common Rule838 Requires obtaining legally effective informed consent before involving a human subject in research."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_718",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nNIH Informed Consent for Secondary Research with Data and Biospecimens837 Provides points to consider, instructions for use, and optional sample language that is designed for informed consent documents for research studies that include plans to store and share collected data and biospecimens for future use. Common Rule838 Requires obtaining legally effective informed consent before involving a human subject in research. Informed Consent Posting Instructions839 Provides general instructions on how to comply with the Common Rule’s requirement to gain informed consent before involving human subjects in research."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_719",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nconsent documents for research studies that include plans to store and share collected data and biospecimens for future use. Common Rule838 Requires obtaining legally effective informed consent before involving a human subject in research. Informed Consent Posting Instructions839 Provides general instructions on how to comply with the Common Rule’s requirement to gain informed consent before involving human subjects in research. 830 https://www.whitehouse.gov/wp -content/uploads/2020/11/M -21-06.pdf 831 https://www.hhs.gov/sites/default/files/department -of-health -and-human -services -omb-m-21-06.pdf 832 https://www.ecfr.gov/current/title -45/subtitle -A/subchapter -A/part -92/subpart -C/section -92.210 833 https://www.hhs.gov/ohrp/regulations -and-policy/regulations/45 -cfr-46/index.html 834 https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfcfr/CFRSearch.cfm?CFRPart=50&showFR=1 835 https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfcfr/CFRSearch.cfm?CFRPart=56&showFR=1 836 https://grants.nih.gov/policy -and-compliance/policy -topics/human -subjects/coc 837 https://osp.od.nih.gov/wp -content/uploads/Informed -Consent -Resource -for-Secondary -Research -with-Data -and-Biospecimens.pdf 838 https://www.hhs.gov/ohrp/regulations -and-policy/regulations/45 -cfr-46/revised -common -rule-regulatory -text/index.html#46.116 839 https://www.hhs.gov/ohrp/regulations -and-policy/informed -consent -posting/informed -consent -posting -guidance/index.html 196 Policy focus and goals Specific regulation, policy, or guidance Brief description NIH Information about Protecting Privacy when Sharing Human Research Participant Data840 Provides a set of principles and best practices for protecting the privacy of human research participants when sharing data in NIH -supported research."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_720",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nhttps://www.hhs.gov/ohrp/regulations -and-policy/regulations/45 -cfr-46/revised -common -rule-regulatory -text/index.html#46.116 839 https://www.hhs.gov/ohrp/regulations -and-policy/informed -consent -posting/informed -consent -posting -guidance/index.html 196 Policy focus and goals Specific regulation, policy, or guidance Brief description NIH Information about Protecting Privacy when Sharing Human Research Participant Data840 Provides a set of principles and best practices for protecting the privacy of human research participants when sharing data in NIH -supported research. (Issued under the NIH Data Management and Sharing policy.) Patient Protections: Help protect the privacy and security of health data, including in healthcare delivery, research and discovery, and more. HIPAA Privacy Rule841, 842 HIPAA helps protect the privacy and security of health data used in research, including research involving AI, thereby fostering trust in healthcare research activities. The Privacy Rule establishes the conditions under which protected health information m ay be used or disclosed by covered entities for research purposes."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_721",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nincluding in healthcare delivery, research and discovery, and more. HIPAA Privacy Rule841, 842 HIPAA helps protect the privacy and security of health data used in research, including research involving AI, thereby fostering trust in healthcare research activities. The Privacy Rule establishes the conditions under which protected health information m ay be used or disclosed by covered entities for research purposes. Health Data, Technology, and Interoperability: Certification Program Updates, Algorithm Transparency, and Information Sharing (HTI - 1) Final Rule843 Implements provisions of the 21st Century Cures Act and makes updates to the ONC Health IT Certification Program (Certification Program) with new and updated standards, implementation specifications, and certification criteria. Provisions in the HTI -1 fina l rule advance interoperability, improve transparency, and support the access, exchange, and use of electronic health information. Health Data, Technology, and Interoperability: Patient Engagement, Information Sharing, and Public Health Interoperability (HTI -2) Proposed Rule844 Technology and standards updates that build on the HTI - 1 final rule, ranging from the capability to exchange clinical images (e.g., X -rays) to the addition of multifactor authentication support. 21st Century Cures Act845 Helps to accelerate medical product development and bring new innovations and advances to patients who need them faster and more efficiently."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_722",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n(HTI -2) Proposed Rule844 Technology and standards updates that build on the HTI - 1 final rule, ranging from the capability to exchange clinical images (e.g., X -rays) to the addition of multifactor authentication support. 21st Century Cures Act845 Helps to accelerate medical product development and bring new innovations and advances to patients who need them faster and more efficiently. The law builds on previous work at FDA incorporating the perspective of patients into the development of drugs, biological products, and devices in FDA’s decision -making process and has provisions related to privacy protection and ensuring appropriate access to electronic health information. 840 https://sharing.nih.gov/data -management -and-sharing -policy/protecting -participant -privacy -when -sharing -scientific -data/principles -and-best-practices -for- protecting -participant -privacy 841 https://www.hhs.gov/hipaa/for -professionals/special -topics/research/index.html For the HIPAA Privacy Rule Guidance 842 https://www.hhs.gov/hipaa/for -professionals/privacy/laws -regulations/combined -regulation -text/index.html For links to the full HIPAA Administrative Simplification Regulations including the Privacy Rule."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_723",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nand has provisions related to privacy protection and ensuring appropriate access to electronic health information. 840 https://sharing.nih.gov/data -management -and-sharing -policy/protecting -participant -privacy -when -sharing -scientific -data/principles -and-best-practices -for- protecting -participant -privacy 841 https://www.hhs.gov/hipaa/for -professionals/special -topics/research/index.html For the HIPAA Privacy Rule Guidance 842 https://www.hhs.gov/hipaa/for -professionals/privacy/laws -regulations/combined -regulation -text/index.html For links to the full HIPAA Administrative Simplification Regulations including the Privacy Rule. 843 https://www.healthit.gov/topic/laws -regulation -and-policy/health -data-technology -and-interoperability -certification -program 844 https://www.healthit.gov/topic/laws -regulation -and-policy/health -data-technology -and-interoperability -patient -engagement 845 https://www.fda.gov/regulatory -information/selected -amendments -fdc-act/21st -century -cures -act 197 Policy focus and goals Specific regulation, policy, or guidance Brief description Health Information Technology for Economic and Clinical Health (HITECH) Act846 Provides HHS with the authority to establish programs to improve healthcare quality, safety, and efficiency through the promotion of health IT, including electronic health records and private and secure electronic health information exchange."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_724",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-amendments -fdc-act/21st -century -cures -act 197 Policy focus and goals Specific regulation, policy, or guidance Brief description Health Information Technology for Economic and Clinical Health (HITECH) Act846 Provides HHS with the authority to establish programs to improve healthcare quality, safety, and efficiency through the promotion of health IT, including electronic health records and private and secure electronic health information exchange. The Act addresses privacy and safety concerns related to electronic health information exchange, including with stricter breach notification requirements. Biosecurity and Biosafety: Establish and are part of a comprehensive biosecurity and biosafety oversight system. Research funded by HHS, including research using the tools and technologies enabled or informed by AI, fall under this oversight framework. While some of these policies do not explicitly address AI, they are still applicable to development and use of AI in research involving biological agents, toxins, or nucleic acid molecules if such research involves physical experiments that are covered under these policies. U.S."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_725",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nincluding research using the tools and technologies enabled or informed by AI, fall under this oversight framework. While some of these policies do not explicitly address AI, they are still applicable to development and use of AI in research involving biological agents, toxins, or nucleic acid molecules if such research involves physical experiments that are covered under these policies. U.S. Government Policy for Oversight of Dual Use Research of Concern and Pathogens with Enhanced Pandemic Potential (in effect May 6, 2025)847 Provides a unified federal oversight framework for conducting and managing certain types of federally funded life sciences research on biological agents and toxins that have the potential to pose risks to public health, agriculture, food security, economic security, or national security. The policy “encourages institutional oversight of in silico research, regardless of funding source, that could result in the development of potential dual-use computational models directly enabling the design of a [pathogen with enhanced pandemic potential or a novel biological agent or toxin.” Once in effect (May 6, 2025), this unified framework will supersede the current oversight delineated through: • USG Policy for oversight of Life Sciences Dual Use Research of Concern848 and • HHS Framework for Guiding Funding Decisions about Proposed Research Involving Enhanced Potential Pandemic Pathogens849 U.S."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_726",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nof a [pathogen with enhanced pandemic potential or a novel biological agent or toxin.” Once in effect (May 6, 2025), this unified framework will supersede the current oversight delineated through: • USG Policy for oversight of Life Sciences Dual Use Research of Concern848 and • HHS Framework for Guiding Funding Decisions about Proposed Research Involving Enhanced Potential Pandemic Pathogens849 U.S. Government Framework for Nucleic Acid Synthesis Screening (in effect October 29, 2024)850, 851 Encourages providers of synthetic nucleic acids to implement comprehensive, scalable, and verifiable screening mechanisms to prevent misuse of these nucleotides. Builds on earlier guidance from HHS852 and requires recipients of federal Research and Discovery funds to procure synthetic nucleic acids only from providers that implement these best practices."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_727",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nFramework for Nucleic Acid Synthesis Screening (in effect October 29, 2024)850, 851 Encourages providers of synthetic nucleic acids to implement comprehensive, scalable, and verifiable screening mechanisms to prevent misuse of these nucleotides. Builds on earlier guidance from HHS852 and requires recipients of federal Research and Discovery funds to procure synthetic nucleic acids only from providers that implement these best practices. NIH Guidelines for Research Involving Recombinant or Synthetic Nucleic Acid Molecules853 Establishes safety practices and containment procedures for institutions that receive NIH funding for “basic and clinical research involving recombinant or synthetic nucleic acid molecules, including the creation and use of organisms and viruses containing recombinant or synthetic nucleic acid molecules.” 846 https://www.healthit.gov/sites/default/files/hitech_act_excerpt_from_arra_with_index.pdf 847 https://www.whitehouse.gov/wp -content/uploads/2024/05/USG -Policy -for-Oversight -of-DURC -and-PEPP.pdf 848 https://www.phe.gov/s3/dualuse/Documents/us -policy -durc-032812.pdf 849 https://www.phe.gov/s3/dualuse/Documents/P3CO.pdf 850 https://www.whitehouse.gov/wp -content/uploads/2024/04/Nucleic -Acid_Synthesis_Screening_Framework.pdf 851 https://www.whitehouse.gov/ostp/news -updates/2024/04/29/framework -for-nucleic -acid-synthesis -screening/ 852 https://aspr.hhs.gov/legal/synna/Documents/SynNA -Guidance -2023.pdf 853 https://osp.od.nih.gov/policies/biosafety -and-biosecurity -policy#tab2/ 198 Policy focus and goals Specific regulation, policy, or guidance Brief description Public Access and Data Management and Sharing: Seek to maximize the responsible management and sharing of research products while ensuring that researchers consider how the privacy, rights, and confidentiality of human research participants will be protected."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_728",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\n-updates/2024/04/29/framework -for-nucleic -acid-synthesis -screening/ 852 https://aspr.hhs.gov/legal/synna/Documents/SynNA -Guidance -2023.pdf 853 https://osp.od.nih.gov/policies/biosafety -and-biosecurity -policy#tab2/ 198 Policy focus and goals Specific regulation, policy, or guidance Brief description Public Access and Data Management and Sharing: Seek to maximize the responsible management and sharing of research products while ensuring that researchers consider how the privacy, rights, and confidentiality of human research participants will be protected. Increasing the availability of data through data sharing allows for more accurate development and use of AI models. These policies help ensure that investigators remain good stewards of data used in or produced by AI models. HHS operating divisions have a robust set of policies aimed at responsible data sharing, including but not limited to, NIH Genomic Data Sharing Policy, NIH Public Access Policy, and NIH Data Management and Sharing Policy. Public Access Policies854 In August of 2022, the Office of Science and Technology Policy released a Public Access Memo855 directing Federal Agencies with research and development expenditures to make all peer reviewed scholarly publications publicly accessible by December 31, 2025 , without an embargo or cost. Additionally, all scientific data underlying these publications must be made freely available and publicly accessible by default at the time of publication."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_729",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nOffice of Science and Technology Policy released a Public Access Memo855 directing Federal Agencies with research and development expenditures to make all peer reviewed scholarly publications publicly accessible by December 31, 2025 , without an embargo or cost. Additionally, all scientific data underlying these publications must be made freely available and publicly accessible by default at the time of publication. In response, HHS operating divisions have updated and/or developed Public Access Policies to meet this directive (see NIH Public Access Policy856). NIH Data Management & Sharing (DMS) Policy857 Establishes the requirement to submit a DMS Plan and comply with NIH -approved plans. In addition, NIH Institutes, Centers, and Offices can request additional or specific information be included within the plan to support programmatic priorities or to expan d the utility of the scientific data generated from the research. NIH Genomic Data Sharing Policy858 Promotes and facilitates responsible sharing of large - scale genomic data generated with NIH funds. Licensing, Intellectual Property, & Technology Transfer US Patent and Trademark Office information about AI859 Provides AI -related patent resources and important information concerning AI IP policy. NIH Research Tools Policy860 Expects funding recipients to appropriately disseminate propagate and allow open access to research tools developed with NIH funding."
  },
  {
    "id": "2025-hhs-ai-strategic-plan_full_508_chunk_730",
    "text": "Source: 8 2025-hhs-ai-strategic-plan_full_508.pdf\n\nresponsible sharing of large - scale genomic data generated with NIH funds. Licensing, Intellectual Property, & Technology Transfer US Patent and Trademark Office information about AI859 Provides AI -related patent resources and important information concerning AI IP policy. NIH Research Tools Policy860 Expects funding recipients to appropriately disseminate propagate and allow open access to research tools developed with NIH funding. 854 https://www.hhs.gov/open/public -access -guiding -principles/index.html 855 https://www.whitehouse.gov/wp -content/uploads/2022/08/08 -2022 -OSTP -Public -access -Memo.pdf 856 https://sharing.nih.gov/public -access -policy/public -access -policy -overview 857 https://sharing.nih.gov/data -management -and-sharing -policy 858 https://sharing.nih.gov/genomic -data-sharing -policy 859 https://www.uspto.gov/initiatives/artificial -intelligence 860 https://sharing.nih.gov/other -sharing -policies/research -tools -policy"
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_0",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\n-1- Directive # 139-08 Revision # 00 Department of Homeland Security DHS Directives System Directive Number: 139- 08 Revision Number: 00 Issue Date: 1/15/2025 Certified Current Date: 1/15/2025 ARTIFICIAL INTELLIGENCE USE AND ACQUISITION I. Purpose This Directive establishes Department of Homeland Security (DHS) policy for the use and acquisition of Artificial Intelligence (AI). 1 The purpose is to advance AI innovation and gov ernance while managing risks from the use of AI, particularly those affecting the safety or rights of individuals. Use of AI at DHS encompasses planning, designing, developing, deploying, and operating systems, services, techniques, software, and hardware by or on behalf of DHS. Use of AI at DHS may involve acquisition of AI by or on behalf of DHS by contract or other authorized procurement methods or agreements, including AI use incidental to contract performance. Acquisition of AI by or on behalf of DHS often requires development of specifications for technical requirements and development of such specifications are considered part of use of AI at DHS. II. Scope This Directive applies throughout DHS and to Federal, State, Local, Tribal, and Territorial government, non- U.S. government, and international entities operated by or on behalf of DHS."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_1",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nAcquisition of AI by or on behalf of DHS often requires development of specifications for technical requirements and development of such specifications are considered part of use of AI at DHS. II. Scope This Directive applies throughout DHS and to Federal, State, Local, Tribal, and Territorial government, non- U.S. government, and international entities operated by or on behalf of DHS. This Directive covers all use of AI at DHS, including AI used by elements of the Intelligence Community (IC) or as a component of a National Security System (NSS), and AI that is planned, designed, developed, deployed, operated, obtained, or procured by or on behalf of DHS. This Directive supersedes Policy Statement 139- 06 Acquisition and Use of Artificial Intelligence and Machine Learning Technologies by DHS Components . This Directive does not apply to the DHS Office of Inspector General . This Directive does not address acquisition beyond specifications for technical requirements for acquiring AI; acquisition generally is governed by existing policy, procedures, and processes, such as DHS Directive 102- 01 Acquisition Management Directive. III. Authorities A. Section 7224 in Subtitle B “Advancing American AI Act” of the James M. Inhofe National Defense Authorization Act for Fiscal Year 2023 (Pub. L. 117-263, § 7224) (codified at 40 U.S.C. § 11301 note). 1 For purposes of this Directive, AI encompasses the definitions of that term in Section 238(g) of the John S."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_2",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nAcquisition Management Directive. III. Authorities A. Section 7224 in Subtitle B “Advancing American AI Act” of the James M. Inhofe National Defense Authorization Act for Fiscal Year 2023 (Pub. L. 117-263, § 7224) (codified at 40 U.S.C. § 11301 note). 1 For purposes of this Directive, AI encompasses the definitions of that term in Section 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (Public Law 115–232; 10 U.S.C. 4061 note prec.) and Section 5002 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. 9401). -2- Directive # 139-08 Revision # 00 B. Section 104 of the AI in Government Act of 2020 (Pub. L. 116-260, div. U, title 1) (codified at 40 U.S.C. § 11301 note). C. Se ction 5002 of the National Artificial Intelligence Initiative Act of 2020 (15 U.S.C. § 9401). D. Se ction 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year 2019 (Pub. L. 115- 232, § 238(g)) (codified at 10 U.S.C. § 4061 note prec.). E. Se ction 6702 of the James M. Inhofe National Defense Authorization Act for Fiscal Year 2023 (Pub. L. 117- 263, § 6702) (codified at 50 U.S.C. § 3334m) F. E xecutive Order 14110, Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence , October 30, 2023. G. E xecutive Order 14091, Further Advancing Racial Equity and Support for Underserved Communities Through the Federal Government, February 16, 2023. H."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_3",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nDefense Authorization Act for Fiscal Year 2023 (Pub. L. 117- 263, § 6702) (codified at 50 U.S.C. § 3334m) F. E xecutive Order 14110, Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence , October 30, 2023. G. E xecutive Order 14091, Further Advancing Racial Equity and Support for Underserved Communities Through the Federal Government, February 16, 2023. H. E xecutive Order 14058, Transforming Federal Customer Experience and Service Delivery to Rebuild Trust in Government , December 13, 2021. I. E xecutive Order 13960, Promoting the Use of Trustworthy Artificial Intelligence in the Federal Government , December 8, 2020. J. E xecutive Order 13859, Maintaining American Leadership in Artificial Intelligence , February 11, 2019. K. Offi ce of Management and Budget, Memorandum M-24-10 Advancing Governance, Innovation, and Risk Management for Agency Use of Artificial Intelligence, March 28, 2024. L. Offi ce of Management and Budget, Memorandum M-24-18 Advancing the Responsible Acquisition of Artificial Intelligence in Government, September 24, 2024. M. N ational Security Memorandum -25 Advancing the United States’ Leadership in Artificial Intelligence; Harnessing Artificial Intelligence to Fulfill National Security Objectives; and Fostering the Safety, Security, and Trustworthiness of Artificial Intelligence, October 24, 2024. N. DHS Directive 071-01, DHS Leadership Forums, June 30, 2015. O."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_4",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nMemorandum M-24-18 Advancing the Responsible Acquisition of Artificial Intelligence in Government, September 24, 2024. M. N ational Security Memorandum -25 Advancing the United States’ Leadership in Artificial Intelligence; Harnessing Artificial Intelligence to Fulfill National Security Objectives; and Fostering the Safety, Security, and Trustworthiness of Artificial Intelligence, October 24, 2024. N. DHS Directive 071-01, DHS Leadership Forums, June 30, 2015. O. DHS Instruction 071-01-01, DHS Artificial Intelligence Governance Board -3- Directive # 139-08 Revision # 00 P. DHS Delegation 04000, Delegation to the Chief Information Officer Q. DHS Designation 00-04007, Designation of the Chief Information Officer to Serve as the Chief Artificial Intelligence Officer IV. Responsibilities A. DHS Chief AI Officer (DHS CAIO) leads and coordinates, on behalf of the Secretary of Homeland Security, the use of AI at DHS, risk management from that use, and promotion of AI innovation across the Department. The DHS CAIO is responsible for leading governance and oversight structures and processes, as well as setting strategic priorities for AI deployments across the Department. The DHS CAIO also collaborates with appropriate Offices, Components, and governance groups to create and maintain a comprehensive set of policies that implement this Directive and other related DHS policies, guidelines, and processes."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_5",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nthe Department. The DHS CAIO is responsible for leading governance and oversight structures and processes, as well as setting strategic priorities for AI deployments across the Department. The DHS CAIO also collaborates with appropriate Offices, Components, and governance groups to create and maintain a comprehensive set of policies that implement this Directive and other related DHS policies, guidelines, and processes. The DHS CAIO provides oversight, on behalf of the Department, of the comprehensive set of policy requirements implementing this Directive when the DHS CAIO fulfills such oversight through the AI Council. Per Delegation 04000 and Designation 00- 04007, the DHS CAIO is the DHS Chief Information Officer (DHS CIO) or serves within the Office of the DHS CIO. As such, the DHS CAIO’s responsibilities are fulfilled by the DHS CIO or in coordination with and under the direction of the DHS CIO. B. DHS Chief Information Officer (DHS CIO) oversees AI and related infrastructure in support of DHS missions and activities as part of DHS CIO’s approval and oversight responsibilities and authorities regarding implementation and use of information technology (IT), including AI, within the DHS IT enterprise."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_6",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nthe DHS CIO or in coordination with and under the direction of the DHS CIO. B. DHS Chief Information Officer (DHS CIO) oversees AI and related infrastructure in support of DHS missions and activities as part of DHS CIO’s approval and oversight responsibilities and authorities regarding implementation and use of information technology (IT), including AI, within the DHS IT enterprise. Among other responsibilities, the DHS CIO supports the use of AI at DHS through a DHS data management lifecycle framework and data standards and requirements; and ensures use of AI at DHS complies with relevant cybersecurity requirements and aligns with DHS’s customer experience commitment. C. Under Secretary for Management (USM) is the Chief Acquisition Officer and is responsible for DHS -wide governance, including policy, processes, and procedures, for major and non-major acquisition programs to include acquiring AI by contract or other authorized procurement methods or agreements . The USM ensures, in collaboration with relevant DHS officials, that acquisition of AI by or on behalf of DHS complies with applicable laws and government -wide and DHS policies. D. Under S ecretary for Strategy, Policy, and Plans leads, in collaboration with the DHS CAIO, the development of Department -wide strategies, policies, and plans regarding the use of AI at DHS and coordinates all aspects of the Department’s engagement in the National Security Council policy process. -4- Directive # 139-08 Revision # 00 E."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_7",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\ngovernment -wide and DHS policies. D. Under S ecretary for Strategy, Policy, and Plans leads, in collaboration with the DHS CAIO, the development of Department -wide strategies, policies, and plans regarding the use of AI at DHS and coordinates all aspects of the Department’s engagement in the National Security Council policy process. -4- Directive # 139-08 Revision # 00 E. Under Secretary for Science and Technology leads the Department’s scientific, engineering, and analytical initiatives for research, development, testing, and evaluation of AI, and for assessment of technical risk of AI; coordinates the Department’s technical standards development process for AI; provides enterprise oversight for testing and evaluation of AI use cases in accordance with Delegation 10003; and supports Component Senior AI Officials regarding testing and evaluation of AI use cases within Component s. F. DHS Chief Privacy Officer has primary responsibility for both DHS privacy and information disclosure policy; exercises statutory oversight to ensure the use of AI at DHS sustains, and does not erode, privacy protections for the collection, use, retention, dissemination, or disclosure of personally identifiable information (PII); and investigates causes, weighs mitigations, and oversees implement ation of remediations when suspected or confirmed PII data breaches are reported. G."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_8",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nfor both DHS privacy and information disclosure policy; exercises statutory oversight to ensure the use of AI at DHS sustains, and does not erode, privacy protections for the collection, use, retention, dissemination, or disclosure of personally identifiable information (PII); and investigates causes, weighs mitigations, and oversees implement ation of remediations when suspected or confirmed PII data breaches are reported. G. DHS Officer for Civil Rights and Civil Liberties exercises statutory authority to assess the impacts of the use of AI at DHS on civil rights and civil liberties of persons; conducts compliance and oversight activities and provides policy advice across DHS to ensure such use does not diminish the civil rights and civil liberties of persons; and collaborates with the DHS CAIO and Component Senior AI Officials to support specific AI deployment. H. Assistant Secretary, Office of Partnership and Engagement leads, in coordination with the DHS CAIO and, as appropriate, other DHS subject matter experts, partnership and engagement for the Department with the private sector; state, local, tribal and territorial (SLTT) government; academic sector; civil society organizations and other stakeholders, including underserved communities, regarding use of AI by DHS. This includes building partnerships and conducting engagement to inform policy, operational practice, innovation, and governance; while also being responsive to stakeholder concerns, as appropriate. I."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_9",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nexperts, partnership and engagement for the Department with the private sector; state, local, tribal and territorial (SLTT) government; academic sector; civil society organizations and other stakeholders, including underserved communities, regarding use of AI by DHS. This includes building partnerships and conducting engagement to inform policy, operational practice, innovation, and governance; while also being responsive to stakeholder concerns, as appropriate. I. General Counsel provides legal review, guidance, and advice on applicable laws and government -wide and DHS policies for the use of AI at DHS. J. Component Heads2 are responsible for the use of AI within their Component and ensure that use of AI at DHS by their Component is in support of authorized DHS missions and in accordance with applicable laws and government -wide and DHS policies, including this Directive. In accordance with the authority delegated in Delegation 04000, each named Component Head with delegated responsibilities in Delegation 04000 designates a Component Senior AI Official. 2 “Component” is defined in DHS Directive 252-01. -5- Directive # 139-08 Revision # 00 K."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_10",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nof authorized DHS missions and in accordance with applicable laws and government -wide and DHS policies, including this Directive. In accordance with the authority delegated in Delegation 04000, each named Component Head with delegated responsibilities in Delegation 04000 designates a Component Senior AI Official. 2 “Component” is defined in DHS Directive 252-01. -5- Directive # 139-08 Revision # 00 K. Component Senior AI Officials (SAIOs) are responsible, on behalf of their respective Component Heads, for ensuring that the use of AI within their Component is: coordinated with the DHS CAIO to support the DHS CAIO’s responsibilities; safe, secure, responsible, trustworthy, and human- centered in accordance with this Directive and implementing policy; and aligned with the DHS CAIO’s governance and strategic priorities for AI innovation and deployment. Component SAIOs have the expertise and authority necessary to fulfill this responsibility and work in coordination with their Component’s CIO, Privacy Officer or other Officer responsible for liaising with the DHS Privacy Officer, Officer responsible for liaising with the DHS Officer for Civil Rights and Civil Liberties, senior legal counsel, and SAIO within an Element of the IC as applicable. Each Component SAIO is designated with concurrence from the DHS CAIO. If a Component uses the title of “Chief AI Officer” that Officer must be the same as the Component SAIO."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_11",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nPrivacy Officer, Officer responsible for liaising with the DHS Officer for Civil Rights and Civil Liberties, senior legal counsel, and SAIO within an Element of the IC as applicable. Each Component SAIO is designated with concurrence from the DHS CAIO. If a Component uses the title of “Chief AI Officer” that Officer must be the same as the Component SAIO. For Components without the requirement to designate a Senior AI Official in accordance with Delegation 04000, the DHS CAIO or designee fulfills the responsibilities of the Senior AI Official. L. Under Secretary for Intelligence and Analysis (USIA) serves as the Chief Intelligence Officer and Senior Information Sharing and Safeguarding Executive for the Department. Per Delegation 04000, the USIA collaborates with the DHS CAIO and the DHS CIO to provide guidance and direction, as appropriate, on the use of AI by the DHS Intelligence Enterprise (IE), including the DHS elements of the IC, and AI use within the Department’s secure communications and technology, including as a part of a NSS. 3 The USIA coor dinates with the DHS CAIO, the Under Secretary for Strategy, Policy, and Plans, and the DHS AI Council to ensure DHS IE policy implements this Directive, government -wide national security requirements, including NS M-25, and any other government -wide policies on use of AI within the IC or as part of a NSS, to the maximum extent possible and appropriately addresses any conflicts in requirements. M."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_12",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nUnder Secretary for Strategy, Policy, and Plans, and the DHS AI Council to ensure DHS IE policy implements this Directive, government -wide national security requirements, including NS M-25, and any other government -wide policies on use of AI within the IC or as part of a NSS, to the maximum extent possible and appropriately addresses any conflicts in requirements. M. Senior AI Official within a DHS Element of the Intelligence Community4 (IC SAIO) is designated in accordance with section 3334m(c) of Tit le 50, United States Code and government -wide national security requirements, including the requirement to designate officials to provide oversight of AI activities under NSM -25 and its successor memorandums and implementing policy. The IC SAIO fulfills the duties listed in that U.S. Code section and other applicable laws and policies, and coordinates with the DHS 3 Consistent with the definition of Intelligence Components of the Department contained in 6 U.S.C. § 101, nothing in this Directive shall affect or diminish the authority and responsibilities of the Director of National Intelligence with respect to the Coast Guard as an element of the intelligence community, as defined under 50 U.S.C § 3003. 4 “Intelligence Community” is defined in Section 3003(4) of Title 50, United States Code. -6- Directive # 139-08 Revision # 00 CAIO, the USIA, and relevant Component SAIO regarding use of AI within the element. V. Policy and Requirements A."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_13",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nwith respect to the Coast Guard as an element of the intelligence community, as defined under 50 U.S.C § 3003. 4 “Intelligence Community” is defined in Section 3003(4) of Title 50, United States Code. -6- Directive # 139-08 Revision # 00 CAIO, the USIA, and relevant Component SAIO regarding use of AI within the element. V. Policy and Requirements A. Policy DHS uses AI to fulfill and advance the homeland security mission.5 Use of AI at DHS is, first and foremost, lawful, mission -appropri ate, and mission- enhancing. Use of AI at DHS also is safe, secure, responsible, trustworthy, and human- centered. DHS ensures such use of AI through rigorous testing and evaluation and appropriate data and information management, as well as through compliance with this Directive and applicable laws and government -wide and DHS policies. When use of AI by DHS involves acquisition of AI by or on behalf of DHS, DHS ensures such acquisition is responsible and authorized. DHS will continue to be a leader in the use of AI, within the U.S. Government and for the people we serve. 1. Lawful and Miss ion-Appropriate. Use of AI at DHS complies with the Constitution and applicable laws and government -wide and DHS policies, including those protecting privacy, civil rights, and civil liberties. 2. Mission -Enhancing ."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_14",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nand authorized. DHS will continue to be a leader in the use of AI, within the U.S. Government and for the people we serve. 1. Lawful and Miss ion-Appropriate. Use of AI at DHS complies with the Constitution and applicable laws and government -wide and DHS policies, including those protecting privacy, civil rights, and civil liberties. 2. Mission -Enhancing . Use of AI at DHS is purposeful and performance- driven to enhance the effectiveness of DHS in fulfilling the homeland security mission through operational, administrative, and support functions. 3. Saf e, Secure, and Responsible Use. Use of AI at DHS identifies and appropriately addresses risks and benefits in that use of AI; protects privacy, civil rights, and civil liberties in that use of AI; and remains hardened against compromises and malicious activity. Through rigorous testing and evaluation, DHS confirms use of AI at DHS avoids improper biases, promotes equity and fair treatment, and meets established performance metrics for effectiveness, accuracy, reliability, resilience, and security, for the specific use of AI and in accordance with applicable national and international standards. DHS requires use of AI to have human oversight when the use is safety -impacting or rights -impacting or used by DHS for significant or final agency decisions or action. DHS also ensures DHS personnel using AI and/or relying on AI outputs receive training for understanding AI generally and on the specific use of AI. 4."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_15",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nnational and international standards. DHS requires use of AI to have human oversight when the use is safety -impacting or rights -impacting or used by DHS for significant or final agency decisions or action. DHS also ensures DHS personnel using AI and/or relying on AI outputs receive training for understanding AI generally and on the specific use of AI. 4. Trus tworthy Use. Use of AI at DHS is t ransparent and explainable to our workforce and to those that we serve. Use of AI at DHS is publicly disclosed in plain language along with any opt -out mechanisms, to the maximum extent possible, in accordance with applicable laws and government -wide and DHS policies. Use of AI at DHS is also 5 With honor and integrity, we will safeguard the American people, our homeland, and our values. -7- Directive # 139-08 Revision # 00 understandable to DHS personnel and others using AI at DHS and/or directly relying on AI outputs at DHS; those outputs are traceable and auditable to the maximum extent possible against data standards and requirements . 5. Human- C entered Use. The design, development, deployment, and operation of AI at DHS considers the humans using AI on behalf of DHS, using AI to interact with DHS, and those directly impacted by AI outputs. Use of AI at DHS aligns with DHS’s customer experience commitment to deliver services that are simple to use, accessible, equitable, protective, transparent, and responsive for the people we serve."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_16",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\ndevelopment, deployment, and operation of AI at DHS considers the humans using AI on behalf of DHS, using AI to interact with DHS, and those directly impacted by AI outputs. Use of AI at DHS aligns with DHS’s customer experience commitment to deliver services that are simple to use, accessible, equitable, protective, transparent, and responsive for the people we serve. DHS uses human- centered design practices, including analysis and measurement of internal and external customer experiences related to the use of AI and its impact. DHS also consults with communities and other stakeholders affected by the use of AI at DHS, especially underserved communities, and DHS incorporates their feedback, to the maximum extent practical and as appropriate. 6. Testing and Evaluation. DHS r igorously tests and evaluates AI during design, development, deployment, and operation. Testing and evaluation is a key means of validating safe, secure, responsible, trustworthy, and human- centered use of AI by DHS. Testing and evaluation for performance, including effectiveness, reliability, and accuracy, is in accordance with applicable metrics, standards, guidance, and best practices. Testing and evaluation throughout the AI’s lifecycle confirms that the AI is performing as expected and there is no improper bias in its outputs, ensures proactive risk identification and mitigation, and accounts for the evolving nature of the technology and operational performance metrics."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_17",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nperformance, including effectiveness, reliability, and accuracy, is in accordance with applicable metrics, standards, guidance, and best practices. Testing and evaluation throughout the AI’s lifecycle confirms that the AI is performing as expected and there is no improper bias in its outputs, ensures proactive risk identification and mitigation, and accounts for the evolving nature of the technology and operational performance metrics. When use of AI involves acquisition of AI, requirements for acquiring the AI supports fulfilling these testing and evaluation requirements. 7. Data Management . U se of AI at DHS complies with applicable laws and government -wide and DHS policies governing data, protection of sensitive information, and Federal records management. At DHS, data collection (including acquisition), storage, access, and use (including sharing) related to the use of AI complies with standards and requirements, including those that: pro tect privacy, civil rights, and civil liberties; ensure security; prevent improper biases; enhance interoperability; and advance AI output traceability and auditability . 8. Responsible and Authorized Acquisition . Acquisition of AI by or on behalf of DHS aligns with the U.S. Constitution, applicable laws, and government -wide and DHS policies, including those addressing federal procurement, privacy, confidentiality, intellectual property, cybersecurity, human and civil rights, and civil liberties."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_18",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nensure security; prevent improper biases; enhance interoperability; and advance AI output traceability and auditability . 8. Responsible and Authorized Acquisition . Acquisition of AI by or on behalf of DHS aligns with the U.S. Constitution, applicable laws, and government -wide and DHS policies, including those addressing federal procurement, privacy, confidentiality, intellectual property, cybersecurity, human and civil rights, and civil liberties. When acquisition of AI by -8- Directive # 139-08 Revision # 00 contract and other authorized procurement methods or agreements requires development of specifications for technical requirements, those specifications sufficiently must address testing and evaluation requirements and risk management considerations and requirements regarding use of AI at DHS. Such specifications also ensure that technical requirements support transparency, performance evaluation and improvement in AI acquired, address data ownership and management, and assess environmental efficiency and sustainability. 9. Prohibited Us es. The following uses of AI at DHS and uses of associated data are prohibited: a. Rel ying on outputs of AI as the sole basis for a law enforcement action (which, for purposes of this Directive, include an arrest, search, seizure, or issuing a citation but does not include a referral to secondary screening), a civil enforcement action (including issuing a fine, injunction, or similar legal penalty), or denial of government benefits; b."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_19",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nprohibited: a. Rel ying on outputs of AI as the sole basis for a law enforcement action (which, for purposes of this Directive, include an arrest, search, seizure, or issuing a citation but does not include a referral to secondary screening), a civil enforcement action (including issuing a fine, injunction, or similar legal penalty), or denial of government benefits; b. Using data associated with the use of AI at DHS, or deploying AI, to make or support decisions based on the unlawful or improper consideration of race, ethnicity, gender, national origin, religion, sexual orientation, gender identity, age, nationality, medical condition, disability, emotional state, or future behavior predictions; c. Improperly profiling, targeting, or discriminating against any individual or entity based on the individual characteristics identified above or in retaliation for exercising Constitutional rights; d. Using AI for unlawful or improper systemic, indiscriminate, or large- scale monitoring, surveillance, or tracking of individuals; e. Providing DHS data, or outputs from the use of AI at DHS, to third parties for uses of AI that are prohibited by applicable laws and government -wide and DHS policies, including this Directive; and f. Other uses of AI or associated data that are prohibited by applicable laws and government -wide and DHS policies. B. Requ i rements 1. Governance and Compliance."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_20",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nor outputs from the use of AI at DHS, to third parties for uses of AI that are prohibited by applicable laws and government -wide and DHS policies, including this Directive; and f. Other uses of AI or associated data that are prohibited by applicable laws and government -wide and DHS policies. B. Requ i rements 1. Governance and Compliance. The DHS CAIO, on behalf of the Secretary and Deputy Secretary of Homeland Security and in coordination with Component Heads, Component SAIOs, and the USIA and IC SAIOs as appropriate, provides leadership and accountability for the use of AI at DHS. The DHS AI Governance Board, along with other enterprise- wide and Component -specific governance groups as applicable, provides -9- Directive # 139-08 Revision # 00 coordinated and collaborative governance on issues related to the use of AI at DHS. These leaders and groups support AI use and innovation through dynamic governance that anticipates issues and opportunities, provides proactive guidance and leadership, and promotes equity and inclusivity by ensuring a full array of stakeholders is represented in governance groups and that diverse perspectives are incorporated into decision- making processes. Dynamic governance requires responsive compliance that ensures continuous feedback on requirements and processes, incorporating appropriate adjustments based on that feedback and the operational or real -world context."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_21",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nopportunities, provides proactive guidance and leadership, and promotes equity and inclusivity by ensuring a full array of stakeholders is represented in governance groups and that diverse perspectives are incorporated into decision- making processes. Dynamic governance requires responsive compliance that ensures continuous feedback on requirements and processes, incorporating appropriate adjustments based on that feedback and the operational or real -world context. Responsive compliance is embedded in an enterprise AI risk management framework which is used to: assess and classify the risk of each AI use case at DHS early in its life cycle; ensure ongoing, proactive risk identification and mitigation throughout the life cycle; regularly monitor and periodically or continuously test and evaluate; and provide a foundation for advice, oversight, and support from leadership and governance groups. 2. AI Governance Board. The DHS AI Governance Board is responsible, in collaboration with and in support of the Deputy Secretary of Homeland Security and the DHS CAIO, for coordinating and governing issues related to the use of AI within DHS, including removing barriers to the use of AI and managing its associated risks. The Board serves as the primary coordination entity among DHS officials responsible for aspects of AI adoption and risk management. 3. DHS AI Council."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_22",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nthe Deputy Secretary of Homeland Security and the DHS CAIO, for coordinating and governing issues related to the use of AI within DHS, including removing barriers to the use of AI and managing its associated risks. The Board serves as the primary coordination entity among DHS officials responsible for aspects of AI adoption and risk management. 3. DHS AI Council. The DHS AI Council supports the AI Governance Board and the DHS CAIO in fulfilling their respective responsibilities regarding the use of AI at DHS, and performs any other responsibilities determined appropriate by the Secretary of Homeland Security. The DHS AI Council comprises the DHS CAIO as Chair, Component SAIOs designated in accordance with Delegation 04000, the DHS CIO, IC SAIOs, the DHS Chief Privacy Officer, the DHS Officer for Civil Liberties and Civil Rights, a senior official with expertise on AI testing and evaluation from the Science and Technology Directorate, and a senior official from the Office of Strategy, Policy , and Plans. The DHS AI Council presents action items to the AI Governance Board on the use of AI at DHS, including elevating such issues to the Board as necessary. The DHS AI Council supports the DHS CAIO in issuing and maintaining a comprehensive set of policy requirements governing the safe, secure, responsible, trustworthy, and human- centered use of AI at DHS. 4. AI Incident R eporting and Response."
  },
  {
    "id": "25_0116_CIO_DHS-Directive-139-08-508_chunk_23",
    "text": "Source: 9 25_0116_CIO_DHS-Directive-139-08-508.pdf\n\nto the AI Governance Board on the use of AI at DHS, including elevating such issues to the Board as necessary. The DHS AI Council supports the DHS CAIO in issuing and maintaining a comprehensive set of policy requirements governing the safe, secure, responsible, trustworthy, and human- centered use of AI at DHS. 4. AI Incident R eporting and Response. DHS creates and maintains reporting requirements and response procedures for incidents involving the use of AI at DHS, including incidents that may have resulted in: harm to an individual; diminished civil rights or civil liberties of an individual or group of individuals; unauthorized release of PII or other sensitive -10- Directive # 139-08 Revision # 00 information, or a cybersecurity breach. Procedures for managing such incidents are appropriately coordinated among relevant officials and align with and do not supersede existing incident reporting requirements, such as those related to privacy and cybersecurity incidents. 5. Implementing Policy . DHS implements this Directive through one or more DHS Instructions, along with related policies, guidelines, and processes regarding the use and acquisition of AI at DHS. VI. Questions Address any questions or concerns regarding this Directive to the DHS Chief AI Officer. January 15, 2025 R.D. Alles Date Deputy Under S ecretary for Management RANDOLPH D ALLES 15:56:03 - 05'00'"
  }
]